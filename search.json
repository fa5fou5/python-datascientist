[
  {
    "objectID": "content/annexes/corrections.html",
    "href": "content/annexes/corrections.html",
    "title": "Corrections",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nSeules les chapitres dont les corrections ne sont pas apparentes sont list√©s sur cette page.",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-1-manipuler-des-donn√©es",
    "href": "content/annexes/corrections.html#partie-1-manipuler-des-donn√©es",
    "title": "Corrections",
    "section": "0.1 Partie 1: manipuler des donn√©es",
    "text": "0.1 Partie 1: manipuler des donn√©es\n\nRetour sur Numpy\n\n\nhtml`${printBadges({fpath: \"content/manipulation/01_numpy.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices Pandas\n\n\nhtml`${printBadges({fpath: \"content/manipulation/02b_pandas_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices Geopandas :\n\n\nhtml`${printBadges({fpath: \"content/manipulation/03_geopandas_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices webscraping\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04a_webscraping_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices expressions r√©guli√®res\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04b_regex_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices API\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04c_API_TP.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-2-visualiser-les-donn√©es",
    "href": "content/annexes/corrections.html#partie-2-visualiser-les-donn√©es",
    "title": "Corrections",
    "section": "0.2 Partie 2: visualiser les donn√©es",
    "text": "0.2 Partie 2: visualiser les donn√©es\n\nExercices graphiques classiques\n\n\nhtml`${printBadges({fpath: \"content/visualisation/matplotlib.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la cartographie\n\n\nhtml`${printBadges({fpath: \"content/visualisation/maps.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-3-mod√©liser",
    "href": "content/annexes/corrections.html#partie-3-mod√©liser",
    "title": "Corrections",
    "section": "0.3 Partie 3: mod√©liser",
    "text": "0.3 Partie 3: mod√©liser\n\nExercices sur le preprocessing\n\n\nhtml`${printBadges({fpath: \"content/modelisation/0_preprocessing.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur l‚Äô√©valuation des mod√®les\n\n\nhtml`${printBadges({fpath: \"content/modelisation/1_modelevaluation.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la classification\n\n\nhtml`${printBadges({fpath: \"content/modelisation/2_SVM.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la r√©gression\n\n\nhtml`${printBadges({fpath: \"content/modelisation/3_regression.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la s√©lection de variables\n\n\nhtml`${printBadges({fpath: \"content/modelisation/4_featureselection.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur le clustering\n\n\nhtml`${printBadges({fpath: \"content/manipulation/5_clustering.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur les pipelines\n\n\nhtml`${printBadges({fpath: \"content/manipulation/6_pipeline.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-4-natural-language-processing-nlp",
    "href": "content/annexes/corrections.html#partie-4-natural-language-processing-nlp",
    "title": "Corrections",
    "section": "0.4 Partie 4: Natural Language Processing (NLP)",
    "text": "0.4 Partie 4: Natural Language Processing (NLP)\n\nD√©couverte des enjeux du NLP\n\n\nhtml`${printBadges({fpath: \"content/NLP/01_intro.qmd\", correction: true})}`\n\n\n\n\n\n\n\nMise en pratique de l‚Äôapproche bag of words\n\n\nhtml`${printBadges({fpath: \"content/NLP/02_exoclean.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la latent dirichlet allocation\n\n\nhtml`${printBadges({fpath: \"content/NLP/03_lda.qmd\", correction: true})}`\n\n\n\n\n\n\n\nD√©couverte de Word2Vec\n\n\nhtml`${printBadges({fpath: \"content/NLP/04_word2vec.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices suppl√©mentaires\n\n\nhtml`${printBadges({fpath: \"content/NLP/05_exo_supp.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#informations-additionnelles",
    "href": "content/annexes/corrections.html#informations-additionnelles",
    "title": "Corrections",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n6362a07\n\n\n2023-10-10 15:08:33\n\n\nlinogaliana\n\n\nAjoute corrections\n\n\n\n\n241cab3\n\n\n2023-10-04 17:53:29\n\n\nLino Galiana\n\n\nErgonomie du site web (#421)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nab7ac8a\n\n\n2023-08-17 17:47:59\n\n\nLino Galiana\n\n\nPath error\n\n\n\n\n68f960b\n\n\n2023-08-11 16:27:52\n\n\nlinogaliana\n\n\ncorrige probleme execution\n\n\n\n\n0800d90\n\n\n2023-08-11 13:32:19\n\n\nlinogaliana\n\n\nRetour des corrections\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#informations-additionnelles-1",
    "href": "content/annexes/corrections.html#informations-additionnelles-1",
    "title": "Corrections",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n6362a07\n\n\n2023-10-10 15:08:33\n\n\nlinogaliana\n\n\nAjoute corrections\n\n\n\n\n241cab3\n\n\n2023-10-04 17:53:29\n\n\nLino Galiana\n\n\nErgonomie du site web (#421)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nab7ac8a\n\n\n2023-08-17 17:47:59\n\n\nLino Galiana\n\n\nPath error\n\n\n\n\n68f960b\n\n\n2023-08-11 16:27:52\n\n\nlinogaliana\n\n\ncorrige probleme execution\n\n\n\n\n0800d90\n\n\n2023-08-11 13:32:19\n\n\nlinogaliana\n\n\nRetour des corrections\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/git/exogit.html",
    "href": "content/git/exogit.html",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLes exercices suivants sont inspir√©s d‚Äôun cours de Git que j‚Äôai\nparticip√© √† construire\n√† l‚ÄôInsee et dont les ressources sont disponibles\nici. L‚Äôid√©e\ndu cadavre exquis est inspir√©e de\ncette ressource et de celle-ci.\nCette partie part du principe que les concepts g√©n√©raux de Git sont\nma√Ætris√©s et qu‚Äôun environnement de travail fonctionnel avec Git est\ndisponible. Un exemple de tel environnement est le JupyterLab ou l‚Äôenvironnement VSCode du\nSSPCloud o√π une extension\nGit est pr√©-install√©e :\nOutre le chapitre pr√©c√©dent, il existe de\nnombreuses ressources sur internet sur le sujet,\nnotamment une s√©rie de ressources construites\npour l‚ÄôInsee sur ce site\net des ressources de la documentation collaborative sur R qu‚Äôest utilitR\n(des √©l√©ments sur la configuration\net pratique sur RStudio). Toutes\nles ressources ne sont donc pas du Python car Git est un outil transversal\nqui doit servir quel que soit le langage de pr√©dilection.\nGit fait parti des pratiques collaboratives\ndevenues standards dans le domaine de l‚Äôopen-source\nmais √©galement de plus en plus communes dans les administrations et entreprises\nde la data science.\nCe chapitre propose, pour simplifier l‚Äôapprentissage,\nd‚Äôutiliser l‚Äô extension Git de JupyterLab ou de VSCode.\nUn tutoriel pr√©sentant l‚Äôextension JupyterLab est disponible\nici.\nVSCode propose\nprobablement, √† l‚Äôheure actuelle, l‚Äôensemble le plus complet.\nCertains passages de ce TD n√©cessitent d‚Äôutiliser la ligne de commande.\nIl est tout √† fait possible de r√©aliser ce TD enti√®rement avec celle-ci.\nCependant, pour une personne d√©butante en Git, l‚Äôutilisation d‚Äôune\ninterface graphique peut constituer un √©l√©ment important pour\nla compr√©hension et l‚Äôadoption de Git. Une fois √† l‚Äôaise avec\nGit, on peut tout √† fait se passer des interfaces graphiques\npour les routines quotidiennes et ne les utiliser que\npour certaines op√©rations o√π elles s‚Äôav√®rent fort pratiques\n(notamment la comparaison de deux fichiers avant de devoir fusionner).",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#rappels-sur-la-notion-de-d√©p√¥t-distant",
    "href": "content/git/exogit.html#rappels-sur-la-notion-de-d√©p√¥t-distant",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.1 Rappels sur la notion de d√©p√¥t distant",
    "text": "1.1 Rappels sur la notion de d√©p√¥t distant\nComme expliqu√© dans le chapitre pr√©c√©dent,\nil convient de distinguer\nle d√©p√¥t distant (remote) et la copie ou les copies locales (les clones)\nd‚Äôun d√©p√¥t. Le d√©p√¥t distant est g√©n√©ralement stock√© sur une forge\nlogicielle (Github ou Gitlab) et sert √† centraliser la version\ncollective d‚Äôun projet. Les copies locales sont des copies de travail.\nGit est un syst√®me de contr√¥le de version asynchrone, c‚Äôest-√†-dire\nqu‚Äôon n‚Äôinteragit pas en continu avec le d√©p√¥t distant (comme c‚Äôest le\ncas dans le syst√®me SVN) mais qu‚Äôil est possible d‚Äôavoir une version\nlocale qui se diff√©rencie du d√©p√¥t commun et qu‚Äôon rend coh√©rente\nde temps en temps.\nBien qu‚Äôil soit possible d‚Äôavoir une utilisation hors-ligne de Git,\nc‚Äôest-√†-dire un pur contr√¥le de version local sans d√©p√¥t\ndistant, cela est une utilisation\nrare et qui comporte un int√©r√™t limit√©. L‚Äôint√©r√™t de Git est\nd‚Äôoffrir une mani√®re robuste et efficace d‚Äôinteragir avec un\nd√©p√¥t distant facilitant ainsi la collaboration en √©quipe ou en\nsolitaire.\nPour ces exercices, il est propos√©\nd‚Äôutiliser Github, la forge la plus visible.\nL‚Äôavantage de Github par rapport √† son principal concurrent, Gitlab,\nest que le premier est plus visible, car\nmieux index√© par Google et concentre, en partie pour des raisons historiques, plus\nde d√©veloppeurs Python et R (ce qui est important dans des domaines comme\nle code o√π les externalit√©s de r√©seau jouent).",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#premi√®re-√©tape-cr√©er-un-compte-github",
    "href": "content/git/exogit.html#premi√®re-√©tape-cr√©er-un-compte-github",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.2 Premi√®re √©tape: cr√©er un compte Github",
    "text": "1.2 Premi√®re √©tape: cr√©er un compte Github\nLes deux premi√®res √©tapes se font sur Github.\n\n\n Exercice 1 : Cr√©er un compte Github\n\nSi vous n‚Äôen avez pas d√©j√† un, cr√©er un compte sur https://github.com\nCr√©er un d√©p√¥t en suivant les consignes ci-dessous.\n\n\nCr√©ez ce d√©p√¥t priv√©, cela permettra\ndans l‚Äôexercice 2 d‚Äôactiver notre jeton. Vous pourrez le rendre public\napr√®s l‚Äôexercice 2, c‚Äôest comme vous le souhaitez.\nCr√©er ce d√©p√¥t avec un README.md en cliquant sur la case Add a README file\nAjouter un .gitignore en s√©lectionnant le mod√®le Python\n\nConnexion sur https://github.com &gt; + (en haut de la page) &gt; New repository &gt; Renseigner le ‚ÄúRepository name‚Äù &gt; Cocher ‚Äúprivate‚Äù &gt; ‚ÄúCreate repository‚Äù",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#deuxi√®me-√©tape-cr√©er-un-token-jeton-https",
    "href": "content/git/exogit.html#deuxi√®me-√©tape-cr√©er-un-token-jeton-https",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.3 Deuxi√®me √©tape: cr√©er un token (jeton) HTTPS",
    "text": "1.3 Deuxi√®me √©tape: cr√©er un token (jeton) HTTPS",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#principe",
    "href": "content/git/exogit.html#principe",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.4 Principe",
    "text": "1.4 Principe\nGit est un syst√®me d√©centralis√© de contr√¥le de version :\nles codes sont modifi√©s par chaque personne sur son poste de travail,\npuis sont mis en conformit√© avec la version collective disponible\nsur le d√©p√¥t distant au moment o√π le contributeur le d√©cide.\nIl est donc n√©cessaire que la forge connaisse l‚Äôidentit√© de chacun des\ncontributeurs, afin de d√©terminer qui est l‚Äôauteur d‚Äôune modification apport√©e\naux codes stock√©s dans le d√©p√¥t distant.\nPour que Github reconnaisse un utilisateur proposant des modifications,\nil est n√©cessaire de s‚Äôauthentifier (un d√©p√¥t distant, m√™me public, ne peut pas √™tre modifi√© par n‚Äôimporte qui). L‚Äôauthentification consiste ainsi √† fournir un √©l√©ment que seul vous et la forge √™tes cens√©s conna√Ætre : un mot de passe, une cl√© compliqu√©e, un jeton d‚Äôacc√®s‚Ä¶\nPlus pr√©cis√©ment, il existe deux modalit√©s pour faire conna√Ætre son identit√© √† Github :\n\nune authentification HTTPS (d√©crite ici) : l‚Äôauthentification se fait avec un login et un mot de passe ou avec un token (un mot de passe compliqu√© g√©n√©r√© automatiquement par Github et connu exclusivement du d√©tenteur du compte Github) ;\nune authentification SSH : l‚Äôauthentification se fait par une cl√© crypt√©e disponible sur le poste de travail et que GitHub ou GitLab conna√Æt. Une fois configur√©e, cette m√©thode ne n√©cessite plus de faire conna√Ætre son identit√© : l‚Äôempreinte digitale que constitue la cl√© suffit √† reconna√Ætre un utilisateur.\n\nLa documentation collaborative utilitR pr√©sente les raisons pour lesquelles il convient de favoriser\nla m√©thode HTTPS sur la m√©thode SSH.\n\n\n Note\nDepuis Ao√ªt 2021, Github n‚Äôautorise plus l‚Äôauthentification par mot de passe\nlorsqu‚Äôon interagit (pull/push) avec un d√©p√¥t distant\n(raisons ici).\nIl est n√©cessaire d‚Äôutiliser un token (jeton d‚Äôacc√®s) qui pr√©sente l‚Äôavantage\nd‚Äô√™tre r√©voquable (on peut √† tout moment supprimer un jeton si, par exemple,\non suspecte qu‚Äôil a √©t√© diffus√© par erreur) et √† droits limit√©s\n(le jeton permet certaines op√©rations standards mais\nn‚Äôautorise pas certaines op√©rations d√©terminantes comme la suppression\nd‚Äôun d√©p√¥t).\n√Ä partir de mars 2023 et jusqu‚Äô√† la fin de 2023, GitHub commencera progressivement √† exiger que tous les utilisateurs de GitHub activent une ou plusieurs formes d‚Äôauthentification √† deux facteurs (2FA). Pour plus d‚Äôinformations sur le d√©ploiement de l‚Äôinscription 2FA, consultez cet article de blog. Concr√®tement, cela signifie que vous devrez au choix :\n\nRenseigner votre num√©ro de portable pour valider certaines connexions gr√¢ce √† un code que vous recevrez par sms ;\nInstaller une application d‚Äôauthentification (Ex : Microsoft Authenticator) install√©e sur votre t√©l√©phone qui g√©n√®rera un QR code que vous pourrez scanner depuis github, ce qui ne n√©cessite pas que vous ayez √† fournir votre num√©ro de t√©l√©phone\nUtiliser une clef USB de s√©curit√©\n\nPour choisir entre ces diff√©rentes options, vous pouvez vous rendre sur Settings &gt; Password and authentication &gt; Enable two-factor authentication.\n\n\n\n\n Note\nIl est important de ne jamais stocker un token, et encore moins son mot de passe, dans un projet.\nIl est possible de stocker un mot de passe ou token de mani√®re s√©curis√©e et durable\navec le credential helper de Git. Celui-ci est pr√©sent√© par la suite.\nS‚Äôil n‚Äôest pas possible d‚Äôutiliser le credential helper de Git, un mot de passe\nou token peut √™tre stock√© de mani√®re s√©curis√© dans\nun syst√®me de gestion de mot de passe comme Keepass.\nNe jamais stocker un jeton Github, ou pire un mot de passe, dans un fichier\ntexte non crypt√©. Les logiciels de gestion de mot de passe\n(comme Keepass, recommand√© par l‚ÄôAnssi)\nsont simples\nd‚Äôusage et permettent de ne conserver sur l‚Äôordinateur qu‚Äôune version\nhash√©e du mot de passe qui ne peut √™tre d√©crypt√©e qu‚Äôavec un mot de passe\nconnu de vous seuls.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#cr√©er-un-jeton",
    "href": "content/git/exogit.html#cr√©er-un-jeton",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.5 Cr√©er un jeton",
    "text": "1.5 Cr√©er un jeton\nLa documentation officielle comporte un certain nombre de captures d‚Äô√©cran expliquant\ncomment proc√©der.\nNous allons utiliser le credential helper associ√© √† Git pour stocker\nce jeton. Ce credential helper permet de conserver de mani√®re p√©renne\nun jeton (on peut aussi faire en sorte que le mot de passe soit automatiquement\nsupprim√© de la m√©moire de l‚Äôordinateur au bout, par\nexemple, d‚Äôune heure).\nL‚Äôinconv√©nient de cette m√©thode est que Git √©crit en clair le jeton dans\nun fichier de configuration. C‚Äôest pour cette raison qu‚Äôon utilise des jetons\npuisque, si ces derniers sont r√©v√©l√©s, on peut toujours les r√©voquer et √©viter\nles probl√®mes (pour ne pas stocker en clair un jeton il faudrait utiliser\nune librairie suppl√©mentaire comme libsecrets qui est au-del√† du programme\nde ce cours).\nSi vous d√©sirez conserver de mani√®re plus durable ou plus s√©curis√©e votre jeton\n(en ne conservant pas le jeton en clair mais de mani√®re hash√©e),\nest d‚Äôutiliser un gestionnaire de mot de passe comme\nKeepass (recommand√© par l‚ÄôAnssi). N√©anmoins,\nil est recommand√© de tout de m√™me fixer une date d‚Äôexp√©ritation\naux jetons pour limiter les risques de s√©curit√© d‚Äôun token qui fuite\nsans s‚Äôen rendre compte.\n\n\n Exercice 2.0 : Cr√©er un service sur le SSPCloud\nEn amont de l‚Äôexercice 2, pour les utilisateurs\ndu SSPCloud,\nil est recommand√© d‚Äôouvrir un service Jupyter\nen suivant les consignes suivantes :\n\nDans la page Mes services, cliquer sur le bouton Nouveau service ;\nChoisir Jupyter-Python ;\nCliquer sur Configuration Jupyter-Python. ‚ö†Ô∏è ne pas lancer le service\ntout de suite !\nFaire d√©filer les onglets pour arriver sur l‚Äôonglet Git ;\nRemplacer la valeur sous Cache par un nombre important,\npar exemple 36000 pour que le jeton que vous utiliserez soit\nvalable 10 heures ;\nLancer le service.\n\n\n\n\n\n Exercice 2 : Cr√©er et stocker un token\n1Ô∏è‚É£ Suivre la\ndocumentation officielle en ne donnant que les droits repo au jeton (ajouter les droits\nworkflow si vous d√©sirez que votre jeton soit utilisable pour des projets\no√π l‚Äôint√©gration continue est n√©cessaire).\nPour r√©sumer les √©tapes devraient √™tre les suivantes :\nSettings &gt; Developers Settings &gt; Personal Access Token &gt; Generate a new token &gt; ‚ÄúMy bash script‚Äù &gt; Expiration ‚Äú30 days‚Äù &gt; cocher juste ‚Äúrepo‚Äù &gt; Generate token &gt; Le copier\n2Ô∏è‚É£ Ouvrir un terminal depuis Jupyter (par exemple File &gt; New &gt; Terminal) ou VSCode (Terminal &gt; New Terminal).\n3Ô∏è‚É£ [Optionnel] Taper dans le terminal la commande\nqui convient selon votre syst√®me d‚Äôexploitation pour activer le\ncredential helper:\n# Sous mac et linux et le datalab\ngit config --global credential.helper store\n\n# Sous windows\ngit config --global credential.helper manager-core\n4Ô∏è‚É£ R√©cup√©rer, sur la page d‚Äôaccueil de votre d√©p√¥t, l‚Äôurl du d√©p√¥t distant.\nIl prend la forme suivante\nhttps://github.com/&lt;username&gt;/&lt;reponame&gt;.git\nVous pouvez utiliser l‚Äôicone √† droite pour copier l‚Äôurl.\n5Ô∏è‚É£ Retournez dans le Terminal. Taper\ngit clone repo_url\no√π repo_url est l‚Äôurl du d√©p√¥t en question (vous pouvez utiliser\nMAJ+Inser pour coller l‚Äôurl pr√©c√©demment copi√©)\nTapez Entr√©e. Dans le cas d‚Äôun r√©pertoire priv√© et sans credential helper, renseignez ensuite votre identifiant, faites Entr√©e, puis votre personal access token, Entr√©e. Si vous n‚Äôavez pas d‚Äôerreur, cela signifie\nque l‚Äôauthentification a bien fonctionn√© et donc que tout va\nbien. Sinon, il vous suffit de r√©√©crire l‚Äôinstruction git clone et de retenter de taper votre personal access token. Normalement, si vous avez cr√©√© un d√©p√¥t vide dans l‚Äôexercice 1,\nvous avez un message de Git:\n\nwarning: You appear to have cloned an empty repository.\n\nCe n‚Äôest pas une erreur mais il est pr√©f√©rable de suivre la\nconsigne de l‚Äôexercice 1 et de cr√©er un projet non vide.\nLe dossier de votre projet a bien\n√©t√© cr√©√©.\nSi vous avez une erreur, suivez la consigne pr√©sent√©e ci-apr√®s\npour r√©initialiser\nvotre credential helper\n6Ô∏è‚É£ Si vous le d√©sirez, vous pouvez changer la visibilit√© de votre d√©p√¥t\nen le rendant public.\n7Ô∏è‚É£ Stocker le token sur le SSP Cloud (ou un gestionnaire de mot de passe) :\n\nMon Compte -&gt; Services externes -&gt; Jeton d‚Äôacc√®s personnel GitHub\n\n\n\n\n\n Note\nSi vous avez fait une faute de frappe dans le mot de passe ou dans le jeton, il est possible de vider la m√©moire\nde la mani√®re suivante, sous Mac ou Linux :\ngit config --global --unset credential.helper\nSous Windows, si vous avez utilis√© l‚Äôoption manager-core √©voqu√©e ci-dessus, vous pouvez utiliser une interface graphique pour effacer le mot de passe ou jeton erron√©. Pour cela, dans le menu d√©marrer, taper Gestionnaire d'identification (ou Credential Manager si Windows ne trouve pas). Dans l‚Äôinterface graphique qui s‚Äôouvre, il est possible de supprimer le mot de passe ou jeton en question. Apr√®s cela, vous devriez √† nouveau avoir l‚Äôopportunit√© de taper un mot de passe ou jeton lors d‚Äôune authentification HTTPS.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#envoyer-des-modifications-sur-le-d√©p√¥t-distant-push",
    "href": "content/git/exogit.html#envoyer-des-modifications-sur-le-d√©p√¥t-distant-push",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "4.1 Envoyer des modifications sur le d√©p√¥t distant: push",
    "text": "4.1 Envoyer des modifications sur le d√©p√¥t distant: push\n\n\n Exercice 6 : Interagir avec Github\nIl convient maintenant d‚Äôenvoyer les fichiers sur le d√©p√¥t distant.\n\n1Ô∏è‚É£\nL‚Äôobjectif est d‚Äôenvoyer vos modifications vers origin.\nOn va passer par la ligne de commande car les boutons push/pull\nde l‚Äôextension Jupyter ne fonctionnent pas de mani√®re syst√©matique.\nTaper\ngit push origin main\nCela signifie: ‚Äúgit envoie (push) mes modifications sur la\nbranche main (la branche sur laquelle on a travaill√©, on reviendra\ndessus) vers mon d√©p√¥t (alias\norigin)‚Äù\nRemarque : Si vous obtenez l‚Äôerreur suivante error: src refspec hello does not match any, c‚Äôest probablement que vous avez indiqu√© le mauvais nom de branche. La confusion se fait souvent entre le nom main ou master (ancienne norme de branche par d√©faut).\nNormalement, si vous avez utilis√© le credential helper, Git ne\nvous demande pas vos identifiants de connexion. Sinon,\nil faut taper\nvotre identifiant Github et votre mot de passe correspond au personal access token nouvellement cr√©√© !\n2Ô∏è‚É£ Retournez voir le d√©p√¥t sur Github, vous devriez maintenant voir le fichier\n.gitignore s‚Äôafficher en page d‚Äôaccueil.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#la-fonctionnalit√©-pull",
    "href": "content/git/exogit.html#la-fonctionnalit√©-pull",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "4.2 La fonctionnalit√© pull",
    "text": "4.2 La fonctionnalit√© pull\nLa deuxi√®me mani√®re d‚Äôinteragir avec le d√©p√¥t est de r√©cup√©rer des\nr√©sultats disponibles en ligne sur sa copie de travail. On appelle\ncela pull.\nPour le moment, vous √™tes tout seul sur le d√©p√¥t. Il n‚Äôy a donc pas de\npartenaire pour modifier un fichier dans le d√©p√¥t distant. On va simuler ce\ncas en utilisant l‚Äôinterface graphique de Github pour modifier\ndes fichiers. On rapatriera les r√©sultats en local dans un deuxi√®me temps.\n\n\n Exercice 7 : Rapatrier des modifs en local\n1Ô∏è‚É£ Se rendre sur votre d√©p√¥t depuis l‚Äôinterface https://github.com\n\nSe placer sur le fichier README.md et cliquer sur le bouton Edit this file, qui prend la forme d‚Äôun ic√¥ne de crayon.\n\n2Ô∏è‚É£ L‚Äôobjectif est de\ndonner au README.md un titre en ajoutant, au d√©but du document, la ligne suivante :\n# Mon oeuvre d'art surr√©aliste \nSautez une ligne et entrez le texte que vous d√©sirez, sans ponctuation. Par exemple,\nle ch√™ne un jour dit au roseau\n3Ô∏è‚É£ Cliquez sur l‚Äôonglet Preview pour voir le texte mis en forme au format Markdown\n4Ô∏è‚É£ R√©diger un titre et un message compl√©mentaire pour faire le commit. Conserver\nl‚Äôoption par d√©faut Commit directly to the main branch\n5Ô∏è‚É£ Editer √† nouveau le README en cliquant sur le crayon juste au dessus\nde l‚Äôaffichage du contenu du README.\nAjouter une deuxi√®me phrase et corrigez la\nponctuation de la premi√®re. Ecrire un message de commit et valider.\nLe Ch√™ne un jour dit au roseau :\nVous avez bien sujet d'accuser la Nature\n6Ô∏è‚É£ Au dessus de l‚Äôaborescence des fichiers, vous devriez voir s‚Äôafficher le\ntitre du dernier commit. Vous pouvez cliquer dessus pour voir la modification\nque vous avez faite.\n7Ô∏è‚É£ Les r√©sultats sont sur le d√©p√¥t distant mais ne sont pas sur votre\ndossier de travail dans Jupyter ou VSCode. Il faut re-synchroniser votre copie locale\navec le d√©p√¥t distant :\n\nSur VSCode, cliquez simplement sur ... &gt; Pull √† c√¥t√© du bouton qui permet\nde visualiser le graphe Git.\nAvec l‚Äôinterface Jupyter, si cela est possible, appuyez tout simplement sur la petite\nfl√®che vers le bas, qui est celle qui a d√©sormais la pastille orange.\nSi cette fl√®che n‚Äôest pas disponible ou si vous travaillez dans un autre\nenvironnement, vous pouvez utiliser la ligne de\ncommande et taper\n\ngit pull origin main\nCela signifie : ‚Äúgit r√©cup√®re (pull) les modifications sur la\nbranche main vers mon d√©p√¥t (alias\norigin)‚Äù\n8Ô∏è‚É£ Regarder √† nouveau l‚Äôhistorique des commits. Cliquez sur le\ndernier commit et affichez les changements sur le fichier. Vous pouvez\nremarquer la finesse du contr√¥le de version : Git d√©tecte au sein de\nla premi√®re ligne de votre texte que vous avez mis des majuscules\nou de la ponctuation.\n\n\nL‚Äôop√©ration pull permet :\n\nA votre syst√®me local de v√©rifier les modifications sur le d√©p√¥t distant\nque vous n‚Äôauriez pas faites (cette op√©ration s‚Äôappelle fetch)\nDe les fusionner s‚Äôil n‚Äôy a pas de conflit de version ou si les conflits de\nversion sont automatiquement fusionnables (deux modifications d‚Äôun fichier mais\nqui ne portent pas sur le m√™me emplacement).",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#le-workflow-adopt√©",
    "href": "content/git/exogit.html#le-workflow-adopt√©",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "6.1 Le workflow adopt√©",
    "text": "6.1 Le workflow adopt√©\nNous allons adopter le mode de travail le plus simple, le Github Flow.\nIl correspond √† cette forme caract√©ristique d‚Äôarbre:\n\nLa branche main constitue le tronc\nLes branches partent de main et divergent\nLorsque les modifications aboutissent, elles sont int√©gr√©es √† main ;\nla branche en question dispara√Æt :\n\n\nIl existe des workflows plus complexes, notamment le Git Flow que j‚Äôutilise\npour d√©velopper ce cours. Ce tutoriel, tr√®s bien fait,\nillustre avec un graphique la complexit√© accrue de ce flow :\n\nCette fois, une branche interm√©diaire, par exemple une branche development\nint√®gre des modifications √† tester avant de les int√©grer dans la version\nofficielle (main).\n\n\n Hint\nVous pourrez trouvez des dizaines d‚Äôarticles et d‚Äôouvrages sur ce sujet dont chacun pr√©tend avoir trouv√© la meilleure organisation du travail (Git flow, GitHub flow, GitLab flow‚Ä¶). Ne lisez pas trop ces livres et articles sinon vous serez perdus (un peu comme avec les magazines destin√©s aux jeunes parents‚Ä¶).\nLa m√©thode de travail la plus simple est le Github flow qu‚Äôon vous a propos√© d‚Äôadopter. L‚Äôarborescence est reconnaissable : des branches divergent et reviennent syst√©matiquement vers main.\nPour des projets plus complexes dans des √©quipes d√©veloppant des applications, on pourra utiliser d‚Äôautres m√©thodes de travail, notamment le Git flow. Il n‚Äôexiste pas de r√®gles universelles pour d√©terminer la m√©thode de travail ; l‚Äôimportant c‚Äôest, avant tout, de se mettre d‚Äôaccord sur des r√®gles communes de travail avec votre √©quipe.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#m√©thode-pour-les-merges",
    "href": "content/git/exogit.html#m√©thode-pour-les-merges",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "6.2 M√©thode pour les merges",
    "text": "6.2 M√©thode pour les merges\nLes merges vers main doivent imp√©rativement passer par Github (ou Gitlab). Cela permet de garder une trace explicite de ceux-ci (par exemple ici), sans avoir √† chercher dans l‚Äôarborescence, parfois complexe, d‚Äôun projet.\nLa bonne pratique veut qu‚Äôon fasse un squash commit pour √©viter une inflation du nombre de commits dans main: les branches ont vocation √† proposer une multitude de petits commits, les modifications dans main doivent √™tre simples √† tracer d‚Äôo√π le fait de modifier des petits bouts de code.\nComme on l‚Äôa fait dans un exercice pr√©c√©dent, il est tr√®s pratique d‚Äôajouter dans le corps du message close #xx o√π xx est le num√©ro d‚Äôune issue associ√©e √† la pull request. Lorsque la pull request sera fusionn√©e, l‚Äôissue sera automatiquement ferm√©e et un lien sera cr√©√© entre l‚Äôissue et la pull request. Cela vous permettra de comprendre, plusieurs mois ou ann√©es plus tard comment et pourquoi telle ou telle fonctionnalit√© a √©t√© impl√©ment√©e.\nEn revanche, l‚Äôint√©gration des derni√®res modifications de main vers une branche se fait en local. Si votre branche est en conflit, le conflit doit √™tre r√©solu dans la branche et pas dans main.\nmain doit toujours rester propre.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#mise-en-pratique",
    "href": "content/git/exogit.html#mise-en-pratique",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "6.3 Mise en pratique",
    "text": "6.3 Mise en pratique\n\n\n Exercice 9 : Interactions avec le d√©p√¥t distant\nCet exercice se fait par groupe de trois ou quatre. Il y aura deux r√¥les dans ce sc√©nario :\n\nUne personne aura la responsabilit√© d‚Äô√™tre mainteneur\nDeux √† trois personnes seront d√©veloppeurs.\n\n1Ô∏è‚É£ Le mainteneur cr√©e un d√©p√¥t sur Github. Il/Elle donne des droits au(x) d√©veloppeur(s) du projet (Settings &gt; Manage Access &gt; Invite a collaborator).\n2Ô∏è‚É£ Chaque membre du projet, cr√©e une copie locale du projet gr√¢ce √† la commande git clone ou\navec le bouton Clone a repository de JupyterLab.\nPour cela, r√©cup√©rer l‚Äôurl HTTPS du d√©p√¥t en copiant l‚Äôurl du d√©p√¥t que vous pouvez trouver, par exemple, dans la page d‚Äôaccueil du d√©p√¥t, en dessous de Quick setup ‚Äî if you‚Äôve done this kind of thing before\nEn ligne de commande, cela donnera :\ngit clone https://github.com/&lt;username&gt;/&lt;reponame&gt;.git\n3Ô∏è‚É£ Chaque membre du projet cr√©e un fichier avec son nom et son pr√©nom, selon cette structure nom-prenom.md en √©vitant les caract√®res sp√©ciaux. Il √©crit dedans trois phrases de son choix sans ponctuation ni majuscules (pour pouvoir effectuer une correction ult√©rieurement). Enfin, il commit sur le projet.\nPour rappel, en ligne de commande cela donnera les commandes suivantes √† modifier\ngit add nom-prenom.md\ngit commit -m \"C'est l'histoire de XXXXX\"\n4Ô∏è‚É£ Chacun essaie d‚Äôenvoyer (push) ses modifications locales sur le d√©p√¥t:\ngit push origin main\n5Ô∏è‚É£ A ce stade, une seule personne (la plus rapide) devrait ne pas avoir rencontr√© de rejet du push. C‚Äôest normal, avant d‚Äôaccepter une modification Git v√©rifie en premier lieu la coh√©rence de la branche avec le d√©p√¥t distant. Le premier ayant fait un push a modifi√© le d√©p√¥t commun ; les autres doivent int√©grer ces modifications dans leur version locale (pull) avant d‚Äôavoir le droit de proposer un changement.\nPour celui/celle/ceux dont le push a √©t√© refus√©, faire\ngit pull origin main\npour ramener les modifications distantes en local.\n6Ô∏è‚É£ Taper git log et regarder la mani√®re dont a √©t√© int√©gr√© la modification de votre camarade ayant pu faire son push\nVous remarquerez que les commits de vos camarades sont int√©gr√©s tels quels √†\nl‚Äôhistoire du d√©p√¥t.\n7Ô∏è‚É£ Faire √† nouveau\ngit pull origin main\nLe dernier doit refaire, √† nouveau, les √©tapes 5 √† 7 (dans une √©quipe de quatre\nil faudra encore le refaire une fois).\n\n\n\n\n Warning √† nouveau: ne JAMAIS FAIRE git push force\nQuand on fait face √† un rejet du push, on est tent√© de faire passer en force le push malgr√© la mise en garde pr√©c√©dente.\nIl faut imm√©diatement oublier cette solution, elle cr√©e de nombreux probl√®mes et, en fait, ne r√©sout rien. L‚Äôun des risques est de r√©√©crire enti√®rement l‚Äôhistorique rendant les copies locales, et donc les modifications de vos collaborateurs, caduques. Cela vous vaudra, √† raison, des remontrances de vos partenaires qui perdent le b√©n√©fice de leur historique Git qui, s‚Äôils ont des versions sans push depuis longtemps peuvent avoir diverger fortement du d√©p√¥t ma√Ætre.\n\n\n\n\n Exercice 10 : G√©rer les conflits quand on travaille sur le m√™me fichier\nDans la continuit√© de l‚Äôexercice pr√©c√©dent, chaque personne va travailler sur les fichiers des autres membres de l‚Äô√©quipe.\n1Ô∏è‚É£ Les deux ou trois d√©veloppeurs ajoutent la ponctuation et les majuscules du fichier du premier d√©veloppeur.\n2Ô∏è‚É£ Ils sautent une ligne et ajoutent une phrase (pas tous la m√™me).\n3Ô∏è‚É£ Valider les r√©sultats (git add . et commit) et faire un push\n4Ô∏è‚É£ La personne la plus rapide n‚Äôa, normalement, rencontr√© aucune difficult√© (elle peut s‚Äôarr√™ter temporairement pour regarder ce qui va se passer chez les voisins). Les autres voient leur push refus√© et doivent faire un pull.\nüí• Il y a conflit, ce qui doit √™tre signal√© par un message du type :\nAuto-merging XXXXXX\nCONFLICT (content): Merge conflict in XXXXXX.md\nAutomatic merge failed; fix conflicts and then commit the result.\n5Ô∏è‚É£ Etudier le r√©sultat de git status\n6Ô∏è‚É£ Si vous ouvrez les fichiers incrimin√©s, vous devriez voir des balises du type\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nthis is some content to mess with\ncontent to append\n=======\ntotally different content to merge later\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; new_branch_to_merge_later\n7Ô∏è‚É£ Corriger √† la main les fichiers en choisissant, pour chaque ligne, la version qui vous convient et en retirant les balises. Valider en faisant:\ngit add . && git commit -m \"R√©solution du conflit par XXXX\"\nRemplacer XXXX par votre nom. La balise && permet d‚Äôencha√Æner, en une seule ligne de code, les deux commandes.\n8Ô∏è‚É£ Faire un push. Pour la derni√®re personne, refaire les op√©rations 4 √† 8\n\n\nGit permet donc de travailler, en m√™me temps, sur le m√™me fichier et de limiter le nombre de gestes manuels n√©cessaires pour faire la fusion. Lorsqu‚Äôon travaille sur des bouts diff√©rents du m√™me fichier, on n‚Äôa m√™me pas besoin de faire de modification manuelle, la fusion peut √™tre automatique.\nGit est un outil tr√®s puissant. Mais, il ne remplace pas une bonne organisation du travail. Vous l‚Äôavez vu, ce mode de travail uniquement sur main peut √™tre p√©nible. Les branches prennent tout leur sens dans ce cas.\n\n\n Exercice 11 : Gestion des branches\n1Ô∏è‚É£ Le mainteneur va contribuer directement dans main et ne cr√©e pas de branche. Chaque d√©veloppeur cr√©e une branche, en local nomm√©e contrib-XXXXX o√π XXXXX est le pr√©nom:\ngit checkout -b contrib-XXXXX\n2Ô∏è‚É£ Chaque membre du groupe cr√©e un fichier README.md o√π il √©crit une phrase sujet-verbe-compl√©ment. Le mainteneur est le seul √† ajouter un titre dans le README (qu‚Äôil commit dans main).\n3Ô∏è‚É£ Chacun push le produit de son subconscient sur le d√©p√¥t.\n4Ô∏è‚É£ Les d√©veloppeurs ouvrent, chacun, une pull request sur Github de leur branche vers main. Ils lui donnent un titre explicite.\n5Ô∏è‚É£ Dans la discussion de chaque pull request, le mainteneur demande au d√©veloppeur d‚Äôint√©grer le titre qu‚Äôil a √©crit.\n6Ô∏è‚É£ Chaque d√©veloppeur, en local, int√®gre cette modification en faisant\n# Pour √™tre s√ªr d'√™tre sur sa propre branche\ngit checkout branche-XXXX\ngit merge main\nR√©gler le conflit et valider (add et commit). Pousser le r√©sultat. Le mainteneur choisit une des pull request et la valide avec l‚Äôoption squash commits. V√©rifier sur la page d‚Äôaccueil le r√©sultat.\n7Ô∏è‚É£ L‚Äôauteur (si 2 d√©veloppeurs) ou les deux auteurs (si 3 d√©veloppeurs) de la pull request non valid√©e doivent √† nouveau r√©p√©ter l‚Äôop√©ration 6.\n8Ô∏è‚É£ Une fois le conflit de version r√©gl√© et pouss√©, le mainteneur valide la pull request selon la m√™me proc√©dure que pr√©c√©demment.\n9Ô∏è‚É£ V√©rifier l‚Äôarborescence du d√©p√¥t dans Insights &gt; Network. Votre arbre doit avoir une forme caract√©ristique de ce qu‚Äôon appelle le Github flow:",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#informations-additionnelles",
    "href": "content/git/exogit.html#informations-additionnelles",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n56d092b\n\n\n2023-11-14 15:43:00\n\n\nAntoine Palazzolo\n\n\nupdate readme (#451)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\nb6ae3e3\n\n\n2023-11-14 05:49:42\n\n\nlinogaliana\n\n\nCorrige balise md\n\n\n\n\nae5205f\n\n\n2023-11-13 20:35:43\n\n\nlinogaliana\n\n\npr√©cision\n\n\n\n\n428d669\n\n\n2023-11-13 20:31:11\n\n\nlinogaliana\n\n\nExo gitignore\n\n\n\n\n66c6a29\n\n\n2023-11-13 19:53:49\n\n\nlinogaliana\n\n\njupyter sspcloud credential helper\n\n\n\n\n69d5bc7\n\n\n2023-11-13 19:44:01\n\n\nlinogaliana\n\n\nmise √† jour de quelques consignes\n\n\n\n\ne3f1ef1\n\n\n2023-11-13 11:53:50\n\n\nThomas Faria\n\n\nRelecture git (#448)\n\n\n\n\nea9400a\n\n\n2023-11-05 10:54:04\n\n\ntomseimandi\n\n\nInclude VSCode instructions in exogit (#447)\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nf8831e7\n\n\n2023-10-09 10:53:34\n\n\nLino Galiana\n\n\nRelecture antuki geopandas (#429)\n\n\n\n\n5ab34aa\n\n\n2023-10-04 14:54:20\n\n\nKim A\n\n\nRelecture Kim pandas & git (#416)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\nb649205\n\n\n2023-08-28 15:47:09\n\n\nlinogaliana\n\n\nNice image\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\n34cc32c\n\n\n2022-10-14 22:05:47\n\n\nLino Galiana\n\n\nRelecture Git (#300)\n\n\n\n\nfd439f0\n\n\n2022-09-19 09:37:50\n\n\navouacr\n\n\nfix ssp cloud links\n\n\n\n\n3056d41\n\n\n2022-09-02 12:19:55\n\n\navouacr\n\n\nfix all SSP Cloud launcher links\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n36ed7b1\n\n\n2020-10-07 12:36:03\n\n\nLino Galiana\n\n\nCadavre exquis (#66)\n\n\n\n\nd1ad64c\n\n\n2020-10-04 14:43:55\n\n\nLino Galiana\n\n\nFinalisation de la premi√®re partie de l‚Äôexo git (#62)\n\n\n\n\n283e8e9\n\n\n2020-10-02 18:54:30\n\n\nLino Galiana\n\n\nPremi√®re partie des exos git (#61)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†2.1: Interface graphique Git sous Jupyter (√† gauche) et VSCode (√† droite)\nFigure¬†2.1: Interface graphique Git sous Jupyter (√† gauche) et VSCode (√† droite)",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#footnotes",
    "href": "content/git/exogit.html#footnotes",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCe cas de figure arrive lorsqu‚Äôon contribue √† des projets\nsur lesquels on n‚Äôa pas de droit d‚Äô√©criture. Il est alors\nn√©cessaire d‚Äôeffectuer un fork, une copie de ce d√©p√¥t sur laquelle\non dispose de droits.\nDans ce cas de figure, on rencontre g√©n√©ralement un nouvel alias √† c√¥t√© d‚Äôorigin.\nnomm√© upstream (cf.\nle tutoriel Github pour mettre √† jour un fork\net qui pointe vers le d√©p√¥t source √† l‚Äôorigine du fork.\nLa cr√©ation du bouton Fetch upstream par Github facilite grandement\nla mise en coh√©rence d‚Äôupstream et origin et constitue la m√©thode\nrecommand√©e.‚Ü©Ô∏é\nLa commande checkout est un couteau-suisse de la gestion de branche en Git. Elle permet en effet de basculer d‚Äôune branche √† l‚Äôautre, mais aussi d‚Äôen cr√©er, etc.‚Ü©Ô∏é",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/index.html",
    "href": "content/git/index.html",
    "title": "Git: un outil n√©cessaire pour les data scientists",
    "section": "",
    "text": "Cette partie du site pr√©sente un √©l√©ment qui n‚Äôest pas propre √†\nPython mais qui est n√©anmoins indispensable : la pratique de Git.\nUne grande partie du contenu de la partie provient\nd‚Äôun cours d√©di√© fait avec Romain Avouac.\nLe chapitre de pr√©sentation de Git propose\nune introduction visant √† pr√©senter l‚Äôint√©r√™t d‚Äôutiliser\ncet outil. Une mise en pratique est propos√©e\navec un cadavre exquis.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/git/index.html#utilisation-de-git-avec-python",
    "href": "content/git/index.html#utilisation-de-git-avec-python",
    "title": "Git: un outil n√©cessaire pour les data scientists",
    "section": "0.1 Utilisation de Git avec Python",
    "text": "0.1 Utilisation de Git avec Python\nGit est √† la fois un outil et un langage. Il\nest donc n√©cessaire d‚Äôinstaller, dans un premier\ntemps Git Bash, puis de connecter\nson outil pr√©f√©r√© pour faire du Python (qu‚Äôil\ns‚Äôagisse de Jupyter, VSCode ou PyCharm).\nCette partie est structur√©e en 2 temps :\n\nPr√©sentation de Git\nExercice pour d√©couvrir Git",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/git/index.html#informations-additionnelles",
    "href": "content/git/index.html#informations-additionnelles",
    "title": "Git: un outil n√©cessaire pour les data scientists",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n57f108f\n\n\n2023-11-10 10:59:36\n\n\nlinogaliana\n\n\nIntro git\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n34cc32c\n\n\n2022-10-14 22:05:47\n\n\nLino Galiana\n\n\nRelecture Git (#300)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html",
    "href": "content/modern-ds/elastic_approfondissement.html",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre est issu du travail produit\ndans le cadre d‚Äôun hackathon de l‚ÄôInsee avec\nRapha√´le Adjerad\net pr√©sente quelques √©l√©ments qui peuvent √™tre utiles\npour l‚Äôenrichissement de donn√©es d‚Äôentreprises\n√† partir d‚Äôun r√©pertoire officiel.\n:warning: Il n√©cessite une version particuli√®re du package elasticsearch pour tenir compte de l‚Äôh√©ritage de la version 7 du moteur Elastic. Pour cela, faire",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#objectif",
    "href": "content/modern-ds/elastic_approfondissement.html#objectif",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "1.1 Objectif",
    "text": "1.1 Objectif\nCe chapitre vise √† approfondir les √©l√©ments pr√©sent√©s sur Elastic pr√©c√©demment. L‚Äôid√©e\nest de se placer dans un contexte op√©rationnel o√π on re√ßoit des informations\nsur des entreprises telles que l‚Äôadresse et la localisation et qu‚Äôon\nd√©sire associer √† des donn√©es administratives consid√©r√©es plus fliables.",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#r√©plication-de-ce-chapitre",
    "href": "content/modern-ds/elastic_approfondissement.html#r√©plication-de-ce-chapitre",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "1.2 R√©plication de ce chapitre",
    "text": "1.2 R√©plication de ce chapitre\nComme le pr√©c√©dent, ce chapitre est plus exigeant en termes d‚Äôinfrastructures que les pr√©c√©dents.\nIl n√©cessite un serveur Elastic. Les utilisateurs du\nSSP Cloud pourront r√©pliquer les exemples de ce cours\ncar cette technologie est disponible (que ce soit pour indexer une base ou\npour requ√™ter une base existante).\nLa premi√®re partie de ce tutoriel, qui consiste √† cr√©er une base Sirene g√©olocalis√©e\n√† partir des donn√©es open-data ne n√©cessite pas d‚Äôarchitecture particuli√®re et\npeut ainsi √™tre ex√©cut√©e en utilisant les packages suivants :\n\nimport numpy as np\nimport pandas as pd",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#sources",
    "href": "content/modern-ds/elastic_approfondissement.html#sources",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "1.3 Sources",
    "text": "1.3 Sources\nCe chapitre va utiliser plusieurs sources de diffusion de\nl‚ÄôInsee:\n\nLe stock des √©tablissements pr√©sents dans les donn√©es de diffusion Sirene ;\nLes donn√©es Sirene g√©olocalis√©es\n\nLes donn√©es √† siretiser sont celles du registre Fran√ßais des √©missions polluantes\n√©tabli par le Minist√®re de la Transition Energ√©tique. Le jeu de donn√©es\nest disponible sur data.gouv",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#importer-la-base-d√©j√†-cr√©√©e",
    "href": "content/modern-ds/elastic_approfondissement.html#importer-la-base-d√©j√†-cr√©√©e",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "3.1 Importer la base d√©j√† cr√©√©e",
    "text": "3.1 Importer la base d√©j√† cr√©√©e\nLes donn√©es √† utiliser pour constuire une base Sirene g√©olocalis√©e\nsont trop volumineuses pour les serveurs mis √† disposition\ngratuitement par Github pour la compilation de ce site web.\nNous proposons ainsi une version d√©j√† construite, stock√©e\ndans l‚Äôespace de mise √† disposition du SSP Cloud. Ce fichier est\nau format parquet et est ouvert √†\ntous, m√™me pour les personnes ne disposant pas d‚Äôun compte.\nLe code ayant construit cette base est pr√©sent√© ci-dessous.\nPour importer cette base, on utilise les fonctionalit√©s\nde pyarrow qui permettent d‚Äôimporter un fichier sur\nun syst√®me de stockage cloud comme s‚Äôil √©tait\npr√©sent sur le disque :\n\nfrom pyarrow import fs\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\nbucket = \"lgaliana\"\npath = \"diffusion/sirene_geolocalized.parquet\"\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\ndf_geolocalized = (\n    pq.ParquetDataset(f\"{bucket}/{path}\", filesystem=s3).read_pandas().to_pandas()\n)\ndf_geolocalized.head(3)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#reproduire-la-construction-de-la-base",
    "href": "content/modern-ds/elastic_approfondissement.html#reproduire-la-construction-de-la-base",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "3.2 Reproduire la construction de la base",
    "text": "3.2 Reproduire la construction de la base\nLa premi√®re base d‚Äôentr√©e √† utiliser est disponible sur\ndata.gouv\n\nimport requests\nimport zipfile\n\nurl_download = (\n    \"https://www.data.gouv.fr/fr/datasets/r/0651fb76-bcf3-4f6a-a38d-bc04fa708576\"\n)\nreq = requests.get(url_download)\n\nwith open(\"sirene.zip\", \"wb\") as f:\n    f.write(req.content)\n\nwith zipfile.ZipFile(\"sirene.zip\", \"r\") as zip_ref:\n    zip_ref.extractall(\"sirene\")\n\nOn va importer seulement les colonnes utiles et simplifier la structure\npour √™tre en mesure de ne garder que les informations qui nous\nint√©ressent (nom de l‚Äôentreprise, adresse, commune, code postal‚Ä¶)\n\nimport pandas as pd\nimport numpy as np\n\nlist_cols = [\n    \"siren\",\n    \"siret\",\n    \"activitePrincipaleRegistreMetiersEtablissement\",\n    \"complementAdresseEtablissement\",\n    \"numeroVoieEtablissement\",\n    \"typeVoieEtablissement\",\n    \"libelleVoieEtablissement\",\n    \"codePostalEtablissement\",\n    \"libelleCommuneEtablissement\",\n    \"codeCommuneEtablissement\",\n    \"etatAdministratifEtablissement\",\n    \"denominationUsuelleEtablissement\",\n    \"activitePrincipaleEtablissement\",\n]\n\ndf = pd.read_csv(\"sirene/StockEtablissement_utf8.csv\", usecols=list_cols)\n\ndf[\"numero\"] = (\n    df[\"numeroVoieEtablissement\"]\n    .replace(\"-\", np.NaN)\n    .str.split()\n    .str[0]\n    .str.extract(\"(\\d+)\", expand=False)\n    .fillna(\"0\")\n    .astype(int)\n)\n\ndf[\"numero\"] = df[\"numero\"].astype(str).replace(\"0\", \"\")\n\ndf[\"adresse\"] = (\n    df[\"numero\"]\n    + \" \"\n    + df[\"typeVoieEtablissement\"]\n    + \" \"\n    + df[\"libelleVoieEtablissement\"]\n)\n\ndf[\"adresse\"] = df[\"adresse\"].replace(np.nan, \"\")\n\ndf = df.loc[df[\"etatAdministratifEtablissement\"] == \"A\"]\n\ndf.rename(\n    {\n        \"denominationUsuelleEtablissement\": \"denom\",\n        \"libelleCommuneEtablissement\": \"commune\",\n        \"codeCommuneEtablissement\": \"code_commune\",\n        \"codePostalEtablissement\": \"code_postal\",\n    },\n    axis=\"columns\",\n    inplace=True,\n)\n\ndf[\"ape\"] = df[\"activitePrincipaleEtablissement\"].str.replace(\"\\.\", \"\", regex=True)\ndf[\"denom\"] = df[\"denom\"].replace(np.nan, \"\")\n\ndf_siret = df.loc[\n    :,\n    [\n        \"siren\",\n        \"siret\",\n        \"adresse\",\n        \"ape\",\n        \"denom\",\n        \"commune\",\n        \"code_commune\",\n        \"code_postal\",\n    ],\n]\ndf_siret[\"code_postal\"] = (\n    df_siret[\"code_postal\"]\n    .replace(np.nan, \"0\")\n    .astype(int)\n    .astype(str)\n    .replace(\"0\", \"\")\n)\n\nOn importe ensuite les donn√©es g√©olocalis√©es\n\nimport zipfile\nimport shutil\nimport os\n\n# os.remove(\"sirene.zip\")\n# shutil.rmtree('sirene/')\n\nurl_geoloc = \"https://files.data.gouv.fr/insee-sirene-geo/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.zip\"\nr = requests.get(url_geoloc)\n\nwith open(\"geoloc.zip\", \"wb\") as f:\n    f.write(r.content)\n\nwith zipfile.ZipFile(\"geoloc.zip\", \"r\") as zip_ref:\n    zip_ref.extractall(\"geoloc\")\n\ndf_geoloc = pd.read_csv(\n    \"geoloc/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.csv\",\n    usecols=[\"siret\", \"epsg\", \"x_longitude\", \"y_latitude\"],\n    sep=\";\",\n)\n\nIl ne reste plus qu‚Äô√† associer les deux jeux de donn√©es\n\ndf_geolocalized = df_siret.merge(df_geoloc, on=\"siret\")\ndf_geolocalized[\"code_commune\"] = df_geolocalized[\"code_commune\"].astype(str)\n\nSi vous avez acc√®s √† un espace de stockage cloud de type\nS3, il est possible d‚Äôutiliser pyarrow pour enregister\ncette base. Afin de l‚Äôenregistrer dans un espace de stockage\npublic, nous allons l‚Äôenregistrer dans un dossier diffusion1\n\nfrom pyarrow import fs\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\nbucket = \"lgaliana\"\npath = \"diffusion/sirene_geolocalized.parquet\"\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\ntable = pa.Table.from_pandas(df_geolocalized)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#d√©finition-du-mapping",
    "href": "content/modern-ds/elastic_approfondissement.html#d√©finition-du-mapping",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "5.1 D√©finition du mapping",
    "text": "5.1 D√©finition du mapping\nOn va proc√©der par √©tape en essayant d‚Äôutiliser la structure la plus simple\npossible.\n:one: On s‚Äôoccupe d‚Äôabord de d√©finir le mapping\npour les variables textuelles.\n\nstring_var = [\"adresse\", \"denom\", \"ape\", \"commune\"]\nmap_string = {\n    \"type\": \"text\",\n    \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n}\nmapping_string = {l: map_string for l in string_var}\n\n:two: Les variables cat√©gorielles sont utilis√©es\npar le biais du type keyword:\n\n# keywords\nkeyword_var = [\"siren\", \"siret\", \"code_commune\", \"code_postal\"]\nmap_keywords = {\n    \"type\": \"text\",\n    \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n}\nmapping_keywords = {l: map_keywords for l in keyword_var}\n\n:three: La nouveaut√© par rapport √† la partie\npr√©c√©dente est l‚Äôutilisation de la\ndimension g√©ographique. Elastic propose\nle type geo_point pour cela.\n\n# geoloc\nmapping_geoloc = {\"location\": {\"type\": \"geo_point\"}}\n\nOn collecte tout cela ensemble dans un\ndictionnaire:\n\n# mapping\nmapping_elastic = {\n    \"mappings\": {\"properties\": {**mapping_string, **mapping_geoloc, **mapping_keywords}}\n}\n\nIl est tout √† fait possible de d√©finir un mapping\nplus raffin√©. Ici, on va privil√©gier\nl‚Äôutilisation d‚Äôun mapping simple pour\nillustrer la recherche par distance\ng√©ographique en priorit√©.",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#cr√©ation-de-lindex",
    "href": "content/modern-ds/elastic_approfondissement.html#cr√©ation-de-lindex",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "5.2 Cr√©ation de l‚Äôindex",
    "text": "5.2 Cr√©ation de l‚Äôindex\nPour cr√©er le nouvel index, on s‚Äôassure d‚Äôabord de ne pas\nd√©j√† l‚Äôavoir cr√©√© et on passe le mapping d√©fini\npr√©c√©demment.\n\nif es.indices.exists(\"sirene\"):\n    es.indices.delete(\"sirene\")\n\nes.indices.create(index=\"sirene\", body=mapping_elastic)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#indexation-de-la-base-g√©olocalis√©e",
    "href": "content/modern-ds/elastic_approfondissement.html#indexation-de-la-base-g√©olocalis√©e",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "5.3 Indexation de la base g√©olocalis√©e",
    "text": "5.3 Indexation de la base g√©olocalis√©e\nPour le moment, l‚Äôindex est vide. Il convient de\nle peupler.\nIl est n√©anmoins n√©cessaire de cr√©er le champ location\nau format attendu par elastic: lat, lon √† partir\nde nos colonnes.\n\ndf_geolocalized[\"location\"] = (\n    df_geolocalized[\"y_latitude\"].astype(str)\n    + \", \"\n    + df_geolocalized[\"x_longitude\"].astype(str)\n)\n\nLa fonction suivante permet de structurer chaque\nligne du DataFrame telle qu‚ÄôElastic l‚Äôattend:\n\ndef gen_dict_from_pandas(index_name, df):\n    \"\"\"\n    Lit un dataframe pandas Open Food Facts, renvoi un it√©rable = dictionnaire des donn√©es √† indexer, sous l'index fourni\n    \"\"\"\n    for i, row in df.iterrows():\n        header = {\"_op_type\": \"index\", \"_index\": index_name, \"_id\": i}\n        yield {**header, **row}\n\nEnfin, on peut industrialiser l‚Äôindexation\nde notre DataFrame en faisant tourner de\nmani√®re successive cette fonction :\n\nfrom elasticsearch.helpers import bulk, parallel_bulk\nfrom collections import deque\n\ndeque(\n    parallel_bulk(\n        client=es,\n        actions=gen_dict_from_pandas(\"sirene\", df_geolocalized),\n        chunk_size=1000,\n        thread_count=4,\n    )\n)\n\n\nes.count(index=\"sirene\")\n\nObjectApiResponse({'count': 13059694, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#premier-exemple-de-requ√™te-g√©ographique",
    "href": "content/modern-ds/elastic_approfondissement.html#premier-exemple-de-requ√™te-g√©ographique",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "6.1 Premier exemple de requ√™te g√©ographique",
    "text": "6.1 Premier exemple de requ√™te g√©ographique\n\nex1 = es.search(\n    index=\"sirene\",\n    body=\"\"\"{\n  \"query\": {\n    \"bool\": {\n      \"must\":\n      { \"match\": { \"denom\":   \"institut national de la statistique\"}}\n      }\n  }\n}\n\"\"\",\n)[\"hits\"][\"hits\"]\n\necho_insee = pd.json_normalize(ex1)\necho_insee\n\nOn remarque d√©j√† que les intitul√©s ne sont\npas bons. Quand est-il de leurs localisations ?\n\nplot_folium_sirene(echo_insee, yvar=\"_source.y_latitude\", xvar=\"_source.x_longitude\")\n\nCe premier essai nous sugg√®re qu‚Äôil est\nn√©cessaire d‚Äôam√©liorer notre recherche.\nPlusieurs voies sont possibles:\n\nAm√©liorer le preprocessing de nos champs\ntextuels en excluant, par exemple, les\nstopwords ;\nEffectuer une restriction g√©ographique\npour mieux cibler l‚Äôensemble de recherche\nTrouver une variable cat√©gorielle jouant\nle r√¥le de variable de blocage2 pour\nmieux cibler les paires pertinentes\n\nConcernant la restriction\ng√©ographique, Elastic fournit une approche\ntr√®s efficace de ciblage g√©ographique.\nEn connaissant une position approximative\nde l‚Äôentreprise √† rechercher,\nil est ainsi possible de\nrechercher dans un rayon\nd‚Äôune taille plus ou moins grande.\nEn supposant qu‚Äôon connaisse pr√©cis√©ment\nla localisation de l‚ÄôInsee, on peut\nchercher dans un rayon relativement\nrestreint. Si notre position √©tait plus\napproximative, on pourrait rechercher\ndans un rayon plus large.\n\nex2 = es.search(\n    index=\"sirene\",\n    body=\"\"\"{\n  \"query\": {\n    \"bool\": {\n      \"must\":\n      { \"match\": { \"denom\":   \"institut national de la statistique\"}}\n      ,\n      \"filter\":\n        {\"geo_distance\": {\n          \"distance\": \"1km\",\n          \"location\": {\n            \"lat\": \"48.8168\",\n            \"lon\": \"2.3099\"\n          }\n        }\n      }\n    }\n  }\n}\n\"\"\",\n)[\"hits\"][\"hits\"]\n\necho_insee = pd.json_normalize(ex2)\necho_insee\n\n\n\n Hint\nConna√Ætre la localisation pr√©cise d‚Äôune\nentreprise\nn√©cessite d√©j√† une bonne remont√©e\nd‚Äôinformation sur celle-ci.\nIl est plus plausible de supposer\nqu‚Äôon dispose, dans une phase amont\nde la chaine de production,\nde l‚Äôadresse de celle-ci.\nDans ce cas, il est utile\nd‚Äôutiliser un service de g√©ocodage,\ncomme l‚ÄôAPI Adresse\nd√©velopp√©e par Etalab.\n\n\nLes r√©sultats sont par construction mieux\ncibl√©s. N√©anmoins ils sont toujours d√©cevants\npuisqu‚Äôon ne parvient pas √† identifier l‚ÄôInsee\ndans les dix meilleurs √©chos.\n\nspecificsearch = es.search(\n    index=\"sirus_2020\",\n    body=\"\"\"{\n  \"query\": {\n    \"bool\": {\n      \"should\":\n          { \"match\": { \"rs_denom\":   \"CPCU - CENTRALE DE BERCY\"}},\n      \"filter\": [\n          {\"geo_distance\": {\n                  \"distance\": \"0.5km\",\n                  \"location\": {\n                        \"lat\": \"48.84329\", \n                        \"lon\": \"2.37396\"\n                              }\n                            }\n            }, \n            { \"prefix\":  { \"apet\": \"3530\" }}\n                ]\n            }\n          }\n}\"\"\",\n)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#informations-additionnelles",
    "href": "content/modern-ds/elastic_approfondissement.html#informations-additionnelles",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#footnotes",
    "href": "content/modern-ds/elastic_approfondissement.html#footnotes",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nConcernant la premi√®re piste, il aurait\nfallu mieux d√©finir notre mapping pour\nautoriser des analyzers. A d√©faut,\nnous pourrons\nutiliser nltk ou spacy pour transformer\nles champs textuels avant d‚Äôenvoyer la requ√™te.\nCette solution pr√©sente l‚Äôinconv√©nient\nde ne pas formatter de la m√™me mani√®re l‚Äôensemble\nindex√© mais pourrait malgr√© tout am√©liorer la pertinence\ndes recherches.‚Ü©Ô∏é\nConcernant la premi√®re piste, il aurait\nfallu mieux d√©finir notre mapping pour\nautoriser des analyzers. A d√©faut,\nnous pourrons\nutiliser nltk ou spacy pour transformer\nles champs textuels avant d‚Äôenvoyer la requ√™te.\nCette solution pr√©sente l‚Äôinconv√©nient\nde ne pas formatter de la m√™me mani√®re l‚Äôensemble\nindex√© mais pourrait malgr√© tout am√©liorer la pertinence\ndes recherches.‚Ü©Ô∏é",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/dallE.html",
    "href": "content/modern-ds/dallE.html",
    "title": "G√©n√©ration d‚Äôimages avec Python, DALL-E et StableDiffusion",
    "section": "",
    "text": "Pour tester les exemples pr√©sent√©s dans ce chapitre:\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nNote\nL‚Äôutilisation de ce tutoriel est assez exigeante en termes d‚Äôinfrastructure\ncar il est n√©cessaire de disposer de GPU.\nLes GPU sont des ressources rares et assez ch√®res, elle ne sont donc pas mises √† disposition de fa√ßon\naussi ais√©es que les CPU dans les cloud providers. Il s‚Äôagit de plus\nde ressources plus polluantes que les CPU.\nDes GPU sont disponibles sur Google Colab, la proc√©dure pour les activer\nest expliqu√©e ci-dessous. Des GPU sont √©galement disponibles sur le SSPCloud\nmais sont √† utiliser avec parcimonie. Elles ne sont pas mises √† disposition\npar d√©faut car il s‚Äôagit d‚Äôune ressource rare. Ce chapitre, lanc√© depuis le\nbouton en d√©but de chapitre, active cette option pour permettre la r√©plication\ndes exemples.\nHint\nPar d√©faut, Colab n‚Äôutilise pas de GPU mais de la CPU. Il est donc n√©cessaire\nd‚Äô√©diter les param√®tres d‚Äôex√©cution du Notebook\n\nDans le menu Ex√©cution, cliquer sur Modifier le type d'ex√©cution ;\nS√©lectionner GPU sous Acc√©l√©rateur mat√©riel.",
    "crumbs": [
      "G√©n√©ration d'images avec Python, DALL-E et StableDiffusion"
    ]
  },
  {
    "objectID": "content/modern-ds/dallE.html#installation-de-pytorch",
    "href": "content/modern-ds/dallE.html#installation-de-pytorch",
    "title": "G√©n√©ration d‚Äôimages avec Python, DALL-E et StableDiffusion",
    "section": "3.1 Installation de PyTorch",
    "text": "3.1 Installation de PyTorch\nPour installer PyTorch, la librairie de Deep Learning\nd√©velopp√©e par Meta, il suffit de suivre les recommandations\nsur le site web officiel.\nDans un Notebook, cela prendra la forme suivante :\n\n!conda install mamba\n!mamba install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch\n\n\n\n Note\nJe propose ici d‚Äôutiliser mamba pour acc√©l√©rer l‚Äôinstallation.\nDes √©l√©ments sur mamba sont disponibles dans l‚Äôintroduction de ce cours.",
    "crumbs": [
      "G√©n√©ration d'images avec Python, DALL-E et StableDiffusion"
    ]
  },
  {
    "objectID": "content/modern-ds/dallE.html#acc√®s-√†-huggingface",
    "href": "content/modern-ds/dallE.html#acc√®s-√†-huggingface",
    "title": "G√©n√©ration d‚Äôimages avec Python, DALL-E et StableDiffusion",
    "section": "3.2 Acc√®s √† HuggingFace",
    "text": "3.2 Acc√®s √† HuggingFace\nLa question - non n√©gligeable - de l‚Äôacc√®s √†\nde la GPU mise √† part,\nla r√©utilisation des mod√®les de Stable Diffusion est\ntr√®s facile car la documentation mise √† disposition sur\nHuggingFace est tr√®s bien faite.\nLa premi√®re √©tape est de se cr√©er un compte sur HuggingFace\net se cr√©er un token3. Ce token sera donn√© √† l‚ÄôAPI\nde HuggingFace pour s‚Äôauthentifier.\nL‚ÄôAPI d‚ÄôHuggingFace n√©cessite l‚Äôinstallation du\npackage diffusers.\nDans un Notebook, le code suivant permet d‚Äôinstaller la librairie\nrequise:\n\n!pip install --upgrade diffusers transformers scipy accelerate\n\n\n\n Note\nOn va supposer que le token est stock√© dans une variable\nd‚Äôenvironnement HF_PAT. Cela √©vite d‚Äô√©crire le token\ndans un Notebook qu‚Äôon va\npotentiellement partager, alors que le token\nest un √©l√©ment √† garder secret. Pour l‚Äôimporter\ndans la session Python:\nSi vous n‚Äôavez pas la possibilit√© de rentrer le token dans les variables\nd‚Äôenvironnement, cr√©ez une cellule qui cr√©e la variable\nHF_TOKEN et supprimez l√† de suite pour ne pas l‚Äôoublier avant\nde partager votre token.\n\n\n\nimport os\n\nHF_TOKEN = os.getenv(\"HF_PAT\")",
    "crumbs": [
      "G√©n√©ration d'images avec Python, DALL-E et StableDiffusion"
    ]
  },
  {
    "objectID": "content/modern-ds/dallE.html#informations-additionnelles",
    "href": "content/modern-ds/dallE.html#informations-additionnelles",
    "title": "G√©n√©ration d‚Äôimages avec Python, DALL-E et StableDiffusion",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\n9918817\n\n\n2022-12-30 15:10:59\n\n\nLino Galiana\n\n\nRetour sur le chapitre DallE / StableDiffusion (#344)\n\n\n\n\n86b77e7\n\n\n2022-12-30 08:40:27\n\n\nlgaliana\n\n\nopenAI\n\n\n\n\nd8eafc9\n\n\n2022-12-30 08:38:06\n\n\nlgaliana\n\n\ndallE\n\n\n\n\n8f24e44\n\n\n2022-12-30 08:34:25\n\n\nlgaliana\n\n\ndallE\n\n\n\n\n742add1\n\n\n2022-09-03 18:33:41\n\n\nLino Galiana\n\n\nCorrige quelques coquilles dans le tutoriel DallE (#266)\n\n\n\n\n82254fe\n\n\n2022-08-26 16:11:40\n\n\nLino Galiana\n\n\nChapitre sur Dall-E (#261)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\n‚ÄúA photograph of an astronaut riding a horse‚Äù",
    "crumbs": [
      "G√©n√©ration d'images avec Python, DALL-E et StableDiffusion"
    ]
  },
  {
    "objectID": "content/modern-ds/dallE.html#footnotes",
    "href": "content/modern-ds/dallE.html#footnotes",
    "title": "G√©n√©ration d‚Äôimages avec Python, DALL-E et StableDiffusion",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIl est notamment possible de r√©utiliser l‚Äôimage g√©n√©r√©e √† des fins commerciales. En revanche, il est interdit de chercher √† nuire √† une personne. Pour cette raison, il est fr√©quent que les visages de personnes c√©l√®bres soient flout√©s pour √©viter la cr√©ation de contenu nuisant √† leur r√©putation.‚Ü©Ô∏é\nComme les autres plateformes du monde de la data science,\nHuggingFace a adopt√© l‚Äôutilisation standardis√©e des\njetons (token) comme m√©thode d‚Äôauthentification. Le jeton est\ncomme un mot de passe sauf qu‚Äôil n‚Äôest pas invent√© par l‚Äôutilisateur\n(ce qui permet qu‚Äôil ne soit pas partag√© avec d‚Äôautres sites web potentiellement\nmoins s√©curis√©s), est r√©vocable (date d‚Äôexpiration ou choix de l‚Äôutilisateur)\net dispose de droits moins importants qu‚Äôun\nmot de passe qui vous permet, potentiellement,\nde changer tous les param√®tres de votre compte. Je recommande vivement l‚Äôutilisation\nd‚Äôun gestionnaire de mot de passe pour\nstocker vos token (si vous utilisez Git, Docker, etc.\nvous en avez potentiellement beaucoup) plut√¥t que\nstocker ces jetons dans des fichiers non s√©curis√©s.‚Ü©Ô∏é\nComme les autres plateformes du monde de la data science,\nHuggingFace a adopt√© l‚Äôutilisation standardis√©e des\njetons (token) comme m√©thode d‚Äôauthentification. Le jeton est\ncomme un mot de passe sauf qu‚Äôil n‚Äôest pas invent√© par l‚Äôutilisateur\n(ce qui permet qu‚Äôil ne soit pas partag√© avec d‚Äôautres sites web potentiellement\nmoins s√©curis√©s), est r√©vocable (date d‚Äôexpiration ou choix de l‚Äôutilisateur)\net dispose de droits moins importants qu‚Äôun\nmot de passe qui vous permet, potentiellement,\nde changer tous les param√®tres de votre compte. Je recommande vivement l‚Äôutilisation\nd‚Äôun gestionnaire de mot de passe pour\nstocker vos token (si vous utilisez Git, Docker, etc.\nvous en avez potentiellement beaucoup) plut√¥t que\nstocker ces jetons dans des fichiers non s√©curis√©s.‚Ü©Ô∏é",
    "crumbs": [
      "G√©n√©ration d'images avec Python, DALL-E et StableDiffusion"
    ]
  },
  {
    "objectID": "content/modern-ds/index.html",
    "href": "content/modern-ds/index.html",
    "title": "Partie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart",
    "section": "",
    "text": "Les parties pr√©c√©dentes √©taient tr√®s tourn√©es sur l‚Äôacquisition\nde comp√©tences minimales dans chaque domaine de l‚Äôanalyse de donn√©es.\nCette partie propose des √©l√©ments plus avanc√©s mais plus repr√©sentatifs\ndu travail quotidien du data scientist. Cette partie\npr√©sente la mani√®re dont Python peut √™tre utilis√© dans une architecture\nmoderne de type cloud. Elle illustre la mani√®re dont Python peut\nservir de couteau-suisse faisant l‚Äôinterface entre diff√©rents\nlangages plus efficaces ou plusieurs types de donn√©es.\nCette partie est en cours de construction et pr√©sentera les\n√©l√©ments suivants :",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modern-ds/index.html#contenu-de-la-partie",
    "href": "content/modern-ds/index.html#contenu-de-la-partie",
    "title": "Partie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart",
    "section": "0.1 Contenu de la partie",
    "text": "0.1 Contenu de la partie\n{{&lt; list_children  &gt;}}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modern-ds/index.html#informations-additionnelles",
    "href": "content/modern-ds/index.html#informations-additionnelles",
    "title": "Partie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html",
    "href": "content/NLP/04_word2vec.html",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "",
    "text": "Cette page approfondit certains aspects pr√©sent√©s dans la\npartie introductive. Apr√®s avoir travaill√© sur le\nComte de Monte Cristo, on va continuer notre exploration de la litt√©rature\navec cette fois des auteurs anglophones :\nLes donn√©es sont disponibles sur un CSV mis √† disposition sur Github. L‚ÄôURL pour les r√©cup√©rer directement est\nhttps://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv.\nLe but va √™tre dans un premier temps de regarder dans le d√©tail les termes les plus fr√©quents utilis√©s par les auteurs et de les repr√©senter graphiquement, puis on va ensuite essayer de pr√©dire quel texte correspond √† quel auteur √† partir de diff√©rents mod√®les de vectorisation, notamment les word embeddings.\nCe chapitre s‚Äôinspire de plusieurs ressources disponibles en ligne:",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#preprocessing",
    "href": "content/NLP/04_word2vec.html#preprocessing",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "2.1 Preprocessing",
    "text": "2.1 Preprocessing\nEn NLP, la premi√®re √©tape est souvent celle du preprocessing, qui inclut notamment les √©tapes de tokenization et de nettoyage du texte. Comme celles-ci ont √©t√© vues en d√©tail dans le pr√©c√©dent chapitre, on se contentera ici d‚Äôun preprocessing minimaliste : suppression de la ponctuation et des stop words (pour la visualisation et les m√©thodes de vectorisation bas√©es sur des comptages).\nJusqu‚Äô√† pr√©sent, nous avons utilis√© principalement nltk pour le\npreprocessing de donn√©es textuelles. Cette fois, nous proposons\nd‚Äôutiliser la librairie spaCy qui permet de mieux automatiser sous forme de\npipelines de preprocessing.\nPour initialiser le processus de nettoyage,\non va utiliser le corpus en_core_web_sm (voir plus\nhaut pour l‚Äôinstallation de ce corpus):\n\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nOn va utiliser un pipe spacy qui permet d‚Äôautomatiser, et de parall√©liser,\nun certain nombre d‚Äôop√©rations. Les pipes sont l‚Äô√©quivalent, en NLP, de\nnos pipelines scikit ou des pipes pandas. Il s‚Äôagit donc d‚Äôun outil\ntr√®s appropri√© pour industrialiser un certain nombre d‚Äôop√©rations de\npreprocessing :\n\ndef clean_docs(texts, remove_stopwords=False, n_process=4):\n\n    docs = nlp.pipe(\n        texts, n_process=n_process, disable=[\"parser\", \"ner\", \"lemmatizer\", \"textcat\"]\n    )\n    stopwords = nlp.Defaults.stop_words\n\n    docs_cleaned = []\n    for doc in docs:\n        tokens = [tok.text.lower().strip() for tok in doc if not tok.is_punct]\n        if remove_stopwords:\n            tokens = [tok for tok in tokens if tok not in stopwords]\n        doc_clean = \" \".join(tokens)\n        docs_cleaned.append(doc_clean)\n\n    return docs_cleaned\n\nOn applique la fonction clean_docs √† notre colonne pandas.\nLes pandas.Series √©tant it√©rables, elles se comportent comme des listes et\nfonctionnent ainsi tr√®s bien avec notre pipe spacy.\n\nspooky_df[\"text_clean\"] = clean_docs(spooky_df[\"text\"])\n\n\nspooky_df.head()",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#encodage-de-la-variable-√†-pr√©dire",
    "href": "content/NLP/04_word2vec.html#encodage-de-la-variable-√†-pr√©dire",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "2.2 Encodage de la variable √† pr√©dire",
    "text": "2.2 Encodage de la variable √† pr√©dire\nOn r√©alise un simple encodage de la variable √† pr√©dire :\nil y a trois cat√©gories (auteurs), repr√©sent√©es par des entiers 0, 1 et 2.\nPour cela, on utilise le LabelEncoder de scikit d√©j√† pr√©sent√©\ndans la partie mod√©lisation. On va utiliser la m√©thode\nfit_transform qui permet, en un tour de main, d‚Äôappliquer √† la fois\nl‚Äôentra√Ænement (fit), √† savoir la cr√©ation d‚Äôune correspondance entre valeurs\nnum√©riques et labels, et l‚Äôappliquer (transform) √† la m√™me colonne.\n\nle = LabelEncoder()\nspooky_df[\"author_encoded\"] = le.fit_transform(spooky_df[\"author\"])\n\nOn peut v√©rifier les classes de notre LabelEncoder :\n\nle.classes_",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#construction-des-bases-dentra√Ænement-et-de-test",
    "href": "content/NLP/04_word2vec.html#construction-des-bases-dentra√Ænement-et-de-test",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "2.3 Construction des bases d‚Äôentra√Ænement et de test",
    "text": "2.3 Construction des bases d‚Äôentra√Ænement et de test\nOn met de c√¥t√© un √©chantillon de test (20 %) avant toute analyse (m√™me descriptive).\nCela permettra d‚Äô√©valuer nos diff√©rents mod√®les toute √† la fin de mani√®re tr√®s rigoureuse,\npuisque ces donn√©es n‚Äôauront jamais utilis√©es pendant l‚Äôentra√Ænement.\nNotre √©chantillon initial n‚Äôest pas √©quilibr√© (balanced) : on retrouve plus d‚Äôoeuvres de\ncertains auteurs que d‚Äôautres. Afin d‚Äôobtenir un mod√®le qui soit √©valu√© au mieux, nous allons donc stratifier notre √©chantillon de mani√®re √† obtenir une r√©partition similaire d‚Äôauteurs dans nos\nensembles d‚Äôentra√Ænement et de test.\nAper√ßu du premier √©l√©ment de X_train :\n\nX_train[0]\n\nOn peut aussi v√©rifier qu‚Äôon est capable de retrouver\nla correspondance entre nos auteurs initiaux avec\nla m√©thode inverse_transform :\n\nprint(y_train[0], le.inverse_transform([y_train[0]])[0])",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#r√©partition-des-labels",
    "href": "content/NLP/04_word2vec.html#r√©partition-des-labels",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "3.1 R√©partition des labels",
    "text": "3.1 R√©partition des labels\nRefaisons un graphique que nous avons d√©j√† produit pr√©c√©demment pour voir\nla r√©partition de notre corpus entre auteurs :\n\nfig = pd.Series(le.inverse_transform(y_train)).value_counts().plot(kind=\"bar\")\nfig\n\nOn observe une petite asym√©trie : les passages des livres d‚ÄôEdgar Allen Poe sont plus nombreux que ceux des autres auteurs dans notre corpus d‚Äôentra√Ænement, ce qui peut √™tre probl√©matique dans le cadre d‚Äôune t√¢che de classification.\nL‚Äô√©cart n‚Äôest pas dramatique, mais on essaiera d‚Äôen tenir compte dans l‚Äôanalyse en choisissant une m√©trique d‚Äô√©valuation pertinente.",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#mots-les-plus-fr√©quemment-utilis√©s-par-chaque-auteur",
    "href": "content/NLP/04_word2vec.html#mots-les-plus-fr√©quemment-utilis√©s-par-chaque-auteur",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "3.2 Mots les plus fr√©quemment utilis√©s par chaque auteur",
    "text": "3.2 Mots les plus fr√©quemment utilis√©s par chaque auteur\nOn va supprimer les stop words pour r√©duire le bruit dans notre jeu\nde donn√©es.\n\n# Suppression des stop words\nX_train_no_sw = clean_docs(X_train, remove_stopwords=True)\nX_train_no_sw = np.array(X_train_no_sw)\n\nPour visualiser rapidement nos corpus, on peut utiliser la technique des\nnuages de mots d√©j√† vue √† plusieurs reprises.\nVous pouvez essayer de faire vous-m√™me les nuages ci-dessous\nou cliquer sur la ligne ci-dessous pour afficher le code ayant\ng√©n√©r√© les figures :\n\nCliquer pour afficher le code üëá\n\ndef plot_top_words(initials, ax, n_words=20):\n    # Calcul des mots les plus fr√©quemment utilis√©s par l'auteur\n    texts = X_train_no_sw[le.inverse_transform(y_train) == initials]\n    all_tokens = \" \".join(texts).split()\n    counts = Counter(all_tokens)\n    top_words = [word[0] for word in counts.most_common(n_words)]\n    top_words_counts = [word[1] for word in counts.most_common(n_words)]\n\n    # Repr√©sentation sous forme de barplot\n    ax = sns.barplot(ax=ax, x=top_words, y=top_words_counts)\n    ax.set_title(f\"Most Common Words used by {initials_to_author[initials]}\")\n\n\ninitials_to_author = {\n    \"EAP\": \"Edgar Allen Poe\",\n    \"HPL\": \"H.P. Lovecraft\",\n    \"MWS\": \"Mary Wollstonecraft Shelley\",\n}\n\nfig, axs = plt.subplots(3, 1, figsize=(12, 12))\n\nplot_top_words(\"EAP\", ax=axs[0])\nplot_top_words(\"HPL\", ax=axs[1])\nplot_top_words(\"MWS\", ax=axs[2])\n\n\n\nBeaucoup de mots se retrouvent tr√®s utilis√©s par les trois auteurs.\nIl y a cependant des diff√©rences notables : le mot ‚Äúlife‚Äù\nest le plus employ√© par MWS, alors qu‚Äôil n‚Äôappara√Æt pas dans les deux autres tops.\nDe m√™me, le mot ‚Äúold‚Äù est le plus utilis√© par HPL\nl√† o√π les deux autres ne l‚Äôutilisent pas de mani√®re surrepr√©sent√©e.\nIl semble donc qu‚Äôil y ait des particularit√©s propres √† chacun des auteurs\nen termes de vocabulaire,\nce qui laisse penser qu‚Äôil est envisageable de pr√©dire les auteurs √† partir\nde leurs textes dans une certaine mesure.",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#d√©marche",
    "href": "content/NLP/04_word2vec.html#d√©marche",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "4.1 D√©marche",
    "text": "4.1 D√©marche\nComme nous nous int√©ressons plus √† l‚Äôeffet de la vectorisation qu‚Äô√† la t√¢che de classification en elle-m√™me,\nnous allons utiliser un algorithme de classification simple (un SVM lin√©aire), avec des param√®tres non fine-tun√©s (c‚Äôest-√†-dire des param√®tres pas n√©cessairement choisis pour √™tre les meilleurs de tous).\n\nclf = LinearSVC(max_iter=10000, C=0.1, dual=\"auto\")\n\nCe mod√®le est connu pour √™tre tr√®s performant sur les t√¢ches de classification de texte, et nous fournira donc un bon mod√®le de r√©f√©rence (baseline). Cela nous permettra √©galement de comparer de mani√®re objective l‚Äôimpact des m√©thodes de vectorisation sur la performance finale.\nPour les deux premi√®res m√©thodes de vectorisation\n(bas√©es sur des fr√©quences et fr√©quences relatives des mots),\non va simplement normaliser les donn√©es d‚Äôentr√©e, ce qui va permettre au SVM de converger plus rapidement, ces mod√®les √©tant sensibles aux diff√©rences d‚Äô√©chelle dans les donn√©es.\nOn va √©galement fine-tuner via grid-search\ncertains hyperparam√®tres li√©s √† ces m√©thodes de vectorisation :\n\non teste diff√©rents ranges de n-grams (unigrammes et unigrammes + bigrammes)\non teste avec et sans stop-words\n\nAfin d‚Äô√©viter le surapprentissage,\non va √©valuer les diff√©rents mod√®les via validation crois√©e, calcul√©e sur 4 blocs.\nOn r√©cup√®re √† la fin le meilleur mod√®le selon une m√©trique sp√©cifi√©e.\nOn choisit le score F1,\nmoyenne harmonique de la pr√©cision et du rappel,\nqui donne un poids √©quilibr√© aux deux m√©triques, tout en p√©nalisant fortement le cas o√π l‚Äôune des deux est faible.\nPr√©cis√©ment, on retient le score F1 *micro-averaged* :\nles contributions des diff√©rentes classes √† pr√©dire sont agr√©g√©es,\npuis on calcule le score F1 sur ces donn√©es agr√©g√©es.\nL‚Äôavantage de ce choix est qu‚Äôil permet de tenir compte des diff√©rences\nde fr√©quences des diff√©rentes classes.",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#pipeline-de-pr√©diction",
    "href": "content/NLP/04_word2vec.html#pipeline-de-pr√©diction",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "4.2 Pipeline de pr√©diction",
    "text": "4.2 Pipeline de pr√©diction\nOn va utiliser un pipeline scikit ce qui va nous permettre d‚Äôavoir\nun code tr√®s concis pour effectuer cet ensemble de t√¢ches coh√©rentes.\nDe plus, cela va nous assurer de g√©rer de mani√®re coh√©rentes nos diff√©rentes\ntransformations (cf.¬†partie sur les pipelines)\nPour se faciliter la vie, on d√©finit une fonction fit_vectorizers qui\nint√®gre dans un pipeline g√©n√©rique une m√©thode d‚Äôestimation scikit\net fait de la validation crois√©e en cherchant le meilleur mod√®le\n(en excluant/incluant les stop words et avec unigrammes/bigrammes)\n\ndef fit_vectorizers(vectorizer):\n    pipeline = Pipeline(\n        [\n            (\"vect\", vectorizer()),\n            (\"scaling\", StandardScaler(with_mean=False)),\n            (\"clf\", clf),\n        ]\n    )\n\n    parameters = {\n        \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigrams\n        \"vect__stop_words\": (\"english\", None),\n    }\n\n    grid_search = GridSearchCV(\n        pipeline, parameters, scoring=\"f1_micro\", cv=4, n_jobs=4, verbose=1\n    )\n    grid_search.fit(X_train, y_train)\n\n    best_parameters = grid_search.best_estimator_.get_params()\n    for param_name in sorted(parameters.keys()):\n        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n\n    print(f\"CV scores {grid_search.cv_results_['mean_test_score']}\")\n    print(f\"Mean F1 {np.mean(grid_search.cv_results_['mean_test_score'])}\")\n\n    return grid_search",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#informations-additionnelles",
    "href": "content/NLP/04_word2vec.html#informations-additionnelles",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n6855667\n\n\n2023-11-29 10:21:01\n\n\nRomain Avouac\n\n\nCorrections tp vectorisation + improve badge creation (#465)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nb395985\n\n\n2023-02-13 17:29:36\n\n\nLino Galiana\n\n\nRetire shortcode spoiler (#352)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n7058752\n\n\n2022-03-04 15:35:17\n\n\nLino Galiana\n\n\nRelecture Word2Vec (#216)\n\n\n\n\nce1f2b5\n\n\n2022-02-16 13:54:27\n\n\nLino Galiana\n\n\nspacy corpus pre-downloaded\n\n\n\n\n66e2837\n\n\n2021-12-24 16:54:45\n\n\nLino Galiana\n\n\nFix a few typos in the new pipeline tutorial (#208)\n\n\n\n\n8ab1956\n\n\n2021-12-23 21:07:30\n\n\nRomain Avouac\n\n\nTP vectorization prediction authors (#206)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#footnotes",
    "href": "content/NLP/04_word2vec.html#footnotes",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation.‚Ü©Ô∏é",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html",
    "href": "content/NLP/02_exoclean.html",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page approfondit certains aspects pr√©sent√©s dans la\npartie introductive. Apr√®s avoir travaill√© sur le\nComte de Monte Cristo, on va continuer notre exploration de la litt√©rature\navec cette fois des auteurs anglophones :\nLes donn√©es sont disponibles sur un CSV mis √† disposition sur Github. L‚ÄôURL pour les r√©cup√©rer directement est\nhttps://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv.\nLe but va √™tre dans un premier temps de regarder dans le d√©tail les termes les plus fr√©quemment utilis√©s par les auteurs et de les repr√©senter graphiquement. Il s‚Äôagit donc d‚Äôune approche bas√©e sur l‚Äôanalyse de fr√©quences.\nOn prendra appui sur l‚Äôapproche bag of words pr√©sent√©e dans le chapitre pr√©c√©dent1.\nIl n‚Äôy aura pas de mod√©lisation particuli√®re, ceci est r√©serv√© aux chapitres suivants.\nCe chapitre s‚Äôinspire de plusieurs ressources disponibles en ligne:\nLes chapitres suivants permettront d‚Äôintroduire aux enjeux de mod√©lisation\nde corpus textuels. Dans un premier temps, le mod√®le LDA permettra d‚Äôexplorer\nle principe des mod√®les bay√©siens √† couche cach√©es pour mod√©liser les sujets (topics)\npr√©sents dans un corpus et segmenter ces topics selon les mots qui les composent.\nLe dernier chapitre de la partie visera √†\npr√©dire quel texte correspond √† quel auteur √† partir d‚Äôun mod√®le Word2Vec.\nCela sera un pas suppl√©mentaire dans la formalisation puisqu‚Äôil s‚Äôagira de\nrepr√©senter chaque mot d‚Äôun texte sous forme d‚Äôun vecteur de grande dimension, ce\nqui nous permettra de rapprocher les mots entre eux dans un espace complexe.\nCette technique, dite des plongements de mots (Word Embeddings),\npermet ainsi de transformer une information complexe difficilement quantifiable\ncomme un mot\nen un objet num√©rique qui peut ainsi √™tre rapproch√© d‚Äôautres par des m√©thodes\nalg√©briques. Pour d√©couvrir ce concept, ce post de blog\nest particuli√®rement utile. En pratique, la technique des\nplongements de mots permet d‚Äôobtenir des tableaux comme celui-ci :",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#fr√©quence-dun-mot",
    "href": "content/NLP/02_exoclean.html#fr√©quence-dun-mot",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "2.1 Fr√©quence d‚Äôun mot",
    "text": "2.1 Fr√©quence d‚Äôun mot\nAvant de s‚Äôadonner √† une analyse syst√©matique du champ lexical de chaque\nauteur, on va se focaliser dans un premier temps sur un unique mot, le mot fear.\n\n\n Note\nL‚Äôexercice ci-dessous pr√©sente une repr√©sentation graphique nomm√©e\nwaffle chart. Il s‚Äôagit d‚Äôune approche pr√©f√©rable aux\ncamemberts qui sont des graphiques manipulables car l‚Äôoeil humain se laisse\nfacilement berner par cette repr√©sentation graphique qui ne respecte pas\nles proportions.\n\n\n\n\n Exercice 2 : Fr√©quence d'un mot\n\nCompter le nombre de phrases, pour chaque auteur, o√π appara√Æt le mot fear.\nUtiliser pywaffle pour obtenir les graphiques ci-dessous qui r√©sument\nde mani√®re synth√©tique le nombre d‚Äôoccurrences du mot ‚Äúfear‚Äù par auteur.\nRefaire l‚Äôanalyse avec le mot ‚Äúhorror‚Äù.\n\n\n\nA l‚Äôissue de la question 1, vous devriez obtenir le tableau\nde fr√©quence suivant :\n\n\n\n\n\n\n\n\n\n\nText\nID\nwordtoplot\n\n\nAuthor\n\n\n\n\n\n\n\nEAP\nThis process, however, afforded me no means of...\n2630511008096741351519322166071718908441148621...\n70\n\n\nHPL\nIt never once occurred to me that the fumbling...\n1756912958197641888620836080752790708121117330...\n160\n\n\nMWS\nHow lovely is spring As we looked from Windsor...\n2776322965009121673712799131170076400683052582...\n211\n\n\n\n\n\n\n\n\nCeci permet d‚Äôobtenir le waffle chart suivant :\n\n\n\n\n\n\n\n\nFigure¬†2.1: R√©partition du terme fear dans le corpus de nos trois auteurs\n\n\n\n\n\nOn remarque ainsi de mani√®re tr√®s intuitive\nle d√©s√©quilibre de notre jeu de donn√©es\nlorsqu‚Äôon se focalise sur le terme ‚Äúpeur‚Äù\no√π Mary Shelley repr√©sente pr√®s de 50%\ndes observations.\nSi on reproduit cette analyse avec le terme ‚Äúhorror‚Äù, on peut\nen conclure que la peur est plus √©voqu√©e par Mary Shelley\n(sentiment assez naturel face √† la cr√©ature du docteur Frankenstein) alors\nque Lovecraft n‚Äôa pas vol√© sa r√©putation d‚Äô√©crivain de l‚Äôhorreur !",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#premier-wordcloud",
    "href": "content/NLP/02_exoclean.html#premier-wordcloud",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "2.2 Premier wordcloud",
    "text": "2.2 Premier wordcloud\nPour aller plus loin dans l‚Äôanalyse du champ lexical de chaque auteur,\non peut repr√©senter un wordcloud qui permet d‚Äôafficher chaque mot avec une\ntaille proportionnelle au nombre d‚Äôoccurrence de celui-ci.\n\n\n Exercice 3 : Wordcloud\n\nEn utilisant la fonction wordCloud, faire trois nuages de mot pour repr√©senter les mots les plus utilis√©s par chaque auteur.\nCalculer les 25 mots plus communs pour chaque auteur et repr√©senter les trois histogrammes des d√©comptes.\n\n\n\nLe wordcloud pour nos diff√©rents auteurs est le suivant :\n\n\n\n\n\n\n\n\n\nEnfin, si on fait un histogramme des fr√©quences,\ncela donnera :\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\nOn voit ici que ce sont des mots communs, comme ‚Äúthe‚Äù, ‚Äúof‚Äù, etc. sont tr√®s\npr√©sents. Mais ils sont peu porteurs d‚Äôinformation, on peut donc les √©liminer\navant de faire une analyse syntaxique pouss√©e.\nCeci est une d√©monstration par l‚Äôexemple qu‚Äôil vaut mieux nettoyer le texte avant de\nl‚Äôanalyser (sauf si on est int√©ress√©\npar la loi de Zipf, cf.¬†exercice suivant).\nA noter que l‚Äôhistogramme produit\npar le biais de Matplotlib ou Seaborn est\npeu lisible. Il vaut mieux privil√©gier Plotly\npour faire celui-ci afin d‚Äôavoir les mots qui s‚Äôaffichent en\npassant sa souris sur chaque barre.",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#apart√©-la-loi-de-zipf",
    "href": "content/NLP/02_exoclean.html#apart√©-la-loi-de-zipf",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "2.3 Apart√© : la loi de Zipf",
    "text": "2.3 Apart√© : la loi de Zipf\n\n\n La loi de Zipf\nDans son sens strict, la loi de Zipf pr√©voit que\ndans un texte donn√©, la fr√©quence d‚Äôoccurrence \\(f(n_i)\\) d‚Äôun mot est\nli√©e √† son rang \\(n_i\\) dans l‚Äôordre des fr√©quences par une loi de la forme\n\\(f(n_i) = c/n_i\\) o√π \\(c\\) est une constante. Zipf, dans les ann√©es 1930, se basait sur l‚Äôoeuvre\nde Joyce, Ulysse pour cette affirmation.\nPlus g√©n√©ralement, on peut d√©river la loi de Zipf d‚Äôune distribution exponentielle des fr√©quences : \\(f(n_i) = cn_{i}^{-k}\\). Cela permet d‚Äôutiliser la famille des mod√®les lin√©aires g√©n√©ralis√©s, notamment les r√©gressions poissonniennes, pour mesurer les param√®tres de la loi. Les mod√®les lin√©aire traditionnels en log souffrent en effet, dans ce contexte, de biais (la loi de Zipf est un cas particulier d‚Äôun mod√®le gravitaire, o√π appliquer des OLS est une mauvaise id√©e, cf.¬†Galiana et al. (2020) pour les limites).\n\n\nUn mod√®le exponentiel peut se repr√©senter par un mod√®le de Poisson ou, si\nles donn√©es sont tr√®s dispers√©es, par un mod√®le binomial n√©gatif. Pour\nplus d‚Äôinformations, consulter l‚Äôannexe de Galiana et al. (2020).\nLa technique √©conom√©trique associ√©e pour l‚Äôestimation est\nles mod√®les lin√©aires g√©n√©ralis√©s (GLM) qu‚Äôon peut\nutiliser en Python via le\npackage statsmodels2:\n\\[\n\\mathbb{E}\\bigg( f(n_i)|n_i \\bigg) = \\exp(\\beta_0 + \\beta_1 \\log(n_i))\n\\]\nPrenons les r√©sultats de l‚Äôexercice pr√©c√©dent et enrichissons les du rang et de la fr√©quence d‚Äôoccurrence d‚Äôun mot :\n\ncount_words = pd.DataFrame(\n    {\n        \"counter\": train.groupby(\"Author\")\n        .apply(lambda s: \" \".join(s[\"Text\"]).split())\n        .apply(lambda s: Counter(s))\n        .apply(lambda s: s.most_common())\n        .explode()\n    }\n)\ncount_words[[\"word\", \"count\"]] = pd.DataFrame(\n    count_words[\"counter\"].tolist(), index=count_words.index\n)\ncount_words = count_words.reset_index()\n\ncount_words = count_words.assign(\n    tot_mots_auteur=lambda x: (x.groupby(\"Author\")[\"count\"].transform(\"sum\")),\n    freq=lambda x: x[\"count\"] / x[\"tot_mots_auteur\"],\n    rank=lambda x: x.groupby(\"Author\")[\"count\"].transform(\"rank\", ascending=False),\n)\n\n/tmp/ipykernel_5397/3685081206.py:3: DeprecationWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n\n\nCommen√ßons par repr√©senter la relation entre la fr√©quence et le rang:\n\nfrom plotnine import *\n\ng = (\n    ggplot(count_words)\n    + geom_point(aes(y=\"freq\", x=\"rank\", color=\"Author\"), alpha=0.4)\n    + scale_x_log10()\n    + scale_y_log10()\n    + theme_minimal()\n)\n\nNous avons bien, graphiquement, une relation log-lin√©aire entre les deux :\n\n\n\n\n\n\n\n\n\nAvec statsmodels, v√©rifions plus formellement cette relation:\n\nimport statsmodels.api as sm\n\nexog = sm.add_constant(np.log(count_words[\"rank\"].astype(float)))\n\nmodel = sm.GLM(\n    count_words[\"freq\"].astype(float), exog, family=sm.families.Poisson()\n).fit()\n\n# Afficher les r√©sultats du mod√®le\nprint(model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                   freq   No. Observations:                69301\nModel:                            GLM   Df Residuals:                    69299\nModel Family:                 Poisson   Df Model:                            1\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -23.011\nDate:                Thu, 25 Apr 2024   Deviance:                     0.065676\nTime:                        20:31:11   Pearson chi2:                   0.0656\nNo. Iterations:                     5   Pseudo R-squ. (CS):          0.0002431\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.4388      1.089     -2.239      0.025      -4.574      -0.303\nrank          -0.9831      0.189     -5.196      0.000      -1.354      -0.612\n==============================================================================\n\n\nLe coefficient de la r√©gression est presque 1 ce qui sugg√®re bien une relation\nquasiment log-lin√©aire entre le rang et la fr√©quence d‚Äôoccurrence d‚Äôun mot.\nDit autrement, le mot le plus utilis√© l‚Äôest deux fois plus que le deuxi√®me mot le plus fr√©quent qui l‚Äôest trois plus que le troisi√®me, etc.",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#informations-additionnelles",
    "href": "content/NLP/02_exoclean.html#informations-additionnelles",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na1ab3d9\n\n\n2023-11-24 10:57:02\n\n\nLino Galiana\n\n\nReprise des chapitres NLP (#459)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\na9b384e\n\n\n2023-07-18 18:07:16\n\n\nLino Galiana\n\n\nS√©pare les notebooks (#373)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n934149d\n\n\n2023-02-13 11:45:23\n\n\nLino Galiana\n\n\nget_feature_names is deprecated in scikit 1.0.X versions (#351)\n\n\n\n\n164fa68\n\n\n2022-11-30 09:13:45\n\n\nLino Galiana\n\n\nTravail partie NLP (#328)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n3299f1d\n\n\n2022-01-08 16:50:11\n\n\nLino Galiana\n\n\nClean NLP notebooks (#215)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n17092b2\n\n\n2021-12-13 09:17:13\n\n\nLino Galiana\n\n\nRetouches partie NLP (#199)\n\n\n\n\n3c87483\n\n\n2021-12-13 08:46:52\n\n\nLino Galiana\n\n\nNotebooks NLP update (#198)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n49e2826\n\n\n2021-05-13 18:11:20\n\n\nLino Galiana\n\n\nCorrige quelques images n‚Äôapparaissant pas (#108)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†1: Illustration de l‚Äôint√©r√™t des embeddings (Galiana and Castillo 2022)\nFigure¬†2.1: R√©partition du terme fear dans le corpus de nos trois auteurs",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#footnotes",
    "href": "content/NLP/02_exoclean.html#footnotes",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nL‚Äôapproche bag of words est d√©j√†, si on la pousse √† ses limites, tr√®s int√©ressante. Elle peut notamment\nfaciliter la mise en coh√©rence de diff√©rents corpus\npar la m√©thode des appariements flous\n(cf.¬†Galiana and Castillo (2022).\nLe chapitre sur ElasticSearch pr√©sent dans cette partie du cours pr√©sente quelques\n√©l√©ments de ce travail sur les donn√©es de l‚ÄôOpenFoodFacts.‚Ü©Ô∏é\nLa litt√©rature sur les mod√®les gravitaires, pr√©sent√©e dans Galiana et al. (2020),\ndonne quelques arguments pour privil√©gier les mod√®les GLM √† des mod√®les log-lin√©aires\nestim√©s par moindres carr√©s ordinaires.‚Ü©Ô∏é\nOn parle de bigrams pour les co-occurences de mots deux-√†-deux, trigrams pour les co-occurences trois-√†-trois, etc.‚Ü©Ô∏é",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/index.html",
    "href": "content/NLP/index.html",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "",
    "text": "Les parties pr√©c√©dentes √©taient consacr√©es √† l‚Äôacquisition de comp√©tences\ntransversales pour la valorisation des donn√©es. De mani√®re naturelle,\nnous nous sommes jusqu‚Äô√† pr√©sent plut√¥t consacr√©s\n√† la valorisation de donn√©es structur√©es, d‚Äôune\ndimension certes modeste mais qui ouvraient d√©j√† √©norm√©ment de\nprobl√©matiques √† creuser. Cette partie propose maintenant de se\nconsacrer √† un sujet dont il n‚Äôest pas √©vident a priori que\nles ordinateurs s‚Äôemparent, source de d√©bats philosophiques s√©culaires, de Platon √† Saussure : le langage humain et sa richesse.\nEn faisant l‚Äôanalogie entre langue et langage, c‚Äôest-√†-dire en d√©finissant ce dernier comme la capacit√© d‚Äôexpression et de communication d‚Äôune pens√©e par le biais de signes et en d√©finissant la langue comme la mise en oeuvre conventionnelle de cette capacit√©, on peut se placer dans les traces de la linguistique\net repr√©senter le langage sous une forme de donn√©es.\nCeci ouvre la voix √† l‚Äôanalyse statistique ou algorithmique. N√©anmoins, m√™me s‚Äôil existe des r√©gularit√©s statistiques , comment\ndes ordinateurs, qui au fond ne connaissent que le 0 et le 1, peuvent-ils\ns‚Äôapproprier cet objet √©minemment complexe qu‚Äôest le langage et qu‚Äôun\nhumain met lui-m√™me des ann√©es √† comprendre et s‚Äôapproprier ?1",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#nettoyages-textuels-et-analyse-de-fr√©quences",
    "href": "content/NLP/index.html#nettoyages-textuels-et-analyse-de-fr√©quences",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "3.1 Nettoyages textuels et analyse de fr√©quences",
    "text": "3.1 Nettoyages textuels et analyse de fr√©quences\nPython est un excellent outil pour l‚Äôanalyse de donn√©es textuelles.\nLes m√©thodes de base de transformation de donn√©es textuelles ou de dictionnaires, associ√©es √† des librairies sp√©cialis√©es\ncomme NLTK et SpaCy, permettent d‚Äôeffectuer des t√¢ches de normalisation et d‚Äôanalyse de donn√©es textuelles de mani√®re\ntr√®s efficace. Python est bien mieux outill√© que R pour l‚Äôanalyse de\ndonn√©es textuelles.\nLes ressources en ligne sur le sujet sont tr√®s\nnombreuses et la meilleure des √©coles dans le domaine reste la pratique sur un corpus √† nettoyer.\nDans un premier temps, cette partie propose\nde revenir sur la mani√®re de structurer et nettoyer un corpus\ntextuel au travers de l‚Äôapproche bag of words (sac de mots).\nElle vise √† montrer comment transformer un corpus en outil propre √† une\nanalyse statistique :\n\nElle propose d‚Äôabord une introduction aux enjeux du nettoyage des donn√©es\ntextuelles √† travers l‚Äôanalyse du Comte de Monte Cristo d‚ÄôAlexandre Dumas\nici qui permet de synth√©tiser rapidement l‚Äôinformation disponible\ndans un large volume de donn√©es (√† l‚Äôimage de la ?@fig-wordcloud-dumas)\nElle propose ensuite une s√©rie d‚Äôexercices sur le nettoyage de textes √† partir des\noeuvres d‚ÄôEdgar Allan Poe, Mary Shelley et H.P. Lovecraft visant √† distinguer la\nsp√©cificit√© du vocabulaire employ√© par chaque auteurs (par exemple ?@fig-waffle-fear). Ces exercices sont\ndisponibles dans le deuxi√®me chapitre de la partie.\n\nCette analyse fr√©quentiste permet de prendre du recul sur la nature des donn√©es textuelles et sur les enjeux r√©currents dans la r√©duction de dimension de corpus en langue naturelle. Comme la statistique descriptive entra√Æne naturellement la mod√©lisation, cette approche fr√©quentiste va g√©n√©ralement amener rapidement √† vouloir synth√©tiser quelques lois derri√®re nos corpus textuels.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#mod√©lisation-du-langage",
    "href": "content/NLP/index.html#mod√©lisation-du-langage",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "3.2 Mod√©lisation du langage",
    "text": "3.2 Mod√©lisation du langage\nLa suite de cette partie proposera une introduction aux enjeux de mod√©lisation\ndu langage. Ceux-ci sont tr√®s √† la mode du fait du succ√®s de ChatGPT. N√©anmoins, avant\nd‚Äôen arriver aux grands mod√®les de langage (LLM), ces r√©seaux de neurone ayant des milliards de param√®tres et entra√Æn√©s sur des volumes massifs de donn√©es, il est n√©cessaire de passer par quelques mod√©lisations\npr√©liminaires.\nNous proposerons d‚Äôabord d‚Äôexplorer une approche alternative, prenant en compte\nle contexte d‚Äôapparition d‚Äôun mot. L‚Äôintroduction √† la\nLatent Dirichlet Allocation (LDA) sera l‚Äôoccasion de pr√©senter la mod√©lisation\nde documents sous la forme de topics. Celle-ci est n√©anmoins pass√©e de mode au profit des m√©thodes li√©es au concept d‚Äôembedding.\nNous introduirons ainsi √† la fin de cette partie du cours les enjeux de la transformation de champs textuels\nsous forme de vecteurs num√©riques. Pour cela, nous pr√©senterons le principe\nde Word2Vec qui permet ainsi, par exemple,\nmalgr√© une distance syntaxique importante,\nde dire que s√©mantiquement Homme et Femme sont proches.\nCe chapitre est une passerelle vers le concept d‚Äôembedding, v√©ritable\nr√©volution r√©cente du NLP, et qui permet de rapprocher des corpus\nnon seulement sur leur proximit√© syntaxique (partagent-ils par exemple des mots\ncommuns ?) mais aussi sur leur proximit√© s√©mantique (partagent-ils un th√®me ou un sens commun ?)4. Ce passage par Word2Vec permettra aux curieux de pouvoir ensuite passer aux mod√®les de type transformers, les mod√®les faisant aujourd‚Äôhui office de r√©f√©rence dans le domaine du NLP.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#pour-aller-plus-loin",
    "href": "content/NLP/index.html#pour-aller-plus-loin",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nLa recherche dans le domaine du NLP est tr√®s active. Il est donc recommand√©\nde faire preuve de curiosit√© pour en apprendre plus car une ressource\nunique ne compilera pas l‚Äôensemble des connaissances, a fortiori dans\nun champ de recherche aussi dynamique que le NLP.\nPour approfondir les comp√©tences √©voqu√©es dans ce cours, je recommande vivement\nce cours d‚ÄôHuggingFace.\nPour comprendre l‚Äôarchitecture interne d‚Äôun LLM,\nce post de Sebastian Raschka\nest tr√®s utile.\nCes chapitres n‚Äô√©puisent pas les cas d‚Äôusage du NLP pour les data scientists. Ils n‚Äôen sont que la surface √©merg√©e de l‚Äôiceberg.\nPar exemple,\ndans le domaine de la statistique publique, un des principaux cas d‚Äôusage du NLP est l‚Äôutilisation\nde techniques de classification automatique pour transformer des r√©ponses libres dans des questionnaires\nen champs pr√©d√©finis dans une nomenclature.\nIl s‚Äôagit donc d‚Äôune adaptation, un peu sp√©cifique √† la statistique publique, grande utilisatrice de nomenclatures normalis√©es, de probl√©matiques de classification multi-niveaux.\nVoici un exemple sur un projet de classification automatis√©e des professions dans la typologie\ndes nomenclatures d‚Äôactivit√©s (les PCS) √† partir d‚Äôun mod√®le entra√Æn√© par la librairie Fasttext :\n\nviewof activite = Inputs.text( \n  {label: '', value: 'data scientist', width: 800}\n)\n\n\n\n\n\n\n\nd3.json(urlApe).then(res =&gt; {\n  var IC, results;\n\n  ({ IC, ...results } = res);\n\n  IC = parseFloat(IC);\n\n  const rows = Object.values(results).map(obj =&gt; {\n    return `\n    &lt;tr&gt;\n      &lt;td&gt;${obj.code} | ${obj.libelle}&lt;/td&gt;\n      &lt;td&gt;${obj.probabilite.toFixed(3)}&lt;/td&gt;\n    &lt;/tr&gt;\n  `;\n  }).join('');\n\n  const confidenceRow = `&lt;tr&gt;\n    &lt;td colspan=\"2\" style=\"text-align:left; \"&gt;&lt;em&gt;Indice de confiance : ${IC.toFixed(3)}&lt;/em&gt;&lt;/td&gt;\n  &lt;/tr&gt;`;\n\n  const tableHTML = html`\n  &lt;table&gt;\n    &lt;caption&gt;\n      Pr√©diction de l'activit√©\n    &lt;/caption&gt;\n    &lt;tr&gt;\n      &lt;th style=\"text-align:center;\"&gt;Libell√© (NA2008)&lt;/th&gt;\n      &lt;th&gt;Probabilit√©&lt;/th&gt;\n    &lt;/tr&gt;\n      ${rows}\n      ${confidenceRow}\n  &lt;/table&gt;`;\n\n  // Now you can use the tableHTML as needed, for example, inserting it into the DOM.\n  // For example, assuming you have a container with the id \"tableContainer\":\n  return tableHTML;\n});\n\n\n\n\n\n\n\nactivite_debounce = debounce(viewof activite, 2000)\nurlApe = `https://codification-ape-test.lab.sspcloud.fr/predict?nb_echos_max=3&prob_min=0&text_feature=${activite_debounce}`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport {debounce} from \"@mbostock/debouncing-input\"",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#informations-additionnelles",
    "href": "content/NLP/index.html#informations-additionnelles",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nff42cf2\n\n\n2024-04-25 20:05:33\n\n\nlinogaliana\n\n\nEditorisalisation NLP\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na1ab3d9\n\n\n2023-11-24 10:57:02\n\n\nLino Galiana\n\n\nReprise des chapitres NLP (#459)\n\n\n\n\n7bd768a\n\n\n2023-08-28 09:14:55\n\n\nlinogaliana\n\n\nErreur image\n\n\n\n\n862ea4b\n\n\n2023-08-28 11:07:31\n\n\nLino Galiana\n\n\nAjoute r√©f√©rence au post de Raschka (#398)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\na408cc9\n\n\n2023-02-01 09:07:27\n\n\nLino Galiana\n\n\nAjoute bouton sugg√©rer modification (#347)\n\n\n\n\n164fa68\n\n\n2022-11-30 09:13:45\n\n\nLino Galiana\n\n\nTravail partie NLP (#328)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#footnotes",
    "href": "content/NLP/index.html#footnotes",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEn √©crivant ces lignes j‚Äôai demand√© √† ChatGPT de me faire une blague.\n\nPourquoi les programmeurs d√©testent-ils la plage ?\nParce que le sable change tout le temps de paradigme !\n\nNe l‚Äôayant pas comprise, je lui\nai demand√© de me l‚Äôexpliquer. Voici sa r√©ponse :\n\nBien s√ªr, je serais ravi de l‚Äôexpliquer ! Cette blague joue sur le double sens du mot ‚Äúparadigme‚Äù et fait un jeu de mots avec les notions li√©es √† la programmation et √† la plage.\nDans le domaine de la programmation, un ‚Äúparadigme‚Äù d√©signe un mod√®le ou une m√©thode de programmation, comme la programmation orient√©e objet, la programmation fonctionnelle, etc. Les programmeurs sont souvent familiers avec diff√©rents paradigmes de programmation.\nD‚Äôautre part, en contexte de plage, ‚Äúparadigme‚Äù est utilis√© pour signifier ‚Äúmar√©e qui monte et descend‚Äù, se r√©f√©rant √† l‚Äôaction naturelle du sable et de l‚Äôeau sur la plage.\nLa blague joue sur la frustration humoristique que peuvent ressentir les programmeurs lorsqu‚Äôils doivent s‚Äôadapter √† de nouveaux paradigmes de programmation, tout comme le sable de la plage qui change constamment avec les mar√©es. En associant les deux sens du mot ‚Äúparadigme‚Äù, la blague cr√©e une situation absurde et amusante, faisant sourire ceux qui comprennent les r√©f√©rences √† la programmation et √† la plage.\n\nFinalement, j‚Äôai trouv√© son explication plus dr√¥le que sa blague.‚Ü©Ô∏é\nLe concept de natural language processing tend √† remplacer celui\nde text mining dont le p√©rim√®tre √©tait plus sp√©cifique. Le text mining\nrenvoie √† la recherche d‚Äôinformation - la fouille - dans un ensemble de\ntextes. C‚Äôest l‚Äôun des champs d‚Äôapplications\ndu natural language processing mais ce n‚Äôest pas l‚Äôunique. L‚Äôaccroissement des ressources de calcul et les progr√®s dans la formalisation du langage ont permis d‚Äô√©largir le champ des domaines o√π la linguistique computationnelle intervient.‚Ü©Ô∏é\nPar exemple, le concept d‚Äôembedding - transformation d‚Äôun champ\ntextuel en un vecteur num√©rique multidimensionnel - aujourd‚Äôhui central\ndans le NLP n‚Äôest √©voqu√© qu‚Äô√† quelques reprises.‚Ü©Ô∏é\nUn exemple d‚Äôint√©r√™t de ce type d‚Äôapproche est la ?@fig-relevanc-table-embedding.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html",
    "href": "content/modelisation/6_pipeline.html",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre pr√©sente la premi√®re application\nd‚Äôune journ√©e de cours que j‚Äôai\ndonn√© √† l‚ÄôUniversit√© Dauphine dans le cadre\ndes PSL Data Week.\nPour lire les donn√©es de mani√®re efficace, nous\nproposons d‚Äôutiliser le package duckdb.\nPour l‚Äôinstaller, voici la commande :\n!pip install duckdb",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#d√©finitions-pr√©alables",
    "href": "content/modelisation/6_pipeline.html#d√©finitions-pr√©alables",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "1.1 D√©finitions pr√©alables",
    "text": "1.1 D√©finitions pr√©alables\nCe chapitre nous am√®nera √† explorer plusieurs √©cosyst√®mes, pour lesquels on retrouve quelques buzz-words dont voici les d√©finitions :\n\n\n\n\n\n\n\nTerme\nD√©finition\n\n\n\n\nDevOps\nMouvement en ing√©nierie informatique et une pratique technique visant √† l‚Äôunification du d√©veloppement logiciel (dev) et de l‚Äôadministration des infrastructures informatiques (ops)\n\n\nMLOps\nEnsemble de pratiques qui vise √† d√©ployer et maintenir des mod√®les de machine learning en production de mani√®re fiable et efficace\n\n\n\nCe chapitre fera des r√©f√©rences r√©guli√®res au cours\nde 3e ann√©e de l‚ÄôENSAE\n‚ÄúMise en production de projets data science‚Äù.",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#objectif",
    "href": "content/modelisation/6_pipeline.html#objectif",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "1.2 Objectif",
    "text": "1.2 Objectif\nLes chapitres pr√©c√©dents ont permis de montrer des bouts de code\n√©pars pour entra√Æner des mod√®les ou faire du preprocessing.\nCette d√©marche est int√©ressante pour t√¢tonner mais risque d‚Äô√™tre co√ªteuse\nult√©rieurement s‚Äôil est n√©cessaire d‚Äôajouter une √©tape de preprocessing\nou de changer d‚Äôalgorithme.\nLes pipelines sont pens√©s pour simplifier la mise en production\nult√©rieure d‚Äôun mod√®le de machine learning.\nIls sont au coeur de la d√©marche de MLOps qui est\npr√©sent√©e\ndans le cours de 3e ann√©e de l‚ÄôENSAE\nde ‚ÄúMise en production de projets data science‚Äù,\nqui vise √† simplifier la mise en oeuvre op√©rationnelle de\nprojets utilisant des techniques de machine learning.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#les-pipelines-scikit",
    "href": "content/modelisation/6_pipeline.html#les-pipelines-scikit",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "1.3 Les pipelines Scikit",
    "text": "1.3 Les pipelines Scikit\nHeureusement, Scikit propose un excellent outil pour proposer un cadre\ng√©n√©ral pour cr√©er une cha√Æne de production machine learning. Il\ns‚Äôagit des\npipelines.\nIls pr√©sentent de nombreux int√©r√™ts, parmi lesquels :\n\nIls sont tr√®s pratiques et lisibles. On rentre des donn√©es en entr√©e, on n‚Äôappelle qu‚Äôune seule fois les m√©thodes fit et predict ce qui permet de s‚Äôassurer une gestion coh√©rente des transformations de variables, par exemple apr√®s l‚Äôappel d‚Äôun StandardScaler ;\nLa modularit√© rend ais√©e la mise √† jour d‚Äôun pipeline et renforce la capacit√© √† le r√©utiliser ;\nIls permettent de facilement chercher les hyperparam√®tres d‚Äôun mod√®le. Sans pipeline, √©crire un code qui fait du tuning d‚Äôhyperparam√®tres peut √™tre p√©nible. Avec les pipelines, c‚Äôest une ligne de code ;\nLa s√©curit√© d‚Äô√™tre certain que les √©tapes de preprocessing sont bien appliqu√©es aux jeux de donn√©es d√©sir√©s avant l‚Äôestimation.\n\n\n\n Hint\nUn des int√©r√™ts des pipelines scikit est qu‚Äôils fonctionnent aussi avec\ndes m√©thodes qui ne sont pas issues de scikit.\nIl est possible d‚Äôintroduire un mod√®le de r√©seau de neurone Keras dans\nun pipeline scikit.\nPour introduire un mod√®le √©conom√©trique statsmodels\nc‚Äôest un peu plus co√ªteux mais nous allons proposer des exemples\nqui peuvent servir de mod√®le et qui montrent que c‚Äôest faisable\nsans trop de difficult√©.",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#donn√©es-utilis√©es",
    "href": "content/modelisation/6_pipeline.html#donn√©es-utilis√©es",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "2.1 Donn√©es utilis√©es",
    "text": "2.1 Donn√©es utilis√©es\nNous allons utiliser les donn√©es\nde transactions immobili√®res DVF pour chercher\nla meilleure mani√®re de pr√©dire, sachant les caract√©ristiques d‚Äôun bien, son\nprix.\nCes donn√©es sont mises √† disposition\nsur data.gouv.\nN√©anmoins, le format csv n‚Äô√©tant pas pratique pour importer des jeux de donn√©es\nvolumineux, nous proposons de privil√©gier la version Parquet mise √†\ndisposition par Eric Mauvi√®re sur data.gouv.\nL‚Äôapproche la plus efficace pour lire ces donn√©es est\nd‚Äôutiliser DuckDB afin de lire le fichier, extraire les colonnes\nd‚Äôint√©r√™t puis passer √† Pandas (pour en savoir plus sur\nl‚Äôint√©r√™t de DuckDB pour lire des fichiers volumineux, vous pouvez\nconsulter ce post de blog ou\ncelui-ci √©crit\npar Eric Mauvi√®re).\nM√™me si, en soi, les gains de temps sont faibles car DuckDB optimise\nles requ√™tes HTTPS n√©cessaires √† l‚Äôimport des donn√©es, nous proposons\nde t√©l√©charger les donn√©es pour r√©duire les besoins de bande passante.\n\nimport requests\nimport os\n\nurl = \"https://www.data.gouv.fr/fr/datasets/r/56bde1e9-e214-408b-888d-34c57ff005c4\"\nfile_name = \"dvf.parquet\"\n\n# Check if the file already exists\nif not os.path.exists(file_name):\n    response = requests.get(url)\n\n    if response.status_code == 200:\n        with open(file_name, \"wb\") as f:\n            f.write(response.content)\n        print(\"T√©l√©chargement r√©ussi.\")\n    else:\n        print(f\"√âchec du t√©l√©chargement. Code d'√©tat : {response.status_code}\")\nelse:\n    print(f\"Le fichier '{file_name}' existe d√©j√†. Aucun t√©l√©chargement n√©cessaire.\")\n\nEn premier lieu, puisque cela va faciliter les requ√™tes SQL ult√©rieures, on cr√©e\nune vue :\n\nimport duckdb\n\nduckdb.sql(f'CREATE OR REPLACE VIEW dvf AS SELECT * FROM read_parquet(\"dvf.parquet\")')\n\nLes donn√©es prennent la forme suivante :\n\nduckdb.sql(f\"SELECT * FROM dvf LIMIT 5\")\n\n\n\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Identifiant de doc‚Ä¶  ‚îÇ Reference document ‚îÇ ‚Ä¶ ‚îÇ Nature culture ‚îÇ Nature culture spe‚Ä¶  ‚îÇ Surface terrain ‚îÇ\n‚îÇ       varchar        ‚îÇ      varchar       ‚îÇ   ‚îÇ    varchar     ‚îÇ       varchar        ‚îÇ      int64      ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ NULL           ‚îÇ NULL                 ‚îÇ            NULL ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ S              ‚îÇ NULL                 ‚îÇ              84 ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ S              ‚îÇ NULL                 ‚îÇ              88 ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ NULL           ‚îÇ NULL                 ‚îÇ            NULL ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ T              ‚îÇ NULL                 ‚îÇ             510 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 5 rows                                                                             43 columns (5 shown) ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nLes variables que nous allons conserver sont les suivantes,\nnous allons les reformater pour la suite de l‚Äôexercice.\n\nxvars = [\n    \"Date mutation\",\n    \"Valeur fonciere\",\n    \"Nombre de lots\",\n    \"Code type local\",\n    \"Nombre pieces principales\",\n]\nxvars = \", \".join([f'\"{s}\"' for s in xvars])\n\n\nmutations = duckdb.sql(\n    f\"\"\"\n    SELECT\n    date_part('month', \"Date mutation\") AS month,\n    substring(\"Code postal\", 1, 2) AS dep,\n    {xvars},\n    COLUMNS('Surface Carrez.*')\n    FROM dvf\n    \"\"\"\n).to_df()\n\ncolonnes_surface = mutations.columns[mutations.columns.str.startswith(\"Surface Carrez\")]\nmutations.loc[:, colonnes_surface] = (\n    mutations.loc[:, colonnes_surface]\n    .replace({\",\": \".\"}, regex=True)\n    .astype(float)\n    .fillna(0)\n)\n\n\n\n\n\n\n Note\nLe fichier Parquet mis √† disposition sur data.gouv pr√©sente une incoh√©rence de mise en forme de\ncertaines colonnes √† cause des virgules qui emp√™chent le formattage sous forme de colonne\nnum√©rique.\nLe code ci-dessus effectue la conversion ad√©quate au niveau de Pandas.\n\n\n\nmutations.head(2)\n\n\n\n\n\n\n\n\n\nmonth\ndep\nDate mutation\nValeur fonciere\nNombre de lots\nCode type local\nNombre pieces principales\nSurface Carrez du 1er lot\nSurface Carrez du 2eme lot\nSurface Carrez du 3eme lot\nSurface Carrez du 4eme lot\nSurface Carrez du 5eme lot\n\n\n\n\n0\n1\n01\n2022-01-03\n55000.0\n1\n2.0\n1.0\n24.1\n0.0\n0.0\n0.0\n0.0\n\n\n1\n1\n01\n2022-01-03\n143000.0\n0\nNaN\nNaN\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\n\n\n\nIntroduire un effet confinement\n\nSi vous travaillez avec les donn√©es de 2020, n‚Äôoubliez pas\nd‚Äôint√©grer l‚Äôeffet\nconfinement dans vos mod√®les puisque cela a lourdement\naffect√© les possibilit√©s de transaction sur cette p√©riode, donc\nl‚Äôeffet potentiel de certaines variables explicatives du prix.\nPour introduire cet effet, vous pouvez cr√©er une variable\nindicatrice entre les dates en question:\nmutations[\"confinement\"] = (\n    mutations[\"Date mutation\"]\n    .between(pd.to_datetime(\"2020-03-17\"), pd.to_datetime(\"2020-05-03\"))\n    .astype(int)\n)\nComme nous travaillons sur les donn√©es de 2022,\nnous pouvons nous passer de cette variable.\n\n\nLes donn√©es DVF proposent une observation par transaction.\nCes transactions\npeuvent concerner plusieurs lots. Par exemple, un appartement\navec garage et cave comportera trois lots.\nPour simplifier,\non va cr√©er une variable de surface qui agr√®ge les diff√©rentes informations\nde surface disponibles dans le jeu de donn√©es.\nLes agr√©ger revient √† supposer que le mod√®le de fixation des prix est le m√™me\nentre chaque lot. C‚Äôest une hypoth√®se simplificatrice qu‚Äôune personne plus\nexperte du march√© immobilier, ou qu‚Äôune approche propre de s√©lection\nde variable pourrait amener √† nier. En effet, les variables\nen question sont faiblement corr√©l√©es les unes entre elles, √† quelques\nexceptions pr√®s (Figure¬†2.1):\n\ncorr = mutations.loc[\n    :, mutations.columns[mutations.columns.str.startswith(\"Surface Carrez\")].tolist()\n]\ncorr.columns = corr.columns.str.replace(\"Carrez du \", \"\")\ncorr = corr.corr()\n\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n\nfig, ax = plt.subplots(1)\ng = sns.heatmap(\n    corr,\n    ax=ax,\n    mask=mask,\n    vmax=0.3,\n    center=0,\n    square=True,\n    linewidths=0.5,\n    cbar_kws={\"shrink\": 0.5},\n    xticklabels=corr.columns.values,\n    yticklabels=corr.columns.values,\n    cmap=cmap,\n    annot=True,\n    fmt=\".2f\",\n)\ng\n\n\n\n\n\n\n\nFigure¬†2.1: Matrice de corr√©lation des variables de surface\n\n\n\n\n\n\nmutations[\"lprix\"] = np.log(mutations[\"Valeur fonciere\"])\nmutations[\"surface\"] = mutations.loc[:, colonnes_surface].sum(axis=1).astype(int)\n\n/opt/mamba/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning:\n\ndivide by zero encountered in log\n\n\n\n\nmutations[\"surface\"] = mutations.loc[\n    :, mutations.columns[mutations.columns.str.startswith(\"Surface Carrez\")].tolist()\n].sum(axis=1)",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#d√©finition-des-ensembles-train-et-test",
    "href": "content/modelisation/6_pipeline.html#d√©finition-des-ensembles-train-et-test",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "3.1 D√©finition des ensembles train et test",
    "text": "3.1 D√©finition des ensembles train et test\nNous allons donc nous restreindre √† un sous-ensemble de colonnes dans un\npremier temps.\nNous allons √©galement ne conserver que les\ntransactions inf√©rieures √† 5 millions\nd‚Äôeuros (on anticipe que celles ayant un montant sup√©rieur sont des transactions\nexceptionnelles dont le m√©canisme de fixation du prix diff√®re)\n\nmutations2 = mutations.drop(\n    colonnes_surface.tolist()\n    + [\"Date mutation\", \"lprix\"],  # ajouter \"confinement\" si donn√©es 2020\n    axis=\"columns\",\n).copy()\n\nmutations2 = mutations2.loc[\n    mutations2[\"Valeur fonciere\"] &lt; 5e6\n]  # keep only values below 5 millions\n\nmutations2.columns = mutations2.columns.str.replace(\" \", \"_\")\nmutations2 = mutations2.dropna(subset=[\"dep\", \"Code_type_local\", \"month\"])\n\nNotre pipeline va incorporer deux types de variables: les variables\ncat√©gorielles et les variables num√©riques.\nCes diff√©rents types vont b√©n√©ficier d‚Äô√©tapes de preprocessing\ndiff√©rentes.\n\nnumeric_features = mutations2.columns[\n    ~mutations2.columns.isin([\"dep\", \"Code_type_local\", \"month\", \"Valeur_fonciere\"])\n].tolist()\ncategorical_features = [\"dep\", \"Code_type_local\", \"month\"]\n\nAu passage, nous avons abandonn√© la variable de code postal pour privil√©gier\nle d√©partement afin de r√©duire la dimension de notre jeu de donn√©es. Si on voulait\nvraiment avoir un bon mod√®le, il faudrait faire autrement car le code postal\nest probablement un tr√®s bon pr√©dicteur du prix d‚Äôun bien, une fois que\nles caract√©ristiques du bien sont contr√¥l√©es.\n\n\n Exercice 1 : D√©coupage des √©chantillons\nNous allons stratifier notre √©chantillonage de train/test par d√©partement\nafin de tenir compte, de mani√®re minimale, de la g√©ographie.\nPour acc√©l√©rer les calculs pour ce tutoriel, nous n‚Äôallons consid√©rer que\n30% des transactions observ√©es sur chaque d√©partement.\nVoici le code pour le faire:\nmutations2 = mutations2.groupby(\"dep\").sample(frac=0.1, random_state=123)\nAvec la fonction ad√©quate de Scikit, faire un d√©coupage de mutations2\nen train et test sets\nen suivant les consignes suivantes:\n\n20% des donn√©es dans l‚Äô√©chantillon de test ;\nL‚Äô√©chantillonnage est stratifi√© par d√©partements ;\nPour avoir des r√©sultats reproductibles, choisir une racine √©gale √† 123.",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#d√©finition-du-premier-pipeline",
    "href": "content/modelisation/6_pipeline.html#d√©finition-du-premier-pipeline",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "3.2 D√©finition du premier pipeline",
    "text": "3.2 D√©finition du premier pipeline\nPour commencer, nous allons fixer la taille des arbres de d√©cision avec\nl‚Äôhyperparam√®tre max_depth = 2.\nNotre pipeline va int√©grer les √©tapes suivantes :\n\nPreprocessing :\n\nLes variables num√©riques vont √™tre standardis√©es avec un StandardScaler.\nPour cela, nous allons utiliser la liste numeric_features d√©finie pr√©c√©demment.\nLes variables cat√©gorielles vont √™tre explos√©es avec un one hot encoding\n(m√©thode OneHotEncoder de scikit)\nPour cela, nous allons utiliser la liste categorical_features\n\nRandom forest : nous allons appliquer l‚Äôestimateur ad hoc de Scikit.\n\n\n\n Exercice 2 : Construction d'un premier pipeline formel\n\nInitialiser un random forest de profondeur 2. Fixer la racine √† 123 pour avoir des r√©sultats reproductibles.\nLa premi√®re √©tape du pipeline (nommer cette couche preprocessor) consiste √† appliquer les √©tapes de preprocessing adapt√©es √† chaque type de variables:\n\nPour les variables num√©riques, appliquer une √©tape d‚Äôimputation √† la moyenne puis standardiser celles-ci\nPour les variables cat√©gorielles, appliquer un one hot encoding\n\nAppliquer comme couche de sortie le mod√®le d√©fini plus t√¥t.\n\nüí° Il est recommand√© de s‚Äôaider de la documentation de Scikit. Si vous avez besoin d‚Äôun indice suppl√©mentaire, consulter le pipeline pr√©sent√© ci-dessous.\n\n\nA l‚Äôissue de cet exercice, nous devrions obtenir le pipeline suivant.\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiNot fittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))]) ¬†preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('pipeline',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer()),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['Nombre_de_lots', 'Nombre_pieces_principales',\n                                  'surface']),\n                                ('onehotencoder',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['dep', 'Code_type_local', 'month'])]) pipeline['Nombre_de_lots', 'Nombre_pieces_principales', 'surface'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder['dep', 'Code_type_local', 'month'] ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor(max_depth=2, random_state=123) \n\n\nNous avons construit ce pipeline sous forme de couches successives. La couche\nrandomforest prendra automatiquement le r√©sultat de la couche preprocessor\nen input. La couche features permet d‚Äôintroduire de mani√®re relativement\nsimple (quand on a les bonnes m√©thodes) la complexit√© du preprocessing\nsur donn√©es r√©elles dont les types divergent.\nA cette √©tape, rien n‚Äôa encore √©t√© estim√©.\nC‚Äôest tr√®s simple √† mettre en oeuvre\navec un pipeline.\n\n\n Exercice 3 : Mise en oeuvre du pipeline\n\nEstimer les param√®tres du mod√®le sur le jeu d‚Äôentra√Ænement\nObserver la mani√®re dont les donn√©es d‚Äôentra√Ænement sont transform√©es\npar l‚Äô√©tape de preprocessing avec les m√©thodes ad√©quates sur 4 observations de X_train\ntir√©es al√©atoirement\nUtiliser ce mod√®le pour pr√©dire le prix sur l‚Äô√©chantillon de test. A partir de ces quelques pr√©dictions,\nquel semble √™tre le probl√®me ?\nObserver la mani√®re dont ce preprocessing peut s‚Äôappliquer sur deux exemples fictifs :\n\nUn appartement (code_type_local = 2) dans le 75, vendu au mois de mai, unique lot de la vente avec 3 pi√®ces, faisant 75m¬≤ ;\nUne maison (code_type_local = 1) dans le 06, vendue en d√©cembre, dans une transaction avec 2 lots. La surface compl√®te est de 180m¬≤ et le bien comporte 6 pi√®ces.\n\nD√©duire sur ces deux exemples le prix pr√©dit par le mod√®le.\nCalculer et interpr√©ter le RMSE sur l‚Äô√©chantillon de test. Ce mod√®le est-il satisfaisant ?\n\n\n\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))]) ¬†preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('pipeline',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer()),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['Nombre_de_lots', 'Nombre_pieces_principales',\n                                  'surface']),\n                                ('onehotencoder',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['dep', 'Code_type_local', 'month'])]) pipeline['Nombre_de_lots', 'Nombre_pieces_principales', 'surface'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder['dep', 'Code_type_local', 'month'] ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor(max_depth=2, random_state=123) \n\n\n\n\narray([282871.63598981, 301165.65351098, 301165.65351098, ...,\n       282871.63598981, 471048.40037679, 282871.63598981])\n\n\n\n\narray([642280.20111587, 282871.63598981])\n\n\n\n\n433497.6437239088",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#variable-importance",
    "href": "content/modelisation/6_pipeline.html#variable-importance",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "3.3 Variable importance",
    "text": "3.3 Variable importance\nLes pr√©dictions semblent avoir une assez faible variance, comme si des variables\nde seuils intervenaient. Nous allons donc devoir essayer de comprendre pourquoi.\nLa ‚Äúvariable importance‚Äù\nse r√©f√®re √† la mesure de l‚Äôinfluence de chaque variable d‚Äôentr√©e sur la performance du mod√®le.\nL‚Äôimpuret√© fait r√©f√©rence √† l‚Äôincertitude ou √† l‚Äôentropie pr√©sente dans un ensemble de donn√©es.\nDans le contexte des random forest, cette mesure est souvent calcul√©e en √©valuant la r√©duction moyenne de l‚Äôimpuret√© des n≈ìuds de d√©cision caus√©e par une variable sp√©cifique.\nCette approche permet de quantifier l‚Äôimportance des variables dans le processus de prise de d√©cision du mod√®le, offrant ainsi des intuitions sur les caract√©ristiques les plus informatives pour la pr√©diction (plus de d√©tails sur ce blog).\nOn ne va repr√©senter, parmi notre ensemble important de colonnes, que celles\nqui ont une importance non nulle.\n\n\n Exercice 4 : Compr√©hension du mod√®le\n\nR√©cup√©rer la feature importance directement depuis la couche adapt√©e de votre pipeline\nUtiliser le code suivant pour calculer l‚Äôintervalle de confiance de cette mesure d‚Äôimportance:\n\nstd = np.std(\n    [tree.feature_importances_ for tree in pipe[\"randomforest\"].estimators_], axis=0\n)\n\nRepr√©senter les variables d‚Äôimportance non nulle. Qu‚Äôen concluez-vous ?\n\n\n\nLe graphique d‚Äôimportance des variables que vous devriez obtenir √† l‚Äôissue\nde cet exercice est le suivant.\n\n\n\n\n\n\n\n\n\n\n\n&lt;Axes: title={'center': 'Feature importances using MDI'}, ylabel='Mean decrease in impurity'&gt;\n\n\nLes statistiques obtenues par le biais de cette variable importance\nsont un peu rudimentaires mais permettent d√©j√† de comprendre\nle probl√®me de notre mod√®le.\nOn voit donc que deux de nos variables d√©terminantes sont des effets fixes\ng√©ographiques (qui servent √† ajuster de la diff√©rence de prix entre\nParis et les Hauts de Seine et le reste de la France), une autre variable\nest un effet fixe type de bien. Les deux variables qui pourraient introduire\nde la variabilit√©, √† savoir la surface et, dans une moindre mesure, le\nnombre de lots, ont une importance moindre.\n\n\n Note\nId√©alement, on utiliserait Yellowbrick pour repr√©senter l‚Äôimportance des variables\nMais en l‚Äô√©tat actuel du pipeline on a beaucoup de variables dont le poids\nest nul qui viennent polluer la visualisation. Vous pouvez\nconsulter la\ndocumentation de Yellowbrick sur ce sujet\n\n\nLes pr√©dictions peuvent nous sugg√©rer √©galement\nqu‚Äôil y a un probl√®me:\n\ncompar = pd.DataFrame([y_test, pipe.predict(X_test)]).T\ncompar.columns = [\"obs\", \"pred\"]\ncompar[\"diff\"] = compar.obs - compar.pred\n\ng = sns.relplot(data=compar, x=\"obs\", y=\"pred\", color=\"royalblue\", alpha=0.8)\ng.set(\n    ylim=(0, 2e6),\n    xlim=(0, 2e6),\n    title=\"Evaluating estimation error on test sample\",\n    xlabel=\"Observed values\",\n    ylabel=\"Predicted values\",\n)\ng.ax.axline(xy1=(0, 0), slope=1, color=\"red\", dashes=(5, 2))",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#informations-additionnelles",
    "href": "content/modelisation/6_pipeline.html#informations-additionnelles",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\ne4642ee\n\n\n2023-11-27 17:02:05\n\n\nLino Galiana\n\n\nDeploy ML model as API (#460)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n4960f2b\n\n\n2023-11-22 12:02:32\n\n\nLino Galiana\n\n\nChapitre pipeline scikit sur DVF (#454)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\ned2ddec\n\n\n2022-01-04 13:32:43\n\n\nExpressso\n\n\nretire typo (#212)\n\n\n\n\n66e2837\n\n\n2021-12-24 16:54:45\n\n\nLino Galiana\n\n\nFix a few typos in the new pipeline tutorial (#208)\n\n\n\n\ne94c1c5\n\n\n2021-12-23 21:34:46\n\n\nLino Galiana\n\n\nUn tutoriel sur les pipelines :tada: (#203)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†2.1: Matrice de corr√©lation des variables de surface",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#footnotes",
    "href": "content/modelisation/6_pipeline.html#footnotes",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLes random forest sont l‚Äôune des principales m√©thodes\nensemblistes. Outre cette approche, les plus connues sont\nle bagging (boostrap aggregating) et le boosting\nqui consistent √† choisir la pr√©diction √† privil√©gier\nselon des algorithmes de choix diff√©rens.\nPar exemple le bagging est une technique bas√©e sur le vote majoritaire (Breiman 1996).\nCette technique s‚Äôinspire du bootstrap qui, en √©conom√©trie,\nconsiste √† r√©-estimer sur K sous-√©chantillons\nal√©atoires des donn√©es un estimateur afin d‚Äôen tirer, par exemple, un intervalle\nde confiance empirique √† 95%. Le principe du bagging est le m√™me. On r√©-estime\nK fois notre estimateur (par exemple un arbre de d√©cision) et propose une\nr√®gle d‚Äôagr√©gation pour en tirer une r√®gle moyennis√©e et donc une pr√©diction.\nLe boosting fonctionne selon un principe diff√©rent, bas√© sur\nl‚Äôoptimisation de combinaisons de classifieurs faibles.‚Ü©Ô∏é",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html",
    "href": "content/modelisation/4_featureselection.html",
    "title": "S√©lection de variables : une introduction",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nJusqu‚Äô√† pr√©sent, nous avons suppos√© que les variables utiles √† la pr√©vision du\nvote R√©publicain √©taient connues du mod√©lisateur. Nous n‚Äôavons ainsi exploit√© qu‚Äôune partie\nlimit√©e des variables disponibles dans nos donn√©es. N√©anmoins, outre le fl√©au\ncomputationnel que repr√©senterait la construction d‚Äôun mod√®le avec un grand\nnombre de variables, le choix d‚Äôun nombre restreint de variables\n(mod√®le parcimonieux) limite le risque de sur-apprentissage.\nComment, d√®s lors, choisir le bon nombre de variables et la meilleure\ncombinaison de ces variables ? Il existe de multiples m√©thodes, parmi lesquelles :\nDans ce chapitre, nous allons pr√©senter\nles enjeux principaux de la s√©lection\nde variables par le biais du LASSO.\nNous allons utiliser par la suite les fonctions ou\npackages suivants :\nimport numpy as np\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Lasso\nimport sklearn.metrics\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import lasso_path\nimport seaborn as sns",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#principe-g√©n√©ral",
    "href": "content/modelisation/4_featureselection.html#principe-g√©n√©ral",
    "title": "S√©lection de variables : une introduction",
    "section": "1.1 Principe g√©n√©ral",
    "text": "1.1 Principe g√©n√©ral\nLa classe des mod√®les de feature selection est ainsi tr√®s vaste et regroupe\nun ensemble tr√®s diverse de mod√®les. Nous allons nous focaliser sur le LASSO\n(Least Absolute Shrinkage and Selection Operator)\nqui est une extension de la r√©gression lin√©aire qui vise √† s√©lectionner des\nmod√®les sparses. Ce type de mod√®le est central dans le champ du\nCompressed sensing (o√π on emploie plut√¥t le terme\nde L1-regularization que de LASSO). Le LASSO est un cas particulier des\nr√©gressions elastic-net dont un autre cas fameux est la r√©gression ridge.\nContrairement √† la r√©gression lin√©aire classique, elles fonctionnent √©galement\ndans un cadre o√π \\(p&gt;N\\), c‚Äôest √† dire o√π le nombre de r√©gresseurs est tr√®s grand puisque sup√©rieur\nau nombre d‚Äôobservations.",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#p√©nalisation",
    "href": "content/modelisation/4_featureselection.html#p√©nalisation",
    "title": "S√©lection de variables : une introduction",
    "section": "1.2 P√©nalisation",
    "text": "1.2 P√©nalisation\nEn adoptant le principe d‚Äôune fonction objectif p√©nalis√©e,\nle LASSO permet de fixer un certain nombre de coefficients √† 0.\nLes variables dont la norme est non nulle passent ainsi le test de s√©lection.\n\n\n Hint\nLe LASSO est un programme d‚Äôoptimisation sous contrainte. On cherche √† trouver l‚Äôestimateur \\(\\beta\\) qui minimise l‚Äôerreur quadratique (r√©gression lin√©aire) sous une contrainte additionnelle r√©gularisant les param√®tres:\n\\[\n\\min_{\\beta} \\frac{1}{2}\\mathbb{E}\\bigg( \\big( X\\beta - y  \\big)^2 \\bigg) \\\\\n\\text{s.t. } \\sum_{j=1}^p |\\beta_j| \\leq t\n\\]\nCe programme se reformule gr√¢ce au Lagrangien est permet ainsi d‚Äôobtenir un programme de minimisation plus maniable :\n\\[\n\\beta^{\\text{LASSO}} = \\arg \\min_{\\beta} \\frac{1}{2}\\mathbb{E}\\bigg( \\big( X\\beta - y  \\big)^2 \\bigg) + \\alpha \\sum_{j=1}^p |\\beta_j| = \\arg \\min_{\\beta} ||y-X\\beta||_{2}^{2} + \\lambda ||\\beta||_1\n\\]\no√π \\(\\lambda\\) est une r√©√©criture de la r√©gularisation pr√©c√©dente qui d√©pend de \\(\\alpha\\). La force de la p√©nalit√© appliqu√©e aux mod√®les non parcimonieux d√©pend de ce param√®tre.",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#premi√®re-r√©gression-lasso",
    "href": "content/modelisation/4_featureselection.html#premi√®re-r√©gression-lasso",
    "title": "S√©lection de variables : une introduction",
    "section": "1.3 Premi√®re r√©gression LASSO",
    "text": "1.3 Premi√®re r√©gression LASSO\nComme nous cherchons √† trouver les\nmeilleurs pr√©dicteurs du vote R√©publicain,\nnous allons retirer les variables\nqui sont d√©rivables directement de celles-ci: les scores des concurrents !\n\nimport pandas as pd\n\ndf2 = pd.DataFrame(votes.drop(columns=\"geometry\"))\ndf2 = df2.loc[\n    :,\n    ~df2.columns.str.endswith(\n        (\"_democrat\", \"_green\", \"_other\", \"winner\", \"per_point_diff\", \"per_dem\")\n    ),\n]\n\n\ndf2 = df2.loc[:, ~df2.columns.duplicated()]\n\nDans cet exercice, nous utiliserons\n√©galement une fonction pour extraire\nles variables s√©lectionn√©es par le LASSO,\nla voici\n\n\nFonction pour r√©cup√©rer les variables valid√©es par l‚Äô√©tape de s√©lection\nfrom sklearn.linear_model import Lasso\nfrom sklearn.pipeline import Pipeline\n\n\ndef extract_features_selected(\n    lasso: Pipeline, preprocessing_step_name: str = \"preprocess\"\n) -&gt; pd.Series:\n    \"\"\"\n    Extracts selected features based on the coefficients obtained from Lasso regression.\n\n    Parameters:\n    - lasso (Pipeline): The scikit-learn pipeline containing a trained Lasso regression model.\n    - preprocessing_step_name (str): The name of the preprocessing step in the pipeline. Default is 'preprocess'.\n\n    Returns:\n    - pd.Series: A Pandas Series containing selected features with non-zero coefficients.\n    \"\"\"\n    # Check if lasso object is provided\n    if not isinstance(lasso, Pipeline):\n        raise ValueError(\"The provided lasso object is not a scikit-learn pipeline.\")\n\n    # Extract the final transformer from the pipeline\n    lasso_model = lasso[-1]\n\n    # Check if lasso_model is a Lasso regression model\n    if not isinstance(lasso_model, Lasso):\n        raise ValueError(\n            \"The final step of the pipeline is not a Lasso regression model.\"\n        )\n\n    # Check if lasso model has 'coef_' attribute\n    if not hasattr(lasso_model, \"coef_\"):\n        raise ValueError(\n            \"The provided Lasso regression model does not have 'coef_' attribute. \"\n            \"Make sure it is a trained Lasso regression model.\"\n        )\n\n    # Get feature names from the preprocessing step\n    features_preprocessing = lasso[preprocessing_step_name].get_feature_names_out()\n\n    # Extract selected features based on non-zero coefficients\n    features_selec = pd.Series(features_preprocessing[np.abs(lasso_model.coef_) &gt; 0])\n\n    return features_selec\n\n\n\n\n Exercice 1 : Premier LASSO\nOn cherche toujours √† pr√©dire la variable per_gop. Avant de faire notre estimation, nous allons cr√©er certains objets interm√©diaires qui seront utilis√©s pour\nd√©finir notre pipeline:\n\nDans notre DataFrame, remplacer les valeurs infinies par des NaN.\nCr√©ez un √©chantillon d‚Äôentra√Ænement et un √©chantillon test.\n\nMaintenant nous pouvons passer au coeur de la d√©finition de notre pipeline.\nCet exemple pourra servir de source\nd‚Äôinspiration, ainsi que celui-ci.\n\nCr√©er en premier lieu les √©tapes\nde preprocessing pour notre mod√®le.\nPour cela, il est d‚Äôusage de s√©parer les √©tapes appliqu√©es aux variables num√©riques continues des autres variables, dites\ncat√©gorielles.\n\n\nPour les variables num√©riques, imputer √† la moyenne puis effectuer une standardisation ;\nPour les variables cat√©gorielles, les techniques de r√©gression lin√©aires impliquent d‚Äôutiliser une expansion par one hot encoding. Avant de faire ce one hot encoding, faire une imputation par valeur la plus fr√©quente.\n\n\nFinaliser le pipeline en ajoutant l‚Äô√©tape d‚Äôestimation puis estimer un mod√®le LASSO p√©nalis√© avec \\(\\alpha = 0.1\\).\n\nEn supposant que votre pipeline soit dans un objet nomm√© pipeline et que la derni√®re √©tape\nest nomm√©e model, vous pouvez\ndirectement acc√©der √† cette √©tape en utilisant l‚Äôobjet pipeline['model']\n\nAfficher les valeurs des coefficients. Quelles variables ont une valeur non nulle ?\nMontrer que les variables s√©lectionn√©es sont parfois tr√®s corr√©l√©es.\nComparer la performance de ce mod√®le parcimonieux avec celle d‚Äôun mod√®le avec plus de variables\n\n\n\nAide pour la question 1\n\n# Remplacer les infinis par des NaN\ndf2.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n\n\nAide pour la question 3\n\nLa d√©finition d‚Äôun pipeline\nsuit la structure suivante,\nnumeric_pipeline = Pipeline(steps=[\n    ('impute', #definir la methode d'imputation ici\n     ),\n    ('scale', #definir la m√©thode de standardisation ici\n    )\n])\n\ncategorical_pipeline = #adapter le template\n\n# a vous de d√©finir en amont numerical_features et categorical_features\npreprocessor = ColumnTransformer(transformers=[\n    ('number', numeric_pipeline, numerical_features),\n    ('category', categorical_pipeline, categorical_features)\n])\n\n\n\nLe pipeline de preprocessing (question 3) prend la forme suivante:\n\n\nColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†ColumnTransformer?Documentation for ColumnTransformeriNot fittedColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])]) number['ALAND', 'AWATER', 'votes_gop', 'votes_dem', 'total_votes', 'diff', 'FIPS_y', 'Rural-urban_Continuum Code_2003', 'Rural-urban_Continuum Code_2013', 'Urban_Influence_Code_2003', 'Urban_Influence_Code_2013', 'Economic_typology_2015', 'CENSUS_2010_POP', 'ESTIMATES_BASE_2010', 'POP_ESTIMATE_2010', 'POP_ESTIMATE_2011', 'POP_ESTIMATE_2012', 'POP_ESTIMATE_2013', 'POP_ESTIMATE_2014', 'POP_ESTIMATE_2015', 'POP_ESTIMATE_2016', 'POP_ESTIMATE_2017', 'POP_ESTIMATE_2018', 'POP_ESTIMATE_2019', 'N_POP_CHG_2010', 'N_POP_CHG_2011', 'N_POP_CHG_2012', 'N_POP_CHG_2013', 'N_POP_CHG_2014', 'N_POP_CHG_2015', 'N_POP_CHG_2016', 'N_POP_CHG_2017', 'N_POP_CHG_2018', 'N_POP_CHG_2019', 'Births_2010', 'Births_2011', 'Births_2012', 'Births_2013', 'Births_2014', 'Births_2015', 'Births_2016', 'Births_2017', 'Births_2018', 'Births_2019', 'Deaths_2010', 'Deaths_2011', 'Deaths_2012', 'Deaths_2013', 'Deaths_2014', 'Deaths_2015', 'Deaths_2016', 'Deaths_2017', 'Deaths_2018', 'Deaths_2019', 'NATURAL_INC_2010', 'NATURAL_INC_2011', 'NATURAL_INC_2012', 'NATURAL_INC_2013', 'NATURAL_INC_2014', 'NATURAL_INC_2015', 'NATURAL_INC_2016', 'NATURAL_INC_2017', 'NATURAL_INC_2018', 'NATURAL_INC_2019', 'INTERNATIONAL_MIG_2010', 'INTERNATIONAL_MIG_2011', 'INTERNATIONAL_MIG_2012', 'INTERNATIONAL_MIG_2013', 'INTERNATIONAL_MIG_2014', 'INTERNATIONAL_MIG_2015', 'INTERNATIONAL_MIG_2016', 'INTERNATIONAL_MIG_2017', 'INTERNATIONAL_MIG_2018', 'INTERNATIONAL_MIG_2019', 'DOMESTIC_MIG_2010', 'DOMESTIC_MIG_2011', 'DOMESTIC_MIG_2012', 'DOMESTIC_MIG_2013', 'DOMESTIC_MIG_2014', 'DOMESTIC_MIG_2015', 'DOMESTIC_MIG_2016', 'DOMESTIC_MIG_2017', 'DOMESTIC_MIG_2018', 'DOMESTIC_MIG_2019', 'NET_MIG_2010', 'NET_MIG_2011', 'NET_MIG_2012', 'NET_MIG_2013', 'NET_MIG_2014', 'NET_MIG_2015', 'NET_MIG_2016', 'NET_MIG_2017', 'NET_MIG_2018', 'NET_MIG_2019', 'RESIDUAL_2010', 'RESIDUAL_2011', 'RESIDUAL_2012', 'RESIDUAL_2013', 'RESIDUAL_2014', 'RESIDUAL_2015', 'RESIDUAL_2016', 'RESIDUAL_2017', 'RESIDUAL_2018', 'RESIDUAL_2019', 'GQ_ESTIMATES_BASE_2010', 'GQ_ESTIMATES_2010', 'GQ_ESTIMATES_2011', 'GQ_ESTIMATES_2012', 'GQ_ESTIMATES_2013', 'GQ_ESTIMATES_2014', 'GQ_ESTIMATES_2015', 'GQ_ESTIMATES_2016', 'GQ_ESTIMATES_2017', 'GQ_ESTIMATES_2018', 'GQ_ESTIMATES_2019', 'R_birth_2011', 'R_birth_2012', 'R_birth_2013', 'R_birth_2014', 'R_birth_2015', 'R_birth_2016', 'R_birth_2017', 'R_birth_2018', 'R_birth_2019', 'R_death_2011', 'R_death_2012', 'R_death_2013', 'R_death_2014', 'R_death_2015', 'R_death_2016', 'R_death_2017', 'R_death_2018', 'R_death_2019', 'R_NATURAL_INC_2011', 'R_NATURAL_INC_2012', 'R_NATURAL_INC_2013', 'R_NATURAL_INC_2014', 'R_NATURAL_INC_2015', 'R_NATURAL_INC_2016', 'R_NATURAL_INC_2017', 'R_NATURAL_INC_2018', 'R_NATURAL_INC_2019', 'R_INTERNATIONAL_MIG_2011', 'R_INTERNATIONAL_MIG_2012', 'R_INTERNATIONAL_MIG_2013', 'R_INTERNATIONAL_MIG_2014', 'R_INTERNATIONAL_MIG_2015', 'R_INTERNATIONAL_MIG_2016', 'R_INTERNATIONAL_MIG_2017', 'R_INTERNATIONAL_MIG_2018', 'R_INTERNATIONAL_MIG_2019', 'R_DOMESTIC_MIG_2011', 'R_DOMESTIC_MIG_2012', 'R_DOMESTIC_MIG_2013', 'R_DOMESTIC_MIG_2014', 'R_DOMESTIC_MIG_2015', 'R_DOMESTIC_MIG_2016', 'R_DOMESTIC_MIG_2017', 'R_DOMESTIC_MIG_2018', 'R_DOMESTIC_MIG_2019', 'R_NET_MIG_2011', 'R_NET_MIG_2012', 'R_NET_MIG_2013', 'R_NET_MIG_2014', 'R_NET_MIG_2015', 'R_NET_MIG_2016', 'R_NET_MIG_2017', 'R_NET_MIG_2018', 'R_NET_MIG_2019', '2003 Rural-urban Continuum Code', '2003 Urban Influence Code', '2013 Rural-urban Continuum Code', '2013 Urban Influence Code', 'Less than a high school diploma, 1970', 'High school diploma only, 1970', 'Some college (1-3 years), 1970', 'Four years of college or higher, 1970', 'Percent of adults with less than a high school diploma, 1970', 'Percent of adults with a high school diploma only, 1970', 'Percent of adults completing some college (1-3 years), 1970', 'Percent of adults completing four years of college or higher, 1970', 'Less than a high school diploma, 1980', 'High school diploma only, 1980', 'Some college (1-3 years), 1980', 'Four years of college or higher, 1980', 'Percent of adults with less than a high school diploma, 1980', 'Percent of adults with a high school diploma only, 1980', 'Percent of adults completing some college (1-3 years), 1980', 'Percent of adults completing four years of college or higher, 1980', 'Less than a high school diploma, 1990', 'High school diploma only, 1990', \"Some college or associate's degree, 1990\", \"Bachelor's degree or higher, 1990\", 'Percent of adults with less than a high school diploma, 1990', 'Percent of adults with a high school diploma only, 1990', \"Percent of adults completing some college or associate's degree, 1990\", \"Percent of adults with a bachelor's degree or higher, 1990\", 'Less than a high school diploma, 2000', 'High school diploma only, 2000', \"Some college or associate's degree, 2000\", \"Bachelor's degree or higher, 2000\", 'Percent of adults with less than a high school diploma, 2000', 'Percent of adults with a high school diploma only, 2000', \"Percent of adults completing some college or associate's degree, 2000\", \"Percent of adults with a bachelor's degree or higher, 2000\", 'Less than a high school diploma, 2015-19', 'High school diploma only, 2015-19', \"Some college or associate's degree, 2015-19\", \"Bachelor's degree or higher, 2015-19\", 'Percent of adults with less than a high school diploma, 2015-19', 'Percent of adults with a high school diploma only, 2015-19', \"Percent of adults completing some college or associate's degree, 2015-19\", \"Percent of adults with a bachelor's degree or higher, 2015-19\", 'Rural_urban_continuum_code_2013', 'Urban_influence_code_2013', 'Metro_2013', 'Civilian_labor_force_2000', 'Employed_2000', 'Unemployed_2000', 'Unemployment_rate_2000', 'Civilian_labor_force_2001', 'Employed_2001', 'Unemployed_2001', 'Unemployment_rate_2001', 'Civilian_labor_force_2002', 'Employed_2002', 'Unemployed_2002', 'Unemployment_rate_2002', 'Civilian_labor_force_2003', 'Employed_2003', 'Unemployed_2003', 'Unemployment_rate_2003', 'Civilian_labor_force_2004', 'Employed_2004', 'Unemployed_2004', 'Unemployment_rate_2004', 'Civilian_labor_force_2005', 'Employed_2005', 'Unemployed_2005', 'Unemployment_rate_2005', 'Civilian_labor_force_2006', 'Employed_2006', 'Unemployed_2006', 'Unemployment_rate_2006', 'Civilian_labor_force_2007', 'Employed_2007', 'Unemployed_2007', 'Unemployment_rate_2007', 'Civilian_labor_force_2008', 'Employed_2008', 'Unemployed_2008', 'Unemployment_rate_2008', 'Civilian_labor_force_2009', 'Employed_2009', 'Unemployed_2009', 'Unemployment_rate_2009', 'Civilian_labor_force_2010', 'Employed_2010', 'Unemployed_2010', 'Unemployment_rate_2010', 'Civilian_labor_force_2011', 'Employed_2011', 'Unemployed_2011', 'Unemployment_rate_2011', 'Civilian_labor_force_2012', 'Employed_2012', 'Unemployed_2012', 'Unemployment_rate_2012', 'Civilian_labor_force_2013', 'Employed_2013', 'Unemployed_2013', 'Unemployment_rate_2013', 'Civilian_labor_force_2014', 'Employed_2014', 'Unemployed_2014', 'Unemployment_rate_2014', 'Civilian_labor_force_2015', 'Employed_2015', 'Unemployed_2015', 'Unemployment_rate_2015', 'Civilian_labor_force_2016', 'Employed_2016', 'Unemployed_2016', 'Unemployment_rate_2016', 'Civilian_labor_force_2017', 'Employed_2017', 'Unemployed_2017', 'Unemployment_rate_2017', 'Civilian_labor_force_2018', 'Employed_2018', 'Unemployed_2018', 'Unemployment_rate_2018', 'Civilian_labor_force_2019', 'Employed_2019', 'Unemployed_2019', 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Med_HH_Income_Percent_of_State_Total_2019', 'Rural-urban_Continuum_Code_2003', 'Rural-urban_Continuum_Code_2013', 'POVALL_2019', 'CI90LBALL_2019', 'CI90UBALL_2019', 'PCTPOVALL_2019', 'CI90LBALLP_2019', 'CI90UBALLP_2019', 'POV017_2019', 'CI90LB017_2019', 'CI90UB017_2019', 'PCTPOV017_2019', 'CI90LB017P_2019', 'CI90UB017P_2019', 'POV517_2019', 'CI90LB517_2019', 'CI90UB517_2019', 'PCTPOV517_2019', 'CI90LB517P_2019', 'CI90UB517P_2019', 'MEDHHINC_2019', 'CI90LBINC_2019', 'CI90UBINC_2019', 'POV04_2019', 'CI90LB04_2019', 'CI90UB04_2019', 'PCTPOV04_2019', 'CI90LB04P_2019', 'CI90UB04P_2019', 'candidatevotes_2000_republican', 'candidatevotes_2004_republican', 'candidatevotes_2008_republican', 'candidatevotes_2012_republican', 'candidatevotes_2016_republican', 'share_2000_republican', 'share_2004_republican', 'share_2008_republican', 'share_2012_republican', 'share_2016_republican'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() category['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'FIPS_x', 'state_name', 'county_fips', 'county_name', 'State', 'Area_Name', 'FIPS'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) \n\n\n\n\n/opt/mamba/lib/python3.11/site-packages/sklearn/impute/_base.py:577: UserWarning:\n\nSkipping features without any observed values: ['POV04_2019' 'CI90LB04_2019' 'CI90UB04_2019' 'PCTPOV04_2019'\n 'CI90LB04P_2019' 'CI90UB04P_2019']. At least one non-missing value is needed for imputation with strategy='mean'.\n\n\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))]) ¬†preprocess: ColumnTransformer?Documentation for preprocess: ColumnTransformerColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])]) number['ALAND', 'AWATER', 'votes_gop', 'votes_dem', 'total_votes', 'diff', 'FIPS_y', 'Rural-urban_Continuum Code_2003', 'Rural-urban_Continuum Code_2013', 'Urban_Influence_Code_2003', 'Urban_Influence_Code_2013', 'Economic_typology_2015', 'CENSUS_2010_POP', 'ESTIMATES_BASE_2010', 'POP_ESTIMATE_2010', 'POP_ESTIMATE_2011', 'POP_ESTIMATE_2012', 'POP_ESTIMATE_2013', 'POP_ESTIMATE_2014', 'POP_ESTIMATE_2015', 'POP_ESTIMATE_2016', 'POP_ESTIMATE_2017', 'POP_ESTIMATE_2018', 'POP_ESTIMATE_2019', 'N_POP_CHG_2010', 'N_POP_CHG_2011', 'N_POP_CHG_2012', 'N_POP_CHG_2013', 'N_POP_CHG_2014', 'N_POP_CHG_2015', 'N_POP_CHG_2016', 'N_POP_CHG_2017', 'N_POP_CHG_2018', 'N_POP_CHG_2019', 'Births_2010', 'Births_2011', 'Births_2012', 'Births_2013', 'Births_2014', 'Births_2015', 'Births_2016', 'Births_2017', 'Births_2018', 'Births_2019', 'Deaths_2010', 'Deaths_2011', 'Deaths_2012', 'Deaths_2013', 'Deaths_2014', 'Deaths_2015', 'Deaths_2016', 'Deaths_2017', 'Deaths_2018', 'Deaths_2019', 'NATURAL_INC_2010', 'NATURAL_INC_2011', 'NATURAL_INC_2012', 'NATURAL_INC_2013', 'NATURAL_INC_2014', 'NATURAL_INC_2015', 'NATURAL_INC_2016', 'NATURAL_INC_2017', 'NATURAL_INC_2018', 'NATURAL_INC_2019', 'INTERNATIONAL_MIG_2010', 'INTERNATIONAL_MIG_2011', 'INTERNATIONAL_MIG_2012', 'INTERNATIONAL_MIG_2013', 'INTERNATIONAL_MIG_2014', 'INTERNATIONAL_MIG_2015', 'INTERNATIONAL_MIG_2016', 'INTERNATIONAL_MIG_2017', 'INTERNATIONAL_MIG_2018', 'INTERNATIONAL_MIG_2019', 'DOMESTIC_MIG_2010', 'DOMESTIC_MIG_2011', 'DOMESTIC_MIG_2012', 'DOMESTIC_MIG_2013', 'DOMESTIC_MIG_2014', 'DOMESTIC_MIG_2015', 'DOMESTIC_MIG_2016', 'DOMESTIC_MIG_2017', 'DOMESTIC_MIG_2018', 'DOMESTIC_MIG_2019', 'NET_MIG_2010', 'NET_MIG_2011', 'NET_MIG_2012', 'NET_MIG_2013', 'NET_MIG_2014', 'NET_MIG_2015', 'NET_MIG_2016', 'NET_MIG_2017', 'NET_MIG_2018', 'NET_MIG_2019', 'RESIDUAL_2010', 'RESIDUAL_2011', 'RESIDUAL_2012', 'RESIDUAL_2013', 'RESIDUAL_2014', 'RESIDUAL_2015', 'RESIDUAL_2016', 'RESIDUAL_2017', 'RESIDUAL_2018', 'RESIDUAL_2019', 'GQ_ESTIMATES_BASE_2010', 'GQ_ESTIMATES_2010', 'GQ_ESTIMATES_2011', 'GQ_ESTIMATES_2012', 'GQ_ESTIMATES_2013', 'GQ_ESTIMATES_2014', 'GQ_ESTIMATES_2015', 'GQ_ESTIMATES_2016', 'GQ_ESTIMATES_2017', 'GQ_ESTIMATES_2018', 'GQ_ESTIMATES_2019', 'R_birth_2011', 'R_birth_2012', 'R_birth_2013', 'R_birth_2014', 'R_birth_2015', 'R_birth_2016', 'R_birth_2017', 'R_birth_2018', 'R_birth_2019', 'R_death_2011', 'R_death_2012', 'R_death_2013', 'R_death_2014', 'R_death_2015', 'R_death_2016', 'R_death_2017', 'R_death_2018', 'R_death_2019', 'R_NATURAL_INC_2011', 'R_NATURAL_INC_2012', 'R_NATURAL_INC_2013', 'R_NATURAL_INC_2014', 'R_NATURAL_INC_2015', 'R_NATURAL_INC_2016', 'R_NATURAL_INC_2017', 'R_NATURAL_INC_2018', 'R_NATURAL_INC_2019', 'R_INTERNATIONAL_MIG_2011', 'R_INTERNATIONAL_MIG_2012', 'R_INTERNATIONAL_MIG_2013', 'R_INTERNATIONAL_MIG_2014', 'R_INTERNATIONAL_MIG_2015', 'R_INTERNATIONAL_MIG_2016', 'R_INTERNATIONAL_MIG_2017', 'R_INTERNATIONAL_MIG_2018', 'R_INTERNATIONAL_MIG_2019', 'R_DOMESTIC_MIG_2011', 'R_DOMESTIC_MIG_2012', 'R_DOMESTIC_MIG_2013', 'R_DOMESTIC_MIG_2014', 'R_DOMESTIC_MIG_2015', 'R_DOMESTIC_MIG_2016', 'R_DOMESTIC_MIG_2017', 'R_DOMESTIC_MIG_2018', 'R_DOMESTIC_MIG_2019', 'R_NET_MIG_2011', 'R_NET_MIG_2012', 'R_NET_MIG_2013', 'R_NET_MIG_2014', 'R_NET_MIG_2015', 'R_NET_MIG_2016', 'R_NET_MIG_2017', 'R_NET_MIG_2018', 'R_NET_MIG_2019', '2003 Rural-urban Continuum Code', '2003 Urban Influence Code', '2013 Rural-urban Continuum Code', '2013 Urban Influence Code', 'Less than a high school diploma, 1970', 'High school diploma only, 1970', 'Some college (1-3 years), 1970', 'Four years of college or higher, 1970', 'Percent of adults with less than a high school diploma, 1970', 'Percent of adults with a high school diploma only, 1970', 'Percent of adults completing some college (1-3 years), 1970', 'Percent of adults completing four years of college or higher, 1970', 'Less than a high school diploma, 1980', 'High school diploma only, 1980', 'Some college (1-3 years), 1980', 'Four years of college or higher, 1980', 'Percent of adults with less than a high school diploma, 1980', 'Percent of adults with a high school diploma only, 1980', 'Percent of adults completing some college (1-3 years), 1980', 'Percent of adults completing four years of college or higher, 1980', 'Less than a high school diploma, 1990', 'High school diploma only, 1990', \"Some college or associate's degree, 1990\", \"Bachelor's degree or higher, 1990\", 'Percent of adults with less than a high school diploma, 1990', 'Percent of adults with a high school diploma only, 1990', \"Percent of adults completing some college or associate's degree, 1990\", \"Percent of adults with a bachelor's degree or higher, 1990\", 'Less than a high school diploma, 2000', 'High school diploma only, 2000', \"Some college or associate's degree, 2000\", \"Bachelor's degree or higher, 2000\", 'Percent of adults with less than a high school diploma, 2000', 'Percent of adults with a high school diploma only, 2000', \"Percent of adults completing some college or associate's degree, 2000\", \"Percent of adults with a bachelor's degree or higher, 2000\", 'Less than a high school diploma, 2015-19', 'High school diploma only, 2015-19', \"Some college or associate's degree, 2015-19\", \"Bachelor's degree or higher, 2015-19\", 'Percent of adults with less than a high school diploma, 2015-19', 'Percent of adults with a high school diploma only, 2015-19', \"Percent of adults completing some college or associate's degree, 2015-19\", \"Percent of adults with a bachelor's degree or higher, 2015-19\", 'Rural_urban_continuum_code_2013', 'Urban_influence_code_2013', 'Metro_2013', 'Civilian_labor_force_2000', 'Employed_2000', 'Unemployed_2000', 'Unemployment_rate_2000', 'Civilian_labor_force_2001', 'Employed_2001', 'Unemployed_2001', 'Unemployment_rate_2001', 'Civilian_labor_force_2002', 'Employed_2002', 'Unemployed_2002', 'Unemployment_rate_2002', 'Civilian_labor_force_2003', 'Employed_2003', 'Unemployed_2003', 'Unemployment_rate_2003', 'Civilian_labor_force_2004', 'Employed_2004', 'Unemployed_2004', 'Unemployment_rate_2004', 'Civilian_labor_force_2005', 'Employed_2005', 'Unemployed_2005', 'Unemployment_rate_2005', 'Civilian_labor_force_2006', 'Employed_2006', 'Unemployed_2006', 'Unemployment_rate_2006', 'Civilian_labor_force_2007', 'Employed_2007', 'Unemployed_2007', 'Unemployment_rate_2007', 'Civilian_labor_force_2008', 'Employed_2008', 'Unemployed_2008', 'Unemployment_rate_2008', 'Civilian_labor_force_2009', 'Employed_2009', 'Unemployed_2009', 'Unemployment_rate_2009', 'Civilian_labor_force_2010', 'Employed_2010', 'Unemployed_2010', 'Unemployment_rate_2010', 'Civilian_labor_force_2011', 'Employed_2011', 'Unemployed_2011', 'Unemployment_rate_2011', 'Civilian_labor_force_2012', 'Employed_2012', 'Unemployed_2012', 'Unemployment_rate_2012', 'Civilian_labor_force_2013', 'Employed_2013', 'Unemployed_2013', 'Unemployment_rate_2013', 'Civilian_labor_force_2014', 'Employed_2014', 'Unemployed_2014', 'Unemployment_rate_2014', 'Civilian_labor_force_2015', 'Employed_2015', 'Unemployed_2015', 'Unemployment_rate_2015', 'Civilian_labor_force_2016', 'Employed_2016', 'Unemployed_2016', 'Unemployment_rate_2016', 'Civilian_labor_force_2017', 'Employed_2017', 'Unemployed_2017', 'Unemployment_rate_2017', 'Civilian_labor_force_2018', 'Employed_2018', 'Unemployed_2018', 'Unemployment_rate_2018', 'Civilian_labor_force_2019', 'Employed_2019', 'Unemployed_2019', 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Med_HH_Income_Percent_of_State_Total_2019', 'Rural-urban_Continuum_Code_2003', 'Rural-urban_Continuum_Code_2013', 'POVALL_2019', 'CI90LBALL_2019', 'CI90UBALL_2019', 'PCTPOVALL_2019', 'CI90LBALLP_2019', 'CI90UBALLP_2019', 'POV017_2019', 'CI90LB017_2019', 'CI90UB017_2019', 'PCTPOV017_2019', 'CI90LB017P_2019', 'CI90UB017P_2019', 'POV517_2019', 'CI90LB517_2019', 'CI90UB517_2019', 'PCTPOV517_2019', 'CI90LB517P_2019', 'CI90UB517P_2019', 'MEDHHINC_2019', 'CI90LBINC_2019', 'CI90UBINC_2019', 'POV04_2019', 'CI90LB04_2019', 'CI90UB04_2019', 'PCTPOV04_2019', 'CI90LB04P_2019', 'CI90UB04P_2019', 'candidatevotes_2000_republican', 'candidatevotes_2004_republican', 'candidatevotes_2008_republican', 'candidatevotes_2012_republican', 'candidatevotes_2016_republican', 'share_2000_republican', 'share_2004_republican', 'share_2008_republican', 'share_2012_republican', 'share_2016_republican'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() category['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'FIPS_x', 'state_name', 'county_fips', 'county_name', 'State', 'Area_Name', 'FIPS'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†Lasso?Documentation for LassoLasso(alpha=0.1) \n\n\nLe pipeline prend la forme suivante, une\nfois finalis√© (question 4):\n\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))]) ¬†preprocess: ColumnTransformer?Documentation for preprocess: ColumnTransformerColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])]) number['ALAND', 'AWATER', 'votes_gop', 'votes_dem', 'total_votes', 'diff', 'FIPS_y', 'Rural-urban_Continuum Code_2003', 'Rural-urban_Continuum Code_2013', 'Urban_Influence_Code_2003', 'Urban_Influence_Code_2013', 'Economic_typology_2015', 'CENSUS_2010_POP', 'ESTIMATES_BASE_2010', 'POP_ESTIMATE_2010', 'POP_ESTIMATE_2011', 'POP_ESTIMATE_2012', 'POP_ESTIMATE_2013', 'POP_ESTIMATE_2014', 'POP_ESTIMATE_2015', 'POP_ESTIMATE_2016', 'POP_ESTIMATE_2017', 'POP_ESTIMATE_2018', 'POP_ESTIMATE_2019', 'N_POP_CHG_2010', 'N_POP_CHG_2011', 'N_POP_CHG_2012', 'N_POP_CHG_2013', 'N_POP_CHG_2014', 'N_POP_CHG_2015', 'N_POP_CHG_2016', 'N_POP_CHG_2017', 'N_POP_CHG_2018', 'N_POP_CHG_2019', 'Births_2010', 'Births_2011', 'Births_2012', 'Births_2013', 'Births_2014', 'Births_2015', 'Births_2016', 'Births_2017', 'Births_2018', 'Births_2019', 'Deaths_2010', 'Deaths_2011', 'Deaths_2012', 'Deaths_2013', 'Deaths_2014', 'Deaths_2015', 'Deaths_2016', 'Deaths_2017', 'Deaths_2018', 'Deaths_2019', 'NATURAL_INC_2010', 'NATURAL_INC_2011', 'NATURAL_INC_2012', 'NATURAL_INC_2013', 'NATURAL_INC_2014', 'NATURAL_INC_2015', 'NATURAL_INC_2016', 'NATURAL_INC_2017', 'NATURAL_INC_2018', 'NATURAL_INC_2019', 'INTERNATIONAL_MIG_2010', 'INTERNATIONAL_MIG_2011', 'INTERNATIONAL_MIG_2012', 'INTERNATIONAL_MIG_2013', 'INTERNATIONAL_MIG_2014', 'INTERNATIONAL_MIG_2015', 'INTERNATIONAL_MIG_2016', 'INTERNATIONAL_MIG_2017', 'INTERNATIONAL_MIG_2018', 'INTERNATIONAL_MIG_2019', 'DOMESTIC_MIG_2010', 'DOMESTIC_MIG_2011', 'DOMESTIC_MIG_2012', 'DOMESTIC_MIG_2013', 'DOMESTIC_MIG_2014', 'DOMESTIC_MIG_2015', 'DOMESTIC_MIG_2016', 'DOMESTIC_MIG_2017', 'DOMESTIC_MIG_2018', 'DOMESTIC_MIG_2019', 'NET_MIG_2010', 'NET_MIG_2011', 'NET_MIG_2012', 'NET_MIG_2013', 'NET_MIG_2014', 'NET_MIG_2015', 'NET_MIG_2016', 'NET_MIG_2017', 'NET_MIG_2018', 'NET_MIG_2019', 'RESIDUAL_2010', 'RESIDUAL_2011', 'RESIDUAL_2012', 'RESIDUAL_2013', 'RESIDUAL_2014', 'RESIDUAL_2015', 'RESIDUAL_2016', 'RESIDUAL_2017', 'RESIDUAL_2018', 'RESIDUAL_2019', 'GQ_ESTIMATES_BASE_2010', 'GQ_ESTIMATES_2010', 'GQ_ESTIMATES_2011', 'GQ_ESTIMATES_2012', 'GQ_ESTIMATES_2013', 'GQ_ESTIMATES_2014', 'GQ_ESTIMATES_2015', 'GQ_ESTIMATES_2016', 'GQ_ESTIMATES_2017', 'GQ_ESTIMATES_2018', 'GQ_ESTIMATES_2019', 'R_birth_2011', 'R_birth_2012', 'R_birth_2013', 'R_birth_2014', 'R_birth_2015', 'R_birth_2016', 'R_birth_2017', 'R_birth_2018', 'R_birth_2019', 'R_death_2011', 'R_death_2012', 'R_death_2013', 'R_death_2014', 'R_death_2015', 'R_death_2016', 'R_death_2017', 'R_death_2018', 'R_death_2019', 'R_NATURAL_INC_2011', 'R_NATURAL_INC_2012', 'R_NATURAL_INC_2013', 'R_NATURAL_INC_2014', 'R_NATURAL_INC_2015', 'R_NATURAL_INC_2016', 'R_NATURAL_INC_2017', 'R_NATURAL_INC_2018', 'R_NATURAL_INC_2019', 'R_INTERNATIONAL_MIG_2011', 'R_INTERNATIONAL_MIG_2012', 'R_INTERNATIONAL_MIG_2013', 'R_INTERNATIONAL_MIG_2014', 'R_INTERNATIONAL_MIG_2015', 'R_INTERNATIONAL_MIG_2016', 'R_INTERNATIONAL_MIG_2017', 'R_INTERNATIONAL_MIG_2018', 'R_INTERNATIONAL_MIG_2019', 'R_DOMESTIC_MIG_2011', 'R_DOMESTIC_MIG_2012', 'R_DOMESTIC_MIG_2013', 'R_DOMESTIC_MIG_2014', 'R_DOMESTIC_MIG_2015', 'R_DOMESTIC_MIG_2016', 'R_DOMESTIC_MIG_2017', 'R_DOMESTIC_MIG_2018', 'R_DOMESTIC_MIG_2019', 'R_NET_MIG_2011', 'R_NET_MIG_2012', 'R_NET_MIG_2013', 'R_NET_MIG_2014', 'R_NET_MIG_2015', 'R_NET_MIG_2016', 'R_NET_MIG_2017', 'R_NET_MIG_2018', 'R_NET_MIG_2019', '2003 Rural-urban Continuum Code', '2003 Urban Influence Code', '2013 Rural-urban Continuum Code', '2013 Urban Influence Code', 'Less than a high school diploma, 1970', 'High school diploma only, 1970', 'Some college (1-3 years), 1970', 'Four years of college or higher, 1970', 'Percent of adults with less than a high school diploma, 1970', 'Percent of adults with a high school diploma only, 1970', 'Percent of adults completing some college (1-3 years), 1970', 'Percent of adults completing four years of college or higher, 1970', 'Less than a high school diploma, 1980', 'High school diploma only, 1980', 'Some college (1-3 years), 1980', 'Four years of college or higher, 1980', 'Percent of adults with less than a high school diploma, 1980', 'Percent of adults with a high school diploma only, 1980', 'Percent of adults completing some college (1-3 years), 1980', 'Percent of adults completing four years of college or higher, 1980', 'Less than a high school diploma, 1990', 'High school diploma only, 1990', \"Some college or associate's degree, 1990\", \"Bachelor's degree or higher, 1990\", 'Percent of adults with less than a high school diploma, 1990', 'Percent of adults with a high school diploma only, 1990', \"Percent of adults completing some college or associate's degree, 1990\", \"Percent of adults with a bachelor's degree or higher, 1990\", 'Less than a high school diploma, 2000', 'High school diploma only, 2000', \"Some college or associate's degree, 2000\", \"Bachelor's degree or higher, 2000\", 'Percent of adults with less than a high school diploma, 2000', 'Percent of adults with a high school diploma only, 2000', \"Percent of adults completing some college or associate's degree, 2000\", \"Percent of adults with a bachelor's degree or higher, 2000\", 'Less than a high school diploma, 2015-19', 'High school diploma only, 2015-19', \"Some college or associate's degree, 2015-19\", \"Bachelor's degree or higher, 2015-19\", 'Percent of adults with less than a high school diploma, 2015-19', 'Percent of adults with a high school diploma only, 2015-19', \"Percent of adults completing some college or associate's degree, 2015-19\", \"Percent of adults with a bachelor's degree or higher, 2015-19\", 'Rural_urban_continuum_code_2013', 'Urban_influence_code_2013', 'Metro_2013', 'Civilian_labor_force_2000', 'Employed_2000', 'Unemployed_2000', 'Unemployment_rate_2000', 'Civilian_labor_force_2001', 'Employed_2001', 'Unemployed_2001', 'Unemployment_rate_2001', 'Civilian_labor_force_2002', 'Employed_2002', 'Unemployed_2002', 'Unemployment_rate_2002', 'Civilian_labor_force_2003', 'Employed_2003', 'Unemployed_2003', 'Unemployment_rate_2003', 'Civilian_labor_force_2004', 'Employed_2004', 'Unemployed_2004', 'Unemployment_rate_2004', 'Civilian_labor_force_2005', 'Employed_2005', 'Unemployed_2005', 'Unemployment_rate_2005', 'Civilian_labor_force_2006', 'Employed_2006', 'Unemployed_2006', 'Unemployment_rate_2006', 'Civilian_labor_force_2007', 'Employed_2007', 'Unemployed_2007', 'Unemployment_rate_2007', 'Civilian_labor_force_2008', 'Employed_2008', 'Unemployed_2008', 'Unemployment_rate_2008', 'Civilian_labor_force_2009', 'Employed_2009', 'Unemployed_2009', 'Unemployment_rate_2009', 'Civilian_labor_force_2010', 'Employed_2010', 'Unemployed_2010', 'Unemployment_rate_2010', 'Civilian_labor_force_2011', 'Employed_2011', 'Unemployed_2011', 'Unemployment_rate_2011', 'Civilian_labor_force_2012', 'Employed_2012', 'Unemployed_2012', 'Unemployment_rate_2012', 'Civilian_labor_force_2013', 'Employed_2013', 'Unemployed_2013', 'Unemployment_rate_2013', 'Civilian_labor_force_2014', 'Employed_2014', 'Unemployed_2014', 'Unemployment_rate_2014', 'Civilian_labor_force_2015', 'Employed_2015', 'Unemployed_2015', 'Unemployment_rate_2015', 'Civilian_labor_force_2016', 'Employed_2016', 'Unemployed_2016', 'Unemployment_rate_2016', 'Civilian_labor_force_2017', 'Employed_2017', 'Unemployed_2017', 'Unemployment_rate_2017', 'Civilian_labor_force_2018', 'Employed_2018', 'Unemployed_2018', 'Unemployment_rate_2018', 'Civilian_labor_force_2019', 'Employed_2019', 'Unemployed_2019', 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Med_HH_Income_Percent_of_State_Total_2019', 'Rural-urban_Continuum_Code_2003', 'Rural-urban_Continuum_Code_2013', 'POVALL_2019', 'CI90LBALL_2019', 'CI90UBALL_2019', 'PCTPOVALL_2019', 'CI90LBALLP_2019', 'CI90UBALLP_2019', 'POV017_2019', 'CI90LB017_2019', 'CI90UB017_2019', 'PCTPOV017_2019', 'CI90LB017P_2019', 'CI90UB017P_2019', 'POV517_2019', 'CI90LB517_2019', 'CI90UB517_2019', 'PCTPOV517_2019', 'CI90LB517P_2019', 'CI90UB517P_2019', 'MEDHHINC_2019', 'CI90LBINC_2019', 'CI90UBINC_2019', 'POV04_2019', 'CI90LB04_2019', 'CI90UB04_2019', 'PCTPOV04_2019', 'CI90LB04P_2019', 'CI90UB04P_2019', 'candidatevotes_2000_republican', 'candidatevotes_2004_republican', 'candidatevotes_2008_republican', 'candidatevotes_2012_republican', 'candidatevotes_2016_republican', 'share_2000_republican', 'share_2004_republican', 'share_2008_republican', 'share_2012_republican', 'share_2016_republican'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() category['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'FIPS_x', 'state_name', 'county_fips', 'county_name', 'State', 'Area_Name', 'FIPS'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†Lasso?Documentation for LassoLasso(alpha=0.1) \n\n\nA l‚Äôissue de la question 5,\nles variables s√©lectionn√©es sont :\nLe mod√®le est assez parcimonieux puisqu‚Äôun sous-√©chantillon de nos\nvariables initiales (d‚Äôautant que nos variables cat√©gorielles\nont √©t√© √©clat√©es en de nombreuses variables\npar le one hot encoding)\n\n\n0                                                 ALAND\n1                                                FIPS_y\n2                                INTERNATIONAL_MIG_2017\n3                                     DOMESTIC_MIG_2014\n4                                     DOMESTIC_MIG_2017\n5                                         RESIDUAL_2010\n6                                         RESIDUAL_2019\n7                                          R_death_2012\n8                                          R_death_2019\n9                                    R_NATURAL_INC_2019\n10                             R_INTERNATIONAL_MIG_2011\n11                                  R_DOMESTIC_MIG_2012\n12    Percent of adults with a bachelor's degree or ...\n13    Percent of adults with a high school diploma o...\n14    Percent of adults with a bachelor's degree or ...\n15    Percent of adults with a bachelor's degree or ...\n16                      Rural_urban_continuum_code_2013\n17                                           Metro_2013\n18                               Unemployment_rate_2002\n19                               Unemployment_rate_2003\n20                               Unemployment_rate_2012\n21                      Rural-urban_Continuum_Code_2003\n22                      Rural-urban_Continuum_Code_2013\n23                                      CI90LB517P_2019\n24                       candidatevotes_2016_republican\n25                                share_2012_republican\n26                                share_2016_republican\ndtype: object\n\n\nCertaines variables font sens, comme les variables d‚Äô√©ducation par exemple. Notamment, un des meilleurs pr√©dicteurs pour le score des R√©publicains en 2020 est‚Ä¶ le score des R√©publicains (et m√©caniquement des d√©mocrates) en 2016 et 2012.\nPar ailleurs, on s√©lectionne des variables redondantes. Une phase plus approfondie de nettoyage des donn√©es serait en r√©alit√© n√©cessaire.\nLe mod√®le parcimonieux est (l√©g√®rement) plus performant:\n\n\n\n\n\n\n\n\nparcimonieux\nnon parcimonieux\n\n\n\n\nRMSE\n2.703622\n2.309011\n\n\nR2\n0.972728\n0.980108\n\n\nNombre de param√®tres\n27.000000\n332.000000\n\n\n\n\n\n\nD‚Äôailleurs, on pourrait d√©j√† remarquer\nque r√©gresser le score de 2020 sur celui\nde 2016 am√®ne d√©j√† √† de tr√®s bonnes\nperformances explicatives, ce qui sugg√®re\nque le vote se comporte comme un processus\nautor√©gressif:\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsmf.ols(\"per_gop ~ share_2016_republican\", data=df2).fit().summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\nper_gop\nR-squared:\n0.968\n\n\nModel:\nOLS\nAdj. R-squared:\n0.968\n\n\nMethod:\nLeast Squares\nF-statistic:\n9.292e+04\n\n\nDate:\nThu, 25 Apr 2024\nProb (F-statistic):\n0.00\n\n\nTime:\n20:27:06\nLog-Likelihood:\n6603.5\n\n\nNo. Observations:\n3107\nAIC:\n-1.320e+04\n\n\nDf Residuals:\n3105\nBIC:\n-1.319e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0109\n0.002\n5.056\n0.000\n0.007\n0.015\n\n\nshare_2016_republican\n1.0101\n0.003\n304.835\n0.000\n1.004\n1.017\n\n\n\n\n\n\nOmnibus:\n2045.232\nDurbin-Watson:\n1.982\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n51553.266\n\n\nSkew:\n2.731\nProb(JB):\n0.00\n\n\nKurtosis:\n22.193\nCond. No.\n9.00\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#informations-additionnelles",
    "href": "content/modelisation/4_featureselection.html#informations-additionnelles",
    "title": "S√©lection de variables : une introduction",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n0b405bc\n\n\n2023-11-27 20:58:37\n\n\nLino Galiana\n\n\nUpdate box lasso\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\ne12187b\n\n\n2023-06-12 10:31:40\n\n\nLino Galiana\n\n\nFeature selection deprecated functions (#363)\n\n\n\n\nf5ad021\n\n\n2022-11-15 17:40:16\n\n\nLino Galiana\n\n\nRelec clustering et lasso (#322)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n7058752\n\n\n2022-03-04 15:35:17\n\n\nLino Galiana\n\n\nRelecture Word2Vec (#216)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n8fea62e\n\n\n2020-11-13 11:58:17\n\n\nLino Galiana\n\n\nCorrection de quelques typos partie ML (#85)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html",
    "href": "content/modelisation/2_SVM.html",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nPour ce TP, nous aurons besoin des packages suivants :\nimport pandas as pd\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html#la-m√©thode-des-svm-support-vector-machines",
    "href": "content/modelisation/2_SVM.html#la-m√©thode-des-svm-support-vector-machines",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "0.1 La m√©thode des SVM (Support Vector Machines)",
    "text": "0.1 La m√©thode des SVM (Support Vector Machines)\nL‚Äôune des m√©thodes de machine learning les\nplus utilis√©es en classification sont les SVM (Support Vector Machines).\nIl s‚Äôagit de trouver, dans un syst√®me de projection ad√©quat (noyau ou kernel),\nles param√®tres de l‚Äôhyperplan (en fait d‚Äôun hyperplan √† marges maximales)\ns√©parant les classes de donn√©es :\n\n\n\n Formalisation math√©matique\nLes SVM sont l‚Äôune des m√©thodes de machine learning les plus intuitives\ndu fait de l‚Äôinterpr√©tation g√©om√©trique simple de la m√©thode. Il s‚Äôagit\naussi d‚Äôun des algorithmes de machine learning √† la formalisation\nla moins complexe pour les praticiens ayant des notions en statistique\ntraditionnelle. Cette bo√Æte revient dessus. N√©anmoins,\ncelle-ci n‚Äôest pas n√©cessaire √† la compr√©hension du chapitre.\nEn machine learning, plus que les d√©tails math√©matiques, l‚Äôimportant\nest d‚Äôavoir des intuitions.\nL‚Äôobjectif des SVM est, rappelons-le, de trouver un hyperplan qui permette\nde s√©parer les diff√©rentes classes au mieux. Par exemple, dans un espace\n√† deux dimensions, il s‚Äôagit de trouver une droite avec des marges\nqui permette de s√©parer au mieux l‚Äôespace en partie avec\ndes labels homog√®nes.\nOn peut, sans perdre de g√©n√©ralit√©,\nsupposer que le probl√®me consiste √† supposer l‚Äôexistence d‚Äôune loi de probabilit√© \\(\\mathbb{P}(x,y)\\) (\\(\\mathbb{P} \\to \\{-1,1\\}\\)) qui est inconnue. Le probl√®me de discrimination\nvise √† construire un estimateur de la fonction de d√©cision id√©ale qui minimise la probabilit√© d‚Äôerreur, autrement dit\n\\[\n\\theta = \\arg\\min_\\Theta \\mathbb{P}(h_\\theta(X) \\neq y |x)\n\\]\nLes SVM les plus simples sont les SVM lin√©aires. Dans ce cas, on suppose qu‚Äôil existe un s√©parateur lin√©aire qui permet d‚Äôassocier chaque classe √† son signe:\n\\[\nh_\\theta(x) = \\text{signe}(f_\\theta(x)) ; \\text{ avec } f_\\theta(x) = \\theta^T x + b\n\\]\navec \\(\\theta \\in \\mathbb{R}^p\\) et \\(w \\in \\mathbb{R}\\).\n\nLorsque des observations sont lin√©airement s√©parables,\nil existe une infinit√© de fronti√®res de d√©cision lin√©aire s√©parant les deux classes. Le ‚Äúmeilleur‚Äù choix est de prendre la marge maximale permettant de s√©parer les donn√©es. La distance entre les deux marges est \\(\\frac{2}{||\\theta||}\\). Donc maximiser cette distance entre deux hyperplans revient √† minimiser \\(||\\theta||^2\\) sous la contrainte \\(y_i(\\theta^Tx_i + b) \\geq 1\\).\nDans le cas non lin√©airement s√©parable, la hinge loss \\(\\max\\big(0,y_i(\\theta^Tx_i + b)\\big)\\) permet de lin√©ariser la fonction de perte:\n\nce qui donne le programme d‚Äôoptimisation suivant :\n\\[\n\\frac{1}{n} \\sum_{i=1}^n \\max\\big(0,y_i(\\theta^Tx_i + b)\\big) + \\lambda ||\\theta||^2\n\\]\nLa g√©n√©ralisation au cas non lin√©aire implique d‚Äôintroduire des noyaux transformant l‚Äôespace de coordonn√©es des observations.",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html#application",
    "href": "content/modelisation/2_SVM.html#application",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "0.2 Application",
    "text": "0.2 Application\nPour appliquer un mod√®le de classification, il nous faut\ntrouver une variable dichotomique. Le choix naturel est\nde prendre la variable dichotomique qu‚Äôest la victoire ou\nd√©faite d‚Äôun des partis.\nM√™me si les R√©publicains ont perdu en 2020, ils l‚Äôont emport√©\ndans plus de comt√©s (moins peupl√©s). Nous allons consid√©rer\nque la victoire des R√©publicains est notre label 1 et la d√©faite 0.\n\n\n Exercice 1 : Premier algorithme de classification\n\nCr√©er une variable dummy appel√©e y dont la valeur vaut 1 quand les r√©publicains l‚Äôemportent.\nEn utilisant la fonction pr√™te √† l‚Äôemploi nomm√©e train_test_split de la librairie sklearn.model_selection,\ncr√©er des √©chantillons de test (20 % des observations) et d‚Äôestimation (80 %) avec comme features : 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Percent of adults with less than a high school diploma, 2015-19', \"Percent of adults with a bachelor's degree or higher, 2015-19\" et comme label la variable y.\n\nNote: Il se peut que vous ayez le warning suivant :\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel()\n\nNote : Pour √©viter ce warning √† chaque fois que vous estimez votre mod√®le, vous pouvez utiliser DataFrame[['y']].values.ravel() plut√¥t que DataFrame[['y']] lorsque vous constituez vos √©chantillons.\n\nEntra√Æner un classifieur SVM avec comme param√®tre de r√©gularisation C = 1. Regarder les mesures de performance suivante : accuracy, f1, recall et precision.\nV√©rifier la matrice de confusion : vous devriez voir que malgr√© des scores en apparence pas si mauvais, il y a un probl√®me notable.\nRefaire les questions pr√©c√©dentes avec des variables normalis√©es. Le r√©sultat est-il diff√©rent ?\nChanger de variables x. Utiliser uniquement le r√©sultat pass√© du vote d√©mocrate (ann√©e 2016) et le revenu. Les variables en question sont share_2016_republican et Median_Household_Income_2019. Regarder les r√©sultats, notamment la matrice de confusion.\n[OPTIONNEL] Faire une 5-fold validation crois√©e pour d√©terminer le param√®tre C id√©al.\n\n\n\nA l‚Äôissue de la question 3,\nle classifieur avec C = 1\ndevrait avoir les performances suivantes :\n\n\n\n\nScore\n\n\n\n\nAccuracy\n0.882637\n\n\nRecall\n0.897297\n\n\nPrecision\n0.968872\n\n\nF1\n0.931712\n\n\n\nLa matrice de confusion associ√©e\nprend cette forme:\n\n\nA l‚Äôissue de la question 6,\nle nouveau classifieur avec devrait avoir les performances suivantes :\n\n\n\n\nScore\n\n\n\n\nAccuracy\n0.882637\n\n\nRecall\n0.897297\n\n\nPrecision\n0.968872\n\n\nF1\n0.931712\n\n\n\nEt la matrice de confusion associ√©e :",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html#informations-additionnelles",
    "href": "content/modelisation/2_SVM.html#informations-additionnelles",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n8d81b5f\n\n\n2023-02-18 18:21:59\n\n\nLino Galiana\n\n\nChange source get_vectorfile (#355)\n\n\n\n\n2ed4aa7\n\n\n2022-11-07 15:57:31\n\n\nLino Galiana\n\n\nReprise 2e partie ML + R√®gle probl√®me mathjax (#319)\n\n\n\n\na26b865\n\n\n2022-09-03 15:34:28\n\n\nlinogaliana\n\n\nFix problem with SVM wikipedia image\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n0a14dfa\n\n\n2021-07-07 15:17:11\n\n\nLino Galiana\n\n\nR√©gler bug sc_recall (#119)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html",
    "href": "content/modelisation/0_preprocessing.html",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise le jeu de donn√©es pr√©sent√© dans l‚Äôintroduction\nde cette partie :\nles donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines de 2020 au niveau des comt√©s\ncrois√©es √† des variables socio-d√©mographiques.\nLe code de consitution de la base de donn√©es\nest disponible sur Github.\nL‚Äôexercice 1 permet, √† ceux qui le d√©sirent, d‚Äôessayer de le reconstituer pas √† pas.\nLe guide utilisateur de Scikit est une r√©f√©rence pr√©cieuse,\n√† consulter r√©guli√®rement. La partie sur le preprocessing est\ndisponible ici.\nL‚Äôobjectif de ce chapitre est de pr√©senter quelques √©l√©ments de\npr√©paration des donn√©es. Il s‚Äôagit d‚Äôune √©tape fondamentale, √† ne\npas n√©gliger. Les mod√®les reposent sur certaines hypoth√®ses, g√©n√©ralement\nrelatives √† la distribution th√©orique des variables qui y sont int√©gr√©es.\nIl est n√©cessaire de faire correspondre la distribution empirique\n√† ces hypoth√®ses, ce qui implique un travail de restructuration des donn√©es.\nCelui-ci permettra d‚Äôavoir des r√©sultats de mod√©lisation plus pertinents.\nNous verrons dans le chapitre sur les pipelines comment industrialiser\nces √©tapes de preprocessing afin de se simplifier la vie pour appliquer\nun mod√®le sur un jeu de donn√©es diff√©rent de celui sur lequel il a √©t√© estim√©.\nScikit-Learn \nscikit-learn est aujourd‚Äôhui la librairie de r√©f√©rence dans l‚Äô√©cosyst√®me du\nMachine Learning. Il s‚Äôagit d‚Äôune librairie qui, malgr√© les tr√®s nombreuses\nm√©thodes impl√©ment√©es, pr√©sente l‚Äôavantage d‚Äô√™tre un point d‚Äôentr√©e unifi√©.\nCet aspect unifi√© est l‚Äôune des raisons du succ√®s pr√©coce de celle-ci. R n‚Äôa\nb√©n√©fici√© que plus r√©cemment d‚Äôune librairie unifi√©e,\n√† savoir tidymodels.\nUne autre raison du succ√®s de scikit est son approche op√©rationnelle : la mise\nen production de mod√®les d√©velopp√©s via les pipelines scikit est peu co√ªteuse.\nUn chapitre sp√©cial de ce cours est d√©di√© aux pipelines.\nAvec Romain Avouac, nous proposons un cours plus avanc√©\nen derni√®re ann√©e d‚ÄôENSAE o√π nous pr√©sentons certains enjeux relatifs\n√† la mise en production de mod√®les d√©velopp√©s avec scikit.\nLe coeur de l‚Äô√©quipe de d√©veloppement de scikit-learn est situ√©\n√† l‚ÄôInria üá´üá∑.\nPour d√©couvrir la richesse de l‚Äô√©cosyst√®me scikit, il\nest recommand√© de suivre le\nMOOC scikit,\nd√©velopp√© dans le cadre de l‚Äôinitiative Inria Academy.\nLes packages suivants sont n√©cessaires pour importer et visualiser\nles donn√©es d‚Äô√©lection :\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nDans ce chapitre, nous allons nous focaliser sur la pr√©paration\ndes donn√©es √† faire en amont du travail de mod√©lisation.\nCette √©tape est indispensable pour s‚Äôassurer de la coh√©rence\nentre les donn√©es et les hypoth√®ses de mod√©lisation mais aussi\npour produire des analyses valides scientifiquement.\nLa d√©marche g√©n√©rale que nous adopterons dans ce chapitre, et\nqui sera ensuite raffin√©e dans les prochains chapitres,\nest la suivante :\nC‚Äôest l‚Äôapproche classique du machine learning. On d√©coupe\nl‚Äôensemble des donn√©es disponibles en deux parties, √©chantillons\nd‚Äôapprentissage et de validation. Le premier sert √† entra√Æner\nun mod√®le et la qualit√© des pr√©dictions de celui-ci est\n√©valu√©e sur le deuxi√®me pour limiter\nle biais de surapprentissage. Le chapitre suivant approfondira\ncette question de l‚Äô√©valuation des mod√®les. A ce stade de notre\nprogression, on se concentrera dans ce chapitre\nsur la question des donn√©es. La librairie Scikit est non seulement\nparticuli√®rement\npratique parce qu‚Äôelle propose √©norm√©ment d‚Äôalgorithmes de machine learning\nmais aussi parce qu‚Äôelle facilite la pr√©paration des donn√©es en amont,\nce qui est l‚Äôobjet de ce chapitre.\nN√©anmoins, avant de se concentrer sur la pr√©paration des donn√©es, nous\nallons passer un peu de temps √† explorer la structure des donn√©es\n√† partir de laquelle nous d√©sirons construire une mod√©lisation. Ceci\nest indispensable afin de comprendre la nature de celles-ci et choisir\nune mod√©lisation ad√©quate.",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#standardisation",
    "href": "content/modelisation/0_preprocessing.html#standardisation",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.1 Standardisation",
    "text": "3.1 Standardisation\nLa standardisation consiste √† transformer des donn√©es pour que la distribution empirique suive une loi \\(\\mathcal{N}(0,1)\\). Pour √™tre performants, la plupart des mod√®les de machine learning n√©cessitent souvent d‚Äôavoir des donn√©es dans cette distribution.\n\n\n Exercice 3: Standardisation\n\nStandardiser la variable Median_Household_Income_2019 (ne pas √©craser les valeurs !) et regarder l‚Äôhistogramme avant/apr√®s normalisation.\n\nNote : On obtient bien une distribution centr√©e √† z√©ro et on pourrait v√©rifier que la variance empirique soit bien √©gale √† 1. On pourrait aussi v√©rifier que ceci est vrai √©galement quand on transforme plusieurs colonnes √† la fois.\n\nCr√©er scaler, un Transformer que vous construisez sur les 1000 premi√®res lignes de votre DataFrame df2 √† l‚Äôexception de la variable √† expliquer winner. V√©rifier la moyenne et l‚Äô√©cart-type de chaque colonne sur ces m√™mes observations.\n\nNote : Les param√®tres qui seront utilis√©s pour une standardisation ult√©rieure sont stock√©s dans les attributs .mean_ et .scale_\nOn peut voir ces attributs comme des param√®tres entra√Æn√©s sur un certain jeu de\ndonn√©es et qu‚Äôon peut r√©utiliser sur un autre, √† condition que les\ndimensions co√Øncident.\n\nAppliquer scaler sur les autres lignes du DataFrame et comparer les distributions obtenues de la variable Median_Household_Income_2019.\n\nNote : Une fois appliqu√©s √† un autre DataFrame, on peut remarquer que la distribution n‚Äôest pas exactement centr√©e-r√©duite dans le DataFrame sur lequel les param√®tres n‚Äôont pas √©t√© estim√©s. C‚Äôest normal, l‚Äô√©chantillon initial n‚Äô√©tait pas al√©atoire, les moyennes et variances de cet √©chantillon n‚Äôont pas de raison de co√Øncider avec les moments de l‚Äô√©chantillon complet.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoyenne de chaque variable sur 1000 premi√®res observations avant :  [ 1.73616500e+04  3.84530000e+00  5.51891150e+04  1.29669150e+01\n  2.15813433e+01 -2.73468885e-02]\nEcart-type de chaque variable sur 1000 premi√®res observations avant :  [3.28113703e+04 1.28903822e+00 1.33256197e+04 6.45536365e+00\n 9.41139584e+00 9.23129044e-01]\nMoyenne de chaque variable sur 1000 premi√®res observations apr√®s :  [-3.37507799e-17  2.66453526e-17  1.58095759e-16  1.42108547e-17\n  1.24344979e-17 -1.59872116e-17]\nEcart-type de chaque variable sur 1000 premi√®res observations apr√®s :  [1. 1. 1. 1. 1. 1.]",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#normalisation",
    "href": "content/modelisation/0_preprocessing.html#normalisation",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.2 Normalisation",
    "text": "3.2 Normalisation\nLa normalisation est l‚Äôaction de transformer les donn√©es de mani√®re\n√† obtenir une norme (\\(\\mathcal{l}_1\\) ou \\(\\mathcal{l}_2\\)) unitaire.\nAutrement dit, avec la norme ad√©quate, la somme des √©l√©ments est √©gale √† 1.\nPar d√©faut, la norme est dans \\(\\mathcal{l}_2\\).\nCette transformation est particuli√®rement utilis√©e en classification de texte ou pour effectuer du clustering.\n\n\n Exercice 4 : Normalisation\n\nNormaliser la variable Median_Household_Income_2019 (ne pas √©craser les valeurs !) et regarder l‚Äôhistogramme avant/apr√®s normalisation.\nV√©rifier que la norme \\(\\mathcal{l}_2\\) est bien √©gale √† 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#encodage-des-valeurs-cat√©gorielles",
    "href": "content/modelisation/0_preprocessing.html#encodage-des-valeurs-cat√©gorielles",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.3 Encodage des valeurs cat√©gorielles",
    "text": "3.3 Encodage des valeurs cat√©gorielles\nLes donn√©es cat√©gorielles doivent √™tre recod√©es\nsous forme de valeurs num√©riques pour √™tre int√©gr√©s aux mod√®les de machine learning.\nCela peut √™tre fait de plusieurs mani√®res :\n\nLabelEncoder: transforme un vecteur [\"a\",\"b\",\"c\"] en vecteur num√©rique [0,1,2].\nCette approche a l‚Äôinconv√©nient d‚Äôintroduire un ordre dans les modalit√©s, ce qui n‚Äôest pas toujours souhaitable\nOrdinalEncoder: une version g√©n√©ralis√©e du LabelEncoder qui a vocation √† s‚Äôappliquer sur des matrices (\\(X\\)),\nalors que LabelEncoder s‚Äôapplique plut√¥t √† un vecteur (\\(y\\))\npandas.get_dummies effectue une op√©ration de dummy expansion.\nUn vecteur de taille n avec K cat√©gories sera transform√© en matrice de taille \\(n \\times K\\)\npour lequel chaque colonne sera une variable dummy pour la modalit√© k.\nIl y a ici \\(K\\) modalit√©s et il y a donc multicolin√©arit√©.\nAvec une r√©gression lin√©aire avec constante,\nil convient de retirer une modalit√© avant l‚Äôestimation.\nOneHotEncoder est une version g√©n√©ralis√©e (et optimis√©e) de la dummy expansion.\nIl a plut√¥t vocation √† s‚Äôappliquer sur les features (\\(X\\)) du mod√®le",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#imputation",
    "href": "content/modelisation/0_preprocessing.html#imputation",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.4 Imputation",
    "text": "3.4 Imputation\nLes donn√©es peuvent souvent contenir des valeurs manquantes, autrement dit des cases de notre DataFrame contenant un NaN.\nCes trous dans les donn√©es peuvent √™tre √† l‚Äôorigine de bugs ou de mauvaises interpr√©tations lorsque l‚Äôon passe √† la mod√©lisation.\nPour y rem√©dier, une premi√®re approche peut √™tre de retirer toutes les observations pr√©sentant un NaN dans au moins l‚Äôune des colonnes.\nCependant, si notre table contient beaucoup de NaN, ou bien que ces derniers sont r√©partis sur de nombreuses colonnes,\nc‚Äôest aussi prendre le risque de retirer un nombre important de lignes, et avec cela de l‚Äôinformation importante pour un mod√®le car les valeurs manquantes sont rarement r√©parties de mani√®re al√©atoire.\nM√™me si dans plusieurs situations, cette solution reste tout √† fait viable, il existe une autre approche plus robuste appel√©e imputation.\nCette m√©thode consiste √† remplacer les valeurs vides par une valeur donn√©e. Par exemple :\n\nImputation par la moyenne : remplacer tous les NaN dans une colonne par la valeur moyenne de la colonne ;\nImputation par la m√©diane sur le m√™me principe, ou par la valeur de la colonne la plus fr√©quente pour les variables cat√©gorielles ;\nImputation par r√©gression : se servir d‚Äôautres variables pour essayer d‚Äôinterpoler une valeur de remplacement adapt√©e.\n\nDes m√©thodes plus complexes existent, mais dans de nombreux cas,\nles approches ci-dessus peuvent suffire pour donner des r√©sultats beaucoup plus satisfaisants.\nLe package Scikit permet de faire de l‚Äôimputation de mani√®re tr√®s simple (documentation ici).",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#gestion-des-outliers",
    "href": "content/modelisation/0_preprocessing.html#gestion-des-outliers",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.5 Gestion des outliers",
    "text": "3.5 Gestion des outliers\nLes valeurs aberrantes (outliers en anglais) sont des observations qui se situent significativement √† l‚Äôext√©rieur de la tendance g√©n√©rale des autres observations dans un ensemble de donn√©es. En d‚Äôautres termes, ce sont des points de donn√©es qui se d√©marquent de mani√®re inhabituelle par rapport √† la distribution globale des donn√©es.\nCela peut √™tre d√ª √† des erreurs de remplissage, des personnes ayant mal r√©pondu √† un questionnaire, ou\nparfois simplement des valeurs extr√™mes qui peuvent biaiser un mod√®le de fa√ßon trop importante.\nA titre d‚Äôexemple, cela va √™tre 3 individus mesurant plus de 4 m√®tres dans une population,\nou bien des revenus de m√©nage d√©passant les 10M d‚Äôeuros par mois sur l‚Äô√©chelle d‚Äôun pays, etc.\nUne bonne pratique peut donc √™tre de syst√©matiquement regarder la distribution des variables √† disposition,\npour se rendre compte si certaines valeurs s‚Äô√©loignent de fa√ßon trop importante des autres.\nCes valeurs vont parfois nous int√©resser, si par exemple on se concentre uniquement sur les tr√®s hauts revenus (top 0.1%)\nen France. Cependant, ces donn√©es vont souvent nous g√™ner plus qu‚Äôautre chose, surtout si elles n‚Äôont pas de sens dans le monde r√©el.\nSi l‚Äôon estime que la pr√©sence de ces donn√©es extr√™mes, ou outliers, dans notre base de donn√©es vont √™tre probl√©matiques plus qu‚Äôautre chose,\nalors il est tout √† fait entendable et possible de simplement les retirer.\nLa plupart du temps, on va se donner une proportion des donn√©es √† retirer, par exemple 0.1%, 1% ou 5%,\npuis retirer dans les deux queues de la distribution les valeurs extr√™mes correspondantes.\nPlusieurs packages permettent de faire ce type d‚Äôop√©rations, qui sont parfois plus complexes si on s‚Äôint√©resse aux outlier sur plusieurs variables.\nOn pourra notamment citer la fonction IsolationForest() du package sklearn.ensemble.\n\nPour plus de d√©tails sur ces deux derniers points, il est recommand√© d‚Äôaller voir l‚Äôexemple Pour aller plus loin en bas de la page.\n\n\n Exercice 5 : Encoder des variables cat√©gorielles\n\nCr√©er df qui conserve uniquement les variables state_name et county_name dans votes.\nAppliquer √† state_name un LabelEncoder\nNote : Le r√©sultat du label encoding est relativement intuitif, notamment quand on le met en relation avec le vecteur initial.\nRegarder la dummy expansion de state_name\nAppliquer un OrdinalEncoder √† df[['state_name', 'county_name']]\nNote : Le r√©sultat du ordinal encoding est coh√©rent avec celui du label encoding\nAppliquer un OneHotEncoder √† df[['state_name', 'county_name']]\n\nNote : scikit optimise l‚Äôobjet n√©cessaire pour stocker le r√©sultat d‚Äôun mod√®le de transformation. Par exemple, le r√©sultat de l‚Äôencoding One Hot est un objet tr√®s volumineux. Dans ce cas, scikit utilise une matrice Sparse.\n\n\n\n\narray([[23, 'Missouri'],\n       [25, 'Nebraska'],\n       [30, 'New York'],\n       ...,\n       [41, 'Texas'],\n       [41, 'Texas'],\n       [41, 'Texas']], dtype=object)\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\nArizona\nArkansas\nCalifornia\nColorado\nConnecticut\nDelaware\nDistrict of Columbia\nFlorida\nGeorgia\n...\nSouth Dakota\nTennessee\nTexas\nUtah\nVermont\nVirginia\nWashington\nWest Virginia\nWisconsin\nWyoming\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3102\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3103\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3104\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3105\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3106\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n3107 rows √ó 49 columns\n\n\n\n\n\n\narray([23., 25., 30., ..., 41., 41., 41.])\n\n\n\n\n&lt;3107x1891 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n    with 6214 stored elements in Compressed Sparse Row format&gt;",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#informations-additionnelles",
    "href": "content/modelisation/0_preprocessing.html#informations-additionnelles",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\nfd3c955\n\n\n2023-11-18 14:22:38\n\n\nLino Galiana\n\n\nFormattage des chapitres scikit (#453)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nebca985\n\n\n2023-06-11 18:14:51\n\n\nLino Galiana\n\n\nChange handling precision (#361)\n\n\n\n\n129b001\n\n\n2022-12-26 20:36:01\n\n\nLino Galiana\n\n\nCSS for ipynb (#337)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n640b960\n\n\n2022-06-10 15:42:04\n\n\nLino Galiana\n\n\nFinir de r√©gler le probl√®me plotly (#236)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n8f99cd3\n\n\n2021-12-08 15:26:28\n\n\nlinogaliana\n\n\nhide otuput\n\n\n\n\n9c5f718\n\n\n2021-12-08 14:36:59\n\n\nlinogaliana\n\n\nformat dico :sob:\n\n\n\n\n41c8986\n\n\n2021-12-08 14:25:18\n\n\nlinogaliana\n\n\ncorrection erreur\n\n\n\n\n6474746\n\n\n2021-12-08 14:08:06\n\n\nlinogaliana\n\n\ndict ici aussi\n\n\n\n\n8e73912\n\n\n2021-12-08 12:32:17\n\n\nlinogaliana\n\n\ncoquille plotly :sob:\n\n\n\n\n3704213\n\n\n2021-12-08 11:57:51\n\n\nlinogaliana\n\n\nessaye avec un dict classique\n\n\n\n\n85565d5\n\n\n2021-12-08 08:15:29\n\n\nlinogaliana\n\n\nreformat\n\n\n\n\n9ace7b9\n\n\n2021-12-07 17:49:18\n\n\nlinogaliana\n\n\n√©vite la boucle crado\n\n\n\n\n3514e09\n\n\n2021-12-07 16:05:28\n\n\nlinogaliana\n\n\ns√©pare et document\n\n\n\n\n63e67e6\n\n\n2021-12-07 15:15:34\n\n\nLino Galiana\n\n\nDebug du plotly (temporaire) (#193)\n\n\n\n\n65cecdd\n\n\n2021-12-07 10:29:18\n\n\nLino Galiana\n\n\nEncore une erreur de nom de colonne (#192)\n\n\n\n\n81b7023\n\n\n2021-12-07 09:27:35\n\n\nLino Galiana\n\n\nMise √† jour liste des colonnes (#191)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nd91a5eb\n\n\n2021-12-06 18:53:33\n\n\nLino Galiana\n\n\nLa bonne branche c‚Äôest master\n\n\n\n\nd86129c\n\n\n2021-12-06 18:02:32\n\n\nLino Galiana\n\n\nverbose\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec (antuki?) partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n49e2826\n\n\n2021-05-13 18:11:20\n\n\nLino Galiana\n\n\nCorrige quelques images n‚Äôapparaissant pas (#108)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/visualisation/maps.html",
    "href": "content/visualisation/maps.html",
    "title": "De belles cartes avec python : mise en pratique",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLa pratique de la cartographie se fera, dans ce cours, en r√©pliquant des cartes qu‚Äôon peut trouver sur\nla page de l‚Äôopen-data de la ville de Paris\nici.\nNote\nProduire de belles cartes demande du temps mais aussi du bon sens. En fonction de la structure des donn√©es, certaines repr√©sentations sont √† √©viter voire √† exclure. L‚Äôexcellent guide disponible ici propose quelques r√®gles et √©voque les erreurs √† √©viter lorsqu‚Äôon d√©sire effectuer des\nrepr√©sentations spatiales.\nCelui-ci reprend un guide de s√©miologie cartographique\nproduit par l‚ÄôInsee qui propose de nombreux conseils pratiques pour produire des repr√©sentations\ncartographiques sens√©es.\nCe TP vise √† initier :\nLes donn√©es utilis√©es sont :\nAttention\nCertaines librairies g√©ographiques d√©pendent de rtree qui est parfois difficile √† installer car\nce package d√©pend de librairies compil√©es qui sont compliqu√©es √† installer sur Windows.\nPour installer rtree sur Windows, le mieux est d‚Äôutiliser Anaconda.\nAvant de pouvoir commencer, il est n√©cessaire d‚Äôinstaller quelques\npackages au pr√©alable:\n# Sur colab\n!pip install pandas fiona shapely pyproj rtree # √† faire obligatoirement en premier pour utiliser rtree ou pygeos pour les jointures spatiales\n!pip install contextily\n!pip install geopandas\n!pip install geoplot\nDans la premi√®re partie, nous allons utiliser les packages suivants :\nimport pandas as pd\nimport geopandas as gpd\nimport contextily as ctx\nimport geoplot\nimport matplotlib.pyplot as plt\nimport folium\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed",
    "crumbs": [
      "De belles cartes avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/maps.html#densit√©-de-population-dans-la-petite-couronne-parisienne",
    "href": "content/visualisation/maps.html#densit√©-de-population-dans-la-petite-couronne-parisienne",
    "title": "De belles cartes avec python : mise en pratique",
    "section": "3.1 Densit√© de population dans la petite couronne parisienne",
    "text": "3.1 Densit√© de population dans la petite couronne parisienne\nPour cet exercice, le package cartiflette\nva √™tre pratique pour r√©cup√©rer un fonds de carte m√©langeant arrondissements\nparisiens et communes dans les autres villes.\nNous allons privil√©gier une carte √† ronds proportionnels (bubble map)\naux cartes chorol√®pthes qui trompent\nl‚Äôoeil.\n\n\n Exercice: bubble map de densit√© des populations\n\nR√©cup√©rer le fond de carte des d√©partements 75, 92, 93 et 94\navec cartiflette. Pour cela, utiliser carti_download\ndepuis cartiflette en fixant l‚Äôoption borders √† COMMUNE_ARRONDISSEMENT.\nNommer cet objet df.\nAfin que les calculs ult√©rieurs de surface ne soient pas fauss√©s,\nassurez-vous que les donn√©es sont en Lambert 93 en reprojetant\nnos contours (code EPSG: 2154).\nCr√©er un objet departements avec dissolve pour √©galement disposer\nd‚Äôun fond de carte des d√©partements\nCr√©er une variable surface et utilisant la m√©thode area. L‚Äôunit√©\ndoit √™tre le km¬≤, il faut donc diviser par \\(10^6\\)\nCr√©er une variable densite\nUtiliser pd.cut avec les seuils 5000, 15000 et 30000 personnes\npar km¬≤. Vous pouvez utiliser l‚Äôoption label pour d√©nommer les tranches\nCr√©er un GeoDataFrame de points en utilisant la m√©thode centroid. Celui-ci\nnous servira √† localiser le centre de nos ronds.\nRepr√©senter la densit√© communale sous forme de carte avec ronds proportionnels.\nVous pouvez utiliser la variable cr√©√©e √† la question 5 pour les couleurs.\n\n\n\nLa carte obtenue devrait ressembler √† celle-ci :\n\n\nText(0.3, 0.15, 'Source: IGN - AdminExpress')",
    "crumbs": [
      "De belles cartes avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/maps.html#informations-additionnelles",
    "href": "content/visualisation/maps.html#informations-additionnelles",
    "title": "De belles cartes avec python : mise en pratique",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\nce33d5d\n\n\n2024-01-16 15:47:22\n\n\nLino Galiana\n\n\nAdapte les exemples de code de cartiflette (#482)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\nad654c5\n\n\n2023-10-10 14:23:05\n\n\nlinogaliana\n\n\nCQuick fix gzip csv\n\n\n\n\n1c64660\n\n\n2023-10-04 15:52:52\n\n\nLino Galiana\n\n\nQuick fix remove contextily (#420)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\nc7f8c94\n\n\n2023-09-01 09:27:43\n\n\nLino Galiana\n\n\nAjoute un champ citation (#403)\n\n\n\n\n17a238f\n\n\n2023-08-30 15:06:18\n\n\nLino Galiana\n\n\nNouvelles donn√©es compteurs (#402)\n\n\n\n\n0035b74\n\n\n2023-08-29 14:51:26\n\n\nLino Galiana\n\n\nTemporary fix for cartography pipeline (#401)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n8df7cb2\n\n\n2023-07-20 17:16:03\n\n\nlinogaliana\n\n\nChange link\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\nb0abd02\n\n\n2022-12-12 07:57:22\n\n\nLino Galiana\n\n\nFix cartiflette in additional exercise (#334)\n\n\n\n\ne56f6fd\n\n\n2022-12-03 17:00:55\n\n\nLino Galiana\n\n\nCorrige typos exo compteurs (#329)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n66a5276\n\n\n2021-11-23 16:13:20\n\n\nLino Galiana\n\n\nRelecture partie visualisation (#181)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n2924215\n\n\n2020-10-08 13:35:18\n\n\nLino Galiana\n\n\nmodif slug cartographie\n\n\n\n\n6477687\n\n\n2020-10-08 13:31:00\n\n\nLino Galiana\n\n\nVisualisation cartographique (#68)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "De belles cartes avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/index.html",
    "href": "content/visualisation/index.html",
    "title": "Partie 2: visualiser les donn√©es",
    "section": "",
    "text": "La visualisation de donn√©es est l‚Äôart et la science de repr√©senter visuellement des informations complexes et abstraites √† l‚Äôaide d‚Äô√©l√©ments visuels.\nSon objectif principal est de synth√©tiser l‚Äôinformation pr√©sente dans un ensemble de donn√©es afin de faciliter\nla compr√©hension des enjeux de celle-ci pour une analyse ult√©rieure.\nLa visualisation de donn√©es permet, entre autres, de mettre en √©vidence des tendances, des corr√©lations ou\ndes anomalies qui pourraient √™tre difficiles voire impossibles √† saisir simplement en examinant des donn√©es brutes, ces derni√®res n√©cessitant\nune certaine mise en contexte pour porter du sens.\nLa visualisation de donn√©es joue un r√¥le crucial dans le\nprocessus d‚Äôanalyse de donn√©es en fournissant des moyens visuels pour explorer, interpr√©ter et communiquer des informations.\nElle facilite la communication entre experts de la donn√©es, d√©cideurs et grand public,\nen permettant de raconter des histoires bas√©es sur les donn√©es de mani√®re plus convaincante et engageante.\nLa visualisation de donn√©es a une place √† part dans\nl‚Äôensemble des techniques de la data science.\nElle intervient √† tous les stades du processus de\nproduction de la donn√©e, de\nl‚Äôamont (analyse exploratoire) √†\nl‚Äôaval (restitution √† des publics multiples) et\npeut, si elle est bien construite, permettre de\nsaisir de mani√®re intuitive la structure des donn√©es\nou les enjeux de son analyse.\nArt de la synth√®se, la visualisation de donn√©es\nest √©galement l‚Äôart de raconter une histoire et\npeut m√™me, lorsqu‚Äôelle est bien construite, pr√©tendre\nau rang de production artistique.\nLa dataviz est un m√©tier en soi dont on trouve de\nplus en plus de praticiens dans les titres de presse\nou dans des entreprises\nsp√©cialis√©es (Datawrapper par exemple).\nSans pr√©tendre construire\ndes visualisations aussi riches que celles des sp√©cialistes,\ntout data scientist se doit d‚Äô√™tre en mesure de pouvoir\nproduire rapidement quelques visualisations permettant\nde synth√©tiser les jeux de donn√©es √† sa disposition.\nUne visualisation claire et lisible tout en restant simple\npeut √™tre meilleure qu‚Äôun discours pour faire passer un message.\nJe recommande notamment\nce post de blog\nd‚ÄôEric Mauvi√®re qui revient sur deux graphiques dans une publication\nr√©cente\ndu Service statistique du Minist√®re de la Sant√© (DREES)\net montre la mani√®re dont on peut am√©liorer le message transmis\npar des figures :\nDe m√™me qu‚Äôun discours, une visualisation est une communication\npour laquelle un locuteur - la personne construisant la visualisation -\ncherche √† transmettre une information √† un r√©cepteur - √©ventuellement\nla m√™me personne que le locuteur puisqu‚Äôune visualisation peut\n√™tre construite pour soi-m√™me dans une analyse exploratoire. Il n‚Äôest\ndonc pas surprenant qu‚Äô√† l‚Äô√©poque o√π la s√©miologie occupait une\npart importante dans les d√©bats intellectuels, notamment autour\nde la figure de Roland Barthes, le concept de s√©miologie\ngraphique ait √©merg√©\nautour de la personne de Jacques Bertin (Bertin 1967; Palsky 2017).\nCette approche permet de r√©fl√©chir sur la pertinence des\ntechniques mises en oeuvre pour transmettre un message\ngraphique et de nombreuses visualisations, si elles\nsuivaient quelques-unes de ces r√®gles, pourraient\n√™tre am√©lior√©es √† peu de frais.\nL‚ÄôInsee a publi√©, il y a quelques ann√©es, un guide de\ns√©miologie graphique tr√®s utile qu‚Äôil\nest int√©ressant de consulter de temps en temps (Insee 2018).\nPour revenir √† notre cours,\nnous pr√©senterons dans cette partie quelques librairies\net visualisations basiques en Python permettant de\npartir sur de bonnes bases. Les ressources pour\napprofondir et progresser dans l‚Äôart de la visualisation\nne manquent pas, comme cet ouvrage (Wilke 2019).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#l√©cosyst√®me-python",
    "href": "content/visualisation/index.html#l√©cosyst√®me-python",
    "title": "Partie 2: visualiser les donn√©es",
    "section": "L‚Äô√©cosyst√®me Python",
    "text": "L‚Äô√©cosyst√®me Python\nL‚Äô√©cosyst√®me Python pour la valorisation de donn√©es est tr√®s riche et\ntr√®s √©clat√©.\nIl est\npossible de consacrer des livres entiers √† celui-ci (Dale 2022).\nPython propose\nde nombreuses librairies pour produire de mani√®re rapide et relativement\nsimple des visualisations de donn√©es1.\nLes librairies graphiques se distinguent principalement en deux familles:\n\nLes librairies de repr√©sentations fig√©es. Celles-ci ont plut√¥t vocation √† √™tre int√©gr√©es\ndans des publications fig√©es type PDF ou documents texte. Nous pr√©senterons\nprincipalement Matplotlib et Seaborn mais il en existe d‚Äôautres,\ncomme Plotnine.\nLes librairies de repr√©sentations dynamiques. Celles-ci sont adapt√©es √† des repr√©sentations\nweb et offrent la possibilit√© aux lecteurs d‚Äôagir sur la repr√©sentation graphique affich√©e.\nLes librairies qui proposent ces fonctionnalit√©s reposent g√©n√©ralement sur JavaScript, l‚Äô√©cosyst√®me\ndu d√©veloppement web, pour lequel elles offrent un point d‚Äôentr√©e via Python.\nNous √©voquerons principalement Plotly et Folium dans cette famille mais il existe de nombreux\nautres frameworks dans ce domaine2.\n\nDans le domaine de la visualisation, ce cours adopte le parti pris\nd‚Äôexplorer quelques\nlibrairies centrales √† partir d‚Äôun nombre restreint d‚Äôexemples en\nr√©pliquant des graphiques qu‚Äôon peut trouver sur le site d‚Äôopen data de la\nmairie de Paris.\nLa meilleure √©cole pour la visualisation est la pratique sur des jeux de donn√©es.\n\nLes applications de visualisation\nCette partie du cours se focalise sur des repr√©sentations synth√©tiques simples.\nElle n‚Äô√©voque pas (encore ?) la construction d‚Äôapplications de visualisation\nde donn√©es o√π un ensemble de graphiques se mettent √† jour de mani√®re synchrone\nen fonction d‚Äôactions d‚Äôutilisateurs.\nCeci d√©passe en effet le cadre d‚Äôun cours d‚Äôintroduction car cela implique\nde ma√Ætriser des concepts plus complexes comme l‚Äôinteraction entre une page\nweb et un serveur (local). N√©anmoins, j‚Äôai d√©j√† construit\navec Romain Avouac\nun tutoriel 101 tr√®s d√©taill√© sur Streamlit\n(permettant de cr√©er une application type Yuka)\npour une formation √† l‚ÄôInsee.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#r√©sum√©-de-cette-partie",
    "href": "content/visualisation/index.html#r√©sum√©-de-cette-partie",
    "title": "Partie 2: visualiser les donn√©es",
    "section": "R√©sum√© de cette partie",
    "text": "R√©sum√© de cette partie\nCette partie est divis√©e en deux et chaque chapitre est lui-m√™me\ndual, selon qu‚Äôon s‚Äôint√©resse aux repr√©sentations fig√©es\nou dynamiques :\n\nDans un premier temps, nous √©voquerons des\nrepr√©sentations graphiques standards (histogrammes, diagrammes\nen barre‚Ä¶) pour synth√©tiser certaines informations quantitatives ;\n\nLes repr√©sentations fixes reposeront sur Pandas, Matplotlib et Seaborn\nLes graphiques r√©actifs s‚Äôappuieront sur Plotly\n\nDans un deuxi√®me temps, nous pr√©senterons les repr√©sentations\ncartographiques:\n\nLes cartes fixes avec Geopandas ou Geoplot\nLes cartes r√©actives avec Folium (adaptation Python de la librairie Leaflet.js)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#r√©f√©rences-utiles",
    "href": "content/visualisation/index.html#r√©f√©rences-utiles",
    "title": "Partie 2: visualiser les donn√©es",
    "section": "R√©f√©rences utiles",
    "text": "R√©f√©rences utiles\nLa visualisation de donn√©es est un art qui s‚Äôapprend, au d√©but, principalement\npar la pratique. N√©anmoins, il n‚Äôest pas √©vident de produire\ndes visualisations lisibles et ergonomiques\net il est utile de s‚Äôinspirer d‚Äôexemples de\nsp√©cialistes (les grands titres de presse disposent d‚Äôexcellentes visualisations).\nVoici quelques ressources utiles sur ces sujets :\n\nDatawrapper propose un excellent blog sur les\nbonnes pratiques de visualisation, notamment\navec les articles de Lisa Charlotte Muth. Je recommande notamment cet article sur\nles couleurs ou\ncelui-ci sur les textes ;\nLe blog d‚ÄôEric Mauvi√®re ;\n‚ÄúLa S√©miologie graphique de Jacques Bertin a cinquante ans‚Äù ;\nLes visualisations trending sur Observable ;\nLe New York Times (les rois de la dataviz) revient tous les ans sur les meilleures visualisations\nde l‚Äôann√©e dans la veine du data scrollytelling. Voir par exemple la r√©trospective de l‚Äôann√©e 2022.\n\nEt quelques r√©f√©rences suppl√©mentaires, cit√©es dans cette introduction :\n\n\nBertin, Jacques. 1967. S√©miologie Graphique. Paris: Mouton/Gauthier-Villars.\n\n\nDale, Kyran. 2022. Data Visualization with Python and JavaScript. \" O‚ÄôReilly Media, Inc.\".\n\n\nInsee. 2018. ‚ÄúGuide de S√©miologie Cartographique.‚Äù\n\n\nPalsky, Gilles. 2017. ‚ÄúLa s√©miologie Graphique de Jacques Bertin a Cinquante Ans.‚Äù Visions Carto (En Ligne).\n\n\nWilke, Claus O. 2019. Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O‚ÄôReilly Media.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#informations-additionnelles",
    "href": "content/visualisation/index.html#informations-additionnelles",
    "title": "Partie 2: visualiser les donn√©es",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n2dc82e7\n\n\n2022-10-18 22:46:47\n\n\nLino Galiana\n\n\nRelec Kim (visualisation + API) (#302)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\na4e2426\n\n\n2022-06-16 19:34:18\n\n\nLino Galiana\n\n\nImprove style (#238)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n66a5276\n\n\n2021-11-23 16:13:20\n\n\nLino Galiana\n\n\nRelecture partie visualisation (#181)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n5ac3cbe\n\n\n2020-09-28 18:59:24\n\n\nLino Galiana\n\n\nContinue la partie graphiques (#54)\n\n\n\n\n8ed01f4\n\n\n2020-09-24 21:27:29\n\n\nLino Galiana\n\n\nAjout d‚Äôune partie visualisation\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure 1 originale\nFigure 1 modifi√©e\nFigure 2 originale\nFigure 2 modifi√©e",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#footnotes",
    "href": "content/visualisation/index.html#footnotes",
    "title": "Partie 2: visualiser les donn√©es",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour √™tre honn√™te, Python est sur ce point un peu moins agr√©able\nque R qui b√©n√©ficie de\nl‚Äôincontournable librairie ggplot2.\nN‚Äô√©tant pas\nconstruite sur la grammaire des graphiques,\nla principe librairie de graphiques en Python qu‚Äôest Matplotlib est plus fastidieuse\n√† utiliser que ggplot2.\nseaborn, que nous pr√©senterons,\nfacilite un peu le travail de repr√©sentation graphique mais, l√† encore, il est difficile de faire\nplus mall√©able et universel que ggplot2.\nLa librairie plotnine vise √† proposer une impl√©mentation similaire\n√† ggplot pour les utilisateurs de Python. Son d√©veloppement est √† suivre.‚Ü©Ô∏é\nA cet √©gard, je recommande vivement de suivre l‚Äôactualit√© de la dataviz\nsur la plateforme Observable qui tend √†\nrapprocher les communaut√©s des sp√©cialistes de la dataviz et des analystes\nde donn√©es. La librairie Plot pourrait devenir\nun nouveau standard dans les prochaines ann√©es, sorte d‚Äôinterm√©diaire\nentre ggplot et d3.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html",
    "href": "content/manipulation/04c_API_TP.html",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLa partie utilisant l‚ÄôAPI DVF n‚Äôest plus √† jour, elle sera mise √† jour prochainement.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#d√©finition",
    "href": "content/manipulation/04c_API_TP.html#d√©finition",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "1.1 D√©finition",
    "text": "1.1 D√©finition\nPour expliquer le principe d‚Äôune API, je vais reprendre le d√©but de\nla fiche d√©di√©e dans la documentation collaborative\nutilitR que je recommande de lire :\n\nUne Application Programming Interface (ou API) est une interface de programmation qui permet d‚Äôutiliser une application existante pour restituer des donn√©es. Le terme d‚ÄôAPI peut √™tre para√Ætre intimidant, mais il s‚Äôagit simplement d‚Äôune fa√ßon de mettre √† disposition des donn√©es : plut√¥t que de laisser l‚Äôutilisateur consulter directement des bases de donn√©es (souvent volumineuses et complexes), l‚ÄôAPI lui propose de formuler une requ√™te qui est trait√©e par le serveur h√©bergeant la base de donn√©es, puis de recevoir des donn√©es en r√©ponse √† sa requ√™te.\nD‚Äôun point de vue informatique, une API est une porte d‚Äôentr√©e clairement identifi√©e par laquelle un logiciel offre des services √† d‚Äôautres logiciels (ou utilisateurs). L‚Äôobjectif d‚Äôune API est de fournir un point d‚Äôacc√®s √† une fonctionnalit√© qui soit facile √† utiliser et qui masque les d√©tails de la mise en oeuvre. Par exemple, l‚ÄôAPI Sirene permet de r√©cup√©rer la raison sociale d‚Äôune entreprise √† partir de son identifiant Siren en interrogeant le r√©f√©rentiel disponible sur Internet directement depuis un script R, sans avoir √† conna√Ætre tous les d√©tails du r√©pertoire Sirene.\n√Ä l‚ÄôInsee comme ailleurs, la connexion entre les bases de donn√©es pour les nouveaux projets tend √† se r√©aliser par des API. L‚Äôacc√®s √† des donn√©es par des API devient ainsi de plus en plus commun et est amen√© √† devenir une comp√©tence de base de tout utilisateur de donn√©es.\nutilitR",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#avantages-des-api",
    "href": "content/manipulation/04c_API_TP.html#avantages-des-api",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "1.2 Avantages des API",
    "text": "1.2 Avantages des API\nA nouveau, citons la documentation utilitR :\nLes API pr√©sentent de multiples avantages :\n\n\nLes API rendent les programmes plus reproductibles. En effet, gr√¢ce aux API, il est possible de mettre √† jour facilement les donn√©es utilis√©es par un programme si celles-ci √©voluent. Cette flexibilit√© accrue pour l‚Äôutilisateur √©vite au producteur de donn√©es d‚Äôavoir √† r√©aliser de multiples extractions, et r√©duit le probl√®me de la coexistence de versions diff√©rentes des donn√©es.\nGr√¢ce aux API, l‚Äôutilisateur peut extraire facilement une petite partie d‚Äôune base de donn√©es plus cons√©quente.\nLes API permettent de mettre √† disposition des donn√©es tout en limitant le nombre de personnes ayant acc√®s aux bases de donn√©es elles-m√™mes.\nGr√¢ce aux API, il est possible de proposer des services sur mesure pour les utilisateurs (par exemple, un acc√®s sp√©cifique pour les gros utilisateurs).\n\nutilitR\n\nL‚Äôutilisation accrue d‚ÄôAPI dans le cadre de strat√©gies open-data est l‚Äôun\ndes piliers des 15 feuilles de route minist√©rielles\nen mati√®re d‚Äôouverture, de circulation et de valorisation des donn√©es publiques.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#utilisation-des-api",
    "href": "content/manipulation/04c_API_TP.html#utilisation-des-api",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "1.3 Utilisation des API",
    "text": "1.3 Utilisation des API\nCitons encore une fois\nla documentation utilitR :\n\nUne API peut souvent √™tre utilis√©e de deux fa√ßons : par une interface Web, et par l‚Äôinterm√©diaire d‚Äôun logiciel (R, Python‚Ä¶). Par ailleurs, les API peuvent √™tre propos√©es avec un niveau de libert√© variable pour l‚Äôutilisateur :\n\nsoit en libre acc√®s (l‚Äôutilisation n‚Äôest pas contr√¥l√©e et l‚Äôutilisateur peut utiliser le service comme bon lui semble)‚ÄØ;\nsoit via la g√©n√©ration d‚Äôun compte et d‚Äôun jeton d‚Äôacc√®s qui permettent de s√©curiser l‚Äôutilisation de l‚ÄôAPI et de limiter le nombre de requ√™tes.\n\nutilitR\n\nDe nombreuses API n√©cessitent une authentification, c‚Äôest-√†-dire un\ncompte utilisateur afin de pouvoir acc√©der aux donn√©es.\nDans un premier temps,\nnous regarderons exclusivement les API ouvertes sans restriction d‚Äôacc√®s.\nCertains exercices et exemples permettront n√©anmoins d‚Äôessayer des API\navec restrictions d‚Äôacc√®s.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#principe-g√©n√©ral",
    "href": "content/manipulation/04c_API_TP.html#principe-g√©n√©ral",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "2.1 Principe g√©n√©ral",
    "text": "2.1 Principe g√©n√©ral\n\nL‚Äôutilisation de l‚Äôinterface Web est utile dans une d√©marche exploratoire mais trouve rapidement ses limites, notamment lorsqu‚Äôon consulte r√©guli√®rement l‚ÄôAPI. L‚Äôutilisateur va rapidement se rendre compte qu‚Äôil est beaucoup plus commode d‚Äôutiliser une API via un logiciel de traitement pour automatiser la consultation ou pour r√©aliser du t√©l√©chargement de masse. De plus, l‚Äôinterface Web n‚Äôexiste pas syst√©matiquement pour toutes les API.\nLe mode principal de consultation d‚Äôune API consiste √† adresser une requ√™te √† cette API via un logiciel adapt√© (R, Python, Java‚Ä¶). Comme pour l‚Äôutilisation d‚Äôune fonction, l‚Äôappel d‚Äôune API comprend des param√®tres qui sont d√©taill√©es dans la documentation de l‚ÄôAPI.\nutilitR\n\nVoici les √©l√©ments importants √† avoir en t√™te sur les requ√™tes (j‚Äôemprunte encore\n√† utilitR) :\n\nLe point d‚Äôentr√©e d‚Äôun service offert par une API se pr√©sente sous la forme d‚Äôune URL (adresse web).\nChaque service propos√© par une API a sa propre URL. Par exemple, dans le cas de l‚ÄôOpenFood Facts,\nl‚ÄôURL √† utiliser pour obtenir des informations sur un produit particulier (l‚Äôidentifiant 737628064502)\nest https://world.openfoodfacts.org/api/v0/product/737628064502.json\nCette URL doit √™tre compl√©t√©e avec diff√©rents param√®tres qui pr√©cisent la requ√™te (par exemple l‚Äôidentifiant Siren). Ces param√®tres viennent s‚Äôajouter √† l‚ÄôURL, souvent √† la suite de ?. Chaque service propos√© par une API a ses propres param√®tres, d√©taill√©s dans la documentation.\nLorsque l‚Äôutilisateur soumet sa requ√™te, l‚ÄôAPI lui renvoie une r√©ponse structur√©e contenant l‚Äôensemble des informations demand√©es. Le r√©sultat envoy√© par une API est majoritairement aux formats JSON ou XML (deux formats dans lesquels les informations sont hi√©rarchis√©es de mani√®re emboit√©e). Plus rarement, certains services proposent une information sous forme plate (de type csv).\n\nDu fait de la dimension hi√©rarchique des formats JSON ou XML,\nle r√©sultat n‚Äôest pas toujours facile √† r√©cup√©rer mais\nPython propose d‚Äôexcellents outils pour cela (meilleurs que ceux de R).\nCertains packages, notamment json, facilitent l‚Äôextraction de champs d‚Äôune sortie d‚ÄôAPI.\nDans certains cas, des packages sp√©cifiques √† une API ont √©t√© cr√©√©s pour simplifier l‚Äô√©criture d‚Äôune requ√™te ou la r√©cup√©ration du r√©sultat. Par exemple, le package\npynsee\npropose des options qui seront retranscrites automatiquement dans l‚ÄôURL de\nrequ√™te pour faciliter le travail sur les donn√©es Insee.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#illustration-avec-une-api-de-lademe-pour-obtenir-des-diagnostics-energ√©tiques",
    "href": "content/manipulation/04c_API_TP.html#illustration-avec-une-api-de-lademe-pour-obtenir-des-diagnostics-energ√©tiques",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "2.2 Illustration avec une API de l‚ÄôAdeme pour obtenir des diagnostics energ√©tiques",
    "text": "2.2 Illustration avec une API de l‚ÄôAdeme pour obtenir des diagnostics energ√©tiques\nLe diagnostic de performance √©nerg√©tique (DPE)\nrenseigne sur la performance √©nerg√©tique d‚Äôun logement ou d‚Äôun b√¢timent,\nen √©valuant sa consommation d‚Äô√©nergie et son impact en terme d‚Äô√©missions de gaz √† effet de serre.\nLes donn√©es des performances √©nerg√©tiques des b√¢timents sont\nmises √† disposition par l‚ÄôAdeme.\nComme ces donn√©es sont relativement\nvolumineuses, une API peut √™tre utile lorsqu‚Äôon ne s‚Äôint√©resse\nqu‚Äô√† un sous-champ des donn√©es.\nUne documentation et un espace de test de l‚ÄôAPI sont disponibles\nsur le site API GOUV1.\nSupposons qu‚Äôon d√©sire r√©cup√©rer une centaine de valeurs pour la commune\nde Villieu-Loyes-Mollon dans l‚ÄôAin (code Insee 01450).\nL‚ÄôAPI comporte plusieurs points d‚Äôentr√©e. Globalement, la racine\ncommune est :\n\nhttps://koumoul.com/data-fair/api/v1/datasets/dpe-france\n\nEnsuite, en fonction de l‚ÄôAPI d√©sir√©e, on va ajouter des √©l√©ments\n√† cette racine. En l‚Äôoccurrence, on va utiliser\nl‚ÄôAPI field qui permet de r√©cup√©rer des lignes en fonction d‚Äôun\nou plusieurs crit√®res (pour nous, la localisation g√©ographique):\nL‚Äôexemple donn√© dans la documentation technique est\n\nGET https://koumoul.com/data-fair/api/v1/datasets/dpe-france/values/{field}\n\nce qui en Python se traduira par l‚Äôutilisation de la m√©thode get du\npackage Request\nsur un url dont la structure est la suivante :\n\nil commencera par https://koumoul.com/data-fair/api/v1/datasets/dpe-france/values/ ;\nil sera ensuite suivi par des param√®tres de recherche. Le champ {field}\ncommence ainsi g√©n√©ralement par un ? qui permet ensuite de sp√©cifier des param√®tres\nsous la forme nom_parameter=value\n\nA la lecture de la documentation, les premiers param√®tres qu‚Äôon d√©sire :\n\nLe nombre de pages, ce qui nous permet d‚Äôobtenir un certain nombre d‚Äô√©chos. On\nva seulement r√©cup√©rer 10 pages ce qui correspond √† une centaine d‚Äô√©chos. On va\nn√©anmoins pr√©ciser qu‚Äôon veut 100 √©chos\nLe format de sortie. On va privil√©gier le JSON qui est un format standard dans le\nmonde des API. Python offre beaucoup de flexibilit√© gr√¢ce √† l‚Äôun de\nses objets de base, √† savoir le dictionnaire (type dict), pour manipuler de tels\nfichiers\nLe code commune des donn√©es qu‚Äôon d√©sire obtenir. Comme on l‚Äôa √©voqu√©,\non va r√©cup√©rer les donn√©es dont le code commune est 01450. D‚Äôapr√®s la doc,\nil convient de passer le code commune sous le format:\ncode_insee_commune_actualise:{code_commune}. Pour √©viter tout risque de\nmauvais formatage, on va utiliser %3A pour signifier :, %2A pour signifier * et\n%22 pour signifier \".\nD‚Äôautres param√®tres annexes, sugg√©r√©s par la documentation\n\nCela nous donne ainsi un URL dont la structure est la suivante :\n\ncode_commune = \"01450\"\nsize = 100\napi_root = \"https://koumoul.com/data-fair/api/v1/datasets/dpe-france/lines\"\nurl_api = (\n    f\"{api_root}?format=json&q_mode=simple&qs=code_insee_commune_actualise\"\n    + \"%3A%22\"\n    + f\"{code_commune}\"\n    + \"%22\"\n    + f\"&size={size}&select=\"\n    + \"%2A&sampling=neighbors\"\n)\n\nSi vous introduisez cet URL dans votre navigateur, vous devriez aboutir\nsur un JSON non format√©2. En Python,\non peut utiliser requests pour r√©cup√©rer les donn√©es3 :\n\nimport requests\nimport pandas as pd\n\nreq = requests.get(url_api)\nwb = req.json()\n\nPrenons par exemple les 1000 premiers caract√®res du r√©sultat, pour se donner\nune id√©e du r√©sultat et se convaincre que notre filtre au niveau\ncommunal est bien pass√© :\nprint(req.content[:1000])\nb‚Äô{‚Äútotal‚Äù: 121,‚Äúnext‚Äù: ‚Äúhttps://koumoul.com/data-fair/api/v1/datasets/dpe-france/lines?format=json&q_mode=simple&qs=code_insee_commune_actualise%3A%2201450%22&size=100&select=*&sampling=neighbors&after=102719%2C912454‚Äù,‚Äúresults‚Äù: [\\n {‚Äúclasse_consommation_energie‚Äù: ‚ÄúE‚Äù,‚Äútr001_modele_dpe_type_libelle‚Äù: ‚ÄúVente‚Äù,‚Äúannee_construction‚Äù: 1,‚Äú_geopoint‚Äù: ‚Äú45.927488,5.230195‚Äù,‚Äúlatitude‚Äù: 45.927488,‚Äúsurface_thermique_lot‚Äù: 106.87,‚Äú_i‚Äù: 2,‚Äútr002_type_batiment_description‚Äù: ‚ÄúMaison Individuelle‚Äù,‚Äúgeo_adresse‚Äù: ‚ÄúRue du Chateau 01800 Villieu-Loyes-Mollon‚Äù,‚Äú_rand‚Äù: 959550,‚Äúcode_insee_commune_actualise‚Äù: ‚Äú01450‚Äù,‚Äúestimation_ges‚Äù: 9,‚Äúgeo_score‚Äù: 0.58,‚Äúclasse_estimation_ges‚Äù: ‚ÄúB‚Äù,‚Äúnom_methode_dpe‚Äù: ‚ÄúM9thode Facture‚Äù,‚Äútv016_departement_code‚Äù: ‚Äú01‚Äù,‚Äúconsommation_energie‚Äù: 286,‚Äúdate_etablissement_dpe‚Äù: ‚Äú2013-04-15‚Äù,‚Äúlongitude‚Äù: 5.230195,‚Äú_score‚Äù: null,‚Äô\nIci, il n‚Äôest m√™me pas n√©cessaire en premi√®re approche\nd‚Äôutiliser le package json, l‚Äôinformation\n√©tant d√©j√† tabul√©e dans l‚Äô√©cho renvoy√© (on a la m√™me information pour tous les pays):\nOn peut donc se contenter de Pandas pour transformer nos donn√©es en\nDataFrame et Geopandas pour convertir en donn√©es\ng√©ographiques :\n\nimport pandas as pandas\nimport geopandas as gpd\n\n\ndef get_dpe_from_url(url):\n\n    req = requests.get(url)\n    wb = req.json()\n    df = pd.json_normalize(wb[\"results\"])\n\n    dpe = gpd.GeoDataFrame(\n        df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=4326\n    )\n    dpe = dpe.dropna(subset=[\"longitude\", \"latitude\"])\n\n    return dpe\n\n\ndpe = get_dpe_from_url(url_api)\ndpe.head(2)\n\n\n\n\n\n\n\n\n\nclasse_consommation_energie\ntr001_modele_dpe_type_libelle\nannee_construction\n_geopoint\nlatitude\nsurface_thermique_lot\n_i\ntr002_type_batiment_description\ngeo_adresse\n_rand\n...\nclasse_estimation_ges\nnom_methode_dpe\ntv016_departement_code\nconsommation_energie\ndate_etablissement_dpe\nlongitude\n_score\n_id\nversion_methode_dpe\ngeometry\n\n\n\n\n0\nE\nVente\n1\n45.927488,5.230195\n45.927488\n106.87\n2\nMaison Individuelle\nRue du Chateau 01800 Villieu-Loyes-Mollon\n959550\n...\nB\nM√©thode Facture\n01\n286.0\n2013-04-15\n5.230195\nNone\nHJt4TdUa1W0wZiNoQkskk\nNaN\nPOINT (5.23020 45.92749)\n\n\n1\nG\nVente\n1960\n45.931376,5.230461\n45.931376\n70.78\n9\nMaison Individuelle\n552 Rue Royale 01800 Villieu-Loyes-Mollon\n681070\n...\nD\nM√©thode 3CL\n01\n507.0\n2013-04-22\n5.230461\nNone\nUhMxzza1hsUo0syBh9DxH\n3CL-DPE, version 1.3\nPOINT (5.23046 45.93138)\n\n\n\n\n2 rows √ó 23 columns\n\n\n\n\nEssayons de repr√©senter sur une carte ces DPE avec les\nann√©es de construction des logements.\nAvec Folium, on obtient la carte interactive suivante :\n\nimport seaborn as sns\nimport folium\n\npalette = sns.color_palette(\"coolwarm\", 8)\n\n\ndef interactive_map_dpe(dpe):\n\n    # convert in number\n    dpe[\"color\"] = [\n        ord(dpe.iloc[i][\"classe_consommation_energie\"].lower()) - 96\n        for i in range(len(dpe))\n    ]\n    dpe = dpe.loc[dpe[\"color\"] &lt;= 7]\n    dpe[\"color\"] = [palette.as_hex()[x] for x in dpe[\"color\"]]\n\n    center = dpe[[\"latitude\", \"longitude\"]].mean().values.tolist()\n    sw = dpe[[\"latitude\", \"longitude\"]].min().values.tolist()\n    ne = dpe[[\"latitude\", \"longitude\"]].max().values.tolist()\n\n    m = folium.Map(location=center, tiles=\"OpenStreetMap\")\n\n    # I can add marker one by one on the map\n    for i in range(0, len(dpe)):\n        folium.Marker(\n            [dpe.iloc[i][\"latitude\"], dpe.iloc[i][\"longitude\"]],\n            popup=f\"Ann√©e de construction : {dpe.iloc[i]['annee_construction']}, &lt;br&gt;DPE : {dpe.iloc[i]['classe_consommation_energie']}\",\n            icon=folium.Icon(\n                color=\"black\", icon=\"home\", icon_color=dpe.iloc[i][\"color\"]\n            ),\n        ).add_to(m)\n\n    m.fit_bounds([sw, ne])\n\n    return m\n\n\nm = interactive_map_dpe(dpe)\n\n/opt/mamba/lib/python3.11/site-packages/geopandas/geodataframe.py:1443: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n# Afficher la carte\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#un-catalogue-incomplet-dapi-existantes",
    "href": "content/manipulation/04c_API_TP.html#un-catalogue-incomplet-dapi-existantes",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "2.3 Un catalogue incomplet d‚ÄôAPI existantes",
    "text": "2.3 Un catalogue incomplet d‚ÄôAPI existantes\nDe plus en plus de sites mettent des API √† disposition des d√©veloppeurs et autres curieux.\nPour en citer quelques-unes tr√®s connues :\n\nTwitter  : https://dev.twitter.com/rest/public\nFacebook  : https://developers.facebook.com/\nInstagram  : https://www.instagram.com/developer/\nSpotify  : https://developer.spotify.com/web-api/\n\nCependant, il est int√©ressant de ne pas se restreindre √† celles-ci dont les\ndonn√©es ne sont pas toujours les plus int√©ressantes. Beaucoup\nde producteurs de donn√©es, priv√©s comme publics, mettent √† disposition\nleurs donn√©es sous forme d‚ÄôAPI.\n\nAPI gouv : beaucoup d‚ÄôAPI officielles de l‚ÄôEtat fran√ßais\net acc√®s √† de la documentation\nInsee : https://api.insee.fr/catalogue/ et pynsee\nP√¥le Emploi : https://www.emploi-store-dev.fr/portail-developpeur-cms/home.html\nSNCF : https://data.sncf.com/api\nBanque Mondiale : https://datahelpdesk.worldbank.org/knowledgebase/topics/125589",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#utiliser-lapi-ban",
    "href": "content/manipulation/04c_API_TP.html#utiliser-lapi-ban",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "4.1 Utiliser l‚ÄôAPI BAN",
    "text": "4.1 Utiliser l‚ÄôAPI BAN\nLa documentation officielle de l‚ÄôAPI\npropose un certain nombre d‚Äôexemples de mani√®re de g√©olocaliser des donn√©es.\nDans notre situation, deux points d‚Äôentr√©e paraissent int√©ressants:\n\nL‚ÄôAPI /search/ qui repr√©sente un point d‚Äôentr√©e avec des URL de la forme\nhttps://api-adresse.data.gouv.fr/search/?q=\\&lt;adresse\\&gt;&postcode=\\&lt;codepostal\\&gt;&limit=1\nL‚ÄôAPI /search/csv qui prend un CSV en entr√©e et retourne ce m√™me CSV avec\nles observations g√©ocod√©es. La requ√™te prend la forme suivante, en apparence\nmoins simple √† mettre en oeuvre :\ncurl -X POST -F data=@search.csv -F columns=adresse -F columns=postcode https://api-adresse.data.gouv.fr/search/csv/\n\nLa tentation serait forte d‚Äôutiliser la premi√®re m√©thode avec une boucle sur les\nlignes de notre DataFrame pour g√©ocoder l‚Äôensemble de notre jeu de donn√©es.\nCela serait n√©anmoins une mauvaise id√©e car les communications entre notre\nsession Python et les serveurs de l‚ÄôAPI seraient beaucoup trop nombreuses\npour offrir des performances satisfaisantes.\nPour vous en convaincre, vous pouvez ex√©cuter le code suivant sur un petit\n√©chantillon de donn√©es (par exemple 100 comme ici) et remarquer que le temps\nd‚Äôex√©cution est assez important\n\nimport time\n\ndfgeoloc = df.loc[:, [\"Adresse\", \"CP\", \"Ville\"]].apply(\n    lambda s: s.str.lower().str.replace(\",\", \" \")\n)\ndfgeoloc[\"url\"] = (\n    dfgeoloc[\"Adresse\"] + \"+\" + dfgeoloc[\"Ville\"].str.replace(\"-\", \"+\")\n).str.replace(\" \", \"+\")\ndfgeoloc[\"url\"] = (\n    \"https://api-adresse.data.gouv.fr/search/?q=\"\n    + dfgeoloc[\"url\"]\n    + \"&postcode=\"\n    + df[\"CP\"]\n    + \"&limit=1\"\n)\ndfgeoloc = dfgeoloc.dropna()\n\nstart_time = time.time()\n\n\ndef get_geoloc(i):\n    print(i)\n    return gpd.GeoDataFrame.from_features(\n        requests.get(dfgeoloc[\"url\"].iloc[i]).json()[\"features\"]\n    )\n\n\nlocal = [get_geoloc(i) for i in range(len(dfgeoloc.head(10)))]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\nComme l‚Äôindique la documentation, si on d√©sire industrialiser notre processus\nde g√©ocodage, on va privil√©gier l‚ÄôAPI CSV.\nPour obtenir une requ√™te CURL coh√©rente avec le format d√©sir√© par l‚ÄôAPI\non va √† nouveau utiliser Requests mais cette fois avec des param√®tres\nsuppl√©mentaires:\n\ndata va nous permettre de passer des param√®tres √† CURL (√©quivalents aux -F\nde la requ√™te CURL) :\n\ncolumns: Les colonnes utilis√©es pour localiser une donn√©e. En l‚Äôoccurrence,\non utilise l‚Äôadresse et la ville (car les codes postaux n‚Äô√©tant pas uniques,\nun m√™me nom de voirie peut se trouver dans plusieurs villes partageant le m√™me\ncode postal) ;\npostcode: Le code postal de la ville. Id√©alement nous aurions utilis√©\nle code Insee mais nous ne l‚Äôavons pas dans nos donn√©es ;\nresult_columns: on restreint les donn√©es √©chang√©es avec l‚ÄôAPI aux\ncolonnes qui nous int√©ressent. Cela permet d‚Äôacc√©l√©rer les processus (on\n√©change moins de donn√©es) et de r√©duire l‚Äôimpact carbone de notre activit√©\n(moins de transferts = moins d‚Äô√©nergie d√©pens√©e). En l‚Äôoccurrence, on ne ressort\nque les donn√©es g√©olocalis√©es et un score de confiance en la g√©olocalisation ;\n\nfiles: permet d‚Äôenvoyer un fichier via CURL.\n\nLes donn√©es sont r√©cup√©r√©es avec request.post. Comme il s‚Äôagit d‚Äôune\ncha√Æne de caract√®re, nous pouvons directement la lire avec Pandas en\nutilisant io.StringIO pour √©viter d‚Äô√©crire des donn√©es interm√©diaires.\nLe nombre d‚Äô√©chos semblant √™tre limit√©, il\nest propos√© de proc√©der par morceaux\n(ici, le jeu de donn√©es est d√©coup√© en 5 morceaux).\n\nimport requests\nimport io\nimport numpy as np\nimport time\n\nparams = {\n    \"columns\": [\"Adresse\", \"Ville\"],\n    \"postcode\": \"CP\",\n    \"result_columns\": [\"result_score\", \"latitude\", \"longitude\"],\n}\n\ndf[[\"Adresse\", \"CP\", \"Ville\"]] = df.loc[:, [\"Adresse\", \"CP\", \"Ville\"]].apply(\n    lambda s: s.str.lower().str.replace(\",\", \" \")\n)\n\n\ndef geoloc_chunk(x):\n    dfgeoloc = x.loc[:, [\"Adresse\", \"CP\", \"Ville\"]]\n    dfgeoloc.to_csv(\"datageocodage.csv\", index=False)\n    response = requests.post(\n        \"https://api-adresse.data.gouv.fr/search/csv/\",\n        data=params,\n        files={\"data\": (\"datageocodage.csv\", open(\"datageocodage.csv\", \"rb\"))},\n    )\n    geoloc = pd.read_csv(io.StringIO(response.text), dtype={\"CP\": \"str\"})\n    return geoloc\n\n\nstart_time = time.time()\ngeodata = [geoloc_chunk(dd) for dd in np.array_split(df, 10)]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\nCette m√©thode est beaucoup plus rapide et permet ainsi, une fois retourn√© √† nos\ndonn√©es initiales, d‚Äôavoir un jeu de donn√©es g√©olocalis√©.\n\n# Retour aux donn√©es initiales\ngeodata = pd.concat(geodata, ignore_index=True)\ndf_xy = df.merge(geodata, on=[\"Adresse\", \"CP\", \"Ville\"])\ndf_xy = df_xy.dropna(subset=[\"latitude\", \"longitude\"])\n\n# Mise en forme pour le tooltip\ndf_xy[\"text\"] = (\n    df_xy[\"Raison_Sociale\"]\n    + \"&lt;br&gt;\"\n    + df_xy[\"Adresse\"]\n    + \"&lt;br&gt;\"\n    + df_xy[\"Ville\"]\n    + \"&lt;br&gt;Nombre de candidats:\"\n    + df_xy[\"B_NB\"].astype(str)\n)\ndf_xy.filter(\n    [\"Raison_Sociale\", \"Adresse\", \"CP\", \"Ville\", \"latitude\", \"longitude\"],\n    axis=\"columns\",\n).sample(10)\n\n\n\n\n\n\n\n\n\nRaison_Sociale\nAdresse\nCP\nVille\nlatitude\nlongitude\n\n\n\n\n938\nPROVENCE CONDUITE\nrue des ecoles\n13770\nvenelles\n43.598754\n5.483369\n\n\n10980\nLe Berceau de la Conduite\n4 rond-point blanchard ccial la marina\n97110\npointe-√†-pitre\n16.223018\n-61.527147\n\n\n6924\nCARLY-GROUPE LARGER\n329 avenue d'altkirch\n68350\nbrunstatt\n47.719909\n7.317761\n\n\n8166\nMODERNE Auto Ecole\n16 rue de montereau\n77000\nmelun\n48.540565\n2.674720\n\n\n3017\n\"\"\"AUTO-ECOLE LA PRESQU'ILE II\"\"\"\n43 avenue de la presqu'ile\n33950\nlege cap-ferret\n44.790517\n-1.156321\n\n\n11128\nAUTO ECOLE ROUGE ET BLANC\n8 rue joseph clerc\n97214\nle lorrain\n14.832452\n-61.055379\n\n\n3684\nCESR 38 EYBENS\n5 rue des vors\n38320\neybens\n45.152162\n5.748159\n\n\n11276\nECO PERMIS\n28 a rue leconte delisle\n97442\nst philippe\n-21.361268\n55.762783\n\n\n1064\nECPA St Martin\n50 av de la r√©publique\n13310\nst martin de crau\n43.637737\n4.807731\n\n\n3493\nKRISALYDE BOURGUEIL\n3 rue du commerce\n37140\nbourgueil\n47.282235\n0.169184\n\n\n\n\n\n\n\n\nIl ne reste plus qu‚Äô√† utiliser Geopandas\net nous serons en mesure de faire une carte des localisations des auto-√©coles :\n\n# Transforme en geopandas pour les cartes\nimport geopandas as gpd\n\ndfgeo = gpd.GeoDataFrame(\n    df_xy, geometry=gpd.points_from_xy(df_xy.longitude, df_xy.latitude)\n)\n\nNous allons repr√©senter les stations dans l‚ÄôEssonne avec un zoom initialement\nsur les villes de Massy et Palaiseau. Le code est le suivant :\n\nimport folium\n\n# Repr√©senter toutes les auto√©coles de l'Essonne\ndf_91 = df_xy.loc[df_xy[\"Dept\"] == \"091\"]\n\n# Centrer la vue initiale sur Massy-Palaiseau\ndf_pal = df_xy.loc[df_xy[\"Ville\"].isin([\"massy\", \"palaiseau\"])]\ncenter = df_pal[[\"latitude\", \"longitude\"]].mean().values.tolist()\nsw = df_pal[[\"latitude\", \"longitude\"]].min().values.tolist()\nne = df_pal[[\"latitude\", \"longitude\"]].max().values.tolist()\n\nm = folium.Map(location=center, tiles=\"OpenStreetMap\")\n\n# I can add marker one by one on the map\nfor i in range(0, len(df_91)):\n    folium.Marker(\n        [df_91.iloc[i][\"latitude\"], df_91.iloc[i][\"longitude\"]],\n        popup=df_91.iloc[i][\"text\"],\n        icon=folium.Icon(icon=\"car\", prefix=\"fa\"),\n    ).add_to(m)\n\nm.fit_bounds([sw, ne])\n\nCe qui permet d‚Äôobtenir la carte:\n\n# Afficher la carte\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nVous pouvez aller plus loin avec l‚Äôexercice suivant.\n\n\n Exercice 2 : Quelles sont les auto-√©coles les plus proches de chez moi ?\nOn va supposer que vous cherchez, dans un rayon donn√© autour d‚Äôun centre ville,\nles auto-√©coles disponibles.\n\n\nFonction n√©cessaire pour cet exercice\n\nCet exercice n√©cessite une fonction pour cr√©er un cercle\nautour d‚Äôun point\n(source ici).\nLa voici :\nfrom functools import partial\nimport pyproj\nfrom shapely.ops import transform\nfrom shapely.geometry import Point\n\nproj_wgs84 = pyproj.Proj(\"+proj=longlat +datum=WGS84\")\n\n\ndef geodesic_point_buffer(lat, lon, km):\n    # Azimuthal equidistant projection\n    aeqd_proj = \"+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0\"\n    project = partial(\n        pyproj.transform, pyproj.Proj(aeqd_proj.format(lat=lat, lon=lon)), proj_wgs84\n    )\n    buf = Point(0, 0).buffer(km * 1000)  # distance in metres\n    return transform(project, buf).exterior.coords[:]\n\n\nPour commencer, utiliser l‚ÄôAPI Geo\npour la ville de Palaiseau.\nAppliquer la fonction geodesic_point_buffer au centre ville de Palaiseau\nNe conserver que les auto-√©coles dans ce cercle et les ordonner\n\nSi vous avez la r√©ponse √† la question 3, n‚Äôh√©sitez pas √† la soumettre sur Github afin que je compl√®te la correction üòâ !\n\n\n\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed\n\n\n\n\n/opt/mamba/lib/python3.11/site-packages/shapely/ops.py:276: FutureWarning:\n\nThis function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n\n\n\nPour se convaincre, de notre cercle constitu√© lors de\nla question 2, on peut repr√©senter une carte.\nOn a bien un cercle centr√© autour de Palaiseau :",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#d√©couvrir-lapi-dopenfoodfacts",
    "href": "content/manipulation/04c_API_TP.html#d√©couvrir-lapi-dopenfoodfacts",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "5.1 D√©couvrir l‚ÄôAPI d‚ÄôOpenFoodFacts",
    "text": "5.1 D√©couvrir l‚ÄôAPI d‚ÄôOpenFoodFacts\nPour vous aidez, vous pouvez regarder une exemple de structure du JSON ici :\nhttps://world.openfoodfacts.org/api/v0/product/3274080005003.json en particulier la cat√©gorie nutriments.\n\n\n Exercice 3 : Retrouver des produits dans l'openfood facts üçï\nVoici une liste de code-barres:\n3274080005003,  5449000000996, 8002270014901, 3228857000906, 3017620421006, 8712100325953\nUtiliser l‚ÄôAPI d‚Äôopenfoodfacts\n(l‚ÄôAPI, pas depuis le CSV !)\npour retrouver les produits correspondants\net leurs caract√©ristiques nutritionnelles.\nLe panier para√Æt-il √©quilibr√© ? üç´\nR√©cup√©rer l‚ÄôURL d‚Äôune des images et l‚Äôafficher dans votre navigateur.\n\n\nVoici par exemple la photo du produit ayant le code-barre 5449000000996. Vous le reconnaissez ?",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#informations-additionnelles",
    "href": "content/manipulation/04c_API_TP.html#informations-additionnelles",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n04ce567\n\n\n2023-10-23 19:04:01\n\n\nLino Galiana\n\n\nMise en forme chapitre API (#442)\n\n\n\n\n3eb0aeb\n\n\n2023-10-23 11:59:24\n\n\nThomas Faria\n\n\nRelecture jusqu‚Äôaux API (#439)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\na63319a\n\n\n2023-10-04 15:29:04\n\n\nLino Galiana\n\n\nCorrection du TP numpy (#419)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n62aeec1\n\n\n2023-06-10 17:40:39\n\n\nLino Galiana\n\n\nAvertissement sur la partie API (#358)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\n2dc82e7\n\n\n2022-10-18 22:46:47\n\n\nLino Galiana\n\n\nRelec Kim (visualisation + API) (#302)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n1239e3e\n\n\n2022-06-21 14:05:15\n\n\nLino Galiana\n\n\nEnonces (#239)\n\n\n\n\nbb38643\n\n\n2022-06-08 16:59:40\n\n\nLino Galiana\n\n\nR√©pare bug leaflet (#234)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n1ca1a8a\n\n\n2022-05-31 11:44:23\n\n\nLino Galiana\n\n\nRetour du chapitre API (#228)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#footnotes",
    "href": "content/manipulation/04c_API_TP.html#footnotes",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa documentation est √©galement disponible ici‚Ü©Ô∏é\nLe JSON est un format tr√®s appr√©ci√© dans le domaine du big data\ncar il permet d‚Äôempiler des donn√©es\nqui ne sont pas compl√®tes. Il\ns‚Äôagit d‚Äôun des formats privil√©gi√©s du paradigme No-SQL pour lequel\ncet excellent cours propose plus de d√©tails.‚Ü©Ô∏é\nSuivant les API, nous avons soit besoin de rien de plus si nous parvenons directement √† obtenir un json, soit devoir utiliser un parser comme BeautifulSoup dans le cas contraire. Ici, le JSON peut √™tre format√© relativement ais√©ment.‚Ü©Ô∏é",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html",
    "href": "content/manipulation/03_geopandas_TP.html",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nDans ce TP,\nnous allons apprendre √† importer et\nmanipuler des donn√©es spatiales avec\nPython.\nCe langage propose\ndes fonctionnalit√©s tr√®s int√©ressantes pour ce type de\ndonn√©es complexes qui le rendent capable de se comporter\ncomme un logiciel de SIG1.\nGr√¢ce √† la librairie Geopandas, une extension\nde Pandas aux donn√©es spatiales, les\ndonn√©es g√©ographiques pourront √™tre manipul√©es\ncomme n‚Äôimporte quel type de donn√©es avec Python.\nLa complexit√© induite par la dimension spatiale ne sera pas ressentie.\nIllustration du principe des donn√©es spatiales (documentation de `sf`, l'√©quivalent de `Geopandas` en `R`)\n\n\n\n![](https://user-images.githubusercontent.com/520851/50280460-e35c1880-044c-11e9-9ed7-cc46754e49db.jpg){width=\"70%\"}\nCe chapitre illustre √† partir d‚Äôexemples pratiques certains principes centraux de l‚Äôanalyse de donn√©es :\nSi vous √™tes int√©ress√©s par R,\nune version tr√®s proche de ce TP est disponible dans ce cours de R.\nNote\nLe package cartiflette est exp√©rimental\net n‚Äôest disponible que sur\nGithub, pas sur PyPi.\nIl est amen√© √† √©voluer rapidement et cette page sera mise √† jour\nquand de nouvelles fonctionalit√©s (notamment l‚Äôutilisation d‚ÄôAPI)\nseront disponibles pour encore simplifier la r√©cup√©ration de\ncontours g√©ographiques.\nPour installer cartiflette, il est n√©cessaire d‚Äôutiliser les commandes suivantes\ndepuis un Jupyter Notebook (si vous utilisez la ligne de commande directement,\nvous pouvez retirer les ! en d√©but de ligne):\nCes commandes permettent de r√©cup√©rer l‚Äôensemble du code\nsource depuis Github",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#pr√©liminaires",
    "href": "content/manipulation/03_geopandas_TP.html#pr√©liminaires",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "0.1 Pr√©liminaires",
    "text": "0.1 Pr√©liminaires\nAvant de se lancer dans le TD, il est n√©cessaire d‚Äôinstaller quelques\nlibrairies qui ne sont pas disponibles par d√©faut, dans l‚Äôenvironnement Python\nde base de la data science. Pour installer celles-ci depuis une\ncellule de notebook Jupyter, le code suivant est √† ex√©cuter :\n\n!pip install fiona shapely\n!pip install pyproj rtree\n!pip install contextily\n!pip install geopandas\n!pip install pygeos\n!pip install topojson\n\nApr√®s installations,\nles packages √† importer pour progresser\ndans ce chapitre sont les suivants :\n\nimport geopandas as gpd\nimport contextily as ctx\nimport matplotlib.pyplot as plt\n\nLes instructions d‚Äôinstallation du package cartiflette\nsont quant √† elles d√©taill√©es dans le chapitre\npr√©c√©dent.\n\n!pip install requests py7zr geopandas openpyxl tqdm s3fs PyYAML xlrd\n!pip install git+https://github.com/inseefrlab/cartiflette\n\n\nfrom cartiflette import carti_download",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#lire-et-enrichir-des-donn√©es-spatiales",
    "href": "content/manipulation/03_geopandas_TP.html#lire-et-enrichir-des-donn√©es-spatiales",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "0.2 Lire et enrichir des donn√©es spatiales",
    "text": "0.2 Lire et enrichir des donn√©es spatiales\nDans cette partie,\nnous utiliserons\nles fonds de carte de l‚ÄôIGN dont\nla mise √† disposition est facilit√©e\npar le projet cartiflette2.\n\n\n Exercice 1: d√©couverte des objets g√©ographiques\nEn premier lieu, on r√©cup√®re des donn√©es g√©ographiques gr√¢ce\nau package cartiflette.\n\nUtiliser\nle code ci-dessous pour\nt√©l√©charger les donn√©es communales (produit Admin Express de l‚ÄôIGN)\ndes d√©partements de la petite couronne (75, 92, 93 et 94)\nde mani√®re simplifi√©e gr√¢ce au package\ncartiflette:\n\n\ncommunes_borders = carti_download(\n    crs=4326,\n    values=[\"75\", \"92\", \"93\", \"94\"],\n    borders=\"COMMUNE\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\n\nRegarder les premi√®res lignes des donn√©es. Identifier la diff√©rence avec\nun dataframe standard.\n\n\n\n\n\n\n\n\n\n\n\nINSEE_DEP\nINSEE_REG\nID\nNOM\nINSEE_COM\nSTATUT\nPOPULATION\nAREA\nARR\nCV\n...\nAAV2020\nTAAV2017\nTDAAV2017\nCATEAAV2020\nBV2012\nLIBELLE_DEPARTEMENT\nLIBELLE_REGION\nPAYS\nSOURCE\ngeometry\n\n\n\n\n0\n75\n11\nCOMMUNE_0000000009736048\nParis\n75056\nCapitale d'√©tat\n2165423\nmetropole\n751\n75ZZ\n...\n001\n5\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.36420 48.81640, 2.38077 48.82170, ...\n\n\n1\n92\n11\nCOMMUNE_0000000009736037\nLevallois-Perret\n92044\nCommune simple\n66082\nmetropole\n922\n9216\n...\n001\n5\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.28739 48.90364, 2.28427 48.90229, ...\n\n\n2\n92\n11\nCOMMUNE_0000000009736055\nBois-Colombes\n92009\nCommune simple\n28841\nmetropole\n922\n9211\n...\n001\n5\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.26639 48.90629, 2.26494 48.91027, ...\n\n\n3\n92\n11\nCOMMUNE_0000000009736538\nMalakoff\n92046\nCommune simple\n30950\nmetropole\n921\n9218\n...\n001\n5\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.27818 48.81425, 2.27449 48.81343, ...\n\n\n4\n92\n11\nCOMMUNE_0000000009736038\nClichy\n92024\nCommune simple\n63089\nmetropole\n922\n9209\n...\n001\n5\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.30377 48.89415, 2.30769 48.89601, ...\n\n\n\n\n5 rows √ó 26 columns\n\n\n\n\n\nAfficher le crs de communes_borders. Ce dernier contr√¥le la\ntransformation de l‚Äôespace tridimensionnel terrestre en une surface plane.\nUtiliser to_crs pour transformer les donn√©es en Lambert 93, le\nsyst√®me officiel (code EPSG 2154).\nAfficher les communes des Hauts de Seine (d√©partement 92) et utiliser la m√©thode\nplot\nNe conserver que Paris et r√©pr√©senter les fronti√®res sur une carte : quel est le probl√®me pour\nune analyse de Paris intramuros?\n\nOn remarque rapidement le probl√®me.\nOn ne dispose ainsi pas des limites des arrondissements parisiens, ce\nqui appauvrit grandement la carte de Paris.\n\nCette fois, utiliser l‚Äôargument borders=\"COMMUNE_ARRONDISSEMENT\" pour obtenir\nun fonds de carte consolid√© des communes avec les arrondissements dans les grandes villes.\nConvertir en Lambert 93.",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#le-syst√®me-de-projection",
    "href": "content/manipulation/03_geopandas_TP.html#le-syst√®me-de-projection",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "0.3 Le syst√®me de projection",
    "text": "0.3 Le syst√®me de projection\nUn concept central dans les logiciels de SIG est la notion de\nprojection. L‚Äôexercice pr√©c√©dent imposait parfois certaines projections\nsans expliquer l‚Äôimportance de ces choix. Python, comme\ntout SIG, permet une gestion coh√©rente des projections.\nObservez les variations significatives\nde proportions pour certains pays selon les projections\nchoisies:\n\nhtml`&lt;div&gt;${container_projection}&lt;/div&gt;`\n\n\n\n\n\n\n\ncontainer_projection = html`&lt;div class=\"container\"&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projection\"&gt;\n      &lt;div class=\"projection-label\"&gt;Choisir une projection&lt;/div&gt;\n      ${viewof projection}\n    &lt;/div&gt;\n  &lt;/div&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projectedMap\"&gt;\n      ${projectedMap}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\nviewof projection = projectionInput({\n  name: \"\",\n  value: \"Mercator\"\n})\n\n\n\n\n\n\n\nimport {projectionInput} from \"@fil/d3-projections\"\nimport {map} from \"@linogaliana/base-map\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprojectedMap = map(projection,\n                   {\n                     //svg: true,\n                     value: projection.options,\n                     width: width_projected_map,\n                     //height: 300,\n                     //rotate: [0, -90],\n                     //inertia: true,\n                     show_equator: true,\n                     background: \"#f1f0eb\"\n                     \n                     //show_structure: true\n                   })\n\n\n\n\n\n\n\nwidth_projected_map = screen.width/2\n\n\n\n\n\n\n\n\n Exercice 2 : Les projections, repr√©sentations et approximations\nVoici un code utilisant encore\ncartiflette\npour r√©cup√©rer les fronti√®res fran√ßaises (d√©coup√©es par r√©gion):\n\nfrance = carti_download(\n    values=[\"France\"],\n    crs=4326,\n    borders=\"REGION\",\n    vectorfile_format=\"geojson\",\n    simplification=50,\n    filter_by=\"FRANCE_ENTIERE\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\nfrance = france.loc[france[\"INSEE_REG\"] &gt; 10]\n\n\nS‚Äôamuser √† repr√©senter les limites de la France avec plusieurs projections:\n\n\nMercator WGS84 (EPSG: 4326)\nProjection healpix (+proj=healpix +lon_0=0 +a=1)\nProjection pr√©vue pour Tahiti (EPSG: 3304)\nProjection Albers pr√©vue pour Etats-Unis (EPSG: 5070)\n\n\nCalculer la superficie en \\(km^2\\)\ndes r√©gions fran√ßaises dans les deux syst√®mes de projection suivants :\nWorld Mercator WGS84 (EPSG: 3395) et Lambert 93 (EPSG: 2154). Calculer la diff√©rence en \\(km^2\\)\npour chaque r√©gion.\n\n\n\nAvec la question 1 illustrant quelques cas pathologiques,\non comprend que les projections ont un effet d√©formant\nqui se voit bien lorsqu‚Äôon les repr√©sente c√¥te √† c√¥te sous\nforme de cartes :\n\n\n\n\n\n\n\n\n\n\n\n(a) Mercator WGS84 (EPSG: 4326)\n\n\n\n\n\n\n\n\n\n\n\n(b) Projection healpix (+proj=healpix +lon_0=0 +a=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Projection pr√©vue pour Tahiti (EPSG: 3304)\n\n\n\n\n\n\n\n\n\n\n\n(d) Projection Albers pr√©vue pour Etats-Unis (EPSG: 5070)\n\n\n\n\n\n\n\nFigure¬†1: Comparaison des projections\n\n\n\nCependant le probl√®me n‚Äôest pas que visuel, il est √©galement\nnum√©rique. Les calculs g√©om√©triques am√®nent √† des diff√©rences\nassez notables selon le syst√®me de r√©f√©rence utilis√©.\nOn peut repr√©senter ces approximations sur une carte3 pour se faire\nune id√©e des r√©gions o√π l‚Äôerreur de mesure est la plus importante.\n\n\n\n\n\n\n\n\n\nCe type d‚Äôerreur de mesure est normal √† l‚Äô√©chelle du territoire fran√ßais.\nLes projections h√©rit√®res du Mercator d√©forment les distances,\nsurtout lorqu‚Äôon se rapproche de l‚Äô√©quateur ou des p√¥les.\n\n\n\n\n\n\n\n\n\n(a) Exemple de reprojection de pays depuis le site thetruesize.com\n\n\n\n\n\n\n\n\n\n(b) ‚ÄúDon‚Äôt trust the Mercator projection‚Äù sur Reddit\n\n\n\n\n\nFigure¬†2: La projection Mercator, une vision d√©formante\n\n\n\nPour aller plus loin, la carte interactive\nsuivante, construite par Nicolas Lambert, issue de\nce notebook Observable, illustre l‚Äôeffet\nd√©formant de la projection Mercator, et de quelques-unes autres,\nsur notre perception de la taille des pays.\n\n\nVoir la carte interactive\n\n\nhtml`&lt;div class=\"grid-container\"&gt;\n  &lt;div class=\"viewof-projection\"&gt;${viewof projectionBertin}&lt;/div&gt;\n  &lt;div class=\"viewof-mycountry\"&gt;${viewof mycountry}&lt;/div&gt;\n  &lt;div class=\"map-bertin\"&gt;${mapBertin}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\nimport {map as mapBertin, viewof projection as projectionBertin, viewof mycountry} from \"@neocartocnrs/impact-of-projections-on-areas\"\n\n\n\n\n\n\nIl n‚Äôest donc pas suprenant que nos d√©formations soient exacerb√©es aux\nextr√®mes du territoire m√©tropolitain.\nSi les approximations sont l√©g√®res sur de petits territoires,\nles erreurs peuvent √™tre\nnon n√©gligeables √† l‚Äô√©chelle de la France.\nIl faut donc syst√©matiquement\nrepasser les donn√©es dans le syst√®me de projection Lambert 93 (le\nsyst√®me officiel pour la m√©tropole) avant d‚Äôeffectuer des calculs g√©om√©triques.",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#utiliser-des-donn√©es-g√©ographiques-comme-des-couches-graphiques",
    "href": "content/manipulation/03_geopandas_TP.html#utiliser-des-donn√©es-g√©ographiques-comme-des-couches-graphiques",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "0.4 Utiliser des donn√©es g√©ographiques comme des couches graphiques",
    "text": "0.4 Utiliser des donn√©es g√©ographiques comme des couches graphiques\nSouvent, le d√©coupage communal ne sert qu‚Äôen fond de cartes, pour donner des\nrep√®res. En compl√©ment de celui-ci, on peut d√©sirer exploiter\nun autre jeu de donn√©es.\nOn va partir des donn√©es de localisation des\nstations velib,\ndisponibles sur le site d‚Äôopen data de la ville de Paris et\nrequ√™tables directement en utilisant un URL\n\nurl = \"https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr\"\n\nDans le prochain exercice, nous proposons de cr√©er rapidement une\ncarte comprenant trois couches :\n\nLes localisations de stations sous forme de points ;\nLes bordures des communes et arrondissements pour contextualiser ;\nLes bordures des d√©partements en traits plus larges pour contextualiser √©galement.\n\nNous irons plus loin dans le travail cartographique dans le prochain\nchapitre. Mais √™tre en mesure de positionner rapidement\nses donn√©es sur une carte est\ntoujours utile dans un travail exploratoire.\nEn amont de l‚Äôexercice,\nutiliser la fonction suivante du package cartiflette pour r√©cup√©rer\nle fonds de carte des d√©partements de la petite couronne:\n\nidf = carti_download(\n    values=[\"11\"],\n    crs=4326,\n    borders=\"DEPARTEMENT\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"REGION\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\npetite_couronne_departements = idf.loc[\n    idf[\"INSEE_DEP\"].isin([\"75\", \"92\", \"93\", \"94\"])\n].to_crs(2154)\n\n\n\n Exercice 3: importer et explorer les donn√©es velib\nOn commence par r√©cup√©rer les donn√©es n√©cessaires √† la production\nde cette carte.\n\nEn utilisant l‚ÄôURL pr√©c√©dent, importer les donn√©es velib sous le nom station\nV√©rifier la projection g√©ographique de station (attribut crs). Si celle-ci est diff√©rente des donn√©es communales, reprojeter ces\nderni√®res dans le m√™me syst√®me de projection que les stations de v√©lib\nNe conserver que les 50 principales stations (variable capacity)\n\nOn peut maintenant construire la carte de mani√®re s√©quentielle avec la m√©thode plot en s‚Äôaidant de cette documentation\n\nEn premier lieu, gr√¢ce √† boundary.plot,\nrepr√©senter la couche de base des limites des communes et arrondissements:\n\nUtiliser les options edgecolor = \"black\" et linewidth = 0.5\nNommer cet objet base\n\nAjouter la couche des d√©partements avec les options edgecolor = \"blue\" et linewidth = 0.7\nAjouter les positions des stations\net ajuster la taille en fonction de la variable capacity. L‚Äôesth√©tique des points obtenus peut √™tre contr√¥l√© gr√¢ce aux options color = \"red\" et alpha = 0.4.\nRetirer les axes et ajouter un titre avec les options ci-dessous:\n\nbase.set_axis_off()\nbase.set_title(\"Les 50 principales stations de V√©lib\")\n\n\nLa couche de base obtenue √† l‚Äôissue de la question 4.\n\n\n\n\n\n\n\n\n\nPuis en y ajoutant les limites d√©partementales (question 5).\n\n\n\n\n\n\n\n\n\nPuis les stations (question 6).\n\n\n\n\n\n\n\n\n\nLa carte finale, apr√®s mise en forme:",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#jointures-spatiales",
    "href": "content/manipulation/03_geopandas_TP.html#jointures-spatiales",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "0.5 Jointures spatiales",
    "text": "0.5 Jointures spatiales\nLes jointures attributaires fonctionnent comme avec un Pandas classique.\nPour conserver un objet spatial in fine, il faut faire attention √† utiliser en premier (base de gauche) l‚Äôobjet Geopandas.\nEn revanche, l‚Äôun des int√©r√™ts des objets Geopandas est qu‚Äôon peut √©galement faire une jointure sur la dimension spatiale gr√¢ce √† plusieurs fonctions.\nLa documentation √† laquelle se r√©f√©rer est ici.\nUne version p√©dagogique pour R se trouve dans la documentation utilitR.\n\n\n Exercice 4: Associer les stations aux communes et arrondissements auxquels elles appartiennent\nDans cet exercice, on va supposer que :\n\nles localisations des stations velib\nsont stock√©es dans un dataframe nomm√© stations\nles donn√©es administratives\nsont dans un dataframe nomm√© petite_couronne.\n\n\nFaire une jointure spatiale pour enrichir les donn√©es de stations en y ajoutant des informations de petite_couronne. Appeler cet objet stations_info.\nCr√©er les objets stations_19e et arrondissement_19e pour stocker, respectivement,\nles stations appartenant au 19e et les limites de l‚Äôarrondissement.\nRepr√©senter la carte des stations du 19e arrondissement avec le code suivant :\n\nbase = petite_couronne.loc[petite_couronne[\"INSEE_DEP\"] == \"75\"].boundary.plot(\n    edgecolor=\"k\", linewidth=0.5\n)\narrondissement_19e.boundary.plot(ax=base, edgecolor=\"red\", linewidth=0.9)\nstations_19.plot(ax=base, color=\"red\", alpha=0.4)\nbase.set_axis_off()\nbase.set_title(\"Les stations V√©lib du 19e arrondissement\")\nbase\n\nCompter le nombre de stations velib et le nombre de places velib par arrondissement ou commune. Repr√©senter sur une carte chacune des informations\nRepr√©senter les m√™mes informations mais en densit√© (diviser par la surface de l‚Äôarrondissement ou commune en km2)\n\n\n\n\n\n\n\n\n\n\n\n\nCarte obtenue √† la question 4 :\n\n\n\n\n\n\n\n\n\nAvec la carte de la question 4, bas√©e sur des aplats de couleurs (choropleth map), le lecteur est victime d‚Äôune illusion classique. Les arrondissements les plus visibles sur la carte sont les plus grands. D‚Äôailleurs c‚Äôest assez logique qu‚Äôils soient √©galement mieux pourvus en velib. M√™me si l‚Äôoffre de velib est probablement plus reli√©e √† la densit√© de population et d‚Äô√©quipements, on peut penser que l‚Äôeffet taille joue et qu‚Äôainsi on est victime d‚Äôune illusion avec la carte pr√©c√©dente.\nSi on repr√©sente plut√¥t la capacit√© sous forme de densit√©, pour tenir compte de la taille diff√©rente des arrondissements, les conclusions sont invers√©es et correspondent mieux aux attentes d‚Äôun mod√®le centre-p√©riph√©rie. Les arrondissements centraux sont mieux pourvus, cela se voit encore mieux avec des ronds proportionnels plut√¥t qu‚Äôune carte chorol√®pthe.",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#exercice-suppl√©mentaire",
    "href": "content/manipulation/03_geopandas_TP.html#exercice-suppl√©mentaire",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "0.6 Exercice suppl√©mentaire",
    "text": "0.6 Exercice suppl√©mentaire\nLes exercices pr√©c√©dents ont permis de se familiariser au traitement de donn√©es\nspatiales. N√©anmoins il arrive de devoir jongler plus avec la\ndimension g√©om√©trique par exemple pour changer d‚Äô√©chelle ou introduire\ndes fusions/dissolutions de g√©om√©tries.\nImaginons que chaque utilisateur de velib se d√©place exclusivement\nvers la station la plus proche (√† supposer qu‚Äôil n‚Äôy a jamais p√©nurie\nou surcapacit√©). Quelle est la carte de la couverture des v√©libs ?\nPour r√©pondre √† ce type de question, on utilise fr√©quemment la\nla tesselation de Vorono√Ø,\nune op√©ration classique pour transformer des points en polygones. L‚Äôexercice suivant\npermet de se familiariser avec cette approche4.\nExercice √† venir",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#informations-additionnelles",
    "href": "content/manipulation/03_geopandas_TP.html#informations-additionnelles",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc80ffa8\n\n\n2024-04-06 16:12:43\n\n\nlinogaliana\n\n\nProblem with geopandas\n\n\n\n\n3f7fff1\n\n\n2024-04-06 13:55:28\n\n\nLino Galiana\n\n\nUpdate 03_geopandas_TP.qmd\n\n\n\n\ne57f9cc\n\n\n2024-04-06 13:12:25\n\n\nLino Galiana\n\n\nRetire commentaire inutile\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\nce33d5d\n\n\n2024-01-16 15:47:22\n\n\nLino Galiana\n\n\nAdapte les exemples de code de cartiflette (#482)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n8071bbb\n\n\n2023-10-23 17:43:37\n\n\ntomseimandi\n\n\nMake minor changes to 02b, 03, 04a (#440)\n\n\n\n\n102ce9f\n\n\n2023-10-22 11:39:37\n\n\nThomas Faria\n\n\nRelecture Thomas, premi√®re partie (#438)\n\n\n\n\ne918be6\n\n\n2023-10-09 12:39:31\n\n\nlinogaliana\n\n\nchange featured\n\n\n\n\nf8831e7\n\n\n2023-10-09 10:53:34\n\n\nLino Galiana\n\n\nRelecture antuki geopandas (#429)\n\n\n\n\n20432f7\n\n\n2023-09-27 15:31:22\n\n\nLino Galiana\n\n\nRestructure le TP GeoPandas (#414)\n\n\n\n\n338c07e\n\n\n2023-09-26 13:44:45\n\n\nlinogaliana\n\n\neval false\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nbdf396d\n\n\n2023-06-11 17:22:29\n\n\nLino Galiana\n\n\nupdate geopandas part for pandas v2 (#360)\n\n\n\n\n3912a7e\n\n\n2023-02-07 17:18:25\n\n\nLino Galiana\n\n\nBack to IGN provider (#350)\n\n\n\n\n3b8715e\n\n\n2022-12-11 18:52:23\n\n\nLino Galiana\n\n\nTP geopandas (#333)\n\n\n\n\n2e215a9\n\n\n2022-10-28 14:35:09\n\n\nLino Galiana\n\n\nSolve problem geopandas TP (#309)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\naf763cc\n\n\n2022-10-12 10:17:56\n\n\nLino Galiana\n\n\nReprise exercice geopandas (#294)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n735e677\n\n\n2021-10-19 09:46:12\n\n\nLino Galiana\n\n\nR√®gle probl√®me des cartes qui s‚Äôaffichent pas (#165)\n\n\n\n\n5ad057f\n\n\n2021-10-10 15:13:16\n\n\nLino Galiana\n\n\nRelectures pandas & geopandas (#159)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\nbadc492\n\n\n2020-09-22 18:36:33\n\n\nLino Galiana\n\n\nFinalize geopandas section (#48)\n\n\n\n\n15b7dad\n\n\n2020-09-18 11:03:41\n\n\nLino Galiana\n\n\nFinalisation TP geopandas (#33)\n\n\n\n\nffb05cf\n\n\n2020-09-10 17:18:15\n\n\nLino Galiana\n\n\nPartie sur les donn√©es spatiales (#20) :warning: pas fini\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†1¬†(a): Mercator WGS84 (EPSG: 4326)\nFigure¬†1¬†(b): Projection healpix (+proj=healpix +lon_0=0 +a=1)\nFigure¬†1¬†(c): Projection pr√©vue pour Tahiti (EPSG: 3304)\nFigure¬†1¬†(d): Projection Albers pr√©vue pour Etats-Unis (EPSG: 5070)\nFigure¬†2¬†(a): Exemple de reprojection de pays depuis le site thetruesize.com\nFigure¬†2¬†(b): ‚ÄúDon‚Äôt trust the Mercator projection‚Äù sur Reddit",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#footnotes",
    "href": "content/manipulation/03_geopandas_TP.html#footnotes",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nD‚Äôailleurs, le logiciel de cartographie sp√©cialis√© QGIS, s‚Äôappuie sur Python\npour les manipulations de donn√©es n√©cessaires avant de r√©aliser une carte.‚Ü©Ô∏é\nLa librairie Python est encore exp√©rimentale mais\nles prochaines semaines devraient permettre de combler ce manque.\nUne documentation interactive illustrant le code n√©cessaire pour reproduire\ntelle ou telle carte est disponible sur linogaliana.github.io/cartiflette-website.‚Ü©Ô∏é\nCette carte n‚Äôest pas trop soign√©e, c‚Äôest normal nous verrons comment\nfaire de belles cartes ult√©rieurement.‚Ü©Ô∏é\nDans ce document de travail sur donn√©es de t√©l√©phonie mobile, on montre n√©anmoins que cette approche n‚Äôest pas sans biais\nsur des ph√©nom√®nes o√π l‚Äôhypoth√®se de proximit√© spatiale est\ntrop simplificatrice.‚Ü©Ô∏é",
    "crumbs": [
      "Pratique de geopandas avec les donn√©es v√©lib"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html",
    "href": "content/manipulation/02b_pandas_TP.html",
    "title": "Pratique de pandas : un exemple complet",
    "section": "",
    "text": "Les exemples de ce TP sont visualisables sous forme de Jupyter Notebooks:\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nDans cette s√©rie d‚Äôexercices Pandas,\nnous allons d√©couvrir comment manipuler plusieurs\njeux de donn√©es avec Python.\nSi vous √™tes int√©ress√©s par R,\nune version tr√®s proche de ce TP est\ndisponible dans ce cours.\nDans ce tutoriel, nous allons utiliser deux sources de donn√©es :\nLa librairie pynsee n‚Äôest pas install√©e par d√©faut avec Python. Avant de pouvoir l‚Äôutiliser,\nil est n√©cessaire de l‚Äôinstaller :\n!pip install xlrd\n!pip install pynsee\n!pip install great_tables\nToutes les d√©pendances indispensables √©tant install√©es, il suffit\nmaintenant d‚Äôimporter les librairies qui seront utilis√©es\npendant ces exercices :\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pynsee\nimport pynsee.download",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#lire-des-donn√©es-depuis-un-chemin-local",
    "href": "content/manipulation/02b_pandas_TP.html#lire-des-donn√©es-depuis-un-chemin-local",
    "title": "Pratique de pandas : un exemple complet",
    "section": "1.1 Lire des donn√©es depuis un chemin local",
    "text": "1.1 Lire des donn√©es depuis un chemin local\nCet exercice vise √† pr√©senter l‚Äôint√©r√™t d‚Äôutiliser un chemin relatif\nplut√¥t qu‚Äôun chemin absolu.\nPour pr√©parer cet exercice, le code suivant permettra de\nt√©l√©charger des donn√©es qu‚Äôon va √©crire en local\n\nimport requests\n\nurl = \"https://www.insee.fr/fr/statistiques/fichier/6800675/v_commune_2023.csv\"\nresponse = requests.get(url)\n\n# Assurez-vous que la requ√™te a r√©ussi\nif response.status_code == 200:\n    with open(\"cog_2023.csv\", \"wb\") as file:\n        file.write(response.content)\nelse:\n    print(\"√âchec du t√©l√©chargement du fichier. Statut HTTP :\", response.status_code)\n\n\n\n Exercice pr√©liminaire: Importer un CSV (optionnel)\n\nUtiliser le code ci-dessus ‚òùÔ∏è pour t√©l√©charger les donn√©es. Utiliser Pandas pour lire le fichier t√©l√©charg√©.\nChercher o√π les donn√©es ont √©t√© √©crites. Observer la structure de ce dossier.\nCr√©er un dossier depuis l‚Äôexplorateur de fichiers (√† gauche dans Jupyter ou VSCode). D√©placer le CSV et le notebook. Red√©marrer le kernel et adaptez votre code si besoin. Refaire cette manipulation plusieurs fois avec des dossiers diff√©rents. Quel peut √™tre le probl√®me rencontr√© ?\n\n\n\n\n\n\n\n\n\n\n\n\n\nTYPECOM\nCOM\nREG\nDEP\nCTCD\nARR\nTNCC\nNCC\nNCCENR\nLIBELLE\nCAN\nCOMPARENT\n\n\n\n\n0\nCOM\n01001\n84.0\n01\n01D\n012\n5\nABERGEMENT CLEMENCIAT\nAbergement-Cl√©menciat\nL'Abergement-Cl√©menciat\n0108\nNaN\n\n\n1\nCOM\n01002\n84.0\n01\n01D\n011\n5\nABERGEMENT DE VAREY\nAbergement-de-Varey\nL'Abergement-de-Varey\n0101\nNaN",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#importer-et-d√©couvrir-des-donn√©es-depuis-un-csv",
    "href": "content/manipulation/02b_pandas_TP.html#importer-et-d√©couvrir-des-donn√©es-depuis-un-csv",
    "title": "Pratique de pandas : un exemple complet",
    "section": "1.2 Importer et d√©couvrir des donn√©es depuis un CSV",
    "text": "1.2 Importer et d√©couvrir des donn√©es depuis un CSV\nIl est plus pratique lorsque le CSV est disponible directement depuis un lien HTTPS de lire directement les donn√©es avec Pandas, sans passer par l‚Äô√©criture d‚Äôun fichier en local. Cela permet de limiter les probl√®mes d‚Äôadh√©rance √† un file system.\nL‚ÄôURL d‚Äôacc√®s aux donn√©es peut √™tre conserv√© dans une variable ad hoc :\n\nurl = \"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\"\n\nEt utilis√© ensuite pour la lecture des donn√©es.\nL‚Äôobjectif du premier exercice est de se familiariser √† l‚Äôimport et l‚Äôaffichage de donn√©es\navec Pandas.\n\n\n Exercice 1: Importer un CSV et explorer la structure de donn√©es\n\nImporter les donn√©es de l‚ÄôAdeme √† l‚Äôaide du package Pandas et de la commande consacr√©e pour l‚Äôimport de csv. Nommer le DataFrame obtenu emissions1.\nUtiliser les m√©thodes ad√©quates afin d‚Äôafficher pour les 10 premi√®res valeurs, les 15 derni√®res et un √©chantillon al√©atoire de 10 valeurs gr√¢ce aux m√©thodes ad√©quates du package Pandas.\nTirer 5 pourcents de l‚Äô√©chantillon sans remise.\nNe conserver que les 10 premi√®res lignes et tirer al√©atoirement dans celles-ci pour obtenir un DataFrame de 100 donn√©es.\nFaire 100 tirages √† partir des 6 premi√®res lignes avec une probabilit√© de 1/2 pour la premi√®re observation et une probabilit√© uniforme pour les autres.\n\n\n\nEn cas de blocage √† la question 1\n\nLire la documentation de read_csv (tr√®s bien faite) ou chercher des exemples\nen ligne pour d√©couvrir cette fonction.",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#import-des-donn√©es-de-linsee",
    "href": "content/manipulation/02b_pandas_TP.html#import-des-donn√©es-de-linsee",
    "title": "Pratique de pandas : un exemple complet",
    "section": "2.1 Import des donn√©es de l‚ÄôInsee",
    "text": "2.1 Import des donn√©es de l‚ÄôInsee\nEn ce qui concerne nos informations communales, on va utiliser l‚Äôune des\nsources de l‚ÄôInsee les plus utilis√©es : les donn√©es Filosofi.\nAfin de faciliter la r√©cup√©ration de celles-ci, nous allons\nutiliser le package communautaire pynsee :\n\n\n Note\nLe package pynsee comporte deux principaux points d‚Äôentr√©e :\n\nLes API de l‚ÄôInsee, ce qui sera illustr√© dans le chapitre consacr√©.\nQuelques jeux de donn√©es directement issus du site web de\nl‚ÄôInsee (insee.fr)\n\nDans ce chapitre, nous allons exclusivement utiliser cette deuxi√®me\napproche. Cela se fera par le module pynsee.download.\nLa liste des donn√©es disponibles depuis ce package est ici.\nLa fonction download_file attend un identifiant unique\npour savoir quelle base de donn√©es aller chercher et\nrestructurer depuis le\nsite insee.fr.\n\n\nConna√Ætre la liste des bases disponibles\n\nPour conna√Ætre la liste des bases disponibles, vous\npouvez utiliser la fonction meta = pynsee.get_file_list()\napr√®s avoir fait import pynsee.\nCelle-ci renvoie un DataFrame dans lequel on peut\nrechercher, par exemple gr√¢ce √† une recherche\nde mots-clefs :\n\nmeta = pynsee.get_file_list()\nmeta.loc[meta[\"label\"].str.contains(r\"Filosofi.*2016\")]\n\n\n\n\n\n\n\n\n\nid\nname\nlabel\ncollection\nlink\ntype\nzip\nbig_zip\ndata_file\ntab\n...\nlabel_col\ndate_ref\nmeta_file\nseparator\ntype_col\nlong_col\nval_col\nencoding\nlast_row\nmissing_value\n\n\n\n\n79\nFILOSOFI_COM_2016\nFILOSOFI_COM\nDonn√©es Filosofi niveau communal ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nCOM\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n80\nFILOSOFI_EPCI_2016\nFILOSOFI_EPCI\nDonn√©es Filosofi niveau EPCI ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nEPCI\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n81\nFILOSOFI_ARR_2016\nFILOSOFI_ARR\nDonn√©es Filosofi niveau arondissement ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nARR\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n82\nFILOSOFI_DEP_2016\nFILOSOFI_DEP\nDonn√©es Filosofi niveau d√©partemental ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nDEP\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n83\nFILOSOFI_REG_2016\nFILOSOFI_REG\nDonn√©es Filosofi niveau r√©gional ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nREG\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n84\nFILOSOFI_METRO_2016\nFILOSOFI_METRO\nDonn√©es Filosofi niveau France m√©tropolitaine ...\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nMETRO\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n85\nFILOSOFI_AU2010_2016\nFILOSOFI_AU2010\nDonn√©es Filosofi niveau aire urbaine ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nAU2010\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n86\nFILOSOFI_UU2010_2016\nFILOSOFI_UU2010\nDonn√©es Filosofi niveau unit√© urbaine ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nUU2010\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n87\nFILOSOFI_ZE2010_2016\nFILOSOFI_ZE2010\nDonn√©es Filosofi niveau zone d‚Äôemploi ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nZE2010\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n9 rows √ó 24 columns\n\n\n\n\nIci, meta['label'].str.contains(r\"Filosofi.*2016\") signifie:\n‚Äúpandas trouve moi tous les labels o√π sont contenus les termes Filosofi et 2016.‚Äù\n(.* signifiant ‚Äúpeu m‚Äôimporte le nombre de mots ou caract√®res entre‚Äù)\n\n\n\nOn va utiliser les donn√©es Filosofi (donn√©es de revenus) au niveau communal de 2016.\nCe n‚Äôest pas la m√™me ann√©e que les donn√©es d‚Äô√©mission de CO2, ce n‚Äôest donc pas parfaitement rigoureux,\nmais cela permettra tout de m√™me d‚Äôillustrer\nles principales fonctionnalit√©s de Pandas\nLe point d‚Äôentr√©e principal de la fonction pynsee est la fonction download_file.\nLe code pour t√©l√©charger les donn√©es est le suivant :\n\nfrom pynsee.download import download_file\n\nfilosofi = download_file(\"FILOSOFI_COM_2016\")\n\nLe DataFrame en question a l‚Äôaspect suivant :\n\n\n\n\n\n\n\n\n\n\nCODGEO\nLIBGEO\nNBMENFISC16\nNBPERSMENFISC16\nMED16\nPIMP16\nTP6016\nTP60AGE116\nTP60AGE216\nTP60AGE316\n...\nPPEN16\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\n\n\n\n\n1650\n04175\nSainte-Croix-√†-Lauze\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9511\n27201\nDaubeuf-la-Campagne\n85\n240\n23646.666666666668\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n17173\n47102\nFrancescas\n298\n667\n17871.166666666664\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n30289\n77286\nMeigneux\n89\n240.5\n24987\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n23329\n61256\nM√©davy\n58\n150\n21627.777777777777\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows √ó 29 columns\n\n\n\n\nPandas a g√©r√© automatiquement les types de variables. Il le fait relativement bien, mais une v√©rification est toujours utile pour les variables qui ont un statut sp√©cifique.\nPour les variables qui ne sont pas en type float alors qu‚Äôelles devraient l‚Äô√™tre, on modifie leur type.\n\nfilosofi.loc[:, filosofi.columns[2:]] = filosofi.loc[:, filosofi.columns[2:]].apply(\n    pd.to_numeric, errors=\"coerce\"\n)\n\nUn simple coup d‚Äôoeil sur les donn√©es\ndonne une id√©e assez pr√©cise de la mani√®re dont les donn√©es sont organis√©es.\nOn remarque que certaines variables de filosofi semblent avoir beaucoup de valeurs manquantes (secret statistique)\nalors que d‚Äôautres semblent compl√®tes.\nSi on d√©sire exploiter filosofi, il faut faire attention √† la variable choisie.\nNotre objectif √† terme va √™tre de relier l‚Äôinformation contenue entre ces\ndeux jeux de donn√©es. En effet, sinon, nous risquons d‚Äô√™tre frustr√© : nous allons\nvouloir en savoir plus sur les √©missions de gaz carbonique mais seront tr√®s\nlimit√©s dans les possibilit√©s d‚Äôanalyse sans ajout d‚Äôune information annexe\nissue de filosofi.",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#travail-pr√©liminaire",
    "href": "content/manipulation/02b_pandas_TP.html#travail-pr√©liminaire",
    "title": "Pratique de pandas : un exemple complet",
    "section": "5.1 Travail pr√©liminaire",
    "text": "5.1 Travail pr√©liminaire\nJusqu‚Äô√† pr√©sent lorsque nous avons produit des statistiques descriptives,\ncelles-ci √©taient univari√©es, c‚Äôest-√†-dire que nous produisions de l‚Äôinformation\nsur une variable mais nous ne la mettions pas en lien avec une autre. Pourtant,\non est rapidement amen√© √† d√©sirer expliquer certaines statistiques agr√©g√©es √† partir\nde caract√©ristiques issues d‚Äôune autre source de donn√©es. Cela implique\ndonc d‚Äôassocier des jeux de donn√©es,\nautrement dit de mettre en lien deux jeux de donn√©es\npr√©sentant le m√™me niveau d‚Äôinformation.\nOn appelle ceci faire un merge ou un join. De mani√®re illustr√©e,\nceci revient √† effectuer ce type d‚Äôop√©ration :\n\nAvant de faire ceci, il est n√©anmoins n√©cessaire de s‚Äôassurer que les variables\ncommunes entre les bases de donn√©es pr√©sentent le bon niveau d‚Äôinformation.\n\n\n Exercice 6: v√©rification des cl√©s de jointure\nOn commence par v√©rifier les dimensions des DataFrames et la structure de certaines variables cl√©s.\nEn l‚Äôoccurrence, les variables fondamentales pour lier nos donn√©es sont les variables communales.\nIci, on a deux variables g√©ographiques: un code commune et un nom de commune.\n\nV√©rifier les dimensions des DataFrames.\nIdentifier dans filosofi les noms de communes qui correspondent √† plusieurs codes communes et s√©lectionner leurs codes. En d‚Äôautres termes, identifier les LIBGEO tels qu‚Äôil existe des doublons de CODGEO et les stocker dans un vecteur x (conseil: faire attention √† l‚Äôindex de x).\n\nOn se focalise temporairement sur les observations o√π le libell√© comporte plus de deux codes communes diff√©rents\n\nQuestion 3. Regarder dans filosofi ces observations.\nQuestion 4. Pour mieux y voir, r√©ordonner la base obtenue par order alphab√©tique.\nQuestion 5. D√©terminer la taille moyenne (variable nombre de personnes: NBPERSMENFISC16) et quelques statistiques descriptives de ces donn√©es.\nComparer aux m√™mes statistiques sur les donn√©es o√π libell√©s et codes communes co√Øncident.\nQuestion 6. V√©rifier les grandes villes (plus de 100 000 personnes),\nla proportion de villes pour lesquelles un m√™me nom est associ√© √† diff√©rents codes commune.\nQuestion 7. V√©rifier dans filosofi les villes dont le libell√© est √©gal √† Montreuil.\nV√©rifier √©galement celles qui contiennent le terme ‚ÄòSaint-Denis‚Äô.\n\n\n\nCe petit exercice permet de se rassurer car les libell√©s dupliqu√©s\nsont en fait des noms de commune identiques mais qui ne sont pas dans le m√™me d√©partement.\nIl ne s‚Äôagit donc pas d‚Äôobservations dupliqu√©es.\nOn peut donc se fier aux codes communes, qui eux sont uniques.",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#associer-des-donn√©es",
    "href": "content/manipulation/02b_pandas_TP.html#associer-des-donn√©es",
    "title": "Pratique de pandas : un exemple complet",
    "section": "5.2 Associer des donn√©es",
    "text": "5.2 Associer des donn√©es\nUne information que l‚Äôon cherche √† obtenir s‚Äôobtient de moins en moins √† partir d‚Äôune unique base de donn√©es. Il devient commun de devoir combiner des donn√©es issues de sources diff√©rentes.\nNous allons ici nous focaliser sur le cas le plus favorable qui est la situation o√π une information permet d‚Äôapparier de mani√®re exacte deux bases de donn√©es (autrement nous serions dans une situation, beaucoup plus complexe, d‚Äôappariement flou). La situation typique est l‚Äôappariement entre deux sources de donn√©es selon un identifiant individuel ou un identifiant de code commune, ce qui est notre cas.\nIl est recommand√© de lire ce guide assez complet sur la question des jointures avec R qui donne des recommandations √©galement utiles en Python.\nDans le langage courant du statisticien,\non utilise de mani√®re indiff√©rente les termes merge ou join. Le deuxi√®me terme provient de la syntaxe SQL.\nQuand on fait du Pandas, on utilise plut√¥t la commande merge.\n\n\n\n Exercice 7: Calculer l'empreinte carbone par habitant\nEn premier lieu, on va calculer l‚Äôempreinte carbone de chaque commune.\n\nCr√©er une variable emissions qui correspond aux √©missions totales d‚Äôune commune\nFaire une jointure √† gauche entre les donn√©es d‚Äô√©missions et les donn√©es de cadrage2.\nCalculer l‚Äôempreinte carbone (√©missions totales / population).\n\nA ce stade nous pourrions avoir envie d‚Äôaller vers la mod√©lisation pour essayer d‚Äôexpliquer\nles d√©terminants de l‚Äôempreinte carbone √† partir de variables communales.\nUne approche inf√©rentielle n√©cessite n√©anmoins pour √™tre pertinente de\nv√©rifier en amont des statistiques descriptives.\n\nSortir un histogramme en niveau puis en log de l‚Äôempreinte carbone communale.\n\nAvec une meilleure compr√©hension de nos donn√©es, nous nous rapprochons\nde la statistique inf√©rentielle. N√©anmoins, nous avons jusqu‚Äô√† pr√©sent\nconstruit des statistiques univari√©es mais n‚Äôavons pas cherch√© √† comprendre\nles r√©sultats en regardant le lien avec d‚Äôautres variables.\nCela nous am√®ne vers la statistique bivari√©e, notamment l‚Äôanalyse des corr√©lations.\nCe travail est important puisque toute mod√©lisation ult√©rieure consistera √†\nraffiner l‚Äôanalyse des corr√©lations pour tenir compte des corr√©lations crois√©es\nentre multiples facteurs. On propose ici de faire cette analyse\nde mani√®re minimale.\n\nRegarder la corr√©lation entre les variables de cadrage et l‚Äôempreinte carbone. Certaines variables semblent-elles pouvoir potentiellement influer sur l‚Äôempreinte carbone ?\n\n\n\nA l‚Äôissue de la question 5, le graphique des corr√©lations est le suivant :",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#informations-additionnelles",
    "href": "content/manipulation/02b_pandas_TP.html#informations-additionnelles",
    "title": "Pratique de pandas : un exemple complet",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n4d678bf\n\n\n2024-04-23 12:09:46\n\n\nlinogaliana\n\n\nTypo\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n7298c6c\n\n\n2024-04-19 21:34:00\n\n\nLino Galiana\n\n\nExercice great_tables (#489)\n\n\n\n\nc03aa61\n\n\n2024-01-16 17:33:18\n\n\nLino Galiana\n\n\nExercice sur les chemins relatifs (#483)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n8071bbb\n\n\n2023-10-23 17:43:37\n\n\ntomseimandi\n\n\nMake minor changes to 02b, 03, 04a (#440)\n\n\n\n\ndf01f01\n\n\n2023-10-10 15:55:04\n\n\nLino Galiana\n\n\nMenus automatis√©s (#432)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\n98bb886\n\n\n2023-10-09 11:50:03\n\n\nLino Galiana\n\n\ntypo\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nac80862\n\n\n2023-10-07 21:05:25\n\n\nLino Galiana\n\n\nRelecture antuki (#427)\n\n\n\n\n5ab34aa\n\n\n2023-10-04 14:54:20\n\n\nKim A\n\n\nRelecture Kim pandas & git (#416)\n\n\n\n\n7e03cea\n\n\n2023-10-04 14:07:17\n\n\nLino Galiana\n\n\nClean pandas tutorial and exercises (#417)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\n89d0798\n\n\n2022-11-02 10:19:58\n\n\nLino Galiana\n\n\nAjoute icone aux autres TP (#317)\n\n\n\n\na3eadd4\n\n\n2022-11-01 18:51:14\n\n\nRomain Avouac\n\n\nMod√®le de notebooks de correction ex√©cutables (#304)\n\n\n\n\naf763cc\n\n\n2022-10-12 10:17:56\n\n\nLino Galiana\n\n\nReprise exercice geopandas (#294)\n\n\n\n\n1ef97df\n\n\n2022-10-11 12:14:03\n\n\nLino Galiana\n\n\nRelecture chapitre geopandas (#289)\n\n\n\n\ne2b53ac\n\n\n2022-09-28 17:09:31\n\n\nLino Galiana\n\n\nRetouche les chapitres pandas (#287)\n\n\n\n\neb8f922\n\n\n2022-09-22 17:40:43\n\n\nLino Galiana\n\n\nCorrige bug TP pandas (#276)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb138cf3\n\n\n2021-10-21 18:05:59\n\n\nLino Galiana\n\n\nMise √† jour TP webscraping et API (#164)\n\n\n\n\n4870662\n\n\n2021-10-05 08:29:33\n\n\nRomain Avouac\n\n\nfix and simplify pyinsee install (#157)\n\n\n\n\n0677932\n\n\n2021-10-03 15:32:51\n\n\nLino Galiana\n\n\nAjoute un code pour download pynsee (#156)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\nbf5ebc5\n\n\n2021-09-01 14:41:17\n\n\nLino Galiana\n\n\nFix problem import pynsee (#128)\n\n\n\n\n4a317e3\n\n\n2021-08-31 12:38:17\n\n\nLino Galiana\n\n\npynsee pour importer des donn√©es Insee üöÄ (#127)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nR√©ordonner le DataFrame\nCheasheet Pandas\nDonn√©es long et wide",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#footnotes",
    "href": "content/manipulation/02b_pandas_TP.html#footnotes",
    "title": "Pratique de pandas : un exemple complet",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPar manque d‚Äôimagination, on est souvent tent√© d‚Äôappeler notre\ndataframe principal df ou data. C‚Äôest souvent une mauvaise id√©e puisque\nce nom n‚Äôest pas tr√®s informatif quand on relit le code quelques semaines\nplus tard. L‚Äôautodocumentation, approche qui consiste √† avoir un code\nqui se comprend de lui-m√™me, est une bonne pratique et il est donc recommand√©\nde donner un nom simple mais efficace pour conna√Ætre la nature du dataset en question.‚Ü©Ô∏é\nId√©alement, il serait n√©cessaire de s‚Äôassurer que cette jointure n‚Äôintroduit\npas de biais. En effet, comme nos ann√©es de r√©f√©rence ne sont pas forc√©ment identiques,\nil peut y avoir un mismatch entre nos deux sources. Le TP √©tant d√©j√† long, nous n‚Äôallons pas dans cette voie.\nLes lecteurs int√©ress√©s pourront effectuer une telle analyse en exercice suppl√©mentaire.‚Ü©Ô∏é",
    "crumbs": [
      "Pratique de pandas : un exemple complet"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html",
    "href": "content/manipulation/01_numpy.html",
    "title": "Numpy, la brique de base de la data science",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#cr√©er-un-array",
    "href": "content/manipulation/01_numpy.html#cr√©er-un-array",
    "title": "Numpy, la brique de base de la data science",
    "section": "2.1 Cr√©er un array",
    "text": "2.1 Cr√©er un array\nOn peut cr√©er un array de plusieurs mani√®res. Pour cr√©er un array √† partir d‚Äôune liste,\nil suffit d‚Äôutiliser la m√©thode array:\n\nnp.array([1, 2, 5])\n\narray([1, 2, 5])\n\n\nIl est possible d‚Äôajouter un argument dtype pour contraindre le type du array :\n\nnp.array([[\"a\", \"z\", \"e\"], [\"r\", \"t\"], [\"y\"]], dtype=\"object\")\n\narray([list(['a', 'z', 'e']), list(['r', 't']), list(['y'])], dtype=object)\n\n\nIl existe aussi des m√©thodes pratiques pour cr√©er des array:\n\ns√©quences logiques : np.arange (suite) ou np.linspace (interpolation lin√©aire entre deux bornes)\ns√©quences ordonn√©es : array rempli de z√©ros, de 1 ou d‚Äôun nombre d√©sir√© : np.zeros, np.ones ou np.full\ns√©quences al√©atoires : fonctions de g√©n√©ration de nombres al√©atoires : np.rand.uniform, np.rand.normal, etc.\ntableau sous forme de matrice identit√© : np.eye\n\nCeci donne ainsi, pour les s√©quences logiques:\n\nnp.arange(0, 10)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\nnp.arange(0, 10, 3)\n\narray([0, 3, 6, 9])\n\n\n\nnp.linspace(0, 1, 5)\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n\n\nPour un array initialis√© √† 0:\n\nnp.zeros(10, dtype=int)\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\nou initialis√© √† 1:\n\nnp.ones((3, 5), dtype=float)\n\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])\n\n\nou encore initialis√© √† 3.14:\n\n\narray([[3.14, 3.14, 3.14, 3.14, 3.14],\n       [3.14, 3.14, 3.14, 3.14, 3.14],\n       [3.14, 3.14, 3.14, 3.14, 3.14]])\n\n\nEnfin, pour cr√©er la matrice \\(I_3\\):\n\nnp.eye(3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\n\n Exercice 1\nG√©n√©rer:\n\n\\(X\\) une variable al√©atoire, 1000 r√©p√©titions d‚Äôune loi \\(U(0,1)\\)\n\\(Y\\) une variable al√©atoire, 1000 r√©p√©titions d‚Äôune loi normale de moyenne nulle et de variance √©gale √† 2\nV√©rifier la variance de \\(Y\\) avec np.var",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#logique-dans-le-cas-dun-array-unidimensionnel",
    "href": "content/manipulation/01_numpy.html#logique-dans-le-cas-dun-array-unidimensionnel",
    "title": "Numpy, la brique de base de la data science",
    "section": "3.1 Logique dans le cas d‚Äôun array unidimensionnel",
    "text": "3.1 Logique dans le cas d‚Äôun array unidimensionnel\nLa structure la plus simple est l‚Äôarray unidimensionnel:\n\nx = np.arange(10)\nprint(x)\n\n[0 1 2 3 4 5 6 7 8 9]\n\n\nL‚Äôindexation est dans ce cas similaire √† celle d‚Äôune liste:\n\nle premier √©l√©ment est 0\nle √©ni√®me √©l√©ment est accessible √† la position \\(n-1\\)\n\nLa logique d‚Äôacc√®s aux √©l√©ments est ainsi la suivante :\nx[start:stop:step]\nAvec un array unidimensionnel, l‚Äôop√©ration de slicing (garder une coupe du array) est tr√®s simple.\nPar exemple, pour garder les K premiers √©l√©ments d‚Äôun array, on fera:\nx[: (K - 1)]\nEn l‚Äôoccurrence, on s√©lectionne le K\\(^{eme}\\) √©l√©ment en utilisant\nx[K - 1]\nPour s√©lectionner uniquement un √©l√©ment, on fera ainsi:\n\nx = np.arange(10)\nx[2]\n\n2\n\n\nLes syntaxes qui permettent de s√©lectionner des indices particuliers d‚Äôune liste fonctionnent √©galement\navec les arrays.\n\n\n Exercice 2\nPrenez x = np.arange(10) et‚Ä¶\n\nS√©lectionner les √©l√©ments 0,3,5 de x\nS√©lectionner les √©l√©ments pairs\nS√©lectionner tous les √©l√©ments sauf le premier\nS√©lectionner les 5 premiers √©l√©ments",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#sur-la-performance",
    "href": "content/manipulation/01_numpy.html#sur-la-performance",
    "title": "Numpy, la brique de base de la data science",
    "section": "3.2 Sur la performance",
    "text": "3.2 Sur la performance\nUn √©l√©ment d√©terminant dans la performance de Numpy par rapport aux listes,\nlorsqu‚Äôil est question de\nslicing est qu‚Äôun array ne renvoie pas une\ncopie de l‚Äô√©l√©ment en question (copie qui co√ªte de la m√©moire et du temps)\nmais simplement une vue de celui-ci.\nLorsqu‚Äôil est n√©cessaire d‚Äôeffectuer une copie,\npar exemple pour ne pas alt√©rer l‚Äôarray sous-jacent, on peut\nutiliser la m√©thode copy:\nx_sub_copy = x[:2, :2].copy()",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#filtres-logiques",
    "href": "content/manipulation/01_numpy.html#filtres-logiques",
    "title": "Numpy, la brique de base de la data science",
    "section": "3.3 Filtres logiques",
    "text": "3.3 Filtres logiques\nIl est √©galement possible, et plus pratique, de s√©lectionner des donn√©es √† partir de conditions logiques\n(op√©ration qu‚Äôon appelle un boolean mask).\nCette fonctionalit√© servira principalement √†\neffectuer des op√©rations de filtre sur les donn√©es.\nPour des op√©rations de comparaison simples, les comparateurs logiques peuvent √™tre suffisants.\nCes comparaisons fonctionnent aussi sur les tableaux multidimensionnels gr√¢ce au\nbroadcasting sur lequel nous reviendrons :\n\nx = np.arange(10)\nx2 = np.array([[-1, 1, -2], [-3, 2, 0]])\nprint(x)\nprint(x2)\n\n[0 1 2 3 4 5 6 7 8 9]\n[[-1  1 -2]\n [-3  2  0]]\n\n\n\nx == 2\nx2 &lt; 0\n\narray([[ True, False,  True],\n       [ True, False, False]])\n\n\nPour s√©lectionner les observations relatives √† la condition logique,\nil suffit d‚Äôutiliser la logique de slicing de numpy qui fonctionne avec les conditions logiques\n\n\n Exercice 3\nSoit\nx = np.random.normal(size=10000)\n\nNe conserver que les valeurs dont la valeur absolue est sup√©rieure √† 1.96\nCompter le nombre de valeurs sup√©rieures √† 1.96 en valeur absolue et leur proportion dans l‚Äôensemble\nSommer les valeurs absolues de toutes les observations sup√©rieures (en valeur absolue) √† 1.96\net rapportez les √† la somme des valeurs de x (en valeur absolue)\n\n\n\nLorsque c‚Äôest possible, il est recommand√© d‚Äôutiliser les fonctions logiques de numpy (optimis√©es et\nqui g√®rent bien la dimension).\nParmi elles, on peut retrouver:\n\ncount_nonzero\nisnan\nany ; all ; notamment avec l‚Äôargument axis\nnp.array_equal pour v√©rifier, √©l√©ment par √©l√©ment, l‚Äô√©galit√©\n\nSoit\n\nx = np.random.normal(0, size=(3, 4))\n\nun array multidimensionnel et\n\ny = np.array([np.nan, 0, 1])\n\nun array unidimensionnel pr√©sentant une valeur manquante.\n\n\n Exercice 4\n\nUtiliser count_nonzero sur y\nUtiliser isnan sur y et compter le nombre de valeurs non NaN\nV√©rifier que x comporte au moins une valeur positive dans son ensemble, en parcourant les lignes puis les colonnes.\n\n\n\nAide\n\nJetez un oeil au param√®tre axis en vous documentant sur internet. Par exemple ici.",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#fonctions-de-manipulation",
    "href": "content/manipulation/01_numpy.html#fonctions-de-manipulation",
    "title": "Numpy, la brique de base de la data science",
    "section": "4.1 Fonctions de manipulation",
    "text": "4.1 Fonctions de manipulation\nVoici quelques fonctions pour modifier un array,\n\n\n\n\n\n\n\nOp√©ration\nImpl√©mentation\n\n\n\n\nAplatir un array\nx.flatten() (m√©thode)\n\n\nTransposer un array\nx.T (m√©thode) ou np.transpose(x) (fonction)\n\n\nAjouter des √©l√©ments √† la fin\nnp.append(x, [1,2])\n\n\nAjouter des √©l√©ments √† un endroit donn√© (aux positions 1 et 2)\nnp.insert(x, [1,2], 3)\n\n\nSupprimer des √©l√©ments (aux positions 0 et 3)\nnp.delete(x, [0,3])\n\n\n\nPour combiner des array, on peut utiliser, selon les cas,\nles fonctions np.concatenate, np.vstack ou la m√©thode .r_ (concat√©nation rowwise).\nnp.hstack ou la m√©thode .column_stack ou .c_ (concat√©nation column-wise)\n\nx = np.random.normal(size=10)\n\nPour ordonner un array, on utilise np.sort\n\nx = np.array([7, 2, 3, 1, 6, 5, 4])\n\nnp.sort(x)\n\narray([1, 2, 3, 4, 5, 6, 7])\n\n\nSi on d√©sire faire un r√©-ordonnement partiel pour trouver les k valeurs les plus petites d‚Äôun array sans les ordonner, on utilise partition:\n\nnp.partition(x, 3)\n\narray([2, 1, 3, 4, 6, 5, 7])",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#une-application-programmer-ses-propres-k-nearest-neighbors",
    "href": "content/manipulation/01_numpy.html#une-application-programmer-ses-propres-k-nearest-neighbors",
    "title": "Numpy, la brique de base de la data science",
    "section": "5.1 Une application: programmer ses propres k-nearest neighbors",
    "text": "5.1 Une application: programmer ses propres k-nearest neighbors\n\n\n\n Exercice (un peu plus cors√©)\n\nCr√©er X un tableau √† deux dimensions (i.e.¬†une matrice) comportant 10 lignes\net 2 colonnes. Les nombres dans le tableau sont al√©atoires.\nImporter le module matplotlib.pyplot sous le nom plt. Utiliser\nplt.scatter pour repr√©senter les donn√©es sous forme de nuage de points.\nConstuire une matrice 10x10 stockant, √† l‚Äô√©l√©ment \\((i,j)\\), la distance euclidienne entre les points \\(X[i,]\\) et \\(X[j,]\\). Pour cela, il va falloir jouer avec les dimensions en cr√©ant des tableaux embo√Æt√©s √† partir par des appels √† np.newaxis :\n\n\nEn premier lieu, utiliser X1 = X[:, np.newaxis, :] pour transformer la matrice en tableau embo√Æt√©. V√©rifier les dimensions\nCr√©er X2 de dimension (1, 10, 2) √† partir de la m√™me logique\nEn d√©duire, pour chaque point, la distance avec les autres points pour chaque coordonn√©es. Elever celle-ci au carr√©\nA ce stade, vous devriez avoir un tableau de dimension (10, 10, 2). La r√©duction √† une matrice s‚Äôobtient en sommant sur le dernier axe. Regarder dans l‚Äôaide de np.sum comme effectuer une somme sur le dernier axe.\nEnfin, appliquer la racine carr√©e pour obtenir une distance euclidienne en bonne et due forme.\n\n\nV√©rifier que les termes diagonaux sont bien nuls (distance d‚Äôun point √† lui-m√™me‚Ä¶)\nIl s‚Äôagit maintenant de classer, pour chaque point, les points dont les valeurs sont les plus similaires. Utiliser np.argsort pour obtenir, pour chaque ligne, le classement des points les plus proches\nOn va s‚Äôint√©resser aux k-plus proches voisins. Pour le moment, fixons k=2. Utiliser argpartition pour r√©ordonner chaque ligne de mani√®re √† avoir les 2 plus proches voisins de chaque point d‚Äôabord et le reste de la ligne ensuite\nUtiliser le morceau de code ci-dessous\n\n\n\n\nUn indice pour repr√©senter graphiquement les plus proches voisins\nplt.scatter(X[:, 0], X[:, 1], s=100)\n\n# draw lines from each point to its two nearest neighbors\nK = 2\n\nfor i in range(X.shape[0]):\n    for j in nearest_partition[i, : K + 1]:\n        # plot a line from X[i] to X[j]\n        # use some zip magic to make it happen:\n        plt.plot(*zip(X[j], X[i]), color=\"black\")\n\n\nPour la question 2, vous devriez obtenir un graphique ayant cet aspect :\n\n\n\n\n\n\n\n\n\nLe r√©sultat de la question 7 est le suivant :\n\n\n\n\n\n\n\n\n\nAi-je invent√© cet exercice cors√© ? Pas du tout, il vient de l‚Äôouvrage Python Data Science Handbook. Mais, si je vous l‚Äôavais indiqu√© imm√©diatement, auriez-vous cherch√© √† r√©pondre aux questions ?\nPar ailleurs, il ne serait pas une bonne id√©e de g√©n√©raliser cet algorithme √† de grosses donn√©es. La complexit√© de notre approche est \\(O(N^2)\\). L‚Äôalgorithme impl√©ment√© par Scikit-Learn est\nen \\(O[NlogN]\\).\nDe plus, le calcul de distances matricielles en utilisant la puissance des cartes graphiques serait plus rapide. A cet √©gard, la librairie faiss offre des performances beaucoup plus satisfaisantes que celles que permettraient numpy sur ce probl√®me pr√©cis.",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#informations-additionnelles",
    "href": "content/manipulation/01_numpy.html#informations-additionnelles",
    "title": "Numpy, la brique de base de la data science",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\na63319a\n\n\n2023-10-04 15:29:04\n\n\nLino Galiana\n\n\nCorrection du TP numpy (#419)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n9e1e6e4\n\n\n2023-07-20 02:27:22\n\n\nLino Galiana\n\n\nChange launch script (#379)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n7e15843\n\n\n2023-02-13 18:57:28\n\n\nLino Galiana\n\n\nfrom_numpy_array no longer in networkx 3.0 (#353)\n\n\n\n\na408cc9\n\n\n2023-02-01 09:07:27\n\n\nLino Galiana\n\n\nAjoute bouton sugg√©rer modification (#347)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\ne2b53ac\n\n\n2022-09-28 17:09:31\n\n\nLino Galiana\n\n\nRetouche les chapitres pandas (#287)\n\n\n\n\nd068cb6\n\n\n2022-09-24 14:58:07\n\n\nLino Galiana\n\n\nCorrections avec echo true (#279)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\na56dd45\n\n\n2022-09-20 15:27:56\n\n\nLino Galiana\n\n\nFix SSPCloud links (#270)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n1ca1a8a\n\n\n2022-05-31 11:44:23\n\n\nLino Galiana\n\n\nRetour du chapitre API (#228)\n\n\n\n\n4fc58e5\n\n\n2022-05-25 18:29:25\n\n\nLino Galiana\n\n\nChange deployment on SSP Cloud with new filesystem organization (#227)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n26ea709\n\n\n2021-09-27 19:11:00\n\n\nLino Galiana\n\n\nR√®gle quelques probl√®mes np (#154)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\nedca391\n\n\n2020-09-21 19:31:02\n\n\nLino Galiana\n\n\nChange np.is_nan to np.isnan\n\n\n\n\nf9f00cc\n\n\n2020-09-15 21:05:54\n\n\nLino Galiana\n\n\nenl√®ve quelques TO DO\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\nc452b83\n\n\n2020-07-28 17:32:06\n\n\nLino Galiana\n\n\nTP Numpy (#9)\n\n\n\n\n200b6c1\n\n\n2020-07-27 12:50:33\n\n\nLino Galiana\n\n\nEncore une coquille\n\n\n\n\n5041b28\n\n\n2020-07-27 12:44:10\n\n\nLino Galiana\n\n\nUne coquille √† cause d‚Äôun bloc jupyter\n\n\n\n\ne8db4cf\n\n\n2020-07-24 12:56:38\n\n\nLino Galiana\n\n\nmodif des markdown\n\n\n\n\nb24a1fe\n\n\n2020-07-23 18:20:09\n\n\nLino Galiana\n\n\nAdd notebook\n\n\n\n\n4f8f1ca\n\n\n2020-07-23 18:19:28\n\n\nLino Galiana\n\n\nfix typo\n\n\n\n\n434d20e\n\n\n2020-07-23 18:18:46\n\n\nLino Galiana\n\n\nEssai de yaml header\n\n\n\n\n5ac02ef\n\n\n2020-07-23 18:05:12\n\n\nLino Galiana\n\n\nEssai de md g√©n√©r√© avec jupytext\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html",
    "href": "content/getting-started/07_rappels_classes.html",
    "title": "Les classes en Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#quand-utilise-t-on-cela-dans-le-domaine-de-la-data-science",
    "href": "content/getting-started/07_rappels_classes.html#quand-utilise-t-on-cela-dans-le-domaine-de-la-data-science",
    "title": "Les classes en Python",
    "section": "1.1 Quand utilise-t-on cela dans le domaine de la data science ?",
    "text": "1.1 Quand utilise-t-on cela dans le domaine de la data science ?\nLes r√©seaux de neurones programm√©s avec Keras ou PyTorch fonctionnent de\ncette mani√®re. On part d‚Äôune structure de base et modifie les attributs (par\nexemple le nombre de couches) ou les m√©thodes.",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#les-attributs-de-la-classe-chat",
    "href": "content/getting-started/07_rappels_classes.html#les-attributs-de-la-classe-chat",
    "title": "Les classes en Python",
    "section": "3.1 Les attributs de la classe chat",
    "text": "3.1 Les attributs de la classe chat\n\n3.1.1 Classe chat version 1 - premiers attributs\nOn veut pouvoir cr√©er un objet chat() qui nous permettra √† terme de cr√©er une colonie de chats (on sait\njamais ca peut servir ‚Ä¶).\nPour commencer, on va d√©finir un chat avec des attributs de base : une couleur et un nom.\n\nclass chat:  # D√©finition de notre classe chat\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - son nom\n    - sa couleur\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        \"\"\"Pour l'instant, on ne va d√©finir que deux attributs - nom et couleur\"\"\"\n        self.couleur = \"Noir\"\n        self.nom = \"Aucun nom\"\n\n\nmon_chat = chat()\n\nprint(type(mon_chat), mon_chat.couleur, \",\", mon_chat.nom)\n\n&lt;class '__main__.chat'&gt; Noir , Aucun nom\n\n\nOn nous dit bien que Mon chat est d√©fini √† partir de la classe chat,\nc‚Äôest ce que nous apprend la fonction type.\nPour l‚Äôinstant il n‚Äôa pas de nom\n\n\n3.1.2 Classe chat version 2 - autres attributs\nAvec un nom et une couleur, on ne va pas loin. On peut continuer √† d√©finir des attributs pour la classe chat\nde la m√™me fa√ßon que pr√©c√©demment.\n\nclass chat:  # D√©finition de notre classe chat\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.couleur = \"Noir\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        self.nom = \"Aucun nom\"\n\n\nhelp(chat)\n# si on veut savoir ce que fait la classe \"chat\" on appelle l'aide\n\nHelp on class chat in module __main__:\n\nclass chat(builtins.object)\n |  Classe d√©finissant un chat caract√©ris√© par :\n |  - sa couleur\n |  - son √¢ge\n |  - son caract√®re\n |  - son poids\n |  - son maitre\n |  - son nom\n |  \n |  Methods defined here:\n |  \n |  __init__(self)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n\n\n\nmon_chat = chat()\nprint(\"L'√¢ge du chat est\", mon_chat.age, \"ans\")\n# on avait d√©fini l'attribut age de la classe chat comme √©tant √©gal √† 10\n# , si on demande l'attribut age de notre Martin on obtient 10\n\nL'√¢ge du chat est 10 ans\n\n\nPar d√©faut, les attributs de la classe Chat seront toujours les m√™mes √† chaque cr√©ation de chat √† partir\nde la classe Chat.\nMais une fois qu‚Äôune instance de classe est cr√©√©e (ici mon chat est une instance de classe) on peut d√©cider\nde changer la valeur de ses attributs.\n\n\n3.1.3 Un nouveau poids\n\nprint(mon_chat.poids)\n# si on veut changer le poids de mon chat, parce qu'il a un peu grossi apr√®s les f√™tes\nmon_chat.poids = 3.5\nprint(mon_chat.poids)  # maintenant le poids est 3.5\n\n3\n3.5\n\n\n\n\n3.1.4 Un nouveau nom\n\n# on veut aussi lui donner un nom\nmon_chat.nom = \"Martin\"\nmon_chat.nom\n\n'Martin'\n\n\n\n\n3.1.5 Une autre instance de la classe Chat\nOn peut aussi cr√©er d‚Äôautres objets chat √† partir de la classe chat :\n\n# on appelle la classe\nl_autre_chat = chat()\n# on change les attributs qui nous int√©ressent\nl_autre_chat.nom = \"Ginette\"\nl_autre_chat.maitre = \"Roger\"\n# les attributs inchang√©s donnent la m√™me chose\n# que ceux d√©finis par d√©faut pour la classe\nprint(l_autre_chat.couleur)\n\nNoir",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#les-m√©thodes-de-la-classe-chat",
    "href": "content/getting-started/07_rappels_classes.html#les-m√©thodes-de-la-classe-chat",
    "title": "Les classes en Python",
    "section": "3.2 Les m√©thodes de la classe chat",
    "text": "3.2 Les m√©thodes de la classe chat\nLes attributs sont des variables propres √† notre objet, qui servent √† le caract√©riser.\nLes m√©thodes sont plut√¥t des actions, comme nous l‚Äôavons vu dans la partie pr√©c√©dente, agissant sur l‚Äôobjet.\nPar exemple, la m√©thode append de la classe list permet d‚Äôajouter un √©l√©ment dans l‚Äôobjet list manipul√©.\n\n3.2.1 Classe chat version 3 - premi√®re m√©thode\nOn peut d√©finir une premi√®re m√©thode : nourrir\n\nclass chat:  # D√©finition de notre classe chat\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\n\n    L'objet chat a une m√©thode : nourrir\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.couleur = \"Noir\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        self.nom = \"Aucun nom\"\n\n        \"\"\"Par d√©faut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n\n    def nourrir(self, nourriture):\n        \"\"\"M√©thode permettant de donner √† manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"\n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n\nmon_chat = chat()\nmon_chat.nom = \"Martin\"\nmon_chat.ventre  # On n'a rien donn√© √† Martin, son ventre est vide\n\n''\n\n\n\n# on appelle la m√©thode \"nourrir\" de la classe chat,\n# on lui donne un √©l√©ment, ici des croquettes\nmon_chat.nourrir(\"Croquettes\")\nprint(\"Le contenu du ventre de martin : \", mon_chat.ventre)\n\nLe contenu du ventre de martin :  Croquettes\n\n\n\nmon_chat.nourrir(\"Saumon\")\nprint(\"Le contenu du ventre de martin : \", mon_chat.ventre)\n\nLe contenu du ventre de martin :  Croquettes,Saumon\n\n\n\n\n3.2.2 Classe chat version 4 - autre m√©thode\nAvec un chat, on peut imaginer plein de m√©thodes. Ici on va d√©finir une action ‚Äúnourrir‚Äù et une autre action\n‚Äúlitiere‚Äù, qui consiste √† vider l‚Äôestomac du chat.\n\nclass chat:  # D√©finition de notre classe Personne\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\n\n    L'objet chat a deux m√©thodes : nourrir et litiere\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.nom = \"\"\n        self.couleur = \"Roux\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        \"\"\"Par d√©faut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n\n    def nourrir(self, nourriture):\n        \"\"\"M√©thode permettant de donner √† manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"\n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n    def litiere(self):\n        \"\"\"M√©thode permettant au chat d'aller √† sa liti√®re :\n        en cons√©quence son ventre est vide\"\"\"\n        self.ventre = \"\"\n        print(self.nom, \"a le ventre vide\")\n\n\n# on d√©finit Martin le chat\nmon_chat = chat()\nmon_chat.nom = \"Martin\"\n# on le nourrit avec des croquettes\nmon_chat.nourrir(\"croquettes\")\nprint(\"Le contenu du ventre de martin\", mon_chat.ventre)\n\n\n# Il va dans sa litiere\nmon_chat.litiere()\n\nLe contenu du ventre de martin croquettes\nMartin a le ventre vide\n\n\n\nhelp(mon_chat.nourrir)\nhelp(mon_chat.litiere)\n\nHelp on method nourrir in module __main__:\n\nnourrir(nourriture) method of __main__.chat instance\n    M√©thode permettant de donner √† manger au chat.\n    Si le ventre n'est pas vide, on met une virgule avant de rajouter\n    la nourriture\n\nHelp on method litiere in module __main__:\n\nlitiere() method of __main__.chat instance\n    M√©thode permettant au chat d'aller √† sa liti√®re : \n    en cons√©quence son ventre est vide\n\n\n\n\n\n3.2.3 Les m√©thodes sp√©ciales (facultatif)\nSi on reprend notre classe chat, il y a en r√©alit√© des m√©thodes sp√©ciales que nous n‚Äôavons pas d√©finies mais\nqui sont implicites.\nPython comprend seul ce que doivent faire ces m√©thodes. Il a une id√©e pr√©concue de ce qu‚Äôelles doivent\neffectuer comme op√©ration. Si vous ne red√©finissez par une m√©thode sp√©ciale pour qu‚Äôelle fasse ce que vous\nsouhaitez, ca peut donner des r√©sultats inattendus.\nElles servent √† plusieurs choses :\n\n√† initialiser l‚Äôobjet instanci√© : __init__\n√† modifier son affichage : __repr__\n\n\n# pour avoir la valeur de l'attribut \"nom\"\n\nprint(mon_chat.__getattribute__(\"nom\"))\n# on aurait aussi pu faire plus simple :\nprint(mon_chat.nom)\n\nMartin\nMartin\n\n\n# si l'attribut n'existe pas : on a une erreur\n# Python recherche l'attribut et, s'il ne le trouve pas dans l'objet et si une m√©thode __getattr__ est sp√©cifi√©e,\n# il va l'appeler en lui passant en param√®tre le nom de l'attribut recherch√©, sous la forme d'une cha√Æne de caract√®res.\n\nprint(mon_chat.origine)\n## Error in py_call_impl(callable, dots$args, dots$keywords): AttributeError: 'chat' object has no attribute 'origine'\n## \n## Detailed traceback: \n##   File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nMais on peut modifier les m√©thodes sp√©ciales de notre classe chat pour √©viter d‚Äôavoir des erreurs d‚Äôattributs. On va aussi en profiter pour modifier la repr√©sentation de l‚Äôinstance chat qui pour l‚Äôinstant donne &lt;_main_.chat object at 0x0000000005AB4C50&gt;\n\n\n3.2.4 Classe chat version 5 - m√©thode sp√©ciale\n\nclass chat:  # D√©finition de notre classe Personne\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\n\n    L'objet chat a deux m√©thodes : nourrir et litiere\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.nom = \"\"\n        self.couleur = \"Roux\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        \"\"\"Par d√©faut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n\n    def nourrir(self, nourriture):\n        \"\"\"M√©thode permettant de donner √† manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"\n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n    def litiere(self):\n        \"\"\"M√©thode permettant au chat d'aller √† sa liti√®re :\n        en cons√©quence son ventre est vide\"\"\"\n        self.ventre = \"\"\n        print(self.nom, \"a le ventre vide\")\n\n    def __getattribute__(self, key):\n        return print(key, \"n'est pas un attribut de la classe chat\")\n\n    def __repr__(self):\n        return \"Je suis une instance de la classe chat\"\n\n\n# j'ai gard√© l'exemple chat d√©fini selon la classe version 4\n# Martin, le chat\n# on a vu pr√©c√©demment qu'il n'avait pas d'attribut origine\n# et que cela levait une erreur AttributeError\nprint(mon_chat.nom)\n\n\n# on va d√©finir un nouveau chat avec la version 5\n# on appelle √† nouveau un attribut qui n'existe pas \"origine\"\n# on a bien le message d√©fini par la m√©thode sp√©ciale _gettattribute\n\nmon_chat_nouvelle_version = chat()\nmon_chat_nouvelle_version.origine\n\n# Maintenant on a aussi une d√©finition de l'objet plus clair\nprint(mon_chat)\nprint(mon_chat_nouvelle_version)\n\nMartin\norigine n'est pas un attribut de la classe chat\n&lt;__main__.chat object at 0x7f15ba001a50&gt;\nJe suis une instance de la classe chat",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#conclusion-sur-les-classes-ce-quon-retient",
    "href": "content/getting-started/07_rappels_classes.html#conclusion-sur-les-classes-ce-quon-retient",
    "title": "Les classes en Python",
    "section": "3.3 Conclusion sur les classes : ce qu‚Äôon retient",
    "text": "3.3 Conclusion sur les classes : ce qu‚Äôon retient\n\nLes m√©thodes se d√©finissent comme des fonctions, sauf qu‚Äôelles se trouvent dans le corps de la classe.\nOn d√©finit les attributs d‚Äôune instance dans le constructeur de sa classe, en suivant cette syntaxe : self.nom_attribut = valeur.\nfacultatif : Les m√©thodes d‚Äôinstance prennent en premier param√®tre ‚Äúself‚Äù, l‚Äôinstance de l‚Äôobjet manipul√©.\nfacultatif : On construit une instance de classe en appelant son constructeur, une m√©thode d‚Äôinstance appel√©e init.",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#informations-additionnelles",
    "href": "content/getting-started/07_rappels_classes.html#informations-additionnelles",
    "title": "Les classes en Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\na1b8aaf\n\n\n2021-09-20 09:05:55\n\n\nLino Galiana\n\n\nBadges de telechargement dans les premiers TP (#146)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\nc3c7433\n\n\n2020-09-15 12:41:26\n\n\nLino Galiana\n\n\nImprove CI with gitlab and jupyter nb conversion (#35)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html",
    "href": "content/getting-started/05_rappels_types.html",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nPandas et Numpy sont\nessentiels pour manipuler les donn√©es.\nN√©anmoins, il est n√©cessaire de ne pas faire l‚Äôimpasse sur les fondements\ndu langage Python. Une bonne compr√©hension des √©l√©ments structurants le\nlangage entra√Æne une plus grande productivit√© et libert√©.\nCe chapitre est inspir√© du mat√©riel qui √©tait propos√©\npar Xavier Dupr√©,\nle pr√©c√©dent professeur de ce cours.\nVoir aussi Essential Cheat Sheets for Machine Learning and Deep Learning Engineers.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#le-print",
    "href": "content/getting-started/05_rappels_types.html#le-print",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "2.1 Le print",
    "text": "2.1 Le print\n\n# on calcule : dans le cas d'une op√©ration par exemple une somme\n2 + 3  # Python calcule le r√©sultat mais n'affiche rien dans la sortie\n\n# le print : on affiche\n\nprint(2 + 3)  # Python calcule et on lui demande juste de l'afficher\n# le r√©sultat est en dessous du code\n\n5\n\n\n\n# le print dans une fonction\n\n\ndef addition_v1(a, b):\n    print(a + b)\n\n\nresultat_print = addition_v1(2, 0)\nprint(type(resultat_print))\n\n# dans la sortie on a l'affichage du r√©sultat, car la sortie de la fonction est un print\n# en plus on lui demande quel est le type du r√©sultat. Un print ne renvoie aucun type, ce n'est ni un num√©rique,\n# ni une chaine de charact√®res, le r√©sultat d'un print n'est pas un format utilisable\n\n2\n&lt;class 'NoneType'&gt;\n\n\nLe r√©sultat de l‚Äôaddition est affich√©\ncar la fonction addition_v1 effectue un print\nPar contre, l‚Äôobjet cr√©√© n‚Äôa pas de type, il n‚Äôest pas un chiffre,\nce n‚Äôest qu‚Äôun affichage.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#le-return",
    "href": "content/getting-started/05_rappels_types.html#le-return",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "2.2 Le return",
    "text": "2.2 Le return\nPour cr√©er un objet avec le r√©sultat de la fonction, il faut utiliser return\n\n# le return dans une fonction\ndef addition_v2(a, b):\n    return a + b\n\n\nresultat_return = addition_v2(2, 5)  #\nprint(type(resultat_return))\n## l√† on a bien un r√©sultat qui est du type \"entier\"\n\n&lt;class 'int'&gt;\n\n\nLe r√©sultat de addition_v2 n‚Äôest pas affich√© comme dans addition_v1\nPar contre, la fonction addition_v2 permet d‚Äôavoir un objet de type int,\nun entier donc.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-variables-immuables",
    "href": "content/getting-started/05_rappels_types.html#les-variables-immuables",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "3.1 Les variables immuables",
    "text": "3.1 Les variables immuables\nLes variables immuables ne peuvent √™tre modifi√©es\n\nNone : ce type est une convention de programmation pour dire que la valeur n‚Äôest pas calcul√©e\nbool : un bool√©en\nint : un entier\nfloat : un r√©el\nstr : une chaine de caract√®res\ntuple : un vecteur\n\n\ni = 3  # entier = type num√©rique (type int)\nr = 3.3  # r√©el   = type num√©rique (type float)\ns = \"exemple\"  # cha√Æne de caract√®res = type str\nn = None  # None signifie que la variable existe mais qu'elle ne contient rien\n# elle est souvent utilis√©e pour signifier qu'il n'y a pas de r√©sultat\na = (1, 2)  # tuple\n\nprint(i, r, s, n, a)\n\n3 3.3 exemple None (1, 2)\n\n\nSi on essaie de changer le premier √©l√©ment de la chaine de caract√®res s on va avoir un peu de mal.\nPar exemple si on voulait mettre une majuscule √† ‚Äúexemple‚Äù,\non aurait envie d‚Äô√©crire que le premier √©l√©ment de la chaine s est ‚ÄúE‚Äù majuscule\nMais Python ne va pas nous laisser faire, il nous dit que les objets ‚Äúchaine de caract√®re‚Äù ne peuvent √™tre modifi√©s\n\ns[0] = \"E\"  # d√©clenche une exception\n\nTypeError: 'str' object does not support item assignment\n\n\nTout ce qu‚Äôon peut faire avec une variable immuable,\nc‚Äôest la r√©affecter √† une autre valeur : elle ne peut pas √™tre modifi√©e.\nPour s‚Äôen convaincre, utilisons la fonction id() qui donne un identifiant √† chaque objet.\n\nprint(s)\nid(s)\n\nexemple\n\n\n140042033982320\n\n\n\ns = \"autre_mot\"\nid(s)\n\n140040563944176\n\n\nOn voit bien que s a chang√© d‚Äôidentifiant : il peut avoir le m√™me nom, ce n‚Äôest plus le m√™me objet",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-types-modifiable-listes-et-dictionnaires",
    "href": "content/getting-started/05_rappels_types.html#les-types-modifiable-listes-et-dictionnaires",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "3.2 Les types modifiable : listes et dictionnaires",
    "text": "3.2 Les types modifiable : listes et dictionnaires\nHeureusement, il existe des variables modifiables comme les listes et les dictionnaires.\n\n3.2.1 Les listes - elles s‚Äô√©crivent entre [ ]\nLes listes sont des √©lements tr√®s utiles, notamment quand vous souhaitez faire des boucles.\nPour faire appel aux √©lements d‚Äôune liste, on donne leur position dans la liste : le 1er est le 0, le 2√®me est le 1 ‚Ä¶\n\nma_liste = [1, 2, 3, 4]\n\n\nprint(\"La longueur de ma liste est de\", len(ma_liste))\nprint(\"Le premier √©l√©ment de ma liste est :\", ma_liste[0])\nprint(\"Le dernier √©l√©ment de ma liste est :\", ma_liste[3])\nprint(\"Le dernier √©l√©ment de ma liste est :\", ma_liste[-1])\n\nLa longueur de ma liste est de 4\nLe premier √©l√©ment de ma liste est : 1\nLe dernier √©l√©ment de ma liste est : 4\nLe dernier √©l√©ment de ma liste est : 4\n\n\nPour effectuer des boucles sur les listes, la m√©thode la plus lisible\nest d‚Äôutiliser les list comprehension. Cette approche consiste\n√† it√©rer les √©l√©ments d‚Äôune liste √† la vol√©e.\nPar exemple, si on reprend cet exemple,\nun code qui repose sur les list comprehension sera le suivant :\n\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = [x for x in fruits if \"a\" in x]\nprint(newlist)\n\n['apple', 'banana', 'mango']\n\n\nLe m√™me code, ne reposant pas sur les compr√©hensions de liste, sera beaucoup\nmoins concis et ainsi inutilement verbeux:\n\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = []\n\nfor x in fruits:\n    if \"a\" in x:\n        newlist.append(x)\n\nprint(newlist)\n\n['apple', 'banana', 'mango']\n\n\n\n\n3.2.2 Les dictionnaires - ils s‚Äô√©crivent entre accolades {}\nUn dictionnaire associe √† une cl√© un autre √©l√©ment, appel√© une valeur : un chiffre, un nom, une liste, un autre dictionnaire etc.\nLe format d‚Äôun dictionnaire est le suivant : {Cl√© : valeur}. Il s‚Äôagit\nd‚Äôun objet tr√®s pratique pour la recherche, beaucoup plus que les listes\nqui ne permettent pas de stocker de l‚Äôinformation diverse de mani√®re\nhi√©rarchis√©e.\n\n\n3.2.3 Dictionnaire avec des valeurs int\nOn peut par exemple associer √† un nom, un nombre\n\nmon_dictionnaire_notes = {\"Nicolas\": 18, \"Pimprenelle\": 15}\n# un dictionnaire qui √† chaque nom associe un nombre\n# √† Nicolas, on associe 18\n\nprint(mon_dictionnaire_notes)\n\n{'Nicolas': 18, 'Pimprenelle': 15}\n\n\n\n\n3.2.4 Dictionnaire avec des valeurs qui sont des listes\nPour chaque cl√© d‚Äôun dictionnaire, il ne faut pas forc√©ment garder la m√™me forme de valeur\nDans l‚Äôexemple, la valeur de la cl√© ‚ÄúNicolas‚Äù est une liste, alors que celle de ‚ÄúPhilou‚Äù est une liste de liste\n\nmon_dictionnaire_loisirs = {\n    \"Nicolas\": [\"Rugby\", \"Pastis\", \"Belote\"],\n    \"Pimprenelle\": [\"Gin Rami\", \"Tisane\", \"Tara Jarmon\", \"Barcelone\", \"Mickey Mouse\"],\n    \"Philou\": [[\"Maths\", \"Jeux\"], [\"Guillaume\", \"Jeanne\", \"Thimoth√©e\", \"Adrien\"]],\n}\n\nPour acc√©der √† un √©l√©ment du dictionnaire, on fait appel √† la cl√© et non plus √† la position, comme c‚Äô√©tait le cas dans les listes.\nC‚Äôest beaucoup plus pratique pour rechercher de l‚Äôinformation:\n\nprint(mon_dictionnaire_loisirs[\"Nicolas\"])  # on affiche une liste\n\n['Rugby', 'Pastis', 'Belote']\n\n\n\nprint(mon_dictionnaire_loisirs[\"Philou\"])  # on affiche une liste de listes\n\n[['Maths', 'Jeux'], ['Guillaume', 'Jeanne', 'Thimoth√©e', 'Adrien']]\n\n\nSi on ne veut avoir que la premi√®re liste des loisirs de Philou, on demande le premier √©l√©ment de la liste\n\nprint(mon_dictionnaire_loisirs[\"Philou\"][0])  # on affiche alors juste la premi√®re liste\n\n['Maths', 'Jeux']\n\n\nOn peut aussi avoir des valeurs qui sont des int et des list\n\nmon_dictionnaire_patchwork_good = {\n    \"Nicolas\": [\"Rugby\", \"Pastis\", \"Belote\"],\n    \"Pimprenelle\": 18,\n}",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#a-retenir",
    "href": "content/getting-started/05_rappels_types.html#a-retenir",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "3.3 A retenir",
    "text": "3.3 A retenir\n\nL‚Äôindentation du code est importante (4 espaces et pas une tabulation)\nUne liste est entre [] et on peut appeler les positions par leur place\nUn dictionnaire, cl√© x valeur, s‚Äô√©crit entre {} et on appelle un √©l√©ment en fonction de la cl√©",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#premiers-exemples-de-m√©thodes",
    "href": "content/getting-started/05_rappels_types.html#premiers-exemples-de-m√©thodes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "5.1 Premiers exemples de m√©thodes",
    "text": "5.1 Premiers exemples de m√©thodes\nAvec les √©l√©ments d√©finis dans la partie 1\n(les listes, les dictionnaires) on peut faire appel √† des m√©thodes qui sont directement li√©es √† ces objets.\n\n5.1.1 Une m√©thode pour les listes\nPour ajouter un √©l√©ment (item) dans une liste : on va utiliser la m√©thode .append()\n\nma_liste = [\"Nicolas\", \"Michel\", \"Bernard\"]\n\nma_liste.append(\"Philippe\")\n\nprint(ma_liste)\n\n['Nicolas', 'Michel', 'Bernard', 'Philippe']\n\n\n\n\n5.1.2 Une m√©thode pour les dictionnaires\nPour connaitre l‚Äôensemble des cl√©s d‚Äôun dictionnaire, on appelle la m√©thode .keys()\n\nmon_dictionnaire = {\n    \"Marc\": \"Lion\",\n    \"Matthieu\": [\"Ange\", \"Homme ail√©\"],\n    \"Jean\": \"Aigle\",\n    \"Luc\": \"Taureau\",\n}\n\nprint(mon_dictionnaire.keys())\n\ndict_keys(['Marc', 'Matthieu', 'Jean', 'Luc'])",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#connaitre-les-m√©thodes-dun-objet",
    "href": "content/getting-started/05_rappels_types.html#connaitre-les-m√©thodes-dun-objet",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "5.2 Connaitre les m√©thodes d‚Äôun objet",
    "text": "5.2 Connaitre les m√©thodes d‚Äôun objet\nPour savoir quelles sont les m√©thodes d‚Äôun objet vous pouvez :\n\ntaper help(mon_objet) ou mon_objet? dans la console Python\ntaper mon_objet. + touche tabulation dans la console Python ou dans le Notebook.\nPython permet la compl√©tion, c‚Äôest-√†-dire que vous pouvez faire appa√Ætre la liste\ndes m√©thodes possibles.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#cr√©er-une-liste",
    "href": "content/getting-started/05_rappels_types.html#cr√©er-une-liste",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.1 Cr√©er une liste",
    "text": "6.1 Cr√©er une liste\nPour cr√©er un objet de la classe list, il suffit de le d√©clarer. Ici on affecte √† x une liste\n\nx = [4, 5]  # cr√©ation d‚Äôune liste compos√©e de deux entiers\nx = [\"un\", 1, \"deux\", 2]  # cr√©ation d‚Äôune liste compos√©e de 2 cha√Ænes de caract√®res\n# et de deux entiers, l‚Äôordre d‚Äô√©criture est important\nx = [3]  # cr√©ation d‚Äôune liste d‚Äôun √©l√©ment, sans la virgule,\nx = []  # cr√©e une liste vide\nx = list()  # cr√©e une liste vide",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#un-premier-test-sur-les-listes",
    "href": "content/getting-started/05_rappels_types.html#un-premier-test-sur-les-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.2 Un premier test sur les listes",
    "text": "6.2 Un premier test sur les listes\nSi on veut tester la pr√©sence d‚Äôun √©l√©ment dans une liste, on l‚Äô√©crit de la mani√®re suivante :\n\n# Exemple\n\nx = \"Marcel\"\n\nl = [\"Marcel\", \"Edith\", \"Maurice\", \"Jean\"]\n\nprint(x in l)\n\n# vrai si x est un des √©l√©ments de l\n\nTrue",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#une-m√©thode-pour-concat√©ner-deux-listes",
    "href": "content/getting-started/05_rappels_types.html#une-m√©thode-pour-concat√©ner-deux-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.3 +: une m√©thode pour concat√©ner deux listes",
    "text": "6.3 +: une m√©thode pour concat√©ner deux listes\nOn utilise le symbole +\n\nt = [\"Antoine\", \"David\"]\nprint(l + t)  # concat√©nation de l et t\n\n['Marcel', 'Edith', 'Maurice', 'Jean', 'Antoine', 'David']",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#pour-trouver-certains-√©l√©ments-dune-liste",
    "href": "content/getting-started/05_rappels_types.html#pour-trouver-certains-√©l√©ments-dune-liste",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.4 Pour trouver certains √©l√©ments d‚Äôune liste",
    "text": "6.4 Pour trouver certains √©l√©ments d‚Äôune liste\nPour chercher des √©lements dans une liste, on utilise la position dans la liste.\n\nl[1]  # donne l'√©l√©ment qui est en 2√®me position de la liste\n\n'Edith'\n\n\n\nl[1:3]  # donne les √©l√©ments de la 2√®me position de la liste √† la 4√®me exclue\n\n['Edith', 'Maurice']",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#quelques-fonctions-des-listes",
    "href": "content/getting-started/05_rappels_types.html#quelques-fonctions-des-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.5 Quelques fonctions des listes",
    "text": "6.5 Quelques fonctions des listes\nLes listes embarquent ainsi nativement un certain nombre de m√©thodes\nqui sont pratiques. Cependant, pour avoir certaines informations\nsur une liste, il faut parfois plut√¥t passer par\ndes fonctions natives comme les suivantes :\n\nlongueur = len(l)  # nombre d‚Äô√©l√©ments de l\nminimum = min(l)  # plus petit √©l√©ment de l, ici par ordre alphab√©tique\nmaximum = max(l)  # plus grand √©l√©ment de l, ici par ordre alphab√©tique\nprint(longueur, minimum, maximum)\n\n4 Edith Maurice\n\n\n\ndel l[0:2]  # supprime les √©l√©ments entre la position 0 et 2 exclue\nprint(l)\n\n['Maurice', 'Jean']",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-m√©thodes-des-listes",
    "href": "content/getting-started/05_rappels_types.html#les-m√©thodes-des-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.6 Les m√©thodes des listes",
    "text": "6.6 Les m√©thodes des listes\nOn les trouve dans l‚Äôaide de la liste.\nOn distingue les m√©thodes et les m√©thodes sp√©ciales : visuellement,\nles m√©thodes sp√©ciales sont celles qui pr√©c√©d√©es et suivis de deux caract√®res de soulignement,\nles autres sont des m√©thodes classiques.\n\nhelp(l)\n\nHelp on list object:\n\nclass list(object)\n |  list(iterable=(), /)\n |  \n |  Built-in mutable sequence.\n |  \n |  If no argument is given, the constructor creates a new empty list.\n |  The argument must be an iterable if specified.\n |  \n |  Methods defined here:\n |  \n |  __add__(self, value, /)\n |      Return self+value.\n |  \n |  __contains__(self, key, /)\n |      Return key in self.\n |  \n |  __delitem__(self, key, /)\n |      Delete self[key].\n |  \n |  __eq__(self, value, /)\n |      Return self==value.\n |  \n |  __ge__(self, value, /)\n |      Return self&gt;=value.\n |  \n |  __getattribute__(self, name, /)\n |      Return getattr(self, name).\n |  \n |  __getitem__(...)\n |      x.__getitem__(y) &lt;==&gt; x[y]\n |  \n |  __gt__(self, value, /)\n |      Return self&gt;value.\n |  \n |  __iadd__(self, value, /)\n |      Implement self+=value.\n |  \n |  __imul__(self, value, /)\n |      Implement self*=value.\n |  \n |  __init__(self, /, *args, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __iter__(self, /)\n |      Implement iter(self).\n |  \n |  __le__(self, value, /)\n |      Return self&lt;=value.\n |  \n |  __len__(self, /)\n |      Return len(self).\n |  \n |  __lt__(self, value, /)\n |      Return self&lt;value.\n |  \n |  __mul__(self, value, /)\n |      Return self*value.\n |  \n |  __ne__(self, value, /)\n |      Return self!=value.\n |  \n |  __repr__(self, /)\n |      Return repr(self).\n |  \n |  __reversed__(self, /)\n |      Return a reverse iterator over the list.\n |  \n |  __rmul__(self, value, /)\n |      Return value*self.\n |  \n |  __setitem__(self, key, value, /)\n |      Set self[key] to value.\n |  \n |  __sizeof__(self, /)\n |      Return the size of the list in memory, in bytes.\n |  \n |  append(self, object, /)\n |      Append object to the end of the list.\n |  \n |  clear(self, /)\n |      Remove all items from list.\n |  \n |  copy(self, /)\n |      Return a shallow copy of the list.\n |  \n |  count(self, value, /)\n |      Return number of occurrences of value.\n |  \n |  extend(self, iterable, /)\n |      Extend list by appending elements from the iterable.\n |  \n |  index(self, value, start=0, stop=9223372036854775807, /)\n |      Return first index of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  insert(self, index, object, /)\n |      Insert object before index.\n |  \n |  pop(self, index=-1, /)\n |      Remove and return item at index (default last).\n |      \n |      Raises IndexError if list is empty or index is out of range.\n |  \n |  remove(self, value, /)\n |      Remove first occurrence of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  reverse(self, /)\n |      Reverse *IN PLACE*.\n |  \n |  sort(self, /, *, key=None, reverse=False)\n |      Sort the list in ascending order and return None.\n |      \n |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the\n |      order of two equal elements is maintained).\n |      \n |      If a key function is given, apply it once to each list item and sort them,\n |      ascending or descending, according to their function values.\n |      \n |      The reverse flag can be set to sort in descending order.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  __class_getitem__(...) from builtins.type\n |      See PEP 585\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  __new__(*args, **kwargs) from builtins.type\n |      Create and return a new object.  See help(type) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#a-retenir-et-questions",
    "href": "content/getting-started/05_rappels_types.html#a-retenir-et-questions",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.7 A retenir et questions",
    "text": "6.7 A retenir et questions\nA retenir :\n\nChaque objet Python a des attributs et des m√©thodes\nVous pouvez cr√©er des classes avec des attributs et des m√©thodes\nLes m√©thodes des listes et des dictionnaires qui sont les plus utilis√©es :\n\nlist.count()\nlist.sort()\nlist.append()\ndict.keys()\ndict.items()\ndict.values()\n\n\n\n\n Exercice 2\n\nD√©finir la liste allant de 1 √† 10, puis effectuez les actions suivantes :\n\n\ntriez et affichez la liste\najoutez l‚Äô√©l√©ment 11 √† la liste et affichez la liste\nrenversez et affichez la liste\naffichez l‚Äô√©l√©ment d‚Äôindice 7\nenlevez l‚Äô√©l√©ment 9 et affichez la liste\naffichez la sous-liste du 2e au 3e √©l√©ments inclus ;\naffichez la sous-liste du d√©but au 2e √©l√©ment inclus ;\naffichez la sous-liste du 3e √©l√©ment √† la fin de la liste ;\n\n\nConstruire le dictionnaire des 6 premiers mois de l‚Äôann√©e avec comme valeurs le nombre de jours respectif.\n\n\nRenvoyer la liste des mois\nRenvoyer la liste des jours\nAjoutez la cl√© du mois de Juillet",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#informations-additionnelles",
    "href": "content/getting-started/05_rappels_types.html#informations-additionnelles",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\na1b8aaf\n\n\n2021-09-20 09:05:55\n\n\nLino Galiana\n\n\nBadges de telechargement dans les premiers TP (#146)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n4c9ebb8\n\n\n2020-09-17 14:09:07\n\n\nLino Galiana\n\n\nCorrige typo incr√©mentation\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html",
    "href": "content/getting-started/03_data_analysis.html",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "",
    "text": "Pour bien d√©buter des travaux sur une base de donn√©es,\nil est n√©cessaire de se poser quelques questions de bon sens\net de suivre une d√©marche scientifique dont un certain\nnombre de gestes sont assez simple.\nDans un projet sur des jeux de donn√©es, on peut sch√©matiquement\ns√©parer les √©tapes en quatre grandes parties :\nCe cours explore ces diff√©rentes √©tapes de mani√®re progressive gr√¢ce √†\nl‚Äô√©cosyst√®me Python qui est tr√®s complet. Chaque chapitre du cours\npeut √™tre vu comme une mani√®re de progresser dans ce fil conducteur.\nDans ce chapitre, nous allons plut√¥t mettre en avant quelques r√©flexions\n√† avoir avant de se lancer dans chaque √©tape.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#r√©flexions-√†-mener-en-amont",
    "href": "content/getting-started/03_data_analysis.html#r√©flexions-√†-mener-en-amont",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "1.1 R√©flexions √† mener en amont",
    "text": "1.1 R√©flexions √† mener en amont\nLa phase de constitution de son jeu de donn√©es sous-tend tout le projet qui suit.\nLa premi√®re question √† se poser est\n‚Äúde quelles donn√©es ai-je besoin pour r√©pondre √† ma probl√©matique ?‚Äù.\nCette probl√©matique pourra √©ventuellement\n√™tre affin√©e en fonction des besoins mais les travaux sont g√©n√©ralement\nde meilleure qualit√© lorsque la probl√©matique am√®ne √† la r√©flexion sur les donn√©es\ndisponibles plut√¥t que l‚Äôinverse.\nEnsuite, ‚Äúqui produit et met √† disposition ces donn√©es‚Äù ?\nLes sources disponibles sur internet sont-elles fiables ?\nPar exemple, les sites d‚Äôopen data gouvernementaux sont par exemple assez fiables mais autorisent parfois l‚Äôarchivage de donn√©es restructur√©es par des tiers et non des producteurs officiels. A l‚Äôinverse, sur Kaggle ou sur Github la source de certains jeux de donn√©es n‚Äôest pas trac√©e ce qui rend compliqu√©e la confiance sur la qualit√© de la donn√©e\nUne fois identifi√© une ou plusieurs sources de donn√©es,\nest-ce que je peux les compl√©ter avec d‚Äôautres donn√©es ?\n(dans ce cas, faire attention √† avoir des niveaux de granularit√© ad√©quats).",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#structuration-des-donn√©es",
    "href": "content/getting-started/03_data_analysis.html#structuration-des-donn√©es",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "1.2 Structuration des donn√©es",
    "text": "1.2 Structuration des donn√©es\nVient ensuite la phase de mise en forme et nettoyage des jeux de donn√©es r√©cup√©r√©s.\nCette √©tape est primordiale et est g√©n√©ralement celle qui mobilise le plus\nde temps. Pendant quelques ann√©es, on parlait de data cleaning. Cependant,\ncela a pu, implicitement, laisser penser qu‚Äôil s‚Äôagissait d‚Äôune t√¢che\nsubalterne. On commence √† lui pr√©f√©rer le concept de feature engineering\nqui souligne bien qu‚Äôil s‚Äôagit d‚Äôune comp√©tence qui n√©cessite beaucoup\nde comp√©tences.\nUn jeu de donn√©es propre est un jeu de donn√©es dont la structure est\nad√©quate et n‚Äôentra√Ænera pas d‚Äôerreur, visible ou non,\nlors de la phase d‚Äôanalyse. Voici quelques √©l√©ments structurants\nd‚Äôun jeu de donn√©es propre :\n\nles informations manquantes sont bien comprises et trait√©es. numpy et\npandas proposent un certain formalisme sur le sujet qu‚Äôil est utile\nd‚Äôadopter en rempla√ßant par NaN les observations manquantes. Cela\nimplique de faire attention √† la mani√®re dont certains producteurs\ncodent les valeurs manquantes : certains ont la facheuse tendance √†\n√™tre imaginatifs sur les codes pour valeurs manquantes : ‚Äú-999‚Äù, ‚ÄúXXX‚Äù, ‚ÄúNA‚Äù\nles variables servant d‚Äôidentifiants sont bien les m√™mes d‚Äôune table √† l‚Äôautre (notamment dans le cas de jointure) : m√™me format, m√™me modalit√©s\npour des variables textuelles, qui peuvent etre mal saisies, avoir corrig√© les √©ventuelles fautes (ex ‚ÄúRolland Garros‚Äù -&gt; ‚ÄúRoland Garros‚Äù)\ncr√©er des variables qui synth√©tisent l‚Äôinformation dont vous avez besoin\nsupprimer les √©l√©ments inutiles (colonne ou ligne vide)\nrenommer les colonnes avec des noms compr√©hensibles",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#valorisation-des-travaux",
    "href": "content/getting-started/03_data_analysis.html#valorisation-des-travaux",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "3.1 Valorisation des travaux",
    "text": "3.1 Valorisation des travaux\nLa mise √† disposition de code sur Github ou Gitlab est une incitation\ntr√®s forte pour produire du code de qualit√©. Il est ainsi recommand√© de\nsyst√©matiquement utiliser ces plateformes pour la mise √† disposition de\ncode. Cependant, il ne s‚Äôagit que d‚Äôune petite partie des gains √†\nl‚Äôutiliser.\nLe cours que je donne avec Romain Avouac en troisi√®me ann√©e d‚ÄôENSAE\n(ensae-reproductibilite.github.io/website/) √©voque\nl‚Äôun des principaux gains √† utiliser ces plateformes, √† savoir\nla possibilit√© de mettre √† disposition automatiquement diff√©rents livrables\npour valoriser son travail aupr√®s de diff√©rents publics.\nSelon le public vis√©, la communication ne sera pas identique. Le code peut\nint√©resser les personnes d√©sirant avoir des d√©tails sur la m√©thodologie mise\nen oeuvre en pratique mais il peut s‚Äôagir d‚Äôun format rebutant pour d‚Äôautres\npublics. Une visualisation de donn√©es dynamiques parlera √† des publics\nmoins experts de la donn√©e mais est plus dure √† mettre en oeuvre\nqu‚Äôun graphique standard.\n\n\n Note\nLes Notebooks Jupyter ont eu beaucoup de succ√®s dans le monde de\nla data science pour valoriser des travaux. Pourtant il ne s‚Äôagit\npas forc√©ment toujours du meilleur format. En effet, beaucoup\nde notebooks tentent √† empiler des pav√©s de code et du texte, ce\nqui les rend difficilement lisibles.\nSur un projet cons√©quent, il vaut mieux reporter le plus de code\npossible dans des scripts bien structur√©s et avoir un notebook\nqui appelle ces scripts pour produire des outputs. Ou alors ne\npas utiliser un notebook et privil√©gier un autre format (un\ntableau de bord, un site web, une appli r√©active‚Ä¶).\nDans le cours de derni√®re ann√©e de\nl‚ÄôENSAE, Mise en production de projets data science, Romain\nAvouac et moi revenons sur les moyens de communication et de partage de code alternatifs au notebook.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#la-reproductibilit√©-est-importante",
    "href": "content/getting-started/03_data_analysis.html#la-reproductibilit√©-est-importante",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.1 La reproductibilit√© est importante",
    "text": "4.1 La reproductibilit√© est importante\nLes donn√©es sont une repr√©sentation synth√©tique de la r√©alit√© et les\nconclusions de certaines analyses peuvent avoir un vrai impact sur\nla vie des citoyens. Les chiffres erron√©s de\nReinhart et Rogoff ont ainsi pu servir de justification th√©orique √† des\npolitiques d‚Äôaust√©rit√© qui ont pu avoir des cons√©quences violentes\npour certains citoyens de\npays en crise1. En Grande-Bretagne, le recensement des personnes\ncontamin√©es par le Covid en 2020, et donc de leurs proches pour le\nsuivi de l‚Äô√©pid√©mie,\na √©t√© incomplet √† cause de\ntroncatures dues √† l‚Äôutilisation d‚Äôun format non adapt√© de stockage\ndes donn√©es (tableur Excel)2.\nDernier exemple avec le credit scoring mis en oeuvre aux Etats-Unis.\nLa citation ci-dessous, issue de l‚Äôarticle de Hurley and Adebayo (2016),\nillustre tr√®s bien les cons√©quences et les aspects probl√©matiques\nd‚Äôun syst√®me de construction automatis√©e d‚Äôun score de cr√©dit :\n\nConsumers have limited ability to identify and contest unfair credit\ndecisions, and little chance to understand what steps they\nshould take to improve their credit. Recent studies have also\nquestioned the accuracy of the data used by these tools, in some\ncases identifying serious flaws that have a substantial bearing\non lending decisions. Big-data tools may also risk creating a\nsystem of ‚Äúcreditworthinessby association‚Äù in which consumers‚Äô\nfamilial, religious, social, and other affiliations determine their\neligibility for an affordable loan.\nHurley and Adebayo (2016)",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#lutter-contre-les-biais-cognitifs",
    "href": "content/getting-started/03_data_analysis.html#lutter-contre-les-biais-cognitifs",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.2 Lutter contre les biais cognitifs",
    "text": "4.2 Lutter contre les biais cognitifs\nLa transparence sur les int√©r√™ts et limites d‚Äôune m√©thode mise en oeuvre\nest donc importante.\nCette exigence de la recherche, parfois oubli√©e √† cause de la course\naux r√©sultats novateurs, m√©rite √©galement d‚Äô√™tre appliqu√©e\nen entreprise ou administration.\nM√™me sans intention manifeste de la part de la personne qui analyse des donn√©es,\nune mauvaise interpr√©tation est toujours possible. Tout en valorisant un\nr√©sultat, il est possible d‚Äôalerter sur certaines limites. Il est important,\ndans ses recherches comme dans les discussions avec d‚Äôautres interlocuteurs,\nde faire attention au biais de confirmation qui consiste\n√† ne retenir que l‚Äôinformation qui correspond √† nos conceptions a priori et\n√† ne pas consid√©rer celles qui pourraient aller √† l‚Äôencontre de celles-ci :\n\nCertaines repr√©sentations de donn√©es sont √† exclure car des biais cognitifs\npeuvent amener √† des interpr√©tations erron√©es3. Dans le domaine de la\nvisualisation de donn√©es, les camemberts (pie chart) ou les diagrammes\nradar sont par exemple\n√† exclure car l‚Äôoeil humain per√ßoit mal ces formes circulaires. Pour une raison\nsimilaire, les cartes avec aplat de couleur (cartes\nchoropl√®thes) sont trompeuses.\nLes posts de blog pour datawrapper\nde Lisa Charlotte Muth ou ceux d‚ÄôEric Mauvi√®re sont d‚Äôexcellentes ressources\npour apprendre les bonnes et mauvaises pratiques de\nvisualisation (voir la partie visualisation de ce cours\npour plus de d√©tails).",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#r√©glementation-des-donn√©es",
    "href": "content/getting-started/03_data_analysis.html#r√©glementation-des-donn√©es",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.3 R√©glementation des donn√©es",
    "text": "4.3 R√©glementation des donn√©es\nLe cadre r√©glementaire de protection des donn√©es a √©volu√© ces derni√®res\nann√©es avec le RGPD. Cette r√©glementation a permis de mieux faire\nsaisir le fait que la collecte de donn√©es se justifie au nom\nde finalit√©s plus ou moins bien identifi√©es. Prendre conscience que\nla confidentialit√© des donn√©es se justifie pour √©viter la diss√©mination\nnon contr√¥l√©e d‚Äôinformations sur une personne est important.\nDes donn√©es particuli√®rement sensibles, notamment les donn√©es de sant√©,\npeuvent √™tre plus contraignantes √† traiter que des donn√©es peu sensibles.\nEn Europe, par exemple, les agents du service statistique public\n(Insee ou services statistiques minist√©riels) sont tenus au secret professionnel\n(article L121-6 du Code g√©n√©ral de la fonction publique),\nqui leur interdit la communication des informations confidentielles\ndont ils sont d√©positaires au titre de leurs missions ou fonctions,\nsous peine des sanctions pr√©vues par l‚Äôarticle 226-13 du Code p√©nal\n(jusqu‚Äô√† un an d‚Äôemprisonnement et 15 000 ‚Ç¨ d‚Äôamende).\nLe secret statistique, d√©fini dans une loi de 1951,\nrenforce cette obligation dans le cas de donn√©es d√©tenues pour des usages statistiques.\nIl interdit strictement la communication de donn√©es individuelles\nou susceptibles d‚Äôidentifier les personnes,\nissues de traitements √† finalit√©s statistiques,\nque ces traitements proviennent d‚Äôenqu√™tes ou de bases de donn√©es.\nLe secret statistique exclut par principe de diffuser des donn√©es\nqui permettraient l‚Äôidentification des personnes concern√©es,\npersonnes physiques comme personnes morales.\nCette obligation limite la finesse des informations disponibles en diffusion\nCe cadre contraignant s‚Äôexplique par l‚Äôh√©ritage de la Seconde Guerre Mondiale\net le d√©sir de ne plus revivre une situation o√π la collecte d‚Äôinformation\nsert une action publique bas√©e sur la discrimination entre cat√©gories\nde la population.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#partager-les-moyens-de-reproduire-une-analyse",
    "href": "content/getting-started/03_data_analysis.html#partager-les-moyens-de-reproduire-une-analyse",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.4 Partager les moyens de reproduire une analyse",
    "text": "4.4 Partager les moyens de reproduire une analyse\nUn article r√©cent de Nature,\nqui reprend les travaux d‚Äôune √©quipe d‚Äô√©pid√©miologistes (Gabelica, Bojƒçiƒá, and Puljak 2022)\n√©voque le probl√®me de l‚Äôacc√®s aux donn√©es pour des chercheurs d√©sirant reproduire\nune √©tude. M√™me dans les articles scientifiques o√π il est mentionn√© que les\ndonn√©es peuvent √™tre mises √† disposition d‚Äôautres chercheurs, le partage\nde celles-ci est rare :\n\nGraphique issu de l‚Äôarticle de Nature\nCe constat, quelque peu inqui√©tant, est confirm√© par une √©tude r√©cente\nde Samuel and Mietchen (2023) qui a tent√© d‚Äôex√©cuter un peu moins de\n30 000 notebooks associ√©s √† des √©tudes scientifiques. Seuls 3%\ndes notebooks reproduisent les r√©sultats esp√©r√©s.\nAfin de partager les moyens de reproduire des publications sans diffuser des\ndonn√©es potentiellement confidentielles, les jeux de donn√©es synth√©tiques\nsont de plus en plus utilis√©s. Par le biais de mod√®les de deep learning,\nil est ainsi possible de g√©n√©rer des jeux de donn√©es synth√©tiques complexes\nqui permettent de reproduire les principales caract√©ristiques d‚Äôun jeu de donn√©es\ntout en √©vitant, si le mod√®le a √©t√© bien calibr√©, de diffuser une information\nindividuelle.\nDans l‚Äôadministration fran√ßaise, les codes sources sont\nconsid√©r√©s comme des documents administratifs et peuvent\ndonc √™tre mis √† disposition de tout citoyen sur demande √† la\nCommission d‚Äôacc√®s aux documents administratifs (CADA):\n\n¬´ Sont consid√©r√©s comme documents administratifs, au sens des titres Ier, III et IV du pr√©sent livre, quels que soient leur date, leur lieu de conservation, leur forme et leur support, les documents produits ou re√ßus, dans le cadre de leur mission de service public, par l‚Äô√âtat, les collectivit√©s territoriales ainsi que par les autres personnes de droit public ou les personnes de droit priv√© charg√©es d‚Äôune telle mission. Constituent de tels documents notamment les dossiers, rapports, √©tudes, comptes rendus, proc√®s-verbaux, statistiques, instructions, circulaires, notes et r√©ponses minist√©rielles, correspondances, avis, pr√©visions, codes sources et d√©cisions. ¬ª\nAvis 20230314 - S√©ance du 30/03/2023 de la Commission d‚Äôacc√®s aux documents administratifs\n\nEn revanche, les poids des mod√®les utilis√©s par l‚Äôadministration, notamment ceux\ndes mod√®les de machine learning ne sont pas r√©glement√©s de la m√™me\nmani√®re (Avis 20230314 de la CADA).\nEn effet, comme il existe toujours\nun risque de r√©tro-ing√©nierie amenant √† une r√©v√©lation partielle\ndes donn√©es\nd‚Äôentra√Ænement lors d‚Äôun partage de mod√®le, les mod√®les\nentra√Æn√©s sur des donn√©es\nsensibles (comme les d√©cisions de justice √©tudi√©es\npar (l‚Äôavis 20230314 de la CADA))\nn‚Äôont pas vocation √† √™tre partag√©s.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#adopter-une-approche-√©cologique",
    "href": "content/getting-started/03_data_analysis.html#adopter-une-approche-√©cologique",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.5 Adopter une approche √©cologique",
    "text": "4.5 Adopter une approche √©cologique\nLe num√©rique constitue une part croissante des\n√©missions de gaz √† effet de serre.\nRepr√©sentant aujourd‚Äôhui 4 % des √©missions mondiales\nde CO2, cette part devrait encore cro√Ætre (Arcep 2019).\nLe monde de la data science est √©galement\nconcern√©.\nL‚Äôutilisation de donn√©es de plus en\nplus massives, notamment la constitution\nde corpus monumentaux de textes,\nr√©cup√©r√©s par scraping, est une premi√®re source\nde d√©pense d‚Äô√©nergie. De m√™me, la r√©cup√©ration\nen continu de nouvelles traces num√©riques\nn√©cessite d‚Äôavoir des serveurs fonctionnels\nen continu. A cette premi√®re source de\nd√©pense d‚Äô√©nergie, s‚Äôajoute l‚Äôentra√Ænement\ndes mod√®les qui peut prendre des jours,\ny compris sur des architectures tr√®s\npuissantes. Strubell, Ganesh, and McCallum (2019)\nestime que l‚Äôentra√Ænement d‚Äôun mod√®le √†\nl‚Äô√©tat de l‚Äôart dans le domaine du\nNLP n√©cessite autant d‚Äô√©nergie que ce que\nconsommeraient cinq voitures, en moyenne,\nau cours de l‚Äôensemble de leur\ncycle de vie.\nL‚Äôutilisation accrue de l‚Äôint√©gration\ncontinue, qui permet de mettre en oeuvre de mani√®re\nautomatis√©e l‚Äôex√©cution de certains scripts ou\nla production de livrables en continu,\nam√®ne √©galement √† une d√©pense d‚Äô√©nergie importante.\nIl convient donc d‚Äôessayer de limiter l‚Äôint√©gration\ncontinue √† la production d‚Äôoutput vraiment nouveaux.\n\n\n Note\nPar exemple, cet ouvrage utilise de mani√®re intensive\ncette approche. N√©anmoins, pour essayer de limiter\nles effets pervers de la production en continu d‚Äôun\nouvrage extensif, seuls les chapitres modifi√©s\nsont produits lors des pr√©visualisations mises en\noeuvre √† chaque pull request sur le d√©p√¥t\nGithub.\n\n\nLes data scientists doivent √™tre conscients\ndes implications de leur usage intensif de\nressources et essayer de minimiser leur\nimpact. Par exemple, plut√¥t que r√©-estimer\nun mod√®le de NLP,\nla m√©thode de l‚Äôapprentissage par transfert,\nqui permet de transf√©rer les poids d‚Äôapprentissage\nd‚Äôun mod√®le √† une nouvelle source, permet\nde r√©duire les besoins computationnels.\nDe m√™me, il peut √™tre utile, pour prendre\nconscience de l‚Äôeffet d‚Äôun code trop long,\nde convertir le temps de calcul en\n√©missions de gaz √† effet de serre.\nLe package codecarbon\npropose cette solution en adaptant l‚Äôestimation\nen fonction du mix √©nerg√©tique du pays\nen question. Mesurer √©tant le\npr√©requis pour prendre conscience puis comprendre,\nce type d‚Äôinitiatives peut amener √† responsabiliser\nles data scientists et ainsi permettre un\nmeilleur partage des ressources.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#informations-additionnelles",
    "href": "content/getting-started/03_data_analysis.html#informations-additionnelles",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6f20643\n\n\n2023-09-25 14:33:20\n\n\nLino Galiana\n\n\nCorrection lien mort cours ENSAE\n\n\n\n\n6dee48d\n\n\n2023-08-31 11:47:07\n\n\nlinogaliana\n\n\nD√©marche scientifique\n\n\n\n\nfb186dd\n\n\n2023-08-31 08:42:58\n\n\nlinogaliana\n\n\nAjoute avis CADA\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n22d4b5a\n\n\n2022-06-30 12:40:41\n\n\nLino Galiana\n\n\nCorrige la typo pour la ref (#245)\n\n\n\n\n5123634\n\n\n2022-06-30 11:24:49\n\n\nLino Galiana\n\n\nAm√©lioration de la premi√®re partie (#244)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#footnotes",
    "href": "content/getting-started/03_data_analysis.html#footnotes",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe livre de Reinhart et Rogoff, This time is different, s‚Äôappuyait\nsur un Excel constitu√© √† la main. Un doctorant s‚Äôest aper√ßu d‚Äôerreurs\ndans celui-ci et a remarqu√© que lorsqu‚Äôon\nsubstituait les chiffres officiels, les r√©sultats n‚Äô√©taient plus valides.‚Ü©Ô∏é\nOn suppose ici que le message erron√© est transmis sans volont√© de\nmanipulation. La manipulation manifeste est un probl√®me encore plus grave.‚Ü©Ô∏é\nOn suppose ici que le message erron√© est transmis sans volont√© de\nmanipulation. La manipulation manifeste est un probl√®me encore plus grave.‚Ü©Ô∏é",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html",
    "href": "content/getting-started/01_installation.html",
    "title": "Configuration de Python",
    "section": "",
    "text": "Les exercices sont pr√©sent√©s sous la\nforme de notebook jupyter. Ils peuvent √™tre ex√©cut√©s\ndans plusieurs environnement, au gr√© des pr√©f√©rences et des connaissances\nde chacun :\nConcernant la premi√®re m√©thode, qui est celle recommand√©e,\nchaque\nchapitre pr√©sente les badges suivants qui permettent d‚Äôouvrir\nla page web en question dans l‚Äôenvironnement de pr√©dilection.\nPar exemple, pour ouvrir le chapitre relatif √†\nnumpy dans l‚Äôun des environnements temporaires propos√©s,\nles badges suivants sont propos√©s :\nQuel que soit l‚Äôenvironnement d‚Äôex√©cution des scripts, l‚Äôun des objectifs\nde ce cours est d‚Äôadopter un environnement favorable √† la reproductibilit√©\ndes traitements. Ils devraient donc fonctionner, d√®s lors que l‚Äôenvironnement\nest bien configur√©, d‚Äôune mani√®re similaire quel que soit\nla machine qui ex√©cute le code.\nComme la reproductibilit√© est une notion centrale dans une d√©marche\nscientifique mais √©galement importante dans le monde\nde l‚Äôentreprise ou de l‚Äôadministration, en suppl√©ment des notions relatives\n√† Python, ce cours montrera comment utiliser Git avec Python et\n√©voquera un\ncertain nombre de crit√®res de qualit√© du code qui sont devenus\ndes standards dans la communaut√© open-source, dans l‚Äôindustrie et dans\nl‚Äôadministration. Ces comp√©tences ne sont pas\npropres √† Python et seront\nutiles pour tout projet ult√©rieur. Un cours d√©di√© √† cette question\nest propos√© par Romain Avouac et moi en derni√®re ann√©e de l‚ÄôENSAE. Son\ncontenu est disponible sur https://ensae-reproductibilite.github.io/website/.\nLe projet final devra imp√©rativement\n√™tre associ√© √† un d√©p√¥t\nsur Github (nous reviendrons dessus) et r√©pondre √†\nces crit√®res de qualit√©, qui serviront toute la vie.\nCe cours vise √† acculturer √† la conduite de projets de data-science avec\nPython. L‚Äôenvironnement foisonnant de la data-science n√©cessite un\ncertain nombre d‚Äô√©l√©ments suppl√©mentaires √† Python. La suite\nde ce chapitre permettra de d√©crire les configurations √† mettre\nen oeuvre pour √™tre en mesure d‚Äôexploiter la richesse de l‚Äô√©cosyst√®me Python.",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#installer-python-en-local",
    "href": "content/getting-started/01_installation.html#installer-python-en-local",
    "title": "Configuration de Python",
    "section": "1.1 Installer Python en local",
    "text": "1.1 Installer Python en local\nPour installer Python, il est recommand√© d‚Äôutiliser\nla distribution Anaconda\nqui permet d‚Äôinstaller une distribution minimale de Python ainsi qu‚Äô√©ventuellement\nun environnement plus complet :\n\nSous Windows, il suffit de t√©l√©charger l‚Äôex√©cutable puis\nl‚Äôex√©cuter (cf.¬†la doc officielle ;\nSous Mac, se reporter √† la doc officielle ;\nSous Linux, suivre les instructions de la doc officielle selon sa distribution\n\nPasser par Anaconda permet:\n\nd‚Äôinstaller Python ;\nd‚Äôinstaller par d√©faut une multitude de packages utiles ;\nde pouvoir utiliser un gestionnaire de package nomm√© conda.\n\nAnaconda permet de cr√©er des environnements isol√©s et facilite l‚Äôinstallation\nde certaines librairies qui n√©cessitent l‚Äôusage de langages externes (par exemple\ndu C++).",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#installer-un-environnement-de-d√©veloppement",
    "href": "content/getting-started/01_installation.html#installer-un-environnement-de-d√©veloppement",
    "title": "Configuration de Python",
    "section": "1.2 Installer un environnement de d√©veloppement",
    "text": "1.2 Installer un environnement de d√©veloppement\nLes notebooks Jupyter (extension .ipynb)\nsont tr√®s utilis√©s en data science. Ils sont en\nparticulier tr√®s adapt√©s √† la r√©alisation d‚Äôanalyses exploratoires.\nLes notebooks permettent de m√™ler du code, du texte et des sorties\ngraphiques ou des tableaux. L‚Äôint√©r√™t principal des notebooks est qu‚Äôils\npermettent d‚Äôex√©cuter du code tr√®s facilement dans un environnement\nPython donn√© (le kernel Jupyter). Ils sont particuli√®rement pratiques\npour ajouter du code ou du texte √† un document d√©j√† existant, d‚Äôo√π le\nterme de notebook.\nN√©anmoins, pass√©e l‚Äô√©tape d‚Äôexploration, il est recommand√© de plut√¥t recourir √† des\nscripts au format .py. L‚Äôutilisation du format .py est l‚Äôun des premiers\ngestes pour favoriser la reproductibilit√© des analyses.\nCes scripts peuvent √™tre √©dit√©s √† l‚Äôaide d‚Äô√©diteurs de texte adapt√©s au code, comme\nVisual Studio\n(mon pr√©f√©r√©),\nSublime Text,\nou PyCharm (privil√©gier Pycharm Community Edition)\nentre autres.\nCes √©diteurs\noffrent des fonctionalit√©s suppl√©mentaires pratiques :\n\nnombreux plugins pour une pleine utilisation de l‚Äô√©cosyst√®me Python: √©diteur de Markdown,\ninterface Git, etc.\nfonctionalit√©s classiques d‚Äôun IDE dont manque Jupyter: autocompl√©tion, diagnostic du code, etc.\nint√©gration avec les environnements Conda",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#installation-de-git",
    "href": "content/getting-started/01_installation.html#installation-de-git",
    "title": "Configuration de Python",
    "section": "1.3 Installation de Git",
    "text": "1.3 Installation de Git\nLe principe de Git ainsi que son usage avec Python sont pr√©sent√©s dans\nune partie d√©di√©e. Cette partie se concentre ainsi sur la question\nde la configuration de Git.\nGit est un langage dont la fonction est de tracer l‚Äôhistorique de modification\nd‚Äôun fichier. Pour disposer de ce langage, il est n√©cessaire d‚Äôinstaller\nle logiciel Git Bash. Gr√¢ce √† lui, Git sera disponible et des outils\nexternes, notamment les interfaces de d√©veloppement comme\nVisual Studio, pourront l‚Äôutiliser.",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#informations-additionnelles",
    "href": "content/getting-started/01_installation.html#informations-additionnelles",
    "title": "Configuration de Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nfd439f0\n\n\n2022-09-19 09:37:50\n\n\navouacr\n\n\nfix ssp cloud links\n\n\n\n\n3056d41\n\n\n2022-09-02 12:19:55\n\n\navouacr\n\n\nfix all SSP Cloud launcher links\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n61922f0\n\n\n2022-08-03 17:06:55\n\n\nLino Galiana\n\n\nanaconda toss (#251)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n5123634\n\n\n2022-06-30 11:24:49\n\n\nLino Galiana\n\n\nAm√©lioration de la premi√®re partie (#244)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n66fc843\n\n\n2021-11-08 11:19:12\n\n\nLino Galiana\n\n\nAdd badge open in vsode (#176)\n\n\n\n\nf95b174\n\n\n2021-11-03 12:08:34\n\n\nLino Galiana\n\n\nEnrichi la section sur la gestion des d√©pendances (#175)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#footnotes",
    "href": "content/getting-started/01_installation.html#footnotes",
    "title": "Configuration de Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLes gains de performance peuvent √™tre assez impressionnants.\nLa cr√©ation de l‚Äôenvironnement n√©cessaire √† la construction automatis√©e\nde ce site web a ainsi √©t√© divis√©e par 12 en utilisant mamba plut√¥t\nque conda pour installer des packages dans un environnement.‚Ü©Ô∏é\nLes gains de performance peuvent √™tre assez impressionnants.\nLa cr√©ation de l‚Äôenvironnement n√©cessaire √† la construction automatis√©e\nde ce site web a ainsi √©t√© divis√©e par 12 en utilisant mamba plut√¥t\nque conda pour installer des packages dans un environnement.‚Ü©Ô∏é",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python pour la data science",
    "section": "",
    "text": "Python pour la data science \n\n\nLino Galiana\n\n\nStar this website on Github\n\nSite web du cours Python pour la data science\n, une introduction √† Python pour\nla deuxi√®me ann√©e du cursus d‚Äôing√©nieur de l‚ÄôENSAE (Master 1).\n\nL‚Äôensemble du contenu de ce groupe est librement disponible ici\nou sur Github\n et peut √™tre test√©\nsous forme de notebooks Jupyter.\n\n\n\nExemple avec le TP Pandas\n\n\nhtml`${printBadges({fpath: \"content/manipulation/02b_pandas_TP.qmd\"})}`\n\n\n\n\n\n\n\n\n\nAu programme:\n\n\nR√©cup√©rer, structurer et manipuler des donn√©es ;\nVisualiser et communiquer des r√©sultats ;\nMod√©liser gr√¢ce au machine learning des relations entre des jeux de donn√©es ;\nExploiter des donn√©es textuelles."
  },
  {
    "objectID": "index.html#th√®mes-en-vrac",
    "href": "index.html#th√®mes-en-vrac",
    "title": "Python pour la data science",
    "section": "Th√®mes en vrac",
    "text": "Th√®mes en vrac\nPour d√©couvrir Python  de mani√®re th√©matique\n\n\n\n\n\n\n\n\n\n\nQuelques √©l√©ments pour comprendre les enjeux du NLP\n\n\n\nNLP\n\n\nTutoriel\n\n\n\nLes corpus textuels √©tant des objets de tr√®s grande dimension\no√π le ratio signal/bruit est faible, il est n√©cessaire de mettre\nen oeuvre une s√©rie d‚Äô√©tapes de nettoyage de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words\n\n\n\nNLP\n\n\nExercice\n\n\n\nCe chapitre continue de pr√©senter l‚Äôapproche de nettoyage de donn√©es\ndu NLP en s‚Äôappuyant sur le corpus de trois auteurs\nanglo-saxons : Mary Shelley, Edgar Allan Poe‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatent Dirichlet Allocation (LDA)\n\n\n\nTutoriel\n\n\nNLP\n\n\n\nLa Latent Dirichlet Allocation (LDA)\nest un mod√®le probabiliste g√©n√©ratif qui permet\nde d√©crire des‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM√©thodes de vectorisation : comptages et word embeddings\n\n\n\nTutoriel\n\n\nNLP\n\n\n\nPour pouvoir utiliser des donn√©es textuelles dans des algorithmes\nde machine learning, il faut les vectoriser, c‚Äôest √† dire transformer\nle texte en donn√©es num√©riques.‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercices suppl√©mentaires\n\n\n\nExercice\n\n\nNLP\n\n\n\nDes exercices suppl√©mentaires pour pratiquer les concepts du NLP\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 4 : Natural Language Processing (NLP)\n\n\n\nIntroduction\n\n\nNLP\n\n\n\nL‚Äôun des grands avantages comparatifs de  par rapport aux\nlangages concurrents ( notamment) est dans\nla richesse des‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrections\n\n\nNotebooks corrig√©s des diff√©rents chapitres du cours\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation\n\n\nR√©sum√© des attentes pour les projets de fin d‚Äôann√©e\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nL‚Äôenvironnement que propose Python pour la data science\nest tr√®s riche. Afin de b√©n√©ficier du meilleur environnement\npour tirer parti du langage, ce chapitre‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôenvironnement Python pour la data science\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nPython propose un √©cosyst√®me tr√®s riche pour la\ndata science. Ce chapitre fait un tour\nd‚Äôhorizon de celui-ci en pr√©sentant les principaux\npackages qui seront pr√©sent√©s‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD√©marche √† adopter face √† un jeu de donn√©es\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nQuelques √©l√©ments pour adopter une d√©marche\nscientifique et √©thique face √† un\njeu de donn√©es.\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonne pratique de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLes normes communautaires du monde de\nl‚Äôopen-source ont permis une\nharmonisation de la structure des projets\nPython et des scripts. Ce chapitre\n√©voque quelques-unes de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuelques rappels sur les principes de base de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nRappels d‚Äô√©l√©ments essentiels en Python: les r√®gles de syntaxes, les classes,\nles m√©thodes, etc.\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModules, tests, boucles, fonctions\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLes fonctions permettent de g√©n√©raliser des\ninstructions. Il s‚Äôagit ainsi d‚Äôun outil privil√©gi√©\npour automatiser des t√¢ches r√©p√©titives ou r√©duire\nla complexit√© d‚Äôune cha√Æne‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes classes en Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLa programmation orient√©e objet (POO) est\nl‚Äôun des atouts de Python. Elle permet\nd‚Äôadapter des‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\n\nCette introduction propose quelques √©l√©ments de\nr√©vision des concepts de base en Python et\npr√©sente l‚Äô√©cosyst√®me Python que nous allons\nd√©couvrir tout au long de ce‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUn cadavre exquis pour d√©couvrir Git\n\n\n\nExercice\n\n\nGit\n\n\n\nCe chapitre propose une mise en application de quelques principes\ncentraux du langage Git vus pr√©c√©demment.\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGit: un outil n√©cessaire pour les data scientists\n\n\n\nGit\n\n\n\nUne partie annexe au cours pour d√©couvrir Git,\nun outil\ndevenu indispensable pour les data scientists\nafin de mener des projets impliquant\ndu code Python.\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGit : un √©l√©ment essentiel au quotidien\n\n\n\nTutoriel\n\n\nGit\n\n\n\nGit est un syst√®me de contr√¥le de version qui facilite la\nsauvegarde, la gestion des √©volutions et le partage\nd‚Äôun projet informatique. Il s‚Äôagit d‚Äôun √©l√©ment‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumpy, la brique de base de la data science\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nNumpy constitue la brique de base de l‚Äô√©cosyst√®me de la data science en\nPython. Toutes les librairies de manipulation de donn√©es, de mod√©lisation\net de visualisation‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction √† Pandas\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nPandas est l‚Äô√©l√©ment central de l‚Äô√©cosyst√®me Python pour la data science.\nLe succ√®s r√©cent de Python dans l‚Äôanalyse de donn√©es tient beaucoup √† Pandas qui a permis‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPratique de pandas : un exemple complet\n\n\n\nManipulation\n\n\nExercice\n\n\n\nApr√®s avoir pr√©sent√© la logique de Pandas dans le chapitre pr√©c√©dent,\nce chapitre vise √† illustrer les fonctionalit√©s du package\n√† partir de donn√©es d‚Äô√©missions de gaz √†‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPratique de geopandas avec les donn√©es v√©lib\n\n\n\nManipulation\n\n\nExercice\n\n\n\nCe chapitre illustre les fonctionalit√©s de GeoPandas √† partir des\nd√©comptes de v√©lo fournis par la ville de Paris\nen‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDonn√©es spatiales : d√©couverte de geopandas\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nLes donn√©es g√©olocalis√©es se sont multipli√©es depuis quelques ann√©es, qu‚Äôil\ns‚Äôagisse de donn√©es open-data ou de traces num√©riques g√©olocalis√©es de\ntype big-data. Pour les‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping avec Python\n\n\n\nExercice\n\n\nManipulation\n\n\n\nPython permet de facilement r√©cup√©rer une page web pour en extraire des\ndonn√©es √† restructurer. Le web scraping, que les Canadiens nomment\n‚Äúmoissonnage du web‚Äù, est‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMa√Ætriser les expressions r√©guli√®res\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nLes expressions r√©guli√®res fournissent un cadre tr√®s pratique pour manipuler\nde mani√®re flexible des donn√©es textuelles. Elles sont tr√®s utiles\nnotamment pour les t√¢ches de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR√©cup√©rer des donn√©es avec des API depuis Python\n\n\n\nExercice\n\n\nManipulation\n\n\n\nLes API (Application Programming Interface) sont un mode d‚Äôacc√®s aux\ndonn√©es en expansion. Gr√¢ce aux API, l‚Äôautomatisation de scripts\nest facilit√©e puisqu‚Äôil n‚Äôest‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 1: manipuler des donn√©es\n\n\n\nManipulation\n\n\nIntroduction\n\n\n\nPython s‚Äôest impos√© comme une alternative tr√®s cr√©dible √† R dans\nla manipulation de donn√©es. L‚Äô√©cosyst√®me Pandas a permis de d√©mocratiser\nl‚Äôutilisation des DataFrames‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPr√©paration des donn√©es pour construire un mod√®le\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nAfin d‚Äôavoir des donn√©es coh√©rentes avec les hypoth√®ses de mod√©lisation,\nil est absolument fondamental de prendre le temps de\npr√©parer les donn√©es √† fournir √† un mod√®le. La‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluer la qualit√© d‚Äôun mod√®le\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nFaire preuve de m√©thode pour √©valuer la qualit√© d‚Äôun mod√®le\npermet de proposer des pr√©dictions plus robustes, ayant\nde meilleures performances sur un nouveau jeu de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification: premier mod√®le avec les SVM\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nLa classification permet d‚Äôattribuer une classe d‚Äôappartenance (label\ndans la terminologie du machine learning)\ndiscr√®te √† des donn√©es √† partir de certaines variables‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR√©gression : une introduction\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nLa r√©gression lin√©aire est la premi√®re mod√©lisation statistique\nqu‚Äôon d√©couvre dans un cursus quantitatif. Il s‚Äôagit en effet d‚Äôune\nm√©thode tr√®s intuitive et tr√®s riche. Le‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS√©lection de variables : une introduction\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nL‚Äôacc√®s √† des bases de donn√©es de plus en plus riches permet\ndes mod√©lisations de plus en plus raffin√©es. Cependant,\nles mod√®les parcimonieux sont g√©n√©ralement‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustering\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nLe clustering consiste √† r√©partir des observations dans des groupes,\ng√©n√©ralement non observ√©s,\nen fonction de caract√©ristiques observables. Il s‚Äôagit d‚Äôune\napplication‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPremier pas vers l‚Äôindustrialisation avec les pipelines scikit\n\n\n\nMod√©lisation\n\n\nTutoriel\n\n\n\nLes pipelines Scikit permettent d‚Äôint√©grer de mani√®re tr√®s flexible\nun ensemble d‚Äôop√©rations de pre-processing et d‚Äôentra√Ænement de mod√®les\ndans une cha√Æne d‚Äôop√©rations.‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMettre √† disposition un mod√®le par le biais d‚Äôune API\n\n\n\nMod√©lisation\n\n\nTutoriel\n\n\n\nTO BE COMPLETED\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 3: mod√©liser\n\n\n\nIntroduction\n\n\nMod√©lisation\n\n\n\nLa facilit√© √† mod√©liser des processus tr√®s diverses a grandement\nparticip√© au succ√®s de Python. La librairie scikit offre une\ngrande vari√©t√© de mod√®les et permet ainsi‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInt√©gration continue avec Python\n\n\nUn chapitre plus avanc√© sur l‚Äôint√©gration continue\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG√©n√©ration d‚Äôimages avec Python, DALL-E et StableDiffusion\n\n\n\nTutoriel\n\n\nAvanc√©\n\n\n\nLa hype autour du\nmod√®le de g√©n√©ration d‚Äôimage Dall-E a amen√©\nune grande attention sur les mod√®les\nautog√©n√©ratifs de contenu. Dall-E est, √† l‚Äôheure\nactuelle, le mod√®le‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApprofondissement ElasticSearch pour des recherches de proximit√© g√©ographique\n\n\n\nTutoriel\n\n\nAvanc√©\n\n\n\nUn chapitre plus approfondi sur ElasticSearch\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction √† ElasticSearch pour la recherche textuelle\n\n\n\nTutoriel\n\n\nAvanc√©\n\n\n\nElasticSearch est un moteur de recherche extr√™mement rapide et flexible.\nCette technologie s‚Äôest impos√©e dans le domaine du traitement des\ndonn√©es textuelles. L‚ÄôAPI‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart\n\n\n\nIntroduction\n\n\nAvanc√©\n\n\n\nApr√®s avoir abord√© les diff√©rents champs de la\ndata science, nous pouvons maintenant\nintroduire √† quelques outils et m√©thodes plus avanc√©s\nqui correspondent √† des aspects‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud\n\n\n\nTutoriel\n\n\nAvanc√©\n\n\n\n\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 2: visualiser les donn√©es\n\n\n\nIntroduction\n\n\nVisualisation\n\n\n\nCette partie pr√©sente les outils pour visualiser des\ndonn√©es avec Python, qu‚Äôil s‚Äôagisse de graphiques\nfig√©s (matplotlib, seaborn, geoplot‚Ä¶) ou de\nvisualisation‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe belles cartes avec python : mise en pratique\n\n\n\nVisualisation\n\n\nExercice\n\n\n\nLa cartographie est un excellent moyen de diffuser\nune connaissance, y compris √† des publics peu\nfamiliers de la statistique. Ce chapitre permet\nde d√©couvrir la mani√®re dont‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe beaux graphiques avec python : mise en pratique\n\n\n\nVisualisation\n\n\nExercice\n\n\n\nUne partie essentielle du travail du\ndata scientist est d‚Äô√™tre en mesure\nde synth√©tiser une information dans des\nrepr√©sentations graphiques percutantes. Ce\nchapitre permet‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-04-25\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}"
  },
  {
    "objectID": "content/getting-started/index.html",
    "href": "content/getting-started/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours rassemble l‚Äôensemble du contenu du cours\nPython  pour la data science que je donne\n√† l‚ÄôENSAE\ndepuis 2018.\nCe cours √©tait auparavant donn√© par Xavier Dupr√©.\nQuelques √©l√©ments suppl√©mentaires sont disponibles dans\nles slides d‚Äôintroduction.\nDes √©l√©ments plus avanc√©s sont pr√©sents dans un autre cours consacr√©\n√† la mise en production de projets data science\nque je donne avec Romain Avouac\n√† l‚ÄôENSAE (ensae-reproductibilite.github.io/website)\nPython est un langage qui a d√©j√† plus de trente ans\nmais qui a connu, au cours de la d√©cennie 2010, une\nnouvelle jeunesse du fait de l‚Äôengouement pour\nla data science.\nPython, plus que tout autre\nlangage informatique, r√©unit des communaut√©s aussi\ndiverses que des statisticiens, des d√©veloppeurs,\ndes gestionnaires\nd‚Äôapplications ou d‚Äôinfrastructures informatiques,\ndes lyc√©es - Python est au programme du bac fran√ßais\ndepuis quelques ann√©es - ou des chercheurs\ndans des champs √† la fois th√©oriques et appliqu√©s. Contrairement\n√† beaucoup de langages informatiques qui f√©d√®rent\nune communaut√© assez homog√®ne, Python est parvenu √† r√©unir\nlargement gr√¢ce √† quelques principes centraux : la lisibilit√©\ndu langage, la simplicit√© √† utiliser des modules,\nla simplicit√© √† l‚Äôassocier √† des langages plus performants\npour certaines t√¢ches donn√©es, l‚Äô√©norme volume de documentation\ndisponible en ligne‚Ä¶\n√ätre le deuxi√®me meilleur langage pour r√©aliser telle ou telle\nt√¢che\npeut ainsi √™tre une source de succ√®s lorsque la concurrence ne dispose\npas d‚Äôun √©ventail aussi large d‚Äôavantages.\nLe succ√®s de Python, de par sa nature de\nlangage couteau-suisse, est indissociable\nde l‚Äô√©mergence du profil du data scientist, individu\ncapable de s‚Äôint√©grer √† diff√©rents niveaux dans la valorisation\nde donn√©es.\nDavenport and Patil (2012a), dans la Harvard Business Review,\nont ainsi pu parler du ‚Äúboulot le plus sexy du 21e si√®cle‚Äù\net ont pu, dix ans plus tard, faire un panorama complet de l‚Äô√©volution\ndes comp√©tences attendues d‚Äôun data scientist dans\nla m√™me revue (Davenport and Patil 2012b).\nLa richesse de Python permet de l‚Äôutiliser dans toutes les phases\ndu traitement de la donn√©e, de sa r√©cup√©ration et structuration √† partir de\nsources diverses √† sa valorisation.\nPar le prisme de la data science, nous verrons que Python est\nun tr√®s bon candidat pour assister les data scientists dans tous\nles aspects du travail de donn√©es.\nCe cours introduit diff√©rents outils qui permettent de mettre en relation\ndes donn√©es et des th√©ories gr√¢ce √† Python. N√©anmoins, ce cours\nva au-del√† d‚Äôune simple introduction au langage et propose\ndes √©l√©ments plus approfondis, notamment sur les derni√®res\ninnovations permises par la data science dans les m√©thodes de travail.\n\n\nLe succ√®s de scikit-learn et\nde Tensorflow dans la communaut√©\nde la Data-Science ont beaucoup contribu√© √† l‚Äôadoption de Python. Cependant,\nr√©sumer Python √† ces quelques librairies serait r√©ducteur tant il s‚Äôagit\nd‚Äôun v√©ritable couteau-suisse pour les data scientists,\nles social scientists ou les √©conomistes.\nL‚Äôint√©r√™t de Python pour un data scientist ou data economist\nva au-del√† du champ du Machine Learning.\nComme pour R, l‚Äôint√©r√™t de Python est son r√¥le central dans un\n√©cosyst√®me plus large autour d‚Äôoutils puissants, flexibles et open-source.\nPython concurrence tr√®s bien R dans son domaine de pr√©dilection, √†\nsavoir l‚Äôanalyse statistique sur des bases de donn√©es structur√©es.\nComme dans R, les dataframes sont un concept central de Python.\nPython est n√©anmoins bien plus complet dans certains domaines.\nOutre le Machine Learning,\nPython est mieux adapt√© aux donn√©es volumineuses que\nR. Python est √©galement meilleur que R pour faire\ndu webscraping ou acc√©der √† des donn√©es par le biais d‚ÄôAPI.\nDans le domaine de l‚Äô√©conom√©trie, Python offre\nl‚Äôavantage de la simplicit√© avec un nombre restreint de packages (scikit et\nstatsmodels) permettant d‚Äôavoir des mod√®les tr√®s g√©n√©raux\n(les generalized estimating equations)\nalors qu‚Äôil faut\nchoisir parmi une grande vari√©t√© de packages en R pour obtenir les\nmod√®les √©quivalents. Dans le domaine du Deep Learning, Python √©crase\nla concurrence.\nAu contraire, dans certains domaines, R reste meilleur, m√™me si les\n√©volutions tr√®s r√©centes de certains outils peuvent amener √† r√©viser\nce constat. Historiquement,\nR √©tait tr√®s bien int√©gr√© au langage de publication Markdown ce qui,\npermet la construction de documents reproductibles tr√®s raffin√©s.\nL‚Äô√©mergence r√©cente de Quarto, h√©ritier de R Markdown d√©velopp√© par\nla soci√©t√© Posit permet aux utilisateur de Python de b√©n√©ficier\n√©galement de la richesse de cette approche pour leur langage de pr√©dilection.\nCe site web, √† l‚Äôarborescence relativement complexe, est ainsi\nconstruit gr√¢ce √† cet outil qui permet √† la fois de tester les blocs\nde code pr√©sent√©s mais aussi de produire de mani√®re automatis√©e les\ntableaux et graphiques pr√©sent√©s. S‚Äôil fallait trouver un point faible\n√† Python par rapport √† R dans le domaine de la data science\nc‚Äôest sur la production de graphiques. matplotlib et seaborn, qui sont\npr√©sent√©s dans la partie visualisation, sont d‚Äôexcellents outils. N√©anmoins,\nggplot2, l‚Äô√©quivalent en R est plus facile de prise en main et\npropose une syntaxe extr√™mement flexible, qu‚Äôil est difficile de ne pas\nappr√©cier. Cependant, l‚Äô√©cosyst√®me de la\nvisualisation de donn√©es est en pleine r√©volution avec le succ√®s\nd‚ÄôObservable qui\nrapproche l‚Äô√©cosyst√®me JavaScript des d√©veloppeurs web\nde la communaut√© des analystes de donn√©es.\nUn des avantages comparatifs de Python par rapport √† d‚Äôautres\nlangages (notamment R et Julia) est sa dynamique,\nce que montre l‚Äôexplosion du nombre de questions\nsur Stack Overflow.\nCependant, il ne s‚Äôagit pas b√™tement d‚Äôenterrer R.\nAu contraire, outre leur logique tr√®s proche,\nles deux langages sont dans une phase de convergence avec des initiatives comme\nreticulate,\nquarto ou\nsnakemake qui\npermettent, de mani√®re diff√©rente, de cr√©er des cha√Ænes de traitement\nm√©langeant R et Python.\nUne autre raison pour laquelle cette gu√©guerre R/Python n‚Äôa pas\nde sens est que les bonnes\npratiques peuvent √™tre transpos√©es de mani√®re presque transparente d‚Äôun\nlangage √† l‚Äôautre. Il s‚Äôagit d‚Äôun point qui est d√©velopp√© plus amplement\ndans le cours plus avanc√© que je donne avec Romain Avouac en derni√®re ann√©e\nd‚ÄôENSAE : ensae-reproductibilite.github.io/website.\nA terme, les data scientists et chercheurs en sciences sociales ou\n√©conomie utiliseront\nde mani√®re presque indiff√©rente, et en alternance, Python et R. Ce cours\npr√©sentera ainsi r√©guli√®rement des analogies avec R pour aider les\npersonnes d√©couvrant Python, mais connaissant d√©j√† bien R, √†\nmieux comprendre certains messages.\n\n\n\nLe but de ce cours est de rendre autonome sur\nl‚Äôutilisation de Python\ndans un contexte de travail de data scientist ou de\nsocial scientist (√©conomie, sociologie, g√©ographie‚Ä¶).\nAutrement dit,\nil pr√©suppose qu‚Äôon d√©sire faire un usage intense\nde donn√©es dans un cadre statistique rigoureux.\nLa data science est un ensemble de techniques\nvisant √† donner du sens √† des sources de donn√©es\ndiverses. Selon les organisations,\nles data scientists peuvent ainsi √™tre √†\nl‚Äôinterface de projets n√©cessitant un\nlarge spectre de comp√©tences\n(analyse\nde donn√©es textuelles, repr√©sentation\ngraphique interactive‚Ä¶),\navoir des interactions avec des profils\ntr√®s diff√©rents (experts m√©tiers,\nd√©veloppeurs, data architect,\ndata engineer‚Ä¶) voire adopter\nun peu tous ces r√¥les.\nLes innovations\nr√©centes de la data science ne se r√©duisent\nn√©anmoins\npas qu‚Äô√† des d√©couvertes m√©thodologiques.\nLa data science propose un ensemble de\ntechniques et de m√©thodes de travail\npour r√©duire les co√ªts de passage\nd‚Äôun protype √† une chaine\nde production p√©renne.\nCe cours introduit √† quelques notions\nsur le sujet, notamment les\npipelines scikit, pour adopter\nd√®s l‚Äôapprentissage du langage\nquelques bons r√©flexes (ensae-reproductibilite.github.io/website).\n\n\n\nCe cours ne revient que de mani√®re secondaire\nsur les fondements statistiques ou algorithmiques\nderri√®re certaines des techniques √©voqu√©es.\nNe pas conna√Ætre ces notions n‚Äôemp√™che n√©anmoins pas de comprendre\nle contenu de ce site web. En effet, la facilit√© d‚Äôusage de Python\n√©vite de devoir programmer soi-m√™me un mod√®le, ce qui rend\npossible l‚Äôapplication\nde mod√®les dont on n‚Äôest pas expert. La connaissance des mod√®les sera\nplut√¥t n√©cessaire dans l‚Äôinterpr√©tation des r√©sultats.\nCependant, la facilit√© avec laquelle il est possible de construire des mod√®les complexes\navec Python peut laisser appara√Ætre que conna√Ætre les sp√©cifit√©s de chaque\nmod√®le est inutile. Il\ns‚Äôagirait d‚Äôune grave erreur : m√™me si l‚Äôimpl√©mentation de mod√®les est ais√©e, il\nest n√©cessaire de bien comprendre la structure des donn√©es et leur ad√©quation\navec les hypoth√®ses d‚Äôun mod√®le.\n\n\n\nCe cours donne une place centrale √†\nla notion de reproductibilit√©. Cette exigence se traduit de diverses\nmani√®res dans cet enseignement, en particulier en insistant sur un\noutil indispensable pour favoriser le partage de codes informatiques,\n√† savoir Git.\nL‚Äôensemble du contenu du site web est reproductible dans des environnements\ninformatiques divers. Il est bien s√ªr possible de copier-coller les morceaux\nde code pr√©sents dans ce site. Cette m√©thode montrant rapidement ses limites,\nle site pr√©sente un certain nombre de boutons disponibles pour\nouvrir la page sous un format Jupyter Notebook sur divers\npages web :\n\nSur l‚Äôensemble du site web,\nil est possible de cliquer\nsur la petite icone \npour √™tre redirig√© vers le d√©p√¥t Github associ√© √† ce cours.\nUn certain nombre de boutons permettent de transformer chaque\npage web en Jupyter Notebooks s‚Äôil est n√©cessaire de\nvisualiser ou ex√©cuter du code Python.\n\nVoici, par exemple, ces boutons pour le tutoriel numpy :\n\n\n\n\n\n\n\n\n\n\nPour les agents de la fonction publique, ou\nles √©l√®ves des √©coles partenaires, il est recommand√©\nde privil√©gier le bouton SSPCloud qui est\nune infrastructure cloud moderne, puissante et flexible\nd√©velopp√©e par l‚ÄôInsee et accessible √† l‚Äôurl\nhttps://datalab.sspcloud.fr1.\nL‚Äôensemble du contenu de ce site s‚Äôappuie sur des donn√©es\nouvertes, qu‚Äôil s‚Äôagisse de donn√©es fran√ßaises (principalement\nissues de la plateforme\ncentralisatrice data.gouv ou du site\nweb de l‚ÄôInsee) ou de donn√©es\nam√©ricaines. Les r√©sultats sont donc reproductibles pour quelqu‚Äôun\ndisposant d‚Äôun environnement identique.\n\n\n\nCe cours pr√©sente\ndes tutoriels et des exercices complets.\nChaque page est structur√©e sous la forme\nd‚Äôun probl√®me concret et pr√©sente la\nd√©marche g√©n√©rique pour r√©soudre ce probl√®me g√©n√©ral.\nVous pouvez naviguer dans l‚Äôarchitecture du site via la table des mati√®res\nou par les liens vers le contenu ant√©rieur ou post√©rieur √† la fin de chaque\npage. Certaines parties, notamment celle consacr√©e √† la mod√©lisation,\nproposent des exemples fil-rouge pour illustrer la d√©marche de mani√®re\nplus extensive.\n\n\n\nLes √©l√®ves de l‚ÄôENSAE valident le cours gr√¢ce √†\nun projet approfondi.\nLes √©l√©ments relatifs √† l‚Äô√©valuation du cours, ainsi qu‚Äôune\nliste des projets d√©j√† effectu√©s, sont disponibles dans la\nSection Evaluation.\n\n\n\n\n\nDavenport, Thomas H, and DJ Patil. 2012a. ‚ÄúData Scientist, the Sexiest Job of the 21st Century.‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n‚Äî‚Äî‚Äî. 2012b. ‚ÄúIs Data Scientist Still the Sexiest Job of the 21st Century?‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n\n\n\n{{&lt; list_children  &gt;}}\n\n\n\n\n\n\n\n\n\n\n{{&lt; list_children  &gt;}}\n\n\n\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\ndde3e93\n\n\n2023-07-21 22:22:05\n\n\nLino Galiana\n\n\nFix bug on chapter order (#385)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#pourquoi-faire-du-python-pour-lanalyse-de-donn√©es",
    "href": "content/getting-started/index.html#pourquoi-faire-du-python-pour-lanalyse-de-donn√©es",
    "title": "Introduction",
    "section": "",
    "text": "Le succ√®s de scikit-learn et\nde Tensorflow dans la communaut√©\nde la Data-Science ont beaucoup contribu√© √† l‚Äôadoption de Python. Cependant,\nr√©sumer Python √† ces quelques librairies serait r√©ducteur tant il s‚Äôagit\nd‚Äôun v√©ritable couteau-suisse pour les data scientists,\nles social scientists ou les √©conomistes.\nL‚Äôint√©r√™t de Python pour un data scientist ou data economist\nva au-del√† du champ du Machine Learning.\nComme pour R, l‚Äôint√©r√™t de Python est son r√¥le central dans un\n√©cosyst√®me plus large autour d‚Äôoutils puissants, flexibles et open-source.\nPython concurrence tr√®s bien R dans son domaine de pr√©dilection, √†\nsavoir l‚Äôanalyse statistique sur des bases de donn√©es structur√©es.\nComme dans R, les dataframes sont un concept central de Python.\nPython est n√©anmoins bien plus complet dans certains domaines.\nOutre le Machine Learning,\nPython est mieux adapt√© aux donn√©es volumineuses que\nR. Python est √©galement meilleur que R pour faire\ndu webscraping ou acc√©der √† des donn√©es par le biais d‚ÄôAPI.\nDans le domaine de l‚Äô√©conom√©trie, Python offre\nl‚Äôavantage de la simplicit√© avec un nombre restreint de packages (scikit et\nstatsmodels) permettant d‚Äôavoir des mod√®les tr√®s g√©n√©raux\n(les generalized estimating equations)\nalors qu‚Äôil faut\nchoisir parmi une grande vari√©t√© de packages en R pour obtenir les\nmod√®les √©quivalents. Dans le domaine du Deep Learning, Python √©crase\nla concurrence.\nAu contraire, dans certains domaines, R reste meilleur, m√™me si les\n√©volutions tr√®s r√©centes de certains outils peuvent amener √† r√©viser\nce constat. Historiquement,\nR √©tait tr√®s bien int√©gr√© au langage de publication Markdown ce qui,\npermet la construction de documents reproductibles tr√®s raffin√©s.\nL‚Äô√©mergence r√©cente de Quarto, h√©ritier de R Markdown d√©velopp√© par\nla soci√©t√© Posit permet aux utilisateur de Python de b√©n√©ficier\n√©galement de la richesse de cette approche pour leur langage de pr√©dilection.\nCe site web, √† l‚Äôarborescence relativement complexe, est ainsi\nconstruit gr√¢ce √† cet outil qui permet √† la fois de tester les blocs\nde code pr√©sent√©s mais aussi de produire de mani√®re automatis√©e les\ntableaux et graphiques pr√©sent√©s. S‚Äôil fallait trouver un point faible\n√† Python par rapport √† R dans le domaine de la data science\nc‚Äôest sur la production de graphiques. matplotlib et seaborn, qui sont\npr√©sent√©s dans la partie visualisation, sont d‚Äôexcellents outils. N√©anmoins,\nggplot2, l‚Äô√©quivalent en R est plus facile de prise en main et\npropose une syntaxe extr√™mement flexible, qu‚Äôil est difficile de ne pas\nappr√©cier. Cependant, l‚Äô√©cosyst√®me de la\nvisualisation de donn√©es est en pleine r√©volution avec le succ√®s\nd‚ÄôObservable qui\nrapproche l‚Äô√©cosyst√®me JavaScript des d√©veloppeurs web\nde la communaut√© des analystes de donn√©es.\nUn des avantages comparatifs de Python par rapport √† d‚Äôautres\nlangages (notamment R et Julia) est sa dynamique,\nce que montre l‚Äôexplosion du nombre de questions\nsur Stack Overflow.\nCependant, il ne s‚Äôagit pas b√™tement d‚Äôenterrer R.\nAu contraire, outre leur logique tr√®s proche,\nles deux langages sont dans une phase de convergence avec des initiatives comme\nreticulate,\nquarto ou\nsnakemake qui\npermettent, de mani√®re diff√©rente, de cr√©er des cha√Ænes de traitement\nm√©langeant R et Python.\nUne autre raison pour laquelle cette gu√©guerre R/Python n‚Äôa pas\nde sens est que les bonnes\npratiques peuvent √™tre transpos√©es de mani√®re presque transparente d‚Äôun\nlangage √† l‚Äôautre. Il s‚Äôagit d‚Äôun point qui est d√©velopp√© plus amplement\ndans le cours plus avanc√© que je donne avec Romain Avouac en derni√®re ann√©e\nd‚ÄôENSAE : ensae-reproductibilite.github.io/website.\nA terme, les data scientists et chercheurs en sciences sociales ou\n√©conomie utiliseront\nde mani√®re presque indiff√©rente, et en alternance, Python et R. Ce cours\npr√©sentera ainsi r√©guli√®rement des analogies avec R pour aider les\npersonnes d√©couvrant Python, mais connaissant d√©j√† bien R, √†\nmieux comprendre certains messages.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#objectif-du-cours",
    "href": "content/getting-started/index.html#objectif-du-cours",
    "title": "Introduction",
    "section": "",
    "text": "Le but de ce cours est de rendre autonome sur\nl‚Äôutilisation de Python\ndans un contexte de travail de data scientist ou de\nsocial scientist (√©conomie, sociologie, g√©ographie‚Ä¶).\nAutrement dit,\nil pr√©suppose qu‚Äôon d√©sire faire un usage intense\nde donn√©es dans un cadre statistique rigoureux.\nLa data science est un ensemble de techniques\nvisant √† donner du sens √† des sources de donn√©es\ndiverses. Selon les organisations,\nles data scientists peuvent ainsi √™tre √†\nl‚Äôinterface de projets n√©cessitant un\nlarge spectre de comp√©tences\n(analyse\nde donn√©es textuelles, repr√©sentation\ngraphique interactive‚Ä¶),\navoir des interactions avec des profils\ntr√®s diff√©rents (experts m√©tiers,\nd√©veloppeurs, data architect,\ndata engineer‚Ä¶) voire adopter\nun peu tous ces r√¥les.\nLes innovations\nr√©centes de la data science ne se r√©duisent\nn√©anmoins\npas qu‚Äô√† des d√©couvertes m√©thodologiques.\nLa data science propose un ensemble de\ntechniques et de m√©thodes de travail\npour r√©duire les co√ªts de passage\nd‚Äôun protype √† une chaine\nde production p√©renne.\nCe cours introduit √† quelques notions\nsur le sujet, notamment les\npipelines scikit, pour adopter\nd√®s l‚Äôapprentissage du langage\nquelques bons r√©flexes (ensae-reproductibilite.github.io/website).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#public-cible",
    "href": "content/getting-started/index.html#public-cible",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours ne revient que de mani√®re secondaire\nsur les fondements statistiques ou algorithmiques\nderri√®re certaines des techniques √©voqu√©es.\nNe pas conna√Ætre ces notions n‚Äôemp√™che n√©anmoins pas de comprendre\nle contenu de ce site web. En effet, la facilit√© d‚Äôusage de Python\n√©vite de devoir programmer soi-m√™me un mod√®le, ce qui rend\npossible l‚Äôapplication\nde mod√®les dont on n‚Äôest pas expert. La connaissance des mod√®les sera\nplut√¥t n√©cessaire dans l‚Äôinterpr√©tation des r√©sultats.\nCependant, la facilit√© avec laquelle il est possible de construire des mod√®les complexes\navec Python peut laisser appara√Ætre que conna√Ætre les sp√©cifit√©s de chaque\nmod√®le est inutile. Il\ns‚Äôagirait d‚Äôune grave erreur : m√™me si l‚Äôimpl√©mentation de mod√®les est ais√©e, il\nest n√©cessaire de bien comprendre la structure des donn√©es et leur ad√©quation\navec les hypoth√®ses d‚Äôun mod√®le.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#reproductibilit√©",
    "href": "content/getting-started/index.html#reproductibilit√©",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours donne une place centrale √†\nla notion de reproductibilit√©. Cette exigence se traduit de diverses\nmani√®res dans cet enseignement, en particulier en insistant sur un\noutil indispensable pour favoriser le partage de codes informatiques,\n√† savoir Git.\nL‚Äôensemble du contenu du site web est reproductible dans des environnements\ninformatiques divers. Il est bien s√ªr possible de copier-coller les morceaux\nde code pr√©sents dans ce site. Cette m√©thode montrant rapidement ses limites,\nle site pr√©sente un certain nombre de boutons disponibles pour\nouvrir la page sous un format Jupyter Notebook sur divers\npages web :\n\nSur l‚Äôensemble du site web,\nil est possible de cliquer\nsur la petite icone \npour √™tre redirig√© vers le d√©p√¥t Github associ√© √† ce cours.\nUn certain nombre de boutons permettent de transformer chaque\npage web en Jupyter Notebooks s‚Äôil est n√©cessaire de\nvisualiser ou ex√©cuter du code Python.\n\nVoici, par exemple, ces boutons pour le tutoriel numpy :\n\n\n\n\n\n\n\n\n\n\nPour les agents de la fonction publique, ou\nles √©l√®ves des √©coles partenaires, il est recommand√©\nde privil√©gier le bouton SSPCloud qui est\nune infrastructure cloud moderne, puissante et flexible\nd√©velopp√©e par l‚ÄôInsee et accessible √† l‚Äôurl\nhttps://datalab.sspcloud.fr1.\nL‚Äôensemble du contenu de ce site s‚Äôappuie sur des donn√©es\nouvertes, qu‚Äôil s‚Äôagisse de donn√©es fran√ßaises (principalement\nissues de la plateforme\ncentralisatrice data.gouv ou du site\nweb de l‚ÄôInsee) ou de donn√©es\nam√©ricaines. Les r√©sultats sont donc reproductibles pour quelqu‚Äôun\ndisposant d‚Äôun environnement identique.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#architecture-du-site-web",
    "href": "content/getting-started/index.html#architecture-du-site-web",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours pr√©sente\ndes tutoriels et des exercices complets.\nChaque page est structur√©e sous la forme\nd‚Äôun probl√®me concret et pr√©sente la\nd√©marche g√©n√©rique pour r√©soudre ce probl√®me g√©n√©ral.\nVous pouvez naviguer dans l‚Äôarchitecture du site via la table des mati√®res\nou par les liens vers le contenu ant√©rieur ou post√©rieur √† la fin de chaque\npage. Certaines parties, notamment celle consacr√©e √† la mod√©lisation,\nproposent des exemples fil-rouge pour illustrer la d√©marche de mani√®re\nplus extensive.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#evaluation",
    "href": "content/getting-started/index.html#evaluation",
    "title": "Introduction",
    "section": "",
    "text": "Les √©l√®ves de l‚ÄôENSAE valident le cours gr√¢ce √†\nun projet approfondi.\nLes √©l√©ments relatifs √† l‚Äô√©valuation du cours, ainsi qu‚Äôune\nliste des projets d√©j√† effectu√©s, sont disponibles dans la\nSection Evaluation.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#r√©f√©rences",
    "href": "content/getting-started/index.html#r√©f√©rences",
    "title": "Introduction",
    "section": "",
    "text": "Davenport, Thomas H, and DJ Patil. 2012a. ‚ÄúData Scientist, the Sexiest Job of the 21st Century.‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n‚Äî‚Äî‚Äî. 2012b. ‚ÄúIs Data Scientist Still the Sexiest Job of the 21st Century?‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#contenu-g√©n√©ral",
    "href": "content/getting-started/index.html#contenu-g√©n√©ral",
    "title": "Introduction",
    "section": "",
    "text": "{{&lt; list_children  &gt;}}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#structuration-de-cette-partie",
    "href": "content/getting-started/index.html#structuration-de-cette-partie",
    "title": "Introduction",
    "section": "",
    "text": "{{&lt; list_children  &gt;}}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#informations-additionnelles",
    "href": "content/getting-started/index.html#informations-additionnelles",
    "title": "Introduction",
    "section": "",
    "text": "environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\ndde3e93\n\n\n2023-07-21 22:22:05\n\n\nLino Galiana\n\n\nFix bug on chapter order (#385)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#footnotes",
    "href": "content/getting-started/index.html#footnotes",
    "title": "Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour les utilisateurs de cette infrastructure, les notebooks\nsont √©galement list√©s, parmi de nombreuses autres\nressources de qualit√©, sur la\npage Formation‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html",
    "href": "content/getting-started/02_DS_environment.html",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "",
    "text": "La richesse des langages open-source est la possibilit√©\nd‚Äôutiliser des packages\nd√©velopp√©s par des sp√©cialistes. Python est particuli√®rement\nbien dot√© dans le domaine. Pour caricaturer, on lit parfois\nque Python est le deuxi√®me meilleur langage pour toutes les\nt√¢ches, ce qui en fait le meilleur langage.\nEn effet, la mall√©abilit√© de Python fait qu‚Äôon peut\nl‚Äôaborder de mani√®re tr√®s diff√©rentes\nselon que l‚Äôon est plut√¥t SysAdmin, d√©veloppeur web ou\ndata scientist. C‚Äôest ce dernier profil qui va ici nous\nint√©resser.\nLe data scientist devant disposer de nombreuses cordes\n√† son arc. Cela se refl√®te sur l‚Äô√©cosyst√®me de la data science\nqui est assez √©clat√©. Cependant, ce foisonnement\nn‚Äôest pas propre √† Python puisque R propose encore plus de\npackages que Python o√π un certain nombre de framework\nnormalis√©s limitent l‚Äô√©clatement de l‚Äô√©cosyst√®me. De plus,\nle foisonnement de l‚Äôenvironnement du data scientist\nest une v√©ritable opportunit√© puisqu‚Äôelle permet\naux packages de se sp√©cialiser dans un\ndomaine, o√π ils sont plus efficaces, et aux concepteurs\nde package d‚Äôoser mettre en oeuvre de nouvelles m√©thodes,\nindispensables pour que le langage suive les √©volutions\nrapides de la recherche ou de la technologie.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#numpy",
    "href": "content/getting-started/02_DS_environment.html#numpy",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "numpy",
    "text": "numpy\nnumpy g√®re tout ce qui est calcul matriciel.\nLe langage Python est un des langages les plus lents qui soient1.\nTous les calculs rapides ne sont pas √©crits en Python mais en C++, voire Fortran.\nC‚Äôest le cas du package numpy. Celui-ci est incontournable\nd√®s qu‚Äôon veut √™tre rapide. Le package\nscipy est une extension o√π l‚Äôon peut trouver\ndes fonctions statistiques, d‚Äôoptimisation.\nLa Cheat Sheet de numpy est pratique:\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\nComme numpy est la brique de base de l‚Äôanalyse de donn√©es, un chapitre\nde ce cours lui est consacr√©.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#pandas",
    "href": "content/getting-started/02_DS_environment.html#pandas",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "pandas",
    "text": "pandas\nAvant tout, un bon data scientist doit √™tre capable de\ns‚Äôapproprier et manipuler des donn√©es rapidement. Pour cette raison,\npandas est incontournable.\nIl g√®re la plupart des formats de donn√©es. Pour √™tre efficace,\nil est lui aussi impl√©ment√© en C++.\nLe package est rapide si on utilise les m√©thodes pr√©-impl√©ment√©es sur\ndes donn√©es d‚Äôune taille raisonnable (par rapport √† la RAM disponible). Il faut\nn√©anmoins s‚Äôen m√©fier avec des donn√©es volumineuses.\nEn r√®gle g√©n√©rale, un jeu de donn√©es n√©cessite\ntrois fois plus d‚Äôespace en m√©moire que les\ndonn√©es n‚Äôen prennent sur le disque.\nLa Cheat Sheet de pandas :\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Pandas_Cheat_Sheet_2.pdf\npandas √©tant un √©l√©ment incontournable, deux chapitres y sont consacr√©s.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#matplotlib-et-seaborn",
    "href": "content/getting-started/02_DS_environment.html#matplotlib-et-seaborn",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "matplotlib et seaborn",
    "text": "matplotlib et seaborn\nmatplotlib existe depuis une vingtaine d‚Äôann√©es pour doter Python de\nfonctionalit√©s graphiques. Il s‚Äôagit d‚Äôun package tr√®s flexible, offrant\nde nombreuses fonctionalit√©s. N√©anmoins, ces derni√®res ann√©es,\nseaborn a √©merg√© pour simplifier la cr√©ation de certains graphiques\nstandards de l‚Äôanalyse de donn√©es (histogrammes, diagramme en barre, etc. ).\nLe succ√®s de seaborn n‚Äô√©clipse n√©anmoins pas matplotlib puisque ce\ndernier est souvent n√©cessaire pour finaliser la customisation d‚Äôun\ngraphique produit par seaborn2",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#scikit-learn",
    "href": "content/getting-started/02_DS_environment.html#scikit-learn",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "scikit-learn",
    "text": "scikit-learn\nscikit-learn est le module de machine learning le plus populaire pour\ntrois raisons:\n\nil s‚Äôappuie sur une API extr√™mement consistante (m√©thodes fit, transform\net predict, respectivement pour apprendre des donn√©es, appliquer des transformations et pr√©dire sur de nouvelles donn√©es) ;\nil permet de construire\ndes analyses reproductibles en construisant des pipelines de donn√©es ;\nsa documentation est un mod√®le √† suivre.\n\nL‚ÄôINRIA, institution fran√ßaise, est l‚Äôun des √©l√©ments moteurs dans\nla cr√©ation et la maintenance de scikit-learn",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#tensorflow-pytorch-et-keras",
    "href": "content/getting-started/02_DS_environment.html#tensorflow-pytorch-et-keras",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "TensorFlow, PyTorch et Keras",
    "text": "TensorFlow, PyTorch et Keras\nLes librairies essentielles pour impl√©menter et utiliser des mod√®les\nde deep learning en Python ont √©t√© d√©velopp√©es par des acteurs du\nnum√©rique.\nTensorFlow est la librairie la plus mature, mais pas n√©cessairement la plus facile √† prendre en main. D‚Äôailleurs, Google semble l‚Äôabandonner en usage interne pour lui\npr√©f√©rer JAX.\nKeras propose une interface high-level,\ndonc plus facile d‚Äôutilisation,\nmais qui n‚Äôen reste pas moins suffisante pour une grande vari√©t√© d‚Äôusages.\nLa documentation de Keras est tr√®s bien faite.\nPyTorch est un framework plus r√©cent mais tr√®s complet,\ndont la syntaxe plaira aux amateurs de programmation orient√©-objet.\nD√©velopp√© par Facebook,\nil est tr√®s utilis√© dans certains domaines de recherche, comme le NLP.\nIl s‚Äôagit du framework dont la dynamique r√©cente a √©t√© la plus\nascensionnelle.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#statsmodels",
    "href": "content/getting-started/02_DS_environment.html#statsmodels",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "statsmodels",
    "text": "statsmodels\nstatsmodels plaira plus aux statisticiens, il impl√©mente des mod√®les\n√©conom√©triques similaires √† scikit-learn.\nPar rapport √† scikit-learn,\nstatsmodels est plus orient√© √©conom√©trie. La pr√©sentation des\nr√©sultats est tr√®s proche de ce qu‚Äôon trouve en R.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#requests-et-beautifulsoup",
    "href": "content/getting-started/02_DS_environment.html#requests-et-beautifulsoup",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "requests et beautifulsoup",
    "text": "requests et beautifulsoup\nrequests est l‚Äôune des librairies de base de Python, d√©di√©e\n√† g√©rer la connexion avec internet. Les amateurs d‚ÄôAPI\nseront des utilisateurs fr√©quents de celle-ci. Les\npersonnes plus sp√©cialistes de web scraping l‚Äôutiliseront avec\nbeautifulsoup qui offre une syntaxe extr√™mement puissante\npour r√©cup√©rer automatiquement du contenu de pages web.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#nltk-et-spacy",
    "href": "content/getting-started/02_DS_environment.html#nltk-et-spacy",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "nltk et spaCy",
    "text": "nltk et spaCy\nDans le domaine du traitement automis√© du langage, plus connu\nsous son acronyme anglais NLP, les deux packages phares sont\nnltk et spaCy.\nnltk est le package historique. Il existe depuis les ann√©es\n1990 et propose de nombreuses ressources utiles pour l‚Äôanalyse\ntextuelle. N√©anmoins, ces derni√®res ann√©es, spaCy est venu\nmoderniser l‚Äôapproche en proposant une approche permettant\nde mieux int√©grer les diff√©rentes phases du traitement de donn√©es\ntextuelles, une excellente documentation et un meilleur support\ndes langues non anglo-saxonnes, comme le Fran√ßais.\nMais Python est √©galement un outil privil√©gi√© pour communiquer:\n\nUne bonne int√©gration de Python √† Markdown (gr√¢ce notamment √† ‚Ä¶ R Markdown) qui facilite la construction de documents HTML ou PDF (via Latex)\nSphynx et JupyterBook proposent des mod√®les de documentation\ntr√®s complets\nbokeh ou streamlit comme alternative √† shiny (R)\nDjango et Flask permettent de construire des applications web en Python\nLes librairies dynamiques, notamment\nfolium ou\nplotly, sont tr√®s appr√©ci√©es pour construire des\nvisualisations dynamiques qui sont pratiques dans une analyse exploratoire\nmais √©galement lorsqu‚Äôil faut valoriser ses travaux aupr√®s de\npublics non experts de la donn√©e.\n\nL‚Äôun des nouveaux arrivants dans cet √©cosyst√®me d√©j√† riche\nest FastAPI). Avec ce package,\nil est tr√®s facile de transformer un code Python en API ce qui facilite\nla mise √† disposition de donn√©es mais aussi de productions par Python (comme\nla mise √† disposition d‚Äôune API pour permettre √† des personnes de tester\nles r√©sultats d‚Äôun mod√®le de machine learning).\nCe n‚Äôest qu‚Äôune petite partie de l‚Äô√©cosyst√®me Python, d‚Äôune richesse rare.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#informations-additionnelles",
    "href": "content/getting-started/02_DS_environment.html#informations-additionnelles",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n5123634\n\n\n2022-06-30 11:24:49\n\n\nLino Galiana\n\n\nAm√©lioration de la premi√®re partie (#244)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n90641c2\n\n\n2020-09-15 21:16:38\n\n\nLino Galiana\n\n\najout √©l√©ments ecosysteme\n\n\n\n\nf9f00cc\n\n\n2020-09-15 21:05:54\n\n\nLino Galiana\n\n\nenl√®ve quelques TO DO\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#footnotes",
    "href": "content/getting-started/02_DS_environment.html#footnotes",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPython est un langage interpr√©t√©, comme R. Cela le rend tr√®s\nintelligible, y compris par un non-expert. C‚Äôest une des raisons de son\nsucc√®s. Le cr√©ateur de Python, Guido Van Rossum,\nen a fait un des principes philosophiques\n√† l‚Äôorigine de Python: un code est plus souvent lu qu‚Äô√©crit.\nLa contrepartie est qu‚Äôil s‚Äôagit d‚Äôune surcouche √† des langages\nplus bas-niveau, notamment C. Ces derniers proposent beaucoup moins de\nsurcouches. En r√©alit√©, les fonctions Python font appel, plus ou moins\ndirectement, √† du C. Une mani√®re d‚Äôoptimiser le code est ainsi d‚Äôarriver,\navec le moins de surcouches possible, √† la fonction C sous-jacente,\nbeaucoup plus rapide.‚Ü©Ô∏é\nLa situation est diff√©rente en R o√π ggplot2 a quasiment √©clips√©\nl‚Äôoutil de graphique de base de R.‚Ü©Ô∏é",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html",
    "href": "content/getting-started/04_python_practice.html",
    "title": "Bonne pratique de Python",
    "section": "",
    "text": "Une r√©f√©rence utile √† lire est le\nHitchhiker‚Äôs Guide to Python",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#import-des-modules",
    "href": "content/getting-started/04_python_practice.html#import-des-modules",
    "title": "Bonne pratique de Python",
    "section": "2.1 Import des modules",
    "text": "2.1 Import des modules\nLes √©l√©ments suivants concernent plut√¥t les scripts finaux, qui appellent de multiples fonctions, que des\nscripts qui d√©finissent des fonctions.\nUn module est un ensemble de fonctions stock√©es dans un fichier .py. Lorsqu‚Äôon √©crit dans un script\nimport modu\nPython commence par chercher le fichier modu.py dans le dossier de travail. Il n‚Äôest donc pas une bonne\nid√©e d‚Äôappeler un fichier du nom d‚Äôun module standard de python, par exemple math.py ou os.py. Si le fichier\nmodu.py n‚Äôest pas trouv√© dans le dossier de travail, Python va chercher dans le chemin et s‚Äôil ne le trouve pas\nretournera une erreur.\nUne fois que modu.py est trouv√©, il sera ex√©cut√© dans un environnement isol√© (reli√© de mani√®re coh√©rente\naux d√©pendances renseign√©es) et le r√©sultat rendu disponible √† l‚Äôinterpr√©teur Python pour un usage\ndans la session via le namespace (espace o√π Python associe les noms donn√©s aux objets).\nEn premier lieu, ne jamais utiliser la syntaxe suivante :\n# A NE PAS UTILISER\nfrom modu import *\n\nx = sqrt(4)  # Is sqrt part of modu? A builtin? Defined above?\nL‚Äôutilisation de la syntaxe import * cr√©√© une ambiguit√© sur les fonctions disponibles dans l‚Äôenvironnement. Le code\nest ainsi moins clair, moins compartiment√© et ainsi moins robuste. La syntaxe √† privil√©gier est la suivante :\nimport modu\n\nx = modu.sqrt(4)  # Is sqrt part of modu? A builtin? Defined above?",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#aux-arguments-optionnels",
    "href": "content/getting-started/04_python_practice.html#aux-arguments-optionnels",
    "title": "Bonne pratique de Python",
    "section": "4.1 ‚ö†Ô∏è aux arguments optionnels",
    "text": "4.1 ‚ö†Ô∏è aux arguments optionnels\nLa fonction la plus lisible (mais la plus contraignante) est celle\nqui utilise exclusivement des arguments positionnels avec des noms explicites.\nDans le cadre d‚Äôune utilisation avanc√©e des fonctions (par exemple un gros mod√®le de microsimulation), il est\ndifficile d‚Äôanticiper tous les objets qui seront n√©cessaires √† l‚Äôutilisateur. Dans ce cas, on retrouve g√©n√©ralement\ndans la d√©finition d‚Äôune fonction le mot-cl√© **kwargs (√©quivalent du ... en R) qui capture les\narguments suppl√©mentaires et les stocke sous forme de dictionnaire. Il s‚Äôagit d‚Äôune technique avanc√©e de\nprogrammation qui est √† utiliser avec parcimonie.",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#informations-additionnelles",
    "href": "content/getting-started/04_python_practice.html#informations-additionnelles",
    "title": "Bonne pratique de Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\nf9f00cc\n\n\n2020-09-15 21:05:54\n\n\nLino Galiana\n\n\nenl√®ve quelques TO DO\n\n\n\n\nc3c7433\n\n\n2020-09-15 12:41:26\n\n\nLino Galiana\n\n\nImprove CI with gitlab and jupyter nb conversion (#35)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n725d4e1\n\n\n2020-07-24 13:00:45\n\n\nLino Galiana\n\n\nMerge branch ‚Äòmaster‚Äô into pandas_intro\n\n\n\n\n66176dc\n\n\n2020-07-23 17:00:57\n\n\nLino Galiana\n\n\nfix typo in footnotes\n\n\n\n\n0b4d3d1\n\n\n2020-07-23 11:53:00\n\n\nLino Galiana\n\n\nEcnore un mot\n\n\n\n\naa9d09f\n\n\n2020-07-23 11:48:18\n\n\nLino Galiana\n\n\nR√©f√©rence au hitch guide\n\n\n\n\na2facfb\n\n\n2020-07-23 11:46:04\n\n\nLino Galiana\n\n\nUn peu de d√©tails\n\n\n\n\nd2c7518\n\n\n2020-07-23 11:45:48\n\n\nLino Galiana\n\n\nAjout sur les tests et gitignore\n\n\n\n\n304985b\n\n\n2020-07-23 10:47:30\n\n\nLino Galiana\n\n\nMot sur sphinx\n\n\n\n\ne8395c3\n\n\n2020-07-23 10:12:09\n\n\nLino Galiana\n\n\nOn verra pour les fonctions imbriqu√©es\n\n\n\n\ndcff627\n\n\n2020-07-23 10:08:46\n\n\nLino Galiana\n\n\nchange title level\n\n\n\n\n98b6102\n\n\n2020-07-23 10:02:17\n\n\nLino Galiana\n\n\nElements suppl√©mentaires sur la lisibilit√©\n\n\n\n\nc376c32\n\n\n2020-07-23 09:45:51\n\n\nLino Galiana\n\n\nPlus sur la structure\n\n\n\n\ndf95626\n\n\n2020-07-22 18:36:06\n\n\nLino Galiana\n\n\nMet le lien quelque part\n\n\n\n\n179b4bc\n\n\n2020-07-22 18:33:04\n\n\nLino Galiana\n\n\nTopo sur la lisibilit√© du code\n\n\n\n\n0556057\n\n\n2020-07-22 18:02:29\n\n\nLino Galiana\n\n\ntests apr√®s\n\n\n\n\n6ddd071\n\n\n2020-07-22 17:52:30\n\n\nLino Galiana\n\n\nPartager\n\n\n\n\n97419d0\n\n\n2020-07-22 17:42:09\n\n\nLino Galiana\n\n\nquelques mots sur les d√©pendances\n\n\n\n\n2849bac\n\n\n2020-07-22 17:23:35\n\n\nLino Galiana\n\n\nquelques mots sur les d√©pendances\n\n\n\n\n77f71f6\n\n\n2020-07-22 16:20:12\n\n\nLino Galiana\n\n\nptit mot sur les tests\n\n\n\n\nf17fc8d\n\n\n2020-07-22 14:36:48\n\n\nLino Galiana\n\n\nGriffoner des choses\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#footnotes",
    "href": "content/getting-started/04_python_practice.html#footnotes",
    "title": "Bonne pratique de Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n1‚Ü©Ô∏é\n1:‚Ü©Ô∏é\n2‚Ü©Ô∏é\n2:‚Ü©Ô∏é",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html",
    "href": "content/getting-started/06_rappels_fonctions.html",
    "title": "Modules, tests, boucles, fonctions",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#import-module",
    "href": "content/getting-started/06_rappels_fonctions.html#import-module",
    "title": "Modules, tests, boucles, fonctions",
    "section": "1.1 Import module",
    "text": "1.1 Import module\nOn charge un module gr√¢ce √† la commande import.\nPour chaque code que vous ex√©cutez,\nil faut charger les modules en introduction.\nUne fois qu‚Äôon a charg√© le module,\non peut faire appel aux commandes qui en d√©pendent en les appelant\napr√®s avoir tap√© le nom du module.\nSi vous ne pr√©cisez pas le nom du module avant celui de la fonction,\nil ne la trouvera pas forc√©ment.\nVoici un exemple avec le module numpy\nqui est tr√®s courant et permet de faire des\ncalculs matriciels sous Python.\n\nimport numpy\n\nprint(numpy.arange(5))\n\n[0 1 2 3 4]",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#import-module-as-md---donner-un-nom-au-module",
    "href": "content/getting-started/06_rappels_fonctions.html#import-module-as-md---donner-un-nom-au-module",
    "title": "Modules, tests, boucles, fonctions",
    "section": "1.2 Import module as md - donner un nom au module",
    "text": "1.2 Import module as md - donner un nom au module\nOn peut aussi donner un pseudonyme au module pour\n√©viter de taper un nom trop long √† chaque fois\nqu‚Äôon utilise une fonction.\nClassiquement le nom raccourci de numpy est np,\ncelui de pandas est pd.\n\nimport pandas as pd\nimport numpy as np\n\nsmall_array = np.array([[1, 2], [3, 4]])\ndata = pd.DataFrame(small_array)\ndata.head()\n\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n1\n2\n\n\n1\n3\n4",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#from-module-import-fonction---seulement-une-partie-du-module",
    "href": "content/getting-started/06_rappels_fonctions.html#from-module-import-fonction---seulement-une-partie-du-module",
    "title": "Modules, tests, boucles, fonctions",
    "section": "1.3 from Module Import fonction - seulement une partie du module",
    "text": "1.3 from Module Import fonction - seulement une partie du module\nSi on ne veut pas √™tre oblig√© de donner\nle nom du module avant d‚Äôappeler\nla fonction,\nil y a toujours la possibilit√© de n‚Äôimporter qu‚Äôune fonction du module.\nDans le cas de l‚Äôexemple, Python sait que la fonction arrange est celle de numpy.\nMais attention : si deux fonctions de modules diff√©rents\nont le m√™me nom,\nc‚Äôest toujours la derni√®re import√©e qui gagne.\nOn voit souvent from _module_ import *.\nC‚Äôest-√†-dire qu‚Äôon importe toutes\nles fonctions du module\nmais on n‚Äôa pas besoin de sp√©cifier le nom du module avant les m√©thodes.\n\n\n Warning\nLa m√©thode from _module_ import * n‚Äôest pas recommand√©e car elle rend le code moins intelligible.\nEn effet, d‚Äôo√π vient la fonction floor ? De maths ou de numpy ?\nElle risque\naussi de cr√©er des conflits de fonction, qui malgr√© un nom commun peuvent ne\npas attendre les m√™mes arguments ou objets.\n\n\n\nfrom numpy import array\n\nprint(array(5))\n\n5",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#test-avec-contrepartie-if-et-else",
    "href": "content/getting-started/06_rappels_fonctions.html#test-avec-contrepartie-if-et-else",
    "title": "Modules, tests, boucles, fonctions",
    "section": "2.1 Test avec contrepartie : if et else",
    "text": "2.1 Test avec contrepartie : if et else\nComme dans les autres langages,\non teste une condition. Si elle est v√©rifi√©e,\nalors une instruction suit et sinon, une autre instruction est ex√©cut√©e.\nIl est conseill√© de toujours indiquer une contrepartie afin d‚Äô√©viter les surprises.\n\n2.1.1 Test d‚Äôune √©galit√© ou in√©galit√©\n\nx = 6\n\nif x &gt; 5:\n    print(\"x est plus grand que 5\")\nelse:  # la contrepartie si la condition if n'est pas r√©alis√©e\n    print(\"x est plus petit que 5\")\n\nx est plus grand que 5\n\n\n\n\n2.1.2 Test dans un intervalle\n\n# on peut avoir des intervalles directement\nx = 6\nif 5 &lt; x &lt; 10:\n    print(\"x est entre 5 et 10\")\nelse:\n    print(\"x est plus grand que 10\")\n\nx est entre 5 et 10\n\n\n\n# tester plusieurs valeurs avec l'op√©rateur logique \"or\"\nx = 5\nif x == 5 or x == 10:\n    print(\"x vaut 5 ou 10\")\nelse:\n    print(\"x est diff√©rent de 5 et 10\")\n\nx vaut 5 ou 10",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#tests-successifs-if-elif-et-else",
    "href": "content/getting-started/06_rappels_fonctions.html#tests-successifs-if-elif-et-else",
    "title": "Modules, tests, boucles, fonctions",
    "section": "2.2 Tests successifs : if, elif et else",
    "text": "2.2 Tests successifs : if, elif et else\nAvec if et elif,\nd√®s qu‚Äôon rencontre une condition qui est r√©alis√©e,\non n‚Äôen cherche pas d‚Äôautres potentiellement v√©rifi√©es.\nPlusieurs if √† la suite peuvent quant √† eux √™tre v√©rifi√©s.\nSuivant ce que vous souhaitez faire, les op√©rateurs ne sont pas substituables.\nNotez la diff√©rence entre ces deux bouts de code :\n\n# code 1\nx = 5\n\nif x != 10:\n    print(\"x ne vaut pas 10\")\nelif x &gt;= 5:\n    print(\"x est √©gal ou sup√©rieur √† 5\")\n\nx ne vaut pas 10\n\n\nDans le cas de elif, on s‚Äôarr√™te √† la premi√®re condition v√©rifi√©e et dans le cas suivant, on continue √† chaque condition v√©rifi√©e\n\n# code 2\nx = 5\n\nif x != 10:\n    print(\"x ne vaut pas 10\")\nif x &gt;= 5:\n    print(\"x est √©gal ou sup√©rieur √† 5\")\n\nx ne vaut pas 10\nx est √©gal ou sup√©rieur √† 5",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#boucle-for",
    "href": "content/getting-started/06_rappels_fonctions.html#boucle-for",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.1 Boucle for",
    "text": "3.1 Boucle for\n\n3.1.1 Parcourir une liste croissantes d‚Äôentiers\n\n# parcourt les entiers de 0 √† n-1 inclus\nfor i in range(0, 3):\n    print(i)\n\n0\n1\n2\n\n\n\n\n3.1.2 Parcourir une liste d√©croissante d‚Äôentiers\n\n# parcourt les entiers de 3 √† n+1 inclus\nfor i in range(3, 0, -1):\n    print(i)\n\n3\n2\n1\n\n\n\n\n3.1.3 Parcourir une liste de chaines de caract√®res\nOn va faire une boucle sur les √©l√©ments d‚Äôune liste\n\n\n3.1.4 Boucle sur les √©l√©ments d‚Äôune liste\n\nliste_elements = [\"Nicolas\", \"Romain\", \"Florimond\"]\n\n# pour avoir l'ensemble des √©l√©ments de la liste\nfor item in liste_elements:\n    print(item)\n\nNicolas\nRomain\nFlorimond\n\n\n\n\n3.1.5 Boucle sur les √©l√©ments d‚Äôune liste dans une autre liste\n\n# pour avoir la place des √©l√©ments de la premi√®re liste dans la seconde liste\n\nliste_globale = [\"Violette\", \"Nicolas\", \"Mathilde\", \"Romain\", \"Florimond\", \"Helene\"]\n\nfor item in liste_elements:\n    print(item, liste_globale.index(item))\n\nNicolas 1\nRomain 3\nFlorimond 4",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#bonus-les-list-comprehension",
    "href": "content/getting-started/06_rappels_fonctions.html#bonus-les-list-comprehension",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.2 Bonus : les list comprehension",
    "text": "3.2 Bonus : les list comprehension\nAvec les listes, il existe aussi un moyen tr√®s √©l√©gant de condenser son code pour √©viter de faire apparaitre des boucles sans arr√™t. Comme les boucles doivent etre indent√©es, le code peut rapidement devenir illisible.\nGrace aux list comprehension, vous pouvez en une ligne faire ce qu‚Äôune boucle vous permettait de faire en 3 lignes.\nPar exemple, imaginez que vous vouliez faire la liste de toutes les lettres contenues dans un mot, avec un boucle vous devrez d‚Äôabord cr√©er une liste vide, puis ajouter √† cette liste toutes les lettres en question avec un .append()\n\nliste_lettres = []\n\nfor lettre in \"ENSAE\":\n    liste_lettres.append(lettre)\n\nprint(liste_lettres)\n\n['E', 'N', 'S', 'A', 'E']\n\n\navec une list comprehension, on condense la syntaxe de la mani√®re suivante :\n\nh_letters = [letter for letter in \"ENSAE\"]\nprint(h_letters)\n\n['E', 'N', 'S', 'A', 'E']\n\n\nAvec une list comprehension\n[expression for item in list if conditional]\nest √©quivalent √†\nfor item in list:\n    if conditional:\n        expression\n\n3.2.1 Mise en application\nMettez sous forme de list comprehension le bout de code suivant\n\nsquares = []\n\nfor x in range(10):\n    squares.append(x**2)\nprint(squares)\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#boucle-while",
    "href": "content/getting-started/06_rappels_fonctions.html#boucle-while",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.3 Boucle while",
    "text": "3.3 Boucle while\nLe bloc d‚Äôinstruction d‚Äôune boucle while est ex√©cut√© tant que la condition est v√©rifi√©e.\nLe pi√®ge de ces boucles : la boucle while infinie ! Il faut toujours v√©rifier que votre boucle s‚Äôarr√™tera un jour, il faut qu‚Äô√† un moment ou √† un autre, il y ait un √©l√©ment qui s‚Äôincr√©mente ou qui soit modifi√©.\n\nx = 10\ny = 8\n# tant que y est plus petit que 10, je continue de lui ajouter 1\nwhile y &lt;= x:\n    print(\"y n'est pas encore plus grand que x\")\n    y += 1  # l'incr√©ment\nelse:\n    print(\"y est plus grand que x et vaut\", y)\n\ny n'est pas encore plus grand que x\ny n'est pas encore plus grand que x\ny n'est pas encore plus grand que x\ny est plus grand que x et vaut 11",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#break-et-continue",
    "href": "content/getting-started/06_rappels_fonctions.html#break-et-continue",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.4 Break et continue",
    "text": "3.4 Break et continue\nDans les boucles for ou while on peut avoir besoin d‚Äôignorer ou de ne pas effectuer certaines it√©rations. 2 instructions utiles :\n\nl‚Äôinstruction break : permet de sortir de la boucle\nl‚Äôinstruction continue : permet de passer √† l‚Äôit√©ration suivante sans ex√©cuter les instructions qui suivent\n\n\n# utilisation de break\nfor x in range(5):\n    if x == 2:\n        break\n    else:\n        print(x)\n\n0\n1\n\n\n\n# utilisation de continue\nfor x in range(5):\n    if x == 2:\n        continue\n    else:\n        print(x)\n\n0\n1\n3\n4",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#a-retenir",
    "href": "content/getting-started/06_rappels_fonctions.html#a-retenir",
    "title": "Modules, tests, boucles, fonctions",
    "section": "6.1 A retenir",
    "text": "6.1 A retenir\n\nToujours mettre ‚Äú:‚Äù avant un bloc d‚Äôinstructions\nIndenter avant un bloc d‚Äôinstructions (avec 4 espaces et non une tabulation !)\nIndiquer les modules n√©cessaires √† l‚Äôex√©cution en d√©but de code\nDocumenter les fonctions cr√©√©es\nPr√©ciser le type d‚Äôerreur pour les exceptions et potentiellement diff√©rencier les blocs d‚Äôinstructions en fonction de l‚Äôerreur",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#questions",
    "href": "content/getting-started/06_rappels_fonctions.html#questions",
    "title": "Modules, tests, boucles, fonctions",
    "section": "6.2 Questions",
    "text": "6.2 Questions\n\nQue fait ce programme ?\n\n\ndef inverse(x):\n    try:\n        y = 1 / x\n    except ZeroDivisionError:\n        y = None\n        return y\n\n\nEcrivez un programme qui peut trouver tous les nombres divisibles par 7 et non multiples de 5 entre 6523 et 8463 (inclus)\nEcrivez un programme qui prend une phrase en entr√©e et qui calcule le nombre de voyelles en Majuscules et de consonnes en minuscules :\n\nphrase = ‚ÄúVous savez, moi je ne crois pas qu‚Äôil y ait de bonne ou de mauvaise situation. Moi, si je devais r√©sumer ma vie aujourd‚Äôhui avec vous, je dirais que c‚Äôest d‚Äôabord des rencontres. Des gens qui m‚Äôont tendu la main, peut-√™tre √† un moment o√π je ne pouvais pas, o√π j‚Äô√©tais seul chez moi. Et c‚Äôest assez curieux de se dire que les hasards, les rencontres forgent une destin√©e‚Ä¶ Parce que quand on a le go√ªt de la chose, quand on a le go√ªt de la chose bien faite, le beau geste, parfois on ne trouve pas l‚Äôinterlocuteur en face je dirais, le miroir qui vous aide √† avancer. Alors √ßa n‚Äôest pas mon cas, comme je disais l√†, puisque moi au contraire, j‚Äôai pu : et je dis merci √† la vie, je lui dis merci, je chante la vie, je danse la vie‚Ä¶ je ne suis qu‚Äôamour ! Et finalement, quand beaucoup de gens aujourd‚Äôhui me disent ‚ÄòMais comment fais-tu pour avoir cette humanit√© ?‚Äô, et bien je leur r√©ponds tr√®s simplement, je leur dis que c‚Äôest ce go√ªt de l‚Äôamour ce go√ªt donc qui m‚Äôa pouss√© aujourd‚Äôhui √† entreprendre une construction m√©canique, mais demain qui sait ? Peut-√™tre simplement √† me mettre au service de la communaut√©, √† faire le don, le don de soi‚Ä¶‚Äù",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#informations-additionnelles",
    "href": "content/getting-started/06_rappels_fonctions.html#informations-additionnelles",
    "title": "Modules, tests, boucles, fonctions",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\nf95b174\n\n\n2021-11-03 12:08:34\n\n\nLino Galiana\n\n\nEnrichi la section sur la gestion des d√©pendances (#175)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\na1b8aaf\n\n\n2021-09-20 09:05:55\n\n\nLino Galiana\n\n\nBadges de telechargement dans les premiers TP (#146)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n18be8f4\n\n\n2020-10-01 17:08:53\n\n\nLino Galiana\n\n\nInt√©gration de box inspir√©es du th√®me pydata sphinx (#58)\n\n\n\n\nc3c7433\n\n\n2020-09-15 12:41:26\n\n\nLino Galiana\n\n\nImprove CI with gitlab and jupyter nb conversion (#35)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/manipulation/index.html",
    "href": "content/manipulation/index.html",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "",
    "text": "Si on associe souvent les data scientists √† la mise en oeuvre\nde mod√®les d‚Äôintelligence artificielle, il est important\nde ne pas oublier que l‚Äôentra√Ænement et l‚Äôutilisation\nde ces mod√®les ne repr√©sente pas\nforc√©ment le quotidien des data scientists.\nEn pratique,\nla r√©cup√©ration de sources de donn√©es h√©t√©rog√®nes, la structuration\net harmonisation de celles-ci en vue d‚Äôune analyse exploratoire\npr√©alable √† la mod√©lisation ou la visualisation\nrepr√©sente une part importante du travail des data scientists.\nDans de nombreux environnements c‚Äôest m√™me l‚Äôessence du travail\ndu data scientist.\nL‚Äô√©laboration de mod√®les pertinents requiert en effet une r√©flexion approfondie sur les donn√©es ;\nune √©tape que l‚Äôon ne saurait n√©gliger.\nCe cours,\ncomme de nombreuses ressources introductives sur\nla data science (Wickham, √áetinkaya-Rundel, and Grolemund 2023; VanderPlas 2016; McKinney 2012),\nproposera donc beaucoup d‚Äô√©l√©ments sur la manipulation de donn√©es, comp√©tence\nessentielle pour les data scientists.\nLes logiciels de programmation\norient√©s autour du concept de base de donn√©es\nsont devenus les outils principaux des data scientists.\nLe fait de pouvoir appliquer un certain nombre d‚Äôop√©rations\nstandards sur des bases de donn√©es, quelle que soit leur nature,\npermet aux programmeurs d‚Äô√™tre plus efficaces que s‚Äôils devaient\nr√©p√©ter ces op√©rations √† la main, comme dans Excel.\nTous les langages de programmation dominants dans l‚Äô√©cosyst√®me\nde la data science reposent sur le principe du dataframe.\nIl s‚Äôagit m√™me d‚Äôun objet central dans certains logiciels,\nnotamment R.\nLa logique SQL,\nun langage de d√©claration d‚Äôop√©rations sur des donn√©es qui a d√©j√† plus de cinquante ans,\noffre un cadre pertinent pour effectuer des op√©rations standardis√©es\nsur les colonnes (cr√©ation de nouvelles colonnes, s√©lection de sous-ensemble de lignes‚Ä¶).\nN√©anmoins, le dataframe ne s‚Äôest impos√© que r√©cemment en Python,\ngr√¢ce au package Pandas cr√©√©\npar Wes McKinney.\nL‚Äôessor de la librairie Pandas (t√©l√©charg√©e plus de 5 millions de fois\npar jour en 2023) est pour beaucoup dans le succ√®s de Python\ndans l‚Äô√©cosyst√®me de la data science et a amen√©, en quelques ann√©es,\na un renouvellement complet de la mani√®re de coder en Python, ce\nlangage si mall√©able, autour de l‚Äôanalyse de donn√©es.\nCette partie du cours est une introduction\ng√©n√©rale √† l‚Äô√©cosyst√®me tr√®s riche de\nla manipulation de donn√©es avec Python.\nCes chapitres √©voquent aussi bien la r√©cup√©ration de donn√©es\nque la restructuration et la production d‚Äôanalyse\n√† partir de celles-ci.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#r√©sum√©-de-cette-partie",
    "href": "content/manipulation/index.html#r√©sum√©-de-cette-partie",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "R√©sum√© de cette partie",
    "text": "R√©sum√© de cette partie\nPandas est devenu incontournable dans l‚Äô√©cosyst√®me Python pour la data science.\nPandas est lui-m√™me construit √† partir du package Numpy, qu‚Äôil est utile de comprendre\npour √™tre √† l‚Äôaise avec Pandas. Numpy est une librairie bas-niveau\npour stocker et manipuler des donn√©es.\nNumpy est au coeur de l‚Äô√©cosyst√®me de la data science car la plupart des librairies, m√™me celles\nqui manient des objets destructur√©s,\nutilisent des objets construits √† partir de Numpy1.\nL‚Äôapproche Pandas, qui offre un point d‚Äôentr√©e harmonis√© pour manipuler\ndes jeux de donn√©es de nature tr√®s diff√©rente,\na √©t√© √©tendue aux objets g√©ographiques avec Geopandas.\nIl est ainsi possible de manipuler des donn√©es g√©ographiques comme s‚Äôil\ns‚Äôagissait de donn√©es structur√©es classiques. Les donn√©es g√©ographiques et\nla repr√©sentation cartographique deviennent de plus en plus commun avec\nla multiplication de donn√©es ouvertes localis√©es et de big-data g√©olocalis√©es.\nCependant, les donn√©es structur√©es, import√©es depuis des fichiers plats\nne repr√©sentent pas l‚Äôunique source de donn√©es. Les API et le webscraping\npermettent de t√©l√©charger ou d‚Äôextraire\ndes donn√©es de mani√®re tr√®s flexible depuis des pages web ou des guichets\nsp√©cialis√©s. Ces donn√©es, notamment\ncelles obtenues par webscraping n√©cessitent souvent un peu plus de travail\nde nettoyage de donn√©es, notamment des cha√Ænes de caract√®re.\nL‚Äô√©cosyst√®me Pandas repr√©sente donc un couteau-suisse\npour l‚Äôanalyse de donn√©es. C‚Äôest pour cette raison que ce cours\nd√©veloppera beaucoup de contenu dessus.\nAvant d‚Äôessayer de mettre en oeuvre une solution ad hoc, il est\nsouvent utile de se poser la question suivante : ‚Äúne pourrais-je pas le faire\navec les fonctionalit√©s de base de Pandas ?‚Äù Se poser cette question peut\n√©viter des chemins ardus et faire √©conomiser beaucoup de temps.\nN√©anmoins, Pandas n‚Äôest pas\nadapt√© √† des donn√©es ayant une volum√©trie\nimportante. Pour traiter de telles\ndonn√©es, il est plut√¥t recommander\nde privil√©gier Polars ou Dask qui reprennent la logique de Pandas mais\noptimisent son fonctionnement, Spark si on a une infrastructure adapt√©e, g√©n√©ralement dans\ndes environnements big data, ou\nDuckDB si on est pr√™t √† utiliser des requ√™tes SQL plut√¥t qu‚Äôune librairie haut-niveau.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#exercices",
    "href": "content/manipulation/index.html#exercices",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Exercices",
    "text": "Exercices\nCette partie pr√©sente √† la fois des tutoriels d√©taill√©s\net des exercices guid√©s.\nIl est\npossible de les consulter sur ce site ou d‚Äôutiliser l‚Äôun des\nbadges pr√©sents en d√©but de chapitre, par exemple\nceux-ci pour ouvrir\nle chapitre d‚Äôexercices sur Pandas:",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#pour-aller-plus-loin",
    "href": "content/manipulation/index.html#pour-aller-plus-loin",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nCe cours n‚Äôaborde pas vraiment les questions de volum√©trie ou de vitesse de\ncalcul.\nPandas peut montrer ses limites dans ce domaine sur des jeux de donn√©es\nd‚Äôune volum√©trie cons√©quente (plusieurs Gigas).\nIl est ainsi int√©ressant de porter attention √†:\n\nLe livre Modern Pandas\npour obtenir des √©l√©ments suppl√©mentaires sur la question de la performance\navec Pandas ;\nLa question des\nobjets sparse ;\nLes packages Dask ou Polars pour acc√©l√©rer les calculs ;\nDuckDB pour effectuer de mani√®re tr√®s efficace des requ√™tes SQL ;\nPySpark pour des donn√©es tr√®s volumineuses.\n\n\nR√©f√©rences\nVoici une bibliographie s√©lective des ouvrages\nint√©ressants en compl√©ment des chapitres de la partie ‚ÄúManipulation‚Äù de ce cours :\n\n\nMcKinney, Wes. 2012. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython. \" O‚ÄôReilly Media, Inc.\".\n\n\nVanderPlas, Jake. 2016. Python Data Science Handbook: Essential Tools for Working with Data. \" O‚ÄôReilly Media, Inc.\".\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#informations-additionnelles",
    "href": "content/manipulation/index.html#informations-additionnelles",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n5cac236\n\n\n2021-12-16 19:46:43\n\n\nLino Galiana\n\n\nun petit mot sur mercator (#201)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#footnotes",
    "href": "content/manipulation/index.html#footnotes",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCertaines librairies commencent, petit √† petit, √† s‚Äô√©manciper\nde Numpy qui n‚Äôest pas toujours le plus adapt√© pour la gestion\nde certains types de donn√©es. Le framework Arrow tend √† devenir\nla couche basse utilis√©e par de plus en plus de librairies de data science.\nCe post de blog approfondit\nde mani√®re tr√®s p√©dagogique ce sujet.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html",
    "href": "content/manipulation/02a_pandas_tutorial.html",
    "title": "Introduction √† Pandas",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLe package Pandas est l‚Äôune des briques centrales de l‚Äô√©cosyst√®me de\nla data science. Le DataFrame,\nobjet central dans des langages comme R\nou Stata, a longtemps √©tait un grand absent dans l‚Äô√©cosyst√®me Python.\nPourtant, gr√¢ce √† Numpy, toutes les briques de base √©taient pr√©sentes\nmais m√©ritaient d‚Äô√™tre r√©agenc√©es pour convenir aux besoins\ndes data scientists.\nWes McKinney, lorsqu‚Äôil a cr√©√© Pandas en s‚Äôappuyant sur Numpy\na ainsi introduit cet objet devenu banal qu‚Äôest le DataFrame.\nPandas est rapidement\ndevenu un incontournable de la data-science. L‚Äôouvrage\nde r√©f√©rence de McKinney (2012) pr√©sente de mani√®re plus\nample ce package. Les deux prochains chapitres, celui-ci et le\nsuivant, vont pr√©senter quelques √©l√©ments structurants\nde ce package. Ce chapitre prend la forme d‚Äôun tutoriel\nalors que l‚Äôexercice suivant est plut√¥t un ensemble d‚Äôexercices.\nA l‚Äôissue du chapitre pr√©c√©dent, gr√¢ce √† des croisements\nde donn√©es, nous diposerons d‚Äôune base fine sur les empreintes\ncarbones des Fran√ßais1.\nCe tutoriel vise √† introduire aux concepts\nde base de ce package par l‚Äôexemple et √† introduire √† certaines\ndes t√¢ches les plus fr√©quentes de (re)structuration\ndes donn√©es du data scientist. Il ne s‚Äôagit pas d‚Äôun ensemble\nexhaustif de commandes : Pandas est un package tentaculaire\nqui permet de r√©aliser la m√™me op√©ration de nombreuses mani√®res.\nNous nous concentrerons ainsi sur les √©l√©ments les plus pertinents\ndans le cadre d‚Äôune introduction √† la data science et laisserons\nles utilisateurs int√©ress√©s approfondir leurs connaissances\ndans les ressources foisonnantes qu‚Äôil existe sur le sujet.\nDans ce tutoriel Pandas, nous allons utiliser :\nLe chapitre suivant permettra de mettre en application des √©l√©ments pr√©sents dans ce chapitre avec\nles donn√©es ci-dessus associ√©es √† des donn√©es de contexte au niveau communal.\nNous suivrons les conventions habituelles dans l‚Äôimport des packages :\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nPour obtenir des r√©sultats reproductibles, on peut fixer la racine du g√©n√©rateur\npseudo-al√©atoire.\nnp.random.seed(123)\nAu cours de cette d√©monstration des principales fonctionalit√©s de Pandas, et\nlors du chapitre suivant,\nje recommande de se r√©f√©rer r√©guli√®rement aux ressources suivantes :",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#indexation",
    "href": "content/manipulation/02a_pandas_tutorial.html#indexation",
    "title": "Introduction √† Pandas",
    "section": "2.1 Indexation",
    "text": "2.1 Indexation\nLa diff√©rence essentielle entre une Series et un objet Numpy est l‚Äôindexation.\nDans Numpy,\nl‚Äôindexation est implicite ; elle permet d‚Äôacc√©der √† une donn√©e (celle √†\nl‚Äôindex situ√© √† la position i).\nAvec une Series, on peut bien s√ªr utiliser un indice de position mais on peut\nsurtout faire appel √† des indices plus explicites.\nPar exemple,\n\ntaille = pd.Series([1.0, 1.5, 1], index=[\"chat\", \"chien\", \"koala\"])\n\ntaille.head()\n\nchat     1.0\nchien    1.5\nkoala    1.0\ndtype: float64\n\n\nCette indexation permet d‚Äôacc√©der √† des valeurs de la Series\nvia une valeur de l‚Äôindice. Par\nexemple, taille['koala']:\n\ntaille[\"koala\"]\n\n1.0\n\n\nL‚Äôexistence d‚Äôindice rend le subsetting particuli√®rement ais√©, ce que vous\npouvez exp√©rimenter dans les exercices :\n\n\n\n\n\n\n\n\n\n\n\n\nPour transformer un objet pandas.Series en array numpy,\non utilise la m√©thode values. Par exemple, taille.values:\n\ntaille.values\n\narray([1. , 1.5, 1. ])\n\n\nUn avantage des Series par rapport √† un array numpy est que\nles op√©rations sur les Series alignent\nautomatiquement les donn√©es √† partir des labels.\nAvec des Series lab√©lis√©es, il n‚Äôest ainsi pas n√©cessaire\nde se poser la question de l‚Äôordre des lignes.\nL‚Äôexemple dans la partie suivante permettra de s‚Äôen assurer.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#valeurs-manquantes",
    "href": "content/manipulation/02a_pandas_tutorial.html#valeurs-manquantes",
    "title": "Introduction √† Pandas",
    "section": "2.2 Valeurs manquantes",
    "text": "2.2 Valeurs manquantes\nPar d√©faut, les valeurs manquantes sont affich√©es NaN et sont de type np.nan (pour\nles valeurs temporelles, i.e.¬†de type datatime64, les valeurs manquantes sont\nNaT).\nOn a un comportement coh√©rent d‚Äôagr√©gation lorsqu‚Äôon combine deux DataFrames (ou deux colonnes).\nPar exemple,\n\nx = pd.DataFrame(\n    {\"prix\": np.random.uniform(size=5), \"quantite\": [i + 1 for i in range(5)]},\n    index=[\"yaourt\", \"pates\", \"riz\", \"tomates\", \"gateaux\"],\n)\nx\n\n\n\n\n\n\n\n\n\nprix\nquantite\n\n\n\n\nyaourt\n0.696469\n1\n\n\npates\n0.286139\n2\n\n\nriz\n0.226851\n3\n\n\ntomates\n0.551315\n4\n\n\ngateaux\n0.719469\n5\n\n\n\n\n\n\n\n\n\ny = pd.DataFrame(\n    {\"prix\": [np.nan, 0, 1, 2, 3], \"quantite\": [i + 1 for i in range(5)]},\n    index=[\"tomates\", \"yaourt\", \"gateaux\", \"pates\", \"riz\"],\n)\ny\n\n\n\n\n\n\n\n\n\nprix\nquantite\n\n\n\n\ntomates\nNaN\n1\n\n\nyaourt\n0.0\n2\n\n\ngateaux\n1.0\n3\n\n\npates\n2.0\n4\n\n\nriz\n3.0\n5\n\n\n\n\n\n\n\n\n\nx + y\n\n\n\n\n\n\n\n\n\nprix\nquantite\n\n\n\n\ngateaux\n1.719469\n8\n\n\npates\n2.286139\n6\n\n\nriz\n3.226851\n8\n\n\ntomates\nNaN\n5\n\n\nyaourt\n0.696469\n3\n\n\n\n\n\n\n\n\ndonne bien une valeur manquante pour la ligne tomates. Au passage, on peut remarquer que l‚Äôagr√©gation\na tenu compte des index.\nIl est possible de supprimer les valeurs manquantes gr√¢ce √† dropna().\nCette m√©thode va supprimer toutes les lignes o√π il y a au moins une valeur manquante.\nIl est aussi possible de supprimer seulement les colonnes o√π il y a des valeurs manquantes\ndans un DataFrame avec dropna() avec le param√®tre axis=1 (par d√©faut √©gal √† 0).\nIl est √©galement possible de remplir les valeurs manquantes gr√¢ce √† la m√©thode fillna().",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#les-attributs-et-m√©thodes-utiles",
    "href": "content/manipulation/02a_pandas_tutorial.html#les-attributs-et-m√©thodes-utiles",
    "title": "Introduction √† Pandas",
    "section": "3.1 Les attributs et m√©thodes utiles",
    "text": "3.1 Les attributs et m√©thodes utiles\nPour pr√©senter les m√©thodes les plus pratiques pour l‚Äôanalyse de donn√©es,\non peut partir de l‚Äôexemple des consommations de CO2 communales issues\ndes donn√©es de l‚ÄôAdeme. Cette base de donn√©es est exploit√©e plus intens√©ment\ndans le chapitre d‚Äôexercice (prochain chapitre).\nL‚Äôimport de donn√©es depuis un fichier plat se fait avec la fonction read_csv:\n\ndf = pd.read_csv(\n    \"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\"\n)\ndf\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n\n\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n\n\n3\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n\n\n4\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35793\n95676\nVILLERS-EN-ARTHIES\n1628.065094\nNaN\nNaN\n165.045396\n65.063617\n11.772789\n34.556067\n176.098160\n309.627908\n235.439109\n\n\n35794\n95678\nVILLIERS-ADAM\n698.630772\nNaN\nNaN\n1331.126598\n111.480954\n2.354558\n6.911213\n1395.529811\n18759.370071\n403.404815\n\n\n35795\n95680\nVILLIERS-LE-BEL\n107.564967\nNaN\nNaN\n8367.174532\n225.622903\n534.484607\n1568.845431\n22613.830247\n12217.122402\n13849.512001\n\n\n35796\n95682\nVILLIERS-LE-SEC\n1090.890170\nNaN\nNaN\n326.748418\n108.969749\n2.354558\n6.911213\n67.235487\n4663.232127\n85.657725\n\n\n35797\n95690\nWY-DIT-JOLI-VILLAGE\n1495.103542\nNaN\nNaN\n125.236417\n97.728612\n4.709115\n13.822427\n117.450851\n504.400972\n147.867245\n\n\n\n\n35798 rows √ó 12 columns\n\n\n\n\n\n\n Note\nDans un processus de production, o√π normalement on connait les types des variables du DataFrame qu‚Äôon va importer,\nil convient de pr√©ciser les types avec lesquels on souhaite importer les donn√©es\n(argument dtype, sous la forme d‚Äôun dictionnaire).\nCela est particuli√®rement important lorsqu‚Äôon d√©sire utiliser une colonne\ncomme une variable textuelle mais qu‚Äôelle comporte des attributs proches d‚Äôun nombre\nqui vont inciter pandas √† l‚Äôimporter sous forme de variable num√©rique.\nPar exemple, une colonne [00001,00002,...] risque d‚Äô√™tre import√©e comme une variable num√©rique, ignorant l‚Äôinformation des premiers 0 (qui peuvent pourtant la distinguer de la s√©quence 1, 2, etc.). Pour s‚Äôassurer que pandas importe sous forme textuelle la variable, on peut utiliser dtype = {\"code\": \"str\"}\nSinon, on peut importer le csv, et modifier les types avec astype().\nAvec astype, on peut g√©rer les erreurs de conversion avec le param√®tre errors.\n\n\nL‚Äôaffichage des DataFrames dans les notebooks est assez ergonomique.\nLes premi√®res et derni√®res lignes s‚Äôaffichent\nautomatiquement. Pour des tables de valorisation pr√©sentes dans un\nrapport ou un article de recherche, le chapitre suivant\npr√©sente great_tables qui offre de tr√®s riches\nfonctionnalit√©s de mise en forme des tableaux.\nPour afficher une partie cibl√©e des donn√©es, on peut aussi faire:\n\nhead qui permet, comme son\nnom l‚Äôindique, de n‚Äôafficher que les premi√®res lignes ;\ntail qui permet, comme son\nnom l‚Äôindique, de n‚Äôafficher que les derni√®res lignes\nsample qui permet d‚Äôafficher un √©chantillon al√©atoire de n lignes.\nCette m√©thode propose de nombreuses options.\n\n\n\n Warning\nIl faut faire attention au display et aux\ncommandes qui r√©v√®lent des donn√©es (head, tail, etc.)\ndans un notebook qui exploite\ndes donn√©es confidentielles lorsqu‚Äôon utilise\nle logiciel de contr√¥le de version Git (cf.¬†chapitres d√©di√©s).\nEn effet, on peut se\nretrouver √† partager des donn√©es, involontairement, dans l‚Äôhistorique\nGit. Comme cela sera expliqu√© dans le chapitre d√©di√© √† Git,\nun fichier, nomm√© le .gitignore, suffit pour cr√©er quelques r√®gles\n√©vitant le partage involontaire de donn√©es avec Git.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#dimensions-et-structure-du-dataframe",
    "href": "content/manipulation/02a_pandas_tutorial.html#dimensions-et-structure-du-dataframe",
    "title": "Introduction √† Pandas",
    "section": "3.2 Dimensions et structure du DataFrame",
    "text": "3.2 Dimensions et structure du DataFrame\nLes premi√®res m√©thodes utiles permettent d‚Äôafficher quelques\nattributs d‚Äôun DataFrame.\n\ndf.axes\n\n[RangeIndex(start=0, stop=35798, step=1),\n Index(['INSEE commune', 'Commune', 'Agriculture', 'Autres transports',\n        'Autres transports international', 'CO2 biomasse hors-total', 'D√©chets',\n        'Energie', 'Industrie hors-√©nergie', 'R√©sidentiel', 'Routier',\n        'Tertiaire'],\n       dtype='object')]\n\n\n\ndf.columns\n\nIndex(['INSEE commune', 'Commune', 'Agriculture', 'Autres transports',\n       'Autres transports international', 'CO2 biomasse hors-total', 'D√©chets',\n       'Energie', 'Industrie hors-√©nergie', 'R√©sidentiel', 'Routier',\n       'Tertiaire'],\n      dtype='object')\n\n\n\ndf.index\n\nRangeIndex(start=0, stop=35798, step=1)\n\n\nPour conna√Ætre les dimensions d‚Äôun DataFrame, on peut utiliser quelques m√©thodes\npratiques :\n\ndf.ndim\n\n2\n\n\n\ndf.shape\n\n(35798, 12)\n\n\n\ndf.size\n\n429576\n\n\nPour d√©terminer le nombre de valeurs uniques d‚Äôune variable, plut√¥t que chercher √† √©crire soi-m√™me une fonction,\non utilise la\nm√©thode nunique. Par exemple,\n\ndf[\"Commune\"].nunique()\n\n33338\n\n\nComme √©voqu√© pr√©c√©demment, Pandas propose √©norm√©ment de m√©thodes utiles.\nVoici un premier r√©sum√©, accompagn√© d‚Äôun comparatif avec R :\n\n\n\n\n\n\n\n\n\nOp√©ration\npandas\ndplyr (R)\ndata.table (R)\n\n\n\n\nR√©cup√©rer le nom des colonnes\ndf.columns\ncolnames(df)\ncolnames(df)\n\n\nR√©cup√©rer les indices\ndf.index\n\nunique(df[,get(key(df))])\n\n\nR√©cup√©rer les dimensions\ndf.shape\ndim(df)\ndim(df)\n\n\nR√©cup√©rer le nombre de valeurs uniques d‚Äôune variable\ndf['myvar'].nunique()\ndf %&gt;%  summarise(distinct(myvar))\ndf[,uniqueN(myvar)]",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#statistiques-agr√©g√©es",
    "href": "content/manipulation/02a_pandas_tutorial.html#statistiques-agr√©g√©es",
    "title": "Introduction √† Pandas",
    "section": "3.3 Statistiques agr√©g√©es",
    "text": "3.3 Statistiques agr√©g√©es\nPandas propose une s√©rie de m√©thodes pour faire des statistiques\nagr√©g√©es de mani√®re efficace.\nOn peut, par exemple, appliquer des m√©thodes pour compter le nombre de lignes,\nfaire une moyenne ou une somme de l‚Äôensemble des lignes\nEn premier lieu, on peut faire une somme, pour chaque variable, des\nvaleurs pr√©sentes dans celle-ci. Pandas impl√©mente\ncelle-ci par le biais de la m√©thode sum:\n\ndf.sum(numeric_only=True)\n\nAgriculture                        8.790969e+07\nAutres transports                  6.535446e+06\nAutres transports international    2.223857e+07\nCO2 biomasse hors-total            6.351931e+07\nD√©chets                            1.470358e+07\nEnergie                            2.285203e+07\nIndustrie hors-√©nergie             8.357368e+07\nR√©sidentiel                        6.384140e+07\nRoutier                            1.264932e+08\nTertiaire                          3.956273e+07\ndtype: float64\n\n\nIl est √©galement possible de faire une moyenne:\n\ndf.mean(numeric_only=True)\n\nAgriculture                        2459.975760\nAutres transports                   654.919940\nAutres transports international    7692.344960\nCO2 biomasse hors-total            1774.381550\nD√©chets                             410.806329\nEnergie                             662.569846\nIndustrie hors-√©nergie             2423.127789\nR√©sidentiel                        1783.677872\nRoutier                            3535.501245\nTertiaire                          1105.165915\ndtype: float64\n\n\nA noter que les valeurs manquantes sont automatiquement\n√©limin√©es de la statistique. Pour conna√Ætre le nombre de\nvaleurs non manquantes pour chaque colonne, la\nm√©thode count est disponible:\n\ndf.count()\n\nINSEE commune                      35798\nCommune                            35798\nAgriculture                        35736\nAutres transports                   9979\nAutres transports international     2891\nCO2 biomasse hors-total            35798\nD√©chets                            35792\nEnergie                            34490\nIndustrie hors-√©nergie             34490\nR√©sidentiel                        35792\nRoutier                            35778\nTertiaire                          35798\ndtype: int64\n\n\nCependant, cette derni√®re ne distingue pas les\nvaleurs dupliqu√©es. Parfois, il est pratique\nde conna√Ætre le nombre de valeurs uniques d‚Äôune\nvariable afin de savoir si elle dispose\nde beaucoup de modalit√©s ou non:\n\ndf.nunique()\n\nINSEE commune                      35798\nCommune                            33338\nAgriculture                        35576\nAutres transports                   9963\nAutres transports international     2883\nCO2 biomasse hors-total            35798\nD√©chets                            11016\nEnergie                             1453\nIndustrie hors-√©nergie              1889\nR√©sidentiel                        35791\nRoutier                            35749\nTertiaire                           8663\ndtype: int64\n\n\nLes m√©thodes statistiques pr√©implement√©es vont\nau-del√† de simples sommes ou moyennes. Il est\npossible de faire, par exemple, des calculs de quantiles\nsur les diff√©rentes colonnes d‚Äôun jeu de donn√©es\n\ndf.quantile(q=[0.1, 0.25, 0.5, 0.75, 0.9], numeric_only=True)\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\n\n0.10\n382.620882\n25.034578\n4.430792\n109.152816\n14.811230\n2.354558\n6.911213\n50.180933\n199.765410\n49.289082\n\n\n0.25\n797.682631\n52.560412\n10.050967\n197.951108\n25.655166\n2.354558\n6.911213\n96.052911\n419.700460\n94.749885\n\n\n0.50\n1559.381285\n106.795928\n19.924343\n424.849988\n54.748653\n4.709115\n13.822427\n227.091193\n1070.895593\n216.297718\n\n\n0.75\n3007.883903\n237.341501\n32.983111\n1094.749825\n110.820941\n51.800270\n152.046694\n749.469293\n3098.612157\n576.155869\n\n\n0.90\n5442.727470\n528.349529\n59.999169\n3143.759029\n190.695774\n367.311008\n1154.172630\n2937.699671\n8151.047248\n1897.732565\n\n\n\n\n\n\n\n\nLe r√©sultat est un tableau en 2 dimensions: une ligne par statistique\ndemand√©e pour chaque colonne num√©rique de notre jeu de donn√©es. Cela\npeut permettre de se repr√©senter rapidement la distribution des donn√©es.\nN√©anmoins c‚Äôest un produit assez brut ; pour avoir une meilleure\ncompr√©hension de la distribution de chaque colonne, une table stylis√©e\n(obtenue par great_tables) ou un graphique est probablement\nplus pertinent.\n\n\n Warning\nLa version 2.0 de Pandas a introduit un changement\nde comportement dans les m√©thodes d‚Äôagr√©gation.\nIl est dor√©navant n√©cessaire de pr√©ciser quand on d√©sire\neffectuer des op√©rations si on d√©sire ou non le faire\nexclusivement sur les colonnes num√©riques. C‚Äôest pour cette\nraison qu‚Äôon exlicite ici l‚Äôargument numeric_only = True.\nCe comportement\n√©tait par le pass√© implicite.\n\n\nIl faut toujours regarder les options de ces fonctions en termes de valeurs manquantes, car\nces options sont d√©terminantes dans le r√©sultat obtenu.\nLe tableau suivant r√©capitule le code √©quivalent pour avoir des\nstatistiques sur toutes les colonnes d‚Äôun dataframe en R.\n\n\n\n\n\n\n\n\n\nOp√©ration\npandas\ndplyr (R)\ndata.table (R)\n\n\n\n\nNombre de valeurs non manquantes\ndf.count()\ndf %&gt;% summarise_each(funs(sum(!is.na(.))))\ndf[, lapply(.SD, function(x) sum(!is.na(x)))]\n\n\nMoyenne de toutes les variables\ndf.mean()\ndf %&gt;% summarise_each(funs(mean((., na.rm = TRUE))))\ndf[,lapply(.SD, function(x) mean(x, na.rm = TRUE))]\n\n\n\nLa m√©thode describe permet de sortir un tableau de statistiques\nagr√©g√©es :\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\n\ncount\n35736.000000\n9979.000000\n2.891000e+03\n35798.000000\n35792.000000\n3.449000e+04\n3.449000e+04\n35792.000000\n35778.000000\n35798.000000\n\n\nmean\n2459.975760\n654.919940\n7.692345e+03\n1774.381550\n410.806329\n6.625698e+02\n2.423128e+03\n1783.677872\n3535.501245\n1105.165915\n\n\nstd\n2926.957701\n9232.816833\n1.137643e+05\n7871.341922\n4122.472608\n2.645571e+04\n5.670374e+04\n8915.902379\n9663.156628\n5164.182507\n\n\nmin\n0.003432\n0.000204\n3.972950e-04\n3.758088\n0.132243\n2.354558e+00\n1.052998e+00\n1.027266\n0.555092\n0.000000\n\n\n25%\n797.682631\n52.560412\n1.005097e+01\n197.951108\n25.655166\n2.354558e+00\n6.911213e+00\n96.052911\n419.700460\n94.749885\n\n\n50%\n1559.381285\n106.795928\n1.992434e+01\n424.849988\n54.748653\n4.709115e+00\n1.382243e+01\n227.091193\n1070.895593\n216.297718\n\n\n75%\n3007.883903\n237.341501\n3.298311e+01\n1094.749825\n110.820941\n5.180027e+01\n1.520467e+02\n749.469293\n3098.612157\n576.155869\n\n\nmax\n98949.317760\n513140.971691\n3.303394e+06\n576394.181208\n275500.374439\n2.535858e+06\n6.765119e+06\n410675.902028\n586054.672836\n288175.400126",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#m√©thodes-relatives-aux-valeurs-manquantes",
    "href": "content/manipulation/02a_pandas_tutorial.html#m√©thodes-relatives-aux-valeurs-manquantes",
    "title": "Introduction √† Pandas",
    "section": "3.4 M√©thodes relatives aux valeurs manquantes",
    "text": "3.4 M√©thodes relatives aux valeurs manquantes\nLes m√©thodes relatives aux valeurs manquantes peuvent √™tre mobilis√©es\nen conjonction des m√©thodes de statistiques agr√©g√©es. C‚Äôest utile lorsqu‚Äôon\nd√©sire obtenir une id√©e de la part de valeurs manquantes dans un jeu de\ndonn√©es\n\ndf.isnull().sum()\n\nINSEE commune                          0\nCommune                                0\nAgriculture                           62\nAutres transports                  25819\nAutres transports international    32907\nCO2 biomasse hors-total                0\nD√©chets                                6\nEnergie                             1308\nIndustrie hors-√©nergie              1308\nR√©sidentiel                            6\nRoutier                               20\nTertiaire                              0\ndtype: int64\n\n\nOn trouvera aussi la r√©f√©rence √† isna() qui est la m√™me m√©thode que isnull().",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#s√©lectionner-des-colonnes",
    "href": "content/manipulation/02a_pandas_tutorial.html#s√©lectionner-des-colonnes",
    "title": "Introduction √† Pandas",
    "section": "5.1 S√©lectionner des colonnes",
    "text": "5.1 S√©lectionner des colonnes\nEn SQL, effectuer des op√©rations sur les colonnes se fait avec la commande\nSELECT. Avec Pandas,\npour acc√©der √† une colonne dans son ensemble on peut\nutiliser plusieurs approches :\n\ndataframe.variable, par exemple df.Energie.\nCette m√©thode requiert n√©anmoins d‚Äôavoir des\nnoms de colonnes sans espace ou caract√®res sp√©ciaux, ce qui exclut\nsouvent des jeux de donn√©es r√©els. Elle n‚Äôest pas recommand√©e.\ndataframe[['variable']] pour renvoyer la variable sous\nforme de DataFrame ou dataframe['variable'] pour\nla renvoyer sous forme de Series. Par exemple, df[['Autres transports']]\nou df['Autres transports']. C‚Äôest une mani√®re pr√©f√©rable de proc√©der.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#acc√©der-√†-des-lignes",
    "href": "content/manipulation/02a_pandas_tutorial.html#acc√©der-√†-des-lignes",
    "title": "Introduction √† Pandas",
    "section": "5.2 Acc√©der √† des lignes",
    "text": "5.2 Acc√©der √† des lignes\nPour acc√©der √† une ou plusieurs valeurs d‚Äôun DataFrame,\nil existe deux mani√®res conseill√©es de proc√©der, selon la\nforme des indices de lignes ou colonnes utilis√©es :\n\ndf.iloc : utilise les indices. C‚Äôest une m√©thode moyennement fiable car les indices d‚Äôun DataFrame peuvent √©voluer au cours d‚Äôun traitement (notamment lorsqu‚Äôon fait des op√©rations par groupe).\ndf.loc : utilise les labels. Cette m√©thode est recommand√©e.\n\n\n\n Warning\nLes bouts de code utilisant la structure df.ix\nsont √† bannir car la fonction est deprecated et peut\nainsi dispara√Ætre √† tout moment.\n\n\niloc va se r√©f√©rer √† l‚Äôindexation de 0 √† N o√π N est √©gal √† df.shape[0] d‚Äôun\npandas.DataFrame. loc va se r√©f√©rer aux valeurs de l‚Äôindex\nde df.\nPar exemple, avec le pandas.DataFrame df_example:\n\ndf_example = pd.DataFrame(\n    {\"month\": [1, 4, 7, 10], \"year\": [2012, 2014, 2013, 2014], \"sale\": [55, 40, 84, 31]}\n)\ndf_example = df_example.set_index(\"month\")\ndf_example\n\n\n\n\n\n\n\n\n\nyear\nsale\n\n\nmonth\n\n\n\n\n\n\n1\n2012\n55\n\n\n4\n2014\n40\n\n\n7\n2013\n84\n\n\n10\n2014\n31\n\n\n\n\n\n\n\n\n\ndf_example.loc[1, :] donnera la premi√®re ligne de df (ligne o√π l‚Äôindice month est √©gal √† 1) ;\ndf_example.iloc[1, :] donnera la deuxi√®me ligne (puisque l‚Äôindexation en Python commence √† 0) ;\ndf_example.iloc[:, 1] donnera la deuxi√®me colonne, suivant le m√™me principe.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#op√©rations-sur-les-colonnes-select-mutate-drop",
    "href": "content/manipulation/02a_pandas_tutorial.html#op√©rations-sur-les-colonnes-select-mutate-drop",
    "title": "Introduction √† Pandas",
    "section": "6.1 Op√©rations sur les colonnes : select, mutate, drop",
    "text": "6.1 Op√©rations sur les colonnes : select, mutate, drop\nLes DataFrames pandas sont des objets mutables en langage Python,\nc‚Äôest-√†-dire qu‚Äôil est possible de faire √©voluer le DataFrame au gr√®s\ndes op√©rations mises en oeuvre. L‚Äôop√©ration la plus classique consiste √† ajouter ou retirer\ndes variables √† la table de donn√©es.\n\ndf_new = df.copy()\n\n\n\n Warning\nAttention au comportement de Pandas lorsqu‚Äôon cr√©e une duplication\nd‚Äôun DataFrame.\nPar d√©faut, Pandas effectue une copie par r√©f√©rence. Dans ce\ncas, les deux objets (la copie et l‚Äôobjet copi√©) restent reli√©s. Les colonnes\ncr√©√©es sur l‚Äôun vont √™tre r√©percut√©es sur l‚Äôautre. Ce comportement permet de\nlimiter l‚Äôinflation en m√©moire de Python. En faisant √ßa, le deuxi√®me\nobjet prend le m√™me espace m√©moire que le premier. Le package data.table\nen R adopte le m√™me comportement, contrairement √† dplyr.\nCela peut amener √† quelques surprises si ce comportement d‚Äôoptimisation\nn‚Äôest pas anticip√©. Si vous voulez, par s√©curit√©, conserver intact le\npremier DataFrame, faites appel √† une copie profonde (deep copy) en\nutilisant la m√©thode copy, comme ci-dessus.\nAttention toutefois, cela a un co√ªt m√©moire.\nAvec des donn√©es volumineuses, c‚Äôest une pratique √† utiliser avec pr√©caution.\n\n\nLa mani√®re la plus simple d‚Äôop√©rer pour ajouter des colonnes est\nd‚Äôutiliser la r√©assignation. Par exemple, pour cr√©er une variable\nx qui est le log de la\nvariable Agriculture:\n\ndf_new[\"x\"] = np.log(df_new[\"Agriculture\"])\n\nIl est possible d‚Äôappliquer cette approche sur plusieurs colonnes. Un des\nint√©r√™ts de cette approche est qu‚Äôelle permet de recycler le nom de colonnes.\n\nvars = [\"Agriculture\", \"D√©chets\", \"Energie\"]\n\ndf_new[[v + \"_log\" for v in vars]] = np.log(df_new[vars])\ndf_new\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\nx\nAgriculture_log\nD√©chets_log\nEnergie_log\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n8.219171\n8.219171\n4.619374\n0.856353\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n6.164010\n6.164010\n4.946455\n0.856353\n\n\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n6.212693\n6.212693\n8.578159\n6.906086\n\n\n3\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n7.527881\n7.527881\n5.376285\n4.545232\n\n\n4\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n6.106949\n6.106949\n3.879532\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35793\n95676\nVILLERS-EN-ARTHIES\n1628.065094\nNaN\nNaN\n165.045396\n65.063617\n11.772789\n34.556067\n176.098160\n309.627908\n235.439109\n7.395148\n7.395148\n4.175366\n2.465791\n\n\n35794\n95678\nVILLIERS-ADAM\n698.630772\nNaN\nNaN\n1331.126598\n111.480954\n2.354558\n6.911213\n1395.529811\n18759.370071\n403.404815\n6.549122\n6.549122\n4.713854\n0.856353\n\n\n35795\n95680\nVILLIERS-LE-BEL\n107.564967\nNaN\nNaN\n8367.174532\n225.622903\n534.484607\n1568.845431\n22613.830247\n12217.122402\n13849.512001\n4.678095\n4.678095\n5.418865\n6.281303\n\n\n35796\n95682\nVILLIERS-LE-SEC\n1090.890170\nNaN\nNaN\n326.748418\n108.969749\n2.354558\n6.911213\n67.235487\n4663.232127\n85.657725\n6.994749\n6.994749\n4.691070\n0.856353\n\n\n35797\n95690\nWY-DIT-JOLI-VILLAGE\n1495.103542\nNaN\nNaN\n125.236417\n97.728612\n4.709115\n13.822427\n117.450851\n504.400972\n147.867245\n7.309951\n7.309951\n4.582194\n1.549500\n\n\n\n\n35798 rows √ó 16 columns\n\n\n\n\nIl est √©galement possible d‚Äôutiliser la m√©thode assign. Pour des op√©rations\nvectoris√©es, comme le sont les op√©rateurs de numpy, cela n‚Äôa pas d‚Äôint√©r√™t.\nCela permet notamment d‚Äôenchainer les op√©rations sur un m√™me DataFrame (notamment gr√¢ce au pipe que\nnous verrons plus loin).\nCette approche utilise g√©n√©ralement\ndes lambda functions. Par exemple le code pr√©c√©dent (celui concernant une\nseule variable) prendrait la forme:\n\ndf_new.assign(Energie_log=lambda x: np.log(x[\"Energie\"]))\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\nx\nAgriculture_log\nD√©chets_log\nEnergie_log\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n8.219171\n8.219171\n4.619374\n0.856353\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n6.164010\n6.164010\n4.946455\n0.856353\n\n\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n6.212693\n6.212693\n8.578159\n6.906086\n\n\n3\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n7.527881\n7.527881\n5.376285\n4.545232\n\n\n4\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n6.106949\n6.106949\n3.879532\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35793\n95676\nVILLERS-EN-ARTHIES\n1628.065094\nNaN\nNaN\n165.045396\n65.063617\n11.772789\n34.556067\n176.098160\n309.627908\n235.439109\n7.395148\n7.395148\n4.175366\n2.465791\n\n\n35794\n95678\nVILLIERS-ADAM\n698.630772\nNaN\nNaN\n1331.126598\n111.480954\n2.354558\n6.911213\n1395.529811\n18759.370071\n403.404815\n6.549122\n6.549122\n4.713854\n0.856353\n\n\n35795\n95680\nVILLIERS-LE-BEL\n107.564967\nNaN\nNaN\n8367.174532\n225.622903\n534.484607\n1568.845431\n22613.830247\n12217.122402\n13849.512001\n4.678095\n4.678095\n5.418865\n6.281303\n\n\n35796\n95682\nVILLIERS-LE-SEC\n1090.890170\nNaN\nNaN\n326.748418\n108.969749\n2.354558\n6.911213\n67.235487\n4663.232127\n85.657725\n6.994749\n6.994749\n4.691070\n0.856353\n\n\n35797\n95690\nWY-DIT-JOLI-VILLAGE\n1495.103542\nNaN\nNaN\n125.236417\n97.728612\n4.709115\n13.822427\n117.450851\n504.400972\n147.867245\n7.309951\n7.309951\n4.582194\n1.549500\n\n\n\n\n35798 rows √ó 16 columns\n\n\n\n\nDans les m√©thodes suivantes, il est possible de modifier le pandas.DataFrame\nen place, c‚Äôest √† dire en ne le r√©assignant pas, avec le param√®tre inplace = True.\nPar d√©faut, inplace est √©gal √† False et pour modifier le pandas.DataFrame,\nil convient de le r√©assigner.\nOn peut facilement renommer des variables avec la m√©thode rename qui\nfonctionne bien avec des dictionnaires (pour renommer des colonnes il faut\npr√©ciser le param√®tre axis = 1):\n\ndf_new = df_new.rename({\"Energie\": \"eneg\", \"Agriculture\": \"agr\"}, axis=1)\n\nEnfin, pour effacer des colonnes, on utilise la m√©thode drop avec l‚Äôargument\ncolumns:\n\ndf_new = df_new.drop(columns=[\"eneg\", \"agr\"])",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#r√©ordonner",
    "href": "content/manipulation/02a_pandas_tutorial.html#r√©ordonner",
    "title": "Introduction √† Pandas",
    "section": "6.2 R√©ordonner",
    "text": "6.2 R√©ordonner\nLa m√©thode sort_values permet de r√©ordonner un DataFrame. Par exemple,\nsi on d√©sire classer par ordre d√©croissant de consommation de CO2 du secteur\nr√©sidentiel, on fera\n\ndf = df.sort_values(\"R√©sidentiel\", ascending=False)\n\nAinsi, en une ligne de code, on identifie les villes o√π le secteur\nr√©sidentiel consomme le plus.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#filtrer",
    "href": "content/manipulation/02a_pandas_tutorial.html#filtrer",
    "title": "Introduction √† Pandas",
    "section": "6.3 Filtrer",
    "text": "6.3 Filtrer\nL‚Äôop√©ration de s√©lection de lignes s‚Äôappelle FILTER en SQL. Elle s‚Äôutilise\nen fonction d‚Äôune condition logique (clause WHERE). On s√©lectionne les\ndonn√©es sur une condition logique. Il existe plusieurs m√©thodes en pandas.\nLa plus simple est d‚Äôutiliser les boolean mask, d√©j√† vus dans le chapitre\nnumpy.\nPar exemple, pour s√©lectionner les communes dans les Hauts-de-Seine, on\npeut utiliser le r√©sultat de la m√©thode str.startswith (qui renvoie\nTrue ou False) directement dans les crochets:\n\ndf[df[\"INSEE commune\"].str.startswith(\"92\")].head(2)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\n\n35494\n92012\nBOULOGNE-BILLANCOURT\nNaN\n1250.483441\n34.234669\n51730.704250\n964.828694\n8817.818741\n25882.493998\n92216.971456\n64985.280901\n60349.109482\n\n\n35501\n92025\nCOLOMBES\nNaN\n411.371588\n14.220061\n53923.847088\n698.685861\n12855.885267\n50244.664227\n87469.549463\n52070.927943\n41526.600867\n\n\n\n\n\n\n\n\nPour remplacer des valeurs sp√©cifiques, on utilise la m√©thode where ou une\nr√©assignation coupl√©e √† la m√©thode pr√©c√©dente.\nPar exemple, pour assigner des valeurs manquantes aux d√©partements du 92,\non peut faire cela\n\ndf_copy = df.copy()\ndf_copy = df_copy.where(~df[\"INSEE commune\"].str.startswith(\"92\"))\n\net v√©rifier les r√©sultats:\n\ndf_copy[df[\"INSEE commune\"].str.startswith(\"92\")].head(2)\ndf_copy[~df[\"INSEE commune\"].str.startswith(\"92\")].head(2)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\n\n12167\n31555\nTOULOUSE\n1434.045233\n4482.980062\n130.792683\n576394.181208\n88863.732538\n91549.914092\n277062.573234\n410675.902028\n586054.672836\n288175.400126\n\n\n16774\n44109\nNANTES\n248.019465\n138738.544337\n250814.701179\n193478.248177\n18162.261628\n17461.400209\n77897.138554\n354259.013785\n221068.632724\n173447.582779\n\n\n\n\n\n\n\n\nou alors utiliser une r√©assignation plus classique:\n\ndf_copy = df.copy()\ndf_copy[df_copy[\"INSEE commune\"].str.startswith(\"92\")] = np.nan\n\nIl est conseill√© de filtrer avec loc en utilisant un masque.\nEn effet, contrairement √† df[mask], df.loc[mask, :] permet d‚Äôindiquer clairement\n√† Python que l‚Äôon souhaite appliquer le masque aux labels de l‚Äôindex.\nCe n‚Äôest pas le cas avec df[mask].\nD‚Äôailleurs, lorsqu‚Äôon utilise la syntaxe df[mask], pandas renvoie g√©n√©ralement un warning",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#op√©rations-par-groupe",
    "href": "content/manipulation/02a_pandas_tutorial.html#op√©rations-par-groupe",
    "title": "Introduction √† Pandas",
    "section": "6.4 Op√©rations par groupe",
    "text": "6.4 Op√©rations par groupe\nEn SQL, il est tr√®s simple de d√©couper des donn√©es pour\neffectuer des op√©rations sur des blocs coh√©rents et recollecter des r√©sultats\ndans la dimension appropri√©e.\nLa logique sous-jacente est celle du split-apply-combine qui est repris\npar les langages de manipulation de donn√©es, auxquels pandas\nne fait pas exception.\nL‚Äôimage suivante, issue de\nce site\nrepr√©sente bien la mani√®re dont fonctionne l‚Äôapproche\nsplit-apply-combine\n\n\n\nSplit-apply-combine\n\n\nCe tutoriel sur le sujet\nest particuli√®rement utile.\nPour donner quelques exemples, on peut cr√©er une variable d√©partementale qui\nservira de crit√®re de groupe.\n\ndf[\"dep\"] = df[\"INSEE commune\"].str[:2]\n\nEn pandas, on utilise groupby pour d√©couper les donn√©es selon un ou\nplusieurs axes. Techniquement, cette op√©ration consiste √† cr√©er une association\nentre des labels (valeurs des variables de groupe) et des\nobservations.\nPar exemple, pour compter le nombre de communes par d√©partement en SQL, on\nutiliserait la requ√™te suivante :\nSELECT dep, count(INSEE commune)\nFROM df\nGROUP BY dep;\nCe qui, en pandas, donne:\n\ndf.groupby(\"dep\")[\"INSEE commune\"].count()\n\ndep\n01    410\n02    805\n03    318\n04    199\n05    168\n     ... \n91    196\n92     36\n93     40\n94     47\n95    185\nName: INSEE commune, Length: 96, dtype: int64\n\n\nLa syntaxe est quasiment transparente. On peut bien s√ªr effectuer des op√©rations\npar groupe sur plusieurs colonnes. Par exemple,\n\ndf.groupby(\"dep\").mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\ndep\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01\n1974.535382\n100.307344\n8.900375\n1736.353087\n671.743966\n280.485435\n1744.567552\n1346.982227\n3988.658995\n1021.089078\n\n\n02\n1585.417729\n202.878748\n17.390638\n767.072924\n223.907551\n76.316247\n932.135611\n793.615867\n1722.240298\n403.744266\n\n\n03\n6132.029417\n240.076499\n45.429978\n1779.630883\n349.746819\n326.904841\n1452.423506\n1401.650215\n3662.773062\n705.937016\n\n\n04\n1825.455590\n177.321816\nNaN\n583.198128\n253.975910\n62.808435\n313.913553\n587.116013\n1962.654370\n493.609329\n\n\n05\n1847.508592\n141.272766\nNaN\n502.012857\n132.548068\n34.971220\n102.649239\n728.734494\n2071.010178\n463.604908\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n91\n802.793163\n10114.998156\n73976.107892\n3716.906101\n1496.516194\n538.761253\n1880.810170\n6532.123033\n10578.452789\n3866.757200\n\n\n92\n8.309835\n362.964554\n13.132461\n29663.579634\n7347.163353\n6745.611611\n19627.706224\n40744.279029\n33289.456629\n23222.587595\n\n\n93\n50.461775\n1753.443710\n61188.896632\n18148.789684\n6304.173594\n2570.941598\n10830.409025\n32911.305703\n35818.236459\n21575.444794\n\n\n94\n48.072971\n5474.808839\n16559.384091\n14710.744314\n4545.099181\n1624.281505\n9940.192318\n28444.561597\n24881.531613\n16247.876321\n\n\n95\n609.172047\n682.143912\n37984.576873\n3408.871963\n1334.032970\n463.860672\n1729.692179\n6684.181989\n8325.948748\n4014.985843\n\n\n\n\n96 rows √ó 10 columns\n\n\n\n\nA noter que la variable de groupe, ici dep, devient, par d√©faut, l‚Äôindex\ndu DataFrame de sortie. Si on avait utilis√© plusieurs variables de groupe,\non obtiendrait un objet multi-index√©. Sur la gestion des multi-index, on\npourra se r√©f√©rer √† l‚Äôouvrage Modern Pandas dont la r√©f√©rence est\ndonn√©e en fin de cours.\nTant qu‚Äôon n‚Äôappelle pas une action sur un DataFrame par groupe, du type\nhead ou display, pandas n‚Äôeffectue aucune op√©ration. On parle de\nlazy evaluation. Par exemple, le r√©sultat de df.groupby('dep') est\nune transformation qui n‚Äôest pas encore √©valu√©e :\n\ndf.groupby(\"dep\")\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f0784779b50&gt;\n\n\nIl est possible d‚Äôappliquer plus d‚Äôune op√©ration √† la fois gr√¢ce √† la m√©thode\nagg. Par exemple, pour obtenir √† la fois le minimum, la m√©diane et le maximum\nde chaque d√©partement, on peut faire:\n\nnumeric_columns = df.select_dtypes([\"number\"]).columns\ndf.loc[:, numeric_columns.tolist() + [\"dep\"]].groupby(\"dep\").agg(\n    [\"min\", \"median\", \"max\"], numeric_only=True\n)\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\n...\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\n...\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\n\n\ndep\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01\n0.003432\n1304.519570\n14402.057335\n3.307596\n75.686090\n617.281080\n0.297256\n6.985161\n2.209492e+01\n30.571400\n...\n175185.892467\n9.607822\n351.182294\n57689.832901\n20.848982\n1598.934149\n45258.256406\n10.049230\n401.490676\n30847.366865\n\n\n02\n0.391926\n1205.725078\n13257.716591\n0.326963\n130.054615\n1126.961565\n0.517437\n15.492120\n5.799402e+01\n28.294993\n...\n220963.067245\n7.849347\n138.819865\n99038.124236\n22.936184\n700.826152\n49245.101730\n6.220952\n130.639994\n34159.345750\n\n\n03\n5.041238\n5382.194339\n24912.249269\n24.158870\n144.403590\n1433.217868\n29.958027\n42.762328\n8.269019e+01\n44.825515\n...\n154061.446374\n19.441088\n217.959697\n75793.882483\n120.667614\n1426.905646\n40957.845304\n17.705787\n191.892445\n31099.772884\n\n\n04\n30.985972\n1404.752852\n11423.535554\n33.513854\n158.780500\n362.637639\nNaN\nNaN\nNaN\n7.162928\n...\n16889.531061\n1.708652\n133.130946\n18088.189529\n30.206298\n687.390045\n31438.078325\n0.957070\n122.504902\n16478.024806\n\n\n05\n38.651727\n1520.896526\n13143.465812\n0.299734\n139.754980\n456.042002\nNaN\nNaN\nNaN\n20.931602\n...\n4271.129851\n6.871678\n211.945147\n46486.555748\n57.132270\n958.506314\n37846.651181\n4.785348\n151.695524\n23666.235898\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n91\n0.400740\n516.908303\n5965.349174\n25.785594\n177.177127\n513140.971691\n1.651873\n14.762210\n7.858782e+05\n41.661474\n...\n50288.560827\n15.886514\n2580.902085\n48464.979708\n20.260110\n3610.009634\n72288.020125\n36.368643\n1428.426303\n38296.204729\n\n\n92\n0.073468\n6.505185\n32.986132\n7.468879\n297.529178\n1250.483441\n1.104401\n11.482381\n3.423467e+01\n2173.614704\n...\n95840.512400\n4122.277198\n33667.904692\n92216.971456\n4968.382962\n23516.458236\n113716.853033\n800.588678\n18086.633085\n65043.364499\n\n\n93\n3.308495\n3.308495\n1362.351634\n24.188172\n320.755486\n45251.869710\n0.171075\n12.449476\n1.101146e+06\n899.762120\n...\n89135.302368\n4364.038661\n31428.227282\n87927.730552\n1632.496185\n22506.758771\n193039.792609\n2257.370945\n20864.923339\n71918.163984\n\n\n94\n1.781885\n1.781885\n556.939161\n6.249609\n294.204166\n103252.271268\n0.390223\n14.944807\n1.571965e+05\n928.232154\n...\n96716.055178\n2668.358896\n24372.900300\n100948.169898\n1266.101605\n19088.651049\n97625.957714\n1190.115985\n14054.223449\n58528.623477\n\n\n95\n8.779506\n445.279844\n2987.287417\n1.749091\n80.838639\n44883.982753\n0.201508\n13.149987\n1.101131e+06\n13.490977\n...\n66216.914749\n11.585833\n1434.343631\n104543.465908\n2.619451\n3417.197938\n147040.904455\n11.484835\n725.467969\n61497.821477\n\n\n\n\n96 rows √ó 30 columns\n\n\n\n\nLa premi√®re ligne est pr√©sente pour nous faciliter la r√©cup√©ration des noms de colonnes des variables\nnum√©riques",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#appliquer-des-fonctions",
    "href": "content/manipulation/02a_pandas_tutorial.html#appliquer-des-fonctions",
    "title": "Introduction √† Pandas",
    "section": "6.5 Appliquer des fonctions",
    "text": "6.5 Appliquer des fonctions\npandas est, comme on a pu le voir, un package tr√®s flexible, qui\npropose une grande vari√©t√© de m√©thodes optimis√©es. Cependant, il est fr√©quent\nd‚Äôavoir besoin de m√©thodes non impl√©ment√©es.\nDans ce cas, on recourt souvent aux lambda functions. Par exemple, si\non d√©sire conna√Ætre les communes dont le nom fait plus de 40 caract√®res,\non peut appliquer la fonction len de mani√®re it√©rative:\n\n# Noms de communes superieurs √† 40 caracteres\ndf[df[\"Commune\"].apply(lambda s: len(s) &gt; 40)]\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\n\n\n\n\n28082\n70058\nBEAUJEU-SAINT-VALLIER-PIERREJUX-ET-QUITTEUR\n4024.909815\n736.948351\n41.943384\n1253.135313\n125.101996\n2.354558\n6.911213\n549.734302\n1288.215480\n452.693897\n70\n\n\n4984\n14621\nSAINT-MARTIN-DE-BIENFAITE-LA-CRESSONNIERE\n1213.333523\nNaN\nNaN\n677.571743\n72.072503\n63.573059\n186.602760\n298.261044\n1396.353375\n260.801452\n14\n\n\n19276\n51513\nSAINT-REMY-EN-BOUZEMONT-SAINT-GENEST-ET-ISSON\n1927.401921\nNaN\nNaN\n595.583152\n71.675773\n4.709115\n13.822427\n273.826687\n521.864748\n259.365848\n51\n\n\n5402\n16053\nBORS (CANTON DE BAIGNES-SAINTE-RADEGONDE)\n1919.249545\nNaN\nNaN\n165.443226\n16.265904\n2.354558\n6.911213\n54.561623\n719.293151\n58.859777\n16\n\n\n\n\n\n\n\n\nCependant, toutes les lambda functions ne se justifient pas.\nPar exemple, prenons\nle r√©sultat d‚Äôagr√©gation pr√©c√©dent. Imaginons qu‚Äôon d√©sire avoir les r√©sultats\nen milliers de tonnes. Dans ce cas, le premier r√©flexe est d‚Äôutiliser\nla lambda function suivante :\n\nnumeric_columns = df.select_dtypes([\"number\"]).columns\n(\n    df.loc[:, numeric_columns.tolist() + [\"dep\"]]\n    .groupby(\"dep\")\n    .agg([\"min\", \"median\", \"max\"])\n    .apply(lambda s: s / 1000)\n)\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\n...\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\n...\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\nmin\nmedian\nmax\n\n\ndep\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01\n0.000003\n1.304520\n14.402057\n0.003308\n0.075686\n0.617281\n0.000297\n0.006985\n0.022095\n0.030571\n...\n175.185892\n0.009608\n0.351182\n57.689833\n0.020849\n1.598934\n45.258256\n0.010049\n0.401491\n30.847367\n\n\n02\n0.000392\n1.205725\n13.257717\n0.000327\n0.130055\n1.126962\n0.000517\n0.015492\n0.057994\n0.028295\n...\n220.963067\n0.007849\n0.138820\n99.038124\n0.022936\n0.700826\n49.245102\n0.006221\n0.130640\n34.159346\n\n\n03\n0.005041\n5.382194\n24.912249\n0.024159\n0.144404\n1.433218\n0.029958\n0.042762\n0.082690\n0.044826\n...\n154.061446\n0.019441\n0.217960\n75.793882\n0.120668\n1.426906\n40.957845\n0.017706\n0.191892\n31.099773\n\n\n04\n0.030986\n1.404753\n11.423536\n0.033514\n0.158781\n0.362638\nNaN\nNaN\nNaN\n0.007163\n...\n16.889531\n0.001709\n0.133131\n18.088190\n0.030206\n0.687390\n31.438078\n0.000957\n0.122505\n16.478025\n\n\n05\n0.038652\n1.520897\n13.143466\n0.000300\n0.139755\n0.456042\nNaN\nNaN\nNaN\n0.020932\n...\n4.271130\n0.006872\n0.211945\n46.486556\n0.057132\n0.958506\n37.846651\n0.004785\n0.151696\n23.666236\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n91\n0.000401\n0.516908\n5.965349\n0.025786\n0.177177\n513.140972\n0.001652\n0.014762\n785.878155\n0.041661\n...\n50.288561\n0.015887\n2.580902\n48.464980\n0.020260\n3.610010\n72.288020\n0.036369\n1.428426\n38.296205\n\n\n92\n0.000073\n0.006505\n0.032986\n0.007469\n0.297529\n1.250483\n0.001104\n0.011482\n0.034235\n2.173615\n...\n95.840512\n4.122277\n33.667905\n92.216971\n4.968383\n23.516458\n113.716853\n0.800589\n18.086633\n65.043364\n\n\n93\n0.003308\n0.003308\n1.362352\n0.024188\n0.320755\n45.251870\n0.000171\n0.012449\n1101.145545\n0.899762\n...\n89.135302\n4.364039\n31.428227\n87.927731\n1.632496\n22.506759\n193.039793\n2.257371\n20.864923\n71.918164\n\n\n94\n0.001782\n0.001782\n0.556939\n0.006250\n0.294204\n103.252271\n0.000390\n0.014945\n157.196520\n0.928232\n...\n96.716055\n2.668359\n24.372900\n100.948170\n1.266102\n19.088651\n97.625958\n1.190116\n14.054223\n58.528623\n\n\n95\n0.008780\n0.445280\n2.987287\n0.001749\n0.080839\n44.883983\n0.000202\n0.013150\n1101.131222\n0.013491\n...\n66.216915\n0.011586\n1.434344\n104.543466\n0.002619\n3.417198\n147.040904\n0.011485\n0.725468\n61.497821\n\n\n\n\n96 rows √ó 30 columns\n\n\n\n\nEn effet, cela effectue le r√©sultat d√©sir√©. Cependant, il y a mieux : utiliser\nla m√©thode div:\n\nimport timeit\ndf_numeric = df.loc[:, numeric_columns.tolist() + [\"dep\"] ]\n%timeit df_numeric.groupby('dep').agg(['min',\"median\",\"max\"]).div(1000)\n%timeit df_numeric.groupby('dep').agg(['min',\"median\",\"max\"]).apply(lambda s: s/1000)\n\nLa m√©thode div est en moyenne plus rapide et a un temps d‚Äôex√©cution\nmoins variable. Dans ce cas, on pourrait m√™me utiliser le principe\ndu broadcasting de numpy (cf.¬†chapitre numpy) qui offre\ndes performances √©quivalentes:\n\n%timeit df_numeric.groupby('dep').agg(['min',\"median\",\"max\"])/1000\n\napply est plus rapide qu‚Äôune boucle (en interne, apply utilise Cython\npour it√©rer) mais reste moins rapide qu‚Äôune solution vectoris√©e quand\nelle existe. Ce site\npropose des solutions, par exemple les m√©thodes isin ou digitize, pour\n√©viter de manuellement cr√©er des boucles lentes.\nEn particulier, il faut noter que apply avec le param√®tre axis=1 est en g√©n√©rale lente.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#les-pipe",
    "href": "content/manipulation/02a_pandas_tutorial.html#les-pipe",
    "title": "Introduction √† Pandas",
    "section": "9.1 Les pipe",
    "text": "9.1 Les pipe\nEn g√©n√©ral, dans un projet, le nettoyage de donn√©es va consister en un ensemble de\nm√©thodes appliqu√©es √† un pandas.DataFrame.\nOn a vu que assign permettait de cr√©er une variable dans un DataFrame.\nIl est √©galement possible d‚Äôappliquer une fonction, appel√©e par exemple my_udf au\nDataFrame gr√¢ce √† pipe:\ndf = pd.read_csv(path2data).pipe(my_udf)\nL‚Äôutilisation des pipe rend le code tr√®s lisible et peut √™tre tr√®s\npratique lorsqu‚Äôon enchaine des op√©rations sur le m√™me\ndataset.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#quelques-enjeux-de-performance",
    "href": "content/manipulation/02a_pandas_tutorial.html#quelques-enjeux-de-performance",
    "title": "Introduction √† Pandas",
    "section": "9.2 Quelques enjeux de performance",
    "text": "9.2 Quelques enjeux de performance\nLa librairie Dask int√®gre la structure de numpy, pandas et sklearn.\nElle a vocation √† traiter de donn√©es en grande dimension, ainsi elle ne sera pas\noptimale pour des donn√©es qui tiennent tr√®s bien en RAM.\nIl s‚Äôagit d‚Äôune librairie construite sur la parall√©lisation.\nUn chapitre dans ce cours lui est consacr√©.\nPour aller plus loin, se r√©f√©rer √† la documentation de Dask.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#informations-additionnelles",
    "href": "content/manipulation/02a_pandas_tutorial.html#informations-additionnelles",
    "title": "Introduction √† Pandas",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\nc03aa61\n\n\n2024-01-16 17:33:18\n\n\nLino Galiana\n\n\nExercice sur les chemins relatifs (#483)\n\n\n\n\n056c606\n\n\n2023-12-20 20:08:25\n\n\nlinogaliana\n\n\nChange pandas image\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\ncef6a0d\n\n\n2023-10-18 13:18:46\n\n\nLino Galiana\n\n\nAll√®gement des actions github (#437)\n\n\n\n\n97676f5\n\n\n2023-10-14 17:56:44\n\n\nLino Galiana\n\n\nDu style pour le site (#434)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nac80862\n\n\n2023-10-07 21:05:25\n\n\nLino Galiana\n\n\nRelecture antuki (#427)\n\n\n\n\n7e03cea\n\n\n2023-10-04 14:07:17\n\n\nLino Galiana\n\n\nClean pandas tutorial and exercises (#417)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nc312bdc\n\n\n2023-08-11 18:06:25\n\n\nLino Galiana\n\n\nA few controls for Quarto website (#389)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\ndde3e93\n\n\n2023-07-21 22:22:05\n\n\nLino Galiana\n\n\nFix bug on chapter order (#385)\n\n\n\n\n3560f1f\n\n\n2023-07-21 17:04:56\n\n\nLino Galiana\n\n\nBuild on smaller sized image (#384)\n\n\n\n\nf146354\n\n\n2023-07-21 18:15:10\n\n\nLino Galiana\n\n\nUpdate index.qmd\n\n\n\n\nf6dde33\n\n\n2023-07-18 22:32:00\n\n\nLino Galiana\n\n\nChange badges (#376)\n\n\n\n\n143e706\n\n\n2023-07-18 19:37:28\n\n\nLino Galiana\n\n\nAm√©liore la navigation (#375)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\n64baaf8\n\n\n2023-07-03 17:05:53\n\n\nLino Galiana\n\n\nScript for branch deploy (#367)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n867325e\n\n\n2023-06-11 13:56:43\n\n\nLino Galiana\n\n\nAdd numeric_only argument (#359)\n\n\n\n\n9918817\n\n\n2022-12-30 15:10:59\n\n\nLino Galiana\n\n\nRetour sur le chapitre DallE / StableDiffusion (#344)\n\n\n\n\n94e7c0a\n\n\n2022-12-29 09:42:35\n\n\nLino Galiana\n\n\npip install pynsee (#342)\n\n\n\n\na8dd720\n\n\n2022-12-26 21:35:52\n\n\nLino Galiana\n\n\nImprove aesthetics on Github (#338)\n\n\n\n\ne2b53ac\n\n\n2022-09-28 17:09:31\n\n\nLino Galiana\n\n\nRetouche les chapitres pandas (#287)\n\n\n\n\neb8f922\n\n\n2022-09-22 17:40:43\n\n\nLino Galiana\n\n\nCorrige bug TP pandas (#276)\n\n\n\n\nfd439f0\n\n\n2022-09-19 09:37:50\n\n\navouacr\n\n\nfix ssp cloud links\n\n\n\n\n3056d41\n\n\n2022-09-02 12:19:55\n\n\navouacr\n\n\nfix all SSP Cloud launcher links\n\n\n\n\n8042a16\n\n\n2022-08-24 16:23:36\n\n\nLino Galiana\n\n\nBox pour les notebooks :sparkles: (#256)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n2360ff7\n\n\n2022-08-02 16:29:57\n\n\nLino Galiana\n\n\nTest wowchemy update (#247)\n\n\n\n\nd3a5406\n\n\n2022-06-27 17:44:30\n\n\nLino Galiana\n\n\nUtilisation test du syst√®me de r√©f√©rence de quarto (#240)\n\n\n\n\n1239e3e\n\n\n2022-06-21 14:05:15\n\n\nLino Galiana\n\n\nEnonces (#239)\n\n\n\n\n48606dd\n\n\n2022-05-31 19:05:11\n\n\nLino Galiana\n\n\nAm√©lioration rendu dataframe pandas (#229)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n5cac236\n\n\n2021-12-16 19:46:43\n\n\nLino Galiana\n\n\nun petit mot sur mercator (#201)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n5ad057f\n\n\n2021-10-10 15:13:16\n\n\nLino Galiana\n\n\nRelectures pandas & geopandas (#159)\n\n\n\n\n4870662\n\n\n2021-10-05 08:29:33\n\n\nRomain Avouac\n\n\nfix and simplify pyinsee install (#157)\n\n\n\n\n0677932\n\n\n2021-10-03 15:32:51\n\n\nLino Galiana\n\n\nAjoute un code pour download pynsee (#156)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4a317e3\n\n\n2021-08-31 12:38:17\n\n\nLino Galiana\n\n\npynsee pour importer des donn√©es Insee üöÄ (#127)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n175d377\n\n\n2021-05-04 18:29:26\n\n\nRaphaele Adjerad\n\n\nQuelques manipulations suppl√©mentaires pandas (#106)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n76e206c\n\n\n2020-09-09 18:02:08\n\n\nLino Galiana\n\n\nFinalisation du chapitre pandas (#24)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n85365ca\n\n\n2020-09-05 14:50:10\n\n\nlinogaliana\n\n\najout badges onyxia\n\n\n\n\n611be4d\n\n\n2020-09-05 14:27:47\n\n\nlinogaliana\n\n\nmodifs marginales\n\n\n\n\n0559398\n\n\n2020-09-05 14:22:55\n\n\nlinogaliana\n\n\nmodifs marginales\n\n\n\n\n9c12c2c\n\n\n2020-09-04 17:39:09\n\n\nLino Galiana\n\n\nIntroduction √† pandas (#11)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nCheasheet Pandas\nStructuration d‚Äôun DataFrame Pandas,\nemprunt√©e √† https://medium.com/epfl-extension-school/selecting-data-from-a-pandas-dataframe-53917dc39953\nIllustration du concept de tidy data (emprunt√© √† H. Wickham)\nR√©ordonner le DataFrame\nSplit-apply-combine",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#footnotes",
    "href": "content/manipulation/02a_pandas_tutorial.html#footnotes",
    "title": "Introduction √† Pandas",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA vrai dire, ce n‚Äôest pas l‚Äôempreinte carbone\npuisque la base de donn√©es correspond √† une vision production,\npas consommation. Les √©missions faites dans une commune pour satisfaire\nla consommation d‚Äôune autre seront imput√©es √† la premi√®re l√†\no√π le concept d‚Äôempreinte carbone voudrait qu‚Äôon l‚Äôimpute\naux secondes. Il ne s‚Äôagit pas, avec cet exercice, de construire une\nstatistique fiable mais plut√¥t de comprendre la logique de\nl‚Äôassociation de donn√©es pour construire des statistiques descriptives.‚Ü©Ô∏é\nSur l‚Äôappariement flou, se reporter aux chapitres pr√©sentant ElasticSearch.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html",
    "href": "content/manipulation/03_geopandas_tutorial.html",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nDans ce tutoriel, nous allons utiliser les donn√©es suivantes :\nLa repr√©sentation des donn√©es, notamment la cartographie, est pr√©sent√©e plus\namplement dans la partie visualiser. Quelques m√©thodes\npour faire rapidement des cartes seront pr√©sent√©es ici, mais\nl‚Äôobjet de ce chapitre porte davantage sur la manipulation des donn√©es g√©ographiques.\nCe tutoriel s‚Äôinspire beaucoup d‚Äôun autre tutoriel que j‚Äôai fait pour\nR disponible\ndans la documentation utilitr.\nIl peut servir de pendant √† celui-ci pour l‚Äôutilisateur de R.\nQuelques installations pr√©alables sont n√©cessaires :\n!pip install pandas fiona shapely pyproj rtree # √† faire obligatoirement en premier pour utiliser rtree ou pygeos pour les jointures spatiales\n!pip install contextily\n!pip install geopandas\n!pip install topojson\nPour √™tre en mesure d‚Äôex√©cuter ce tutoriel, les imports suivants\nseront utiles.\nimport geopandas as gpd\nimport contextily as ctx\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#quelle-diff√©rence-avec-des-donn√©es-traditionnelles",
    "href": "content/manipulation/03_geopandas_tutorial.html#quelle-diff√©rence-avec-des-donn√©es-traditionnelles",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "1.1 Quelle diff√©rence avec des donn√©es traditionnelles ?",
    "text": "1.1 Quelle diff√©rence avec des donn√©es traditionnelles ?\nLe terme ‚Äúdonn√©es spatiales‚Äù d√©signe les donn√©es qui portent sur les caract√©ristiques g√©ographiques des objets (localisation, contours, liens).\nLes caract√©ristiques g√©ographiques des objets sont d√©crites √† l‚Äôaide d‚Äôun syst√®me de coordonn√©es\nqui permettent une repr√©sentation dans un espace euclidien \\((x,y)\\).\nLe passage de l‚Äôespace r√©el (la Terre, qui est une sph√®re) √† l‚Äôespace plan\nse fait gr√¢ce √† un syst√®me de projection. Voici quelques exemples\nde donn√©es spatiales :\n\nUne table d√©crivant des b√¢timents, avec les coordonn√©es g√©ographiques de chaque b√¢timent ;\nLe d√©coupage communal du territoire, avec le contour du territoire de chaque commune ;\nLes routes terrestres, avec les coordonn√©es d√©crivant leur parcours en 3 dimensions (longitude, latitude, altitude).\n\nLes donn√©es spatiales rassemblent classiquement deux types de donn√©es :\n\ndes donn√©es g√©ographiques (ou g√©om√©tries) : objets g√©om√©triques tels que des points, des vecteurs, des polygones, ou des maillages (raster). Exemple: la forme de chaque commune, les coordonn√©es d‚Äôun b√¢timent;\ndes donn√©es attributaires (ou attributs) : des mesures et des caract√©ristiques associ√©es aux objets g√©om√©triques. Exemple: la population de chaque commune, le nombre de fen√™tres et le nombre d‚Äô√©tages d‚Äôun b√¢timent.\n\nLes donn√©es spatiales sont fr√©quemment trait√©es √† l‚Äôaide d‚Äôun syst√®me d‚Äôinformation g√©ographique (SIG), c‚Äôest-√†-dire un syst√®me d‚Äôinformation capable de stocker, d‚Äôorganiser et de pr√©senter des donn√©es alphanum√©riques spatialement r√©f√©renc√©es par des coordonn√©es dans un syst√®me de r√©f√©rence (CRS). Python dispose de fonctionnalit√©s lui permettant de r√©aliser les m√™mes t√¢ches qu‚Äôun SIG (traitement de donn√©es spatiales, repr√©sentations cartographiques).",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#de-pandas-√†-geopandas",
    "href": "content/manipulation/03_geopandas_tutorial.html#de-pandas-√†-geopandas",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "1.2 De Pandas √† Geopandas",
    "text": "1.2 De Pandas √† Geopandas\nLe package Geopandas est une bo√Æte √† outils con√ßue pour faciliter la manipulation de donn√©es spatiales. La grande force de Geopandas est qu‚Äôil permet de manipuler des donn√©es spatiales comme s‚Äôil s‚Äôagissait de donn√©es traditionnelles, car il repose sur le standard ISO 19125 simple feature access d√©fini conjointement par l‚ÄôOpen Geospatial Consortium (OGC) et l‚ÄôInternational Organization for Standardization (ISO).\nPar rapport √† un DataFrame standard, un objet Geopandas comporte\nune colonne suppl√©mentaire: geometry. Elle stocke les coordonn√©es des\nobjets g√©ographiques (ou ensemble de coordonn√©es s‚Äôagissant de contours). Un objet Geopandas h√©rite des propri√©t√©s d‚Äôun\nDataFrame Pandas mais propose des m√©thodes adapt√©es au traitement des donn√©es spatiales.\nAinsi, gr√¢ce √† Geopandas, on pourra effectuer des manipulations sur les attributs des donn√©es comme avec pandas mais on pourra √©galement faire des manipulations sur la dimension spatiale des donn√©es. En particulier,\n\nCalculer des distances et des surfaces ;\nAgr√©ger rapidement des zonages (regrouper les communes en d√©partement par exemple) ;\nTrouver dans quelle commune se trouve un b√¢timent √† partir de ses coordonn√©es g√©ographiques ;\nRecalculer des coordonn√©es dans un autre syst√®me de projection ;\nFaire une carte, rapidement et simplement.\n\n\n\n Hint\nLes manipulations de donn√©es sur un objet Geopandas sont nettement plus lentes que sur\nun DataFrame traditionnel (car Python doit g√©rer les informations g√©ographiques pendant la manipulation des donn√©es).\nLorsque vous manipulez des donn√©es de grandes dimensions,\nil peut √™tre pr√©f√©rable d‚Äôeffectuer les op√©rations sur les donn√©es avant de joindre une g√©om√©trie √† celles-ci.\n\n\nPar rapport √† un logiciel sp√©cialis√© comme QGIS, Python permettra\nd‚Äôautomatiser le traitement et la repr√©sentation des donn√©es. D‚Äôailleurs,\nQGIS utilise lui-m√™me Python‚Ä¶",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#r√©sum√©",
    "href": "content/manipulation/03_geopandas_tutorial.html#r√©sum√©",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "1.3 R√©sum√©",
    "text": "1.3 R√©sum√©\nEn r√©sum√©, un objet GeoPandas comporte les √©l√©ments suivantes :\n\n\nLes attributs. Ce sont les valeurs associ√©es √† chaque niveau g√©ographique.\nIl s‚Äôagit de la dimension tabulaire usuelle, dont le traitement est similaire\n√† celui d‚Äôun objet Pandas classique.\nLes g√©om√©tries. Ce sont les valeurs num√©riques interpr√©t√©es pour repr√©senter la dimension g√©ographique. Elles permettent de repr√©senter dans un certain\nr√©f√©rentiel (le syst√®me de r√©f√©rence) la dimension g√©ographique.\nLe syst√®me de r√©f√©rence. Il s‚Äôagit du syst√®me permettant de transformer les positions sur\nle globe (3 dimensions avec une boule asym√©trique) en un plan en deux dimensions.\nIl en existe une multitude, identifiables √† partir d‚Äôun code EPSG (4326, 2154‚Ä¶).\nLeur manipulation est facilit√©e par Geopandas qui s‚Äôappuie sur Shapely, de la m√™me\nmani√®re que Pandas s‚Äôappuie sur Numpy ou Arrow.",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#principe",
    "href": "content/manipulation/03_geopandas_tutorial.html#principe",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "2.1 Principe",
    "text": "2.1 Principe\nLes donn√©es spatiales sont\nplus riches que les donn√©es traditionnelles car elles\nincluent, habituellement, des √©l√©ments suppl√©mentaires pour placer dans\nun espace cart√©sien les objets. Cette dimension suppl√©mentaire peut √™tre simple\n(un point comporte deux informations suppl√©mentaire: \\(x\\) et \\(y\\)) ou\nassez complexe (polygones, lignes avec direction, etc.).\nL‚Äôanalyse cartographique emprunte d√®s lors √† la g√©om√©trie\ndes concepts\npour repr√©senter des objets dans l‚Äôespace. Les projections\nsont au coeur de la gestion des donn√©es spatiales.\nCes derni√®res consistent √† transformer une position dans l‚Äôespace\nterrestre √† une position sur un plan. Il s‚Äôagit donc d‚Äôune op√©ration\nde projection d‚Äôun espace tri-dimensionnel dans un espace\n√† deux dimensions.\nCe post propose de riches √©l√©ments sur le\nsujet, notamment l‚Äôimage suivante qui montre bien le principe d‚Äôune projection :\n\n\n\nLes diff√©rents types de projection\n\n\nCette op√©ration n‚Äôest pas neutre. L‚Äôune des cons√©quences du\nth√©or√®me remarquable de Gauss\nest que la surface de la Terre ne peut √™tre cartographi√©e sans distortion.\nUne projection ne peut simultan√©ment conserver intactes les distances et les\nangles (i.e.¬†les positions).\nIl n‚Äôexiste ainsi pas de projection universellement meilleure, ce qui ouvre\nla porte √† la coexistence de nombreuses projections diff√©rentes, pens√©es\npour des t√¢ches diff√©rentes.\nUn mauvais syst√®me de repr√©sentation\nfausse l‚Äôappr√©ciation visuelle mais peut aussi entra√Æner des erreurs dans\nles calculs sur la dimension spatiale.\nLes syst√®mes de projection font l‚Äôobjet de standards internationaux et sont souvent d√©sign√©s par des codes dits codes EPSG. Ce site est un bon aide-m√©moire. Les plus fr√©quents, pour les utilisateurs fran√ßais, sont les suivants (plus d‚Äôinfos ici) :\n\n2154 : syst√®me de projection Lambert 93. Il s‚Äôagit du syst√®me de projection officiel. La plupart des donn√©es diffus√©es par l‚Äôadministration pour la m√©tropole sont disponibles dans ce syst√®me de projection.\n27572 : Lambert II √©tendu. Il s‚Äôagit de l‚Äôancien syst√®me de projection officiel. Les donn√©es spatiales anciennes peuvent √™tre dans ce format.\n4326 : WGS 84 ou syst√®me de pseudo-Mercator ou encore Web Mercator. Ce n‚Äôest en r√©alit√© pas un syst√®me de projection mais un syst√®me de coordonn√©es (longitude / latitude) qui permet simplement un rep√©rage angulaire sur l‚Äôellipso√Øde. Il est utilis√© pour les donn√©es GPS. Il s‚Äôagit du syst√®me le plus\nusuel, notamment quand on travaille avec des fonds de carte web.\n\nComme √©voqu√© plus haut, l‚Äôune des projections les plus connues est la\nprojection Web Mercator dite WGS84 (code EPSG 4326). Il\ns‚Äôagit d‚Äôune projection conservant intacte les angles, ce\nqui implique qu‚Äôelle alt√®re les distances. Celle-ci a en effet √©t√©\npens√©e, √† l‚Äôorigine, pour repr√©senter l‚Äôh√©misph√®re Nord. Plus\non s‚Äô√©loigne de celui-ci, plus les distances sont distordues. Cela\nam√®ne √† des distorsions bien\nconnues (le Groenland hypertrophi√©, l‚ÄôAfrique de taille r√©duite, l‚ÄôAntarctique d√©mesur√©‚Ä¶).\nEn revanche, la projection Mercator conserve intacte les positions.\nC‚Äôest cette propri√©t√© qui explique son utilisation dans les syst√®mes\nGPS et ainsi dans les fonds de carte de navigation du type Google Maps.\n\n\n\nExemple de reprojection de pays depuis le site thetruesize.com\n\n\nObservez les variations significatives\nde proportions pour certains pays selon les projections\nchoisies:\n\nhtml`&lt;div&gt;${container_projection}&lt;/div&gt;`\n\n\n\n\n\n\n\ncontainer_projection = html`&lt;div class=\"container\"&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projection\"&gt;\n      &lt;div class=\"projection-label\"&gt;Choisir une projection&lt;/div&gt;\n      ${viewof projection}\n    &lt;/div&gt;\n  &lt;/div&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projectedMap\"&gt;\n      ${projectedMap}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\nviewof projection = projectionInput({\n  name: \"\",\n  value: \"Mercator\"\n})\n\n\n\n\n\n\n\nimport {projectionInput} from \"@fil/d3-projections\"\nimport {map} from \"@linogaliana/base-map\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprojectedMap = map(projection,\n                   {\n                     //svg: true,\n                     value: projection.options,\n                     width: width_projected_map,\n                     //height: 300,\n                     //rotate: [0, -90],\n                     //inertia: true,\n                     show_equator: true,\n                     background: \"#f1f0eb\"\n                     \n                     //show_structure: true\n                   })\n\n\n\n\n\n\n\nwidth_projected_map = screen.width/2\n\n\n\n\n\n\nPour aller plus loin, la carte interactive\nsuivante, construite par Nicolas Lambert, issue de\nce notebook Observable, illustre l‚Äôeffet\nd√©formant de la projection Mercator, et de quelques-unes autres,\nsur notre perception de la taille des pays.\n\n\nVoir la carte interactive\n\n\nhtml`&lt;div class=\"grid-container\"&gt;\n  &lt;div class=\"viewof-projection\"&gt;${viewof projectionBertin}&lt;/div&gt;\n  &lt;div class=\"viewof-mycountry\"&gt;${viewof mycountry}&lt;/div&gt;\n  &lt;div class=\"map-bertin\"&gt;${mapBertin}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\nimport {map as mapBertin, viewof projection as projectionBertin, viewof mycountry} from \"@neocartocnrs/impact-of-projections-on-areas\"\n\n\n\n\n\n\nIl existe en fait de nombreuses repr√©sentations possibles du monde, plus ou moins\nalambiqu√©es. Les projections sont tr√®s nombreuses et certaines peuvent avoir une forme suprenante.\nPar exemple,\nla projection de Spillhaus\npropose de centrer la vue sur les oc√©ans et non une terre. C‚Äôest pour\ncette raison qu‚Äôon parle parfois de monde tel que vu par les poissons\n√† son propos.\n\nhtml`&lt;div class=\"centered\"&gt;${spilhaus}&lt;/div&gt;`\n\n\n\n\n\n\n\nspilhaus = {\n  const width = 600;\n  const height = width;\n\n  const context = DOM.context2d(width, height);\n  const projection = d3.geoStereographic()\n    .rotate([95, 45])\n    .translate([width / 2, height / 2])\n    .scale(width / 10.1)\n    .center([30, -5])\n    .clipAngle(166);\n  const path = d3.geoPath(projection, context);\n\n  const land = topojson.feature(world, world.objects.land);\n\n  context.lineJoin = \"round\";\n  context.lineCap = \"round\";\n  context.fillStyle = \"#f2f1ed\";\n  context.fillRect(0, 0, width, height);\n\n  context.beginPath();\n  path({type: \"Sphere\"});\n  path(land);\n  context.lineWidth = 0.5;\n  context.stroke();\n  context.clip(\"evenodd\");\n\n  context.save();\n  context.beginPath();\n  path(land);\n  context.filter = \"blur(12px)\";\n  context.fillStyle = \"#006994\";\n  context.fill(\"evenodd\");\n  context.restore();\n  \n  context.beginPath();\n  path(d3.geoGraticule10());\n  context.globalAlpha = 0.2;\n  context.strokeStyle = \"#000\";\n  context.stroke();\n\n  return context.canvas;\n}\n\n\n\n\n\n\n\n//import {map as spilhausmap} with {height, width} from \"@d3/spilhaus-shoreline-map\"\nimport { world } from \"@d3/spilhaus-shoreline-map\"\n\n\n\n\n\n\n\n\n Astuce pour la France\nPour la France, dans le syst√®me WGS84 (4326) :\n\nLongitude (\\(x\\)) tourne autour de 0¬∞ (de -5.2 √† +9.6 pour √™tre plus pr√©cis)\nLa latitude (\\(y\\)) autour de 45 (entre +41.3 √† +51.1)\n\nDans le syst√®me Lambert 93 (2154) :\n\nCoordonn√©es \\(x\\): entre 100 000 et 1 300 000\nLa latitude (\\(y\\)): entre 6 000 000 et 7 200 000\n\nPlus de d√©tails",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#exemple-r√©cup√©rer-les-d√©coupages-territoriaux",
    "href": "content/manipulation/03_geopandas_tutorial.html#exemple-r√©cup√©rer-les-d√©coupages-territoriaux",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "3.1 Exemple : r√©cup√©rer les d√©coupages territoriaux",
    "text": "3.1 Exemple : r√©cup√©rer les d√©coupages territoriaux\nL‚Äôun des fonds de carte les plus fr√©quents qu‚Äôon utilise est celui des\nlimites administratives des communes.\nCelui-ci peut √™tre r√©cup√©r√© de plusieurs mani√®res.\nEn premier lieu, pour r√©cup√©rer\nle fond de carte officiel, produit par l‚ÄôIGN, sous\nle nom d‚ÄôAdminExpress[^1],\nil est possible de se rendre sur le site de l‚ÄôIGN et de le t√©l√©charger.\nIl est √©galement possible d‚Äôutiliser l‚Äôune des API de l‚ÄôIGN\nmais ces derni√®res ne sont pas encore tr√®s document√©es pour des utilisateurs\nde Python.\nLe package cartiflette, issu\nd‚Äôun projet interminist√©riel, propose\nune r√©cup√©ration\nfacilit√©e de fonds de carte officiels de l‚ÄôIGN.\nCe projet vise √† faciliter la r√©cup√©ration des sources officielles, notamment\ncelles de l‚ÄôIGN, et leur association √† des jeux de donn√©es g√©ographiques.\n\n\n Note\nLe package cartiflette est exp√©rimental\net n‚Äôest disponible que sur\nGithub, pas sur PyPi.\nIl est amen√© √† √©voluer rapidement et cette page sera mise √† jour\nquand de nouvelles fonctionalit√©s (notamment l‚Äôutilisation d‚ÄôAPI)\nseront disponibles pour encore simplifier la r√©cup√©ration de\ncontours g√©ographiques.\nPour installer cartiflette, il est n√©cessaire d‚Äôutiliser les commandes suivantes\ndepuis un Jupyter Notebook (si vous utilisez la ligne de commande directement,\nvous pouvez retirer les ! en d√©but de ligne):\n\n!pip install requests py7zr geopandas openpyxl tqdm s3fs PyYAML xlrd\n!pip install git+https://github.com/inseefrlab/cartiflette\n\nCes commandes permettent de r√©cup√©rer l‚Äôensemble du code\nsource depuis Github\n\n\nIci, nous sommes int√©ress√©s par les contours des communes\nde la petite couronne. On pourrait d√©sirer r√©cup√©rer\nl‚Äôensemble de la r√©gion Ile-de-France mais nous\nallons nous contenter de l‚Äôanalyse de Paris intra-muros\net des d√©partements limitrophes.\nC‚Äôest l‚Äôun des avantage de cartiflette que de faciliter\nla r√©cup√©ration de fonds de carte sur un ensemble de d√©partement.\nCela √©vite la r√©cup√©ration d‚Äôun fond de carte tr√®s\nvolumineux (plus de 500Mo) pour une analyse restreinte (quelques d√©partements).\nUn autre avantage de cartiflette est de faciliter la r√©cup√©ration de fonds\nde carte consolid√©s comme celui dont on a besoin ici : arrondissements\ndans Paris, communes ailleurs. Comme cela est expliqu√© dans un encadr√© √† part,\nil s‚Äôagirait d‚Äôune op√©ration p√©nible √† mettre en oeuvre sans cartiflette.\nLes contours de cet espace peuvent √™tre r√©cup√©r√©s de la mani√®re suivante :\n\nfrom cartiflette import carti_download\n\nshp_communes = carti_download(\n    crs=4326,\n    values=[\"75\", \"92\", \"93\", \"94\"],\n    borders=\"COMMUNE_ARRONDISSEMENT\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\n\nshp_communes.head(3)\n\n\n\n\n\n\n\n\n\nINSEE_DEP\nINSEE_REG\nID\nNOM\nINSEE_COM\nSTATUT\nPOPULATION\nINSEE_COG\nARR\nCV\n...\nTAAV2017\nTDAAV2017\nCATEAAV2020\nBV2012\nLIBELLE_DEPARTEMENT\nLIBELLE_REGION\nPAYS\nSOURCE\ngeometry\nAREA\n\n\n\n\n0\n75\n11\nARR_MUNI0000000009736045\nParis 3e Arrondissement\n75056\nArrondissement municipal\n34025\n75103\n751\n75ZZ\n...\n5\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.35016 48.86199, 2.35350 48.86121, ...\nNaN\n\n\n1\n75\n11\nARR_MUNI0000000009736046\nParis 2e Arrondissement\n75056\nArrondissement municipal\n21595\n75102\n751\n75ZZ\n...\n5\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.34792 48.87069, 2.34004 48.87197, ...\nNaN\n\n\n2\n75\n11\nARR_MUNI0000000009736545\nParis 4e Arrondissement\n75056\nArrondissement municipal\n29131\n75104\n751\n75ZZ\n...\n5\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.36849 48.85581, 2.36828 48.85579, ...\nNaN\n\n\n\n\n3 rows √ó 27 columns\n\n\n\n\nOn reconna√Æt la structure d‚Äôun DataFrame Pandas. A cette structure s‚Äôajoute\nune colonne geometry qui enregistre la position des limites des polygones de chaque\nobservation.\nComme vu pr√©c√©demment, le syst√®me de projection est un √©l√©ment important. Il permet √† Python\nd‚Äôinterpr√©ter les valeurs des points (deux dimensions) en position sur\nla terre, qui n‚Äôest pas un espace plan.\n\nshp_communes.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nIci, les donn√©es sont dans le syst√®me WGS84 (code EPSG 4326).\nCe n‚Äôest pas le\nLambert-93 comme on pourrait s‚Äôy attendre, ce dernier\n√©tant le syst√®me l√©gal de projection pour la France\nm√©tropolitaine.\nPour s‚Äôassurer qu‚Äôon a bien r√©cup√©r√© les contours voulus,\non peut repr√©senter graphiquement\nles contours gr√¢ce √† la m√©thode plot sur laquelle nous\nreviendrons :\n\nax = shp_communes.boundary.plot()\nax.set_axis_off()\n\n\n\n\n\n\n\n\n\n\n Note\nSi on ne d√©sire pas utiliser le niveau COMMUNE_ARRONDISSEMENT,\nil est n√©cessaire de mettre en oeuvre une construction du fond de\ncarte en plusieurs phases. C‚Äôest une op√©ration un petit peu p√©nible, source d‚Äôerreur potentielle. Elle est illustr√©e ci-dessous mais il est donc recommand√© de privil√©gier le niveau\nCOMMUNE_ARRONDISSEMENT qui a √©t√© construit pour cela.\nEn premier lieu, il est n√©cessaire de r√©cup√©rer le niveau des communes.\n\nshp_communes = carti_download(\n    crs=4326,\n    values=[\"75\", \"92\", \"93\", \"94\"],\n    borders=\"COMMUNE\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\n\nshp_communes.head(4)\n\n\n\n\n\n\n\n\n\nINSEE_DEP\nINSEE_REG\nID\nNOM\nINSEE_COM\nSTATUT\nPOPULATION\nAREA\nARR\nCV\n...\nAAV2020\nTAAV2017\nTDAAV2017\nCATEAAV2020\nBV2012\nLIBELLE_DEPARTEMENT\nLIBELLE_REGION\nPAYS\nSOURCE\ngeometry\n\n\n\n\n0\n75\n11\nCOMMUNE_0000000009736048\nParis\n75056\nCapitale d'√©tat\n2165423\nmetropole\n751\n75ZZ\n...\n001\n5\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.36420 48.81640, 2.38077 48.82170, ...\n\n\n1\n92\n11\nCOMMUNE_0000000009736037\nLevallois-Perret\n92044\nCommune simple\n66082\nmetropole\n922\n9216\n...\n001\n5\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.28739 48.90364, 2.28427 48.90229, ...\n\n\n2\n92\n11\nCOMMUNE_0000000009736055\nBois-Colombes\n92009\nCommune simple\n28841\nmetropole\n922\n9211\n...\n001\n5\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.26639 48.90629, 2.26494 48.91027, ...\n\n\n3\n92\n11\nCOMMUNE_0000000009736538\nMalakoff\n92046\nCommune simple\n30950\nmetropole\n921\n9218\n...\n001\n5\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((2.27818 48.81425, 2.27449 48.81343, ...\n\n\n\n\n4 rows √ó 26 columns\n\n\n\n\n\nax = shp_communes.boundary.plot()\nax.set_axis_off()\n\n\n\n\n\n\n\n\nOn peut remarquer que la ville de Paris ne comporte pas d‚Äôarrondissements\nsur cette carte. Pour vous en convaincre, vous pouvez ex√©cuter la\ncommande :\n\nax = shp_communes.loc[shp_communes[\"INSEE_DEP\"] == \"75\"].boundary.plot()\nax.set_axis_off()\n\n\n\n\n\n\n\n\nIl faut donc utiliser une source compl√©mentaire.\nLe contour officiel des arrondissements est\nproduit par l‚ÄôIGN s√©paremment des contours de communes.\nLes contours d‚Äôarrondissements sont √©galement\ndisponibles\ngr√¢ce √† cartiflette:\n\narrondissements = carti_download(\n    crs=4326,\n    values=[\"75\"],\n    borders=\"COMMUNE_ARRONDISSEMENT\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\n\nax = arrondissements.boundary.plot(alpha=0.8, edgecolor=\"k\")\nax.set_axis_off()\n\n\n\n\n\n\n\n\nIl ne reste plus qu‚Äô√† remplacer Paris par\nses arrondissements dans shp_communes.\nPour cela, on peut utiliser les m√©thodes\nvues dans le chapitre Pandas relatives\naux filtres et √† la concat√©nation\nde plusieurs DataFrames:\n\nimport pandas as pd\n\nshp_communes = pd.concat(\n    [\n        shp_communes.loc[shp_communes[\"INSEE_DEP\"] != \"75\"].to_crs(2154),\n        arrondissements.to_crs(2154),\n    ]\n)\n\n\nax = shp_communes.boundary.plot(alpha=0.8, edgecolor=\"k\")\nax.set_axis_off()\n\n\n\n\n\n\n\n\nCette approche fonctionne mais elle n√©cessite un certain nombre\nde gestes, qui sont autant de risques d‚Äôerreurs. Il est\ndonc recommand√© de privil√©gier le niveau COMMUNE_ARRONDISSEMENT\nqui fait exactement ceci mais de mani√®re fiable.",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#import-des-donn√©es-v√©lib",
    "href": "content/manipulation/03_geopandas_tutorial.html#import-des-donn√©es-v√©lib",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "4.1 Import des donn√©es v√©lib",
    "text": "4.1 Import des donn√©es v√©lib\nSouvent, le d√©coupage communal ne sert qu‚Äôen fond de cartes, pour donner des\nrep√®res. En compl√©ment de celui-ci, on peut d√©sirer exploiter\nun autre jeu de donn√©es. On va partir des donn√©es de localisation des\nstations velib,\ndisponibles sur le site d‚Äôopen data de la ville de Paris et\nrequ√™tables directement par l‚Äôurl\nhttps://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr\n\nvelib_data = \"https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr\"\nstations = gpd.read_file(velib_data)\nstations.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nLes donn√©es sont dans le syst√®me de projection WGS84 qui est celui du\nsyst√®me GPS. Celui-ci s‚Äôint√®gre bien avec les fonds de carte\nOpenStreetMap ou Google Maps. En toute rigueur, si on\nd√©sire effectuer certains calculs g√©om√©triques (mesurer des surfaces‚Ä¶), il est\nn√©cessaire de re-projeter les donn√©es dans un syst√®me qui pr√©serve la g√©om√©trie\n(c‚Äôest le cas du Lambert 93).\nPour avoir une intuition de la localisation des stations, et notamment de la\ndensit√© h√©t√©rog√®ne de celles-ci,\non peut afficher les donn√©es sur la carte des communes\nde la petite couronne. Il s‚Äôagit donc d‚Äôenrichir la carte\npr√©c√©dente d‚Äôune couche suppl√©mentaire, √† savoir la localisation\ndes stations. Au passage, on va utiliser un fond de carte\nplus esth√©tique:\n\nfig, ax = plt.subplots(figsize=(10, 10))\nstations.sample(200).to_crs(3857).plot(ax=ax, color=\"red\", alpha=0.4, zorder=2)\nshp_communes.to_crs(3857).plot(\n    ax=ax, zorder=1, edgecolor=\"black\", facecolor=\"none\", color=None\n)\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\nax.set_axis_off()\n\n\n\n\n\n\n\n\nD√©couvrez ci-dessous par √©tape les diff√©rentes lignes de commandes permettant d‚Äôafficher cette carte compl√®te,\n√©tape par √©tape :\n1Ô∏è‚É£ Afficher le nuage de points de 200 stations v√©libs prises au hasard\n\nfig, ax = plt.subplots(figsize=(10, 10))\nstations.sample(200).to_crs(3857).plot(ax=ax, color=\"red\", alpha=0.4, zorder=2)\n\n\n\n\n\n\n\n\n2Ô∏è‚É£ Ajouter √† cette couche, en-dessous, les contours des communes\n\nfig, ax = plt.subplots(figsize=(10, 10))\nstations.sample(200).to_crs(3857).plot(ax=ax, color=\"red\", alpha=0.4, zorder=2)\nshp_communes.to_crs(3857).plot(\n    ax=ax, zorder=1, edgecolor=\"black\", facecolor=\"none\", color=None\n)\n\n\n\n\n\n\n\n\n\n\n3Ô∏è‚É£ Ajouter un fond de carte de type open street map gr√¢ce au package\ncontextily\n\nfig, ax = plt.subplots(figsize=(10, 10))\nstations.sample(200).to_crs(3857).plot(ax=ax, color=\"red\", alpha=0.4, zorder=2)\nshp_communes.to_crs(3857).plot(\n    ax=ax, zorder=1, edgecolor=\"black\", facecolor=\"none\", color=None\n)\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n\n\n\n\n\n\n\n\n\n\n4Ô∏è‚É£\nIl ne reste plus qu‚Äô√† retirer l‚Äôaxe des coordonn√©es, qui n‚Äôest pas tr√®s\nesth√©tique.\n\nfig, ax = plt.subplots(figsize=(10, 10))\nstations.sample(200).to_crs(3857).plot(ax=ax, color=\"red\", alpha=0.4, zorder=2)\nshp_communes.to_crs(3857).plot(\n    ax=ax, zorder=1, edgecolor=\"black\", facecolor=\"none\", color=None\n)\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\nax.set_axis_off()\nax\n\n\n\n\n\n\n\n\n\n\nIn fine, on obtient la carte d√©sir√©e.",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#op√©rations-sur-les-attributs",
    "href": "content/manipulation/03_geopandas_tutorial.html#op√©rations-sur-les-attributs",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "4.2 Op√©rations sur les attributs",
    "text": "4.2 Op√©rations sur les attributs\nToutes les op√©rations possibles sur un objet Pandas le sont √©galement\nsur un objet GeoPandas. Pour manipuler les donn√©es, et non la g√©om√©trie,\non parlera d‚Äôop√©rations sur les attributs.\nPar exemple, si on d√©sire\nconna√Ætre quelques statistiques sur la taille des stations, l‚Äôapproche\nest identique √† si on avait un objet Pandas classique :\n\nstations.describe()\n\n\n\n\n\n\n\n\n\ncapacity\n\n\n\n\ncount\n1468.000000\n\n\nmean\n31.168256\n\n\nstd\n12.291324\n\n\nmin\n0.000000\n\n\n25%\n23.000000\n\n\n50%\n29.000000\n\n\n75%\n37.000000\n\n\nmax\n76.000000\n\n\n\n\n\n\n\n\nPour classer les d√©partements de la petite couronne, du plus grand au plus petit,\nproc√©dons en deux √©tapes:\n\nR√©cup√©rons le contour des communes\ngr√¢ce √† cartiflette.\nNotons qu‚Äôon pourrait r√©cup√©rer directement les contours d√©partementaux mais\npour l‚Äôexercice, nous allons le cr√©er nous-m√™mes comme agr√©gation\ndes contours communaux\n(voir plus bas ainsi que ce notebook Observable pour la m√©thode plus\nl√©g√®re qui utilise pleinement les fonctionnalit√©s de cartiflette).\nCalculons la surface totale de ce territoire (m√©thode area sur un objet GeoPandas.GeoDataFrame ramen√©e en km¬≤, attention n√©amoins au syst√®me de projection comme cela est expliqu√© plus bas)\n\n\nshp_communes[\"surface\"] = shp_communes.area.div(10**6)\n\nLes plus grands d√©partements s‚Äôobtiennent par une agr√©gation des\nsurfaces communales :\n\nshp_communes.groupby(\"INSEE_DEP\").sum(numeric_only=True).sort_values(\n    \"surface\", ascending=False\n)\n\n\n\n\n\n\n\n\n\nINSEE_REG\nPOPULATION\nZE2020\nTUU2017\nTDUU2017\nTAAV2017\nTDAAV2017\nCATEAAV2020\nsurface\n\n\nINSEE_DEP\n\n\n\n\n\n\n\n\n\n\n\n\n\n94\n517\n1407124\n52123\n376\n3760\n235\n2350\n564\n244.816689\n\n\n93\n440\n1644903\n44384\n320\n3200\n200\n2000\n480\n236.867414\n\n\n92\n396\n1624357\n39924\n288\n2880\n180\n1800\n432\n175.571633\n\n\n75\n220\n2165423\n22180\n160\n1600\n100\n1000\n220\n105.424231\n\n\n\n\n\n\n\n\nSi on veut directement les plus\ngrandes communes de la petite couronne parisienne :\n\nshp_communes.sort_values(\"surface\", ascending=False).head(10)\n\n\n\n\n\n\n\n\n\nINSEE_DEP\nINSEE_REG\nID\nNOM\nINSEE_COM\nSTATUT\nPOPULATION\nAREA\nARR\nCV\n...\nTDAAV2017\nCATEAAV2020\nBV2012\nLIBELLE_DEPARTEMENT\nLIBELLE_REGION\nPAYS\nSOURCE\ngeometry\nINSEE_COG\nsurface\n\n\n\n\n60\n93\n11\nCOMMUNE_0000000009735015\nTremblay-en-France\n93073\nCommune simple\n36461\nmetropole\n932\n9320\n...\n50\n12\n75056\nSeine-Saint-Denis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((663432.700 6875170.500, 663529.700 6...\nNaN\n22.680549\n\n\n12\n75\n11\nARR_MUNI0000000009736553\nParis 16e Arrondissement\n75056\nArrondissement municipal\n165523\nNaN\n751\n75ZZ\n...\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((647190.200 6864524.400, 647155.000 6...\n75116\n16.412426\n\n\n19\n75\n11\nARR_MUNI0000000009736532\nParis 12e Arrondissement\n75056\nArrondissement municipal\n139297\nNaN\n751\n75ZZ\n...\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((655221.200 6858576.500, 655536.100 6...\n75112\n16.379110\n\n\n44\n93\n11\nCOMMUNE_0000000009735500\nAulnay-sous-Bois\n93005\nCommune simple\n86969\nmetropole\n932\n9302\n...\n50\n12\n75056\nSeine-Saint-Denis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((660415.900 6872923.300, 660459.000 6...\nNaN\n16.166721\n\n\n32\n92\n11\nCOMMUNE_0000000009736056\nRueil-Malmaison\n92063\nCommune simple\n78317\nmetropole\n922\n9222\n...\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((637679.300 6863761.400, 637603.700 6...\nNaN\n14.541191\n\n\n74\n93\n11\nCOMMUNE_0000000009736517\nNoisy-le-Grand\n93051\nCommune simple\n67871\nmetropole\n932\n9314\n...\n50\n12\n75056\nSeine-Saint-Denis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((664453.800 6861358.900, 664703.700 6...\nNaN\n13.144471\n\n\n37\n93\n11\nCOMMUNE_0000000009735515\nSaint-Denis\n93066\nSous-pr√©fecture\n112852\nmetropole\n933\n9399\n...\n50\n12\n75056\nSeine-Saint-Denis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((652098.200 6872022.600, 652002.600 6...\nNaN\n12.371854\n\n\n5\n92\n11\nCOMMUNE_0000000009736052\nNanterre\n92050\nPr√©fecture\n96277\nmetropole\n922\n9299\n...\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((643490.700 6867612.300, 643408.400 6...\nNaN\n12.227927\n\n\n114\n94\n11\nCOMMUNE_0000000009737009\nVitry-sur-Seine\n94081\nCommune simple\n95510\nmetropole\n943\n9499\n...\n50\n12\n75056\nVal-de-Marne\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((653537.000 6852608.400, 653581.100 6...\nNaN\n11.664610\n\n\n21\n92\n11\nCOMMUNE_0000000009735517\nGennevilliers\n92036\nCommune simple\n48530\nmetropole\n922\n9214\n...\n50\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((648070.700 6872566.900, 647847.400 6...\nNaN\n11.633935\n\n\n\n\n10 rows √ó 28 columns\n\n\n\n\nLors des √©tapes d‚Äôagr√©gation, groupby ne conserve pas les g√©om√©tries. Autrement\ndit, si on effectue, par exemple, une somme en fonction d‚Äôune variable de groupe avec\nle combo groupby(...).sum(...) , on perd\nla dimension g√©ographique.\nIl est n√©anmoins possible d‚Äôaggr√©ger √† la fois les g√©om√©tries et les\nattribus avec la m√©thode dissolve:\n\nfig, ax = plt.subplots(figsize=(10, 10))\nshp_communes.dissolve(by=\"INSEE_DEP\", aggfunc=\"sum\").plot(ax=ax, column=\"surface\")\nax.set_axis_off()\nax\n\n\n\n\n\n\n\n\nPour produire l‚Äô√©quivalent de cette carte √† un niveau France enti√®re, il est n√©anmoins plus simple de directement\nr√©cup√©rer les fonds officiels des d√©partements plut√¥t que d‚Äôagr√©ger les\ncontours des communes:\n\ndep = carti_download(\n    values=[\"France\"],\n    crs=4326,\n    borders=\"DEPARTEMENT\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"FRANCE_ENTIERE\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\ndep = dep.loc[dep[\"INSEE_DEP\"].str.len() == 2]\n\ndep[\"area\"] = dep.to_crs(2154).area\n\nAvant de calculer les surfaces des d√©partements, pour √©viter les d√©formations li√©es au\nsyst√®me Mercator, nous faisons une reprojection des donn√©es √† la vol√©e. Plus de d√©tails\npar la suite.\n\ndep.sort_values(\"area\", ascending=False).head(3)\n\n\n\n\n\n\n\n\n\nINSEE_DEP\nPAYS\nLIBELLE_DEPARTEMENT\nPOPULATION\nSOURCE\ngeometry\narea\n\n\n\n\n55\n33\nFrance\nGironde\n1623749\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nMULTIPOLYGON (((-0.71884 45.32753, -0.71845 45...\n1.007271e+10\n\n\n30\n40\nFrance\nLandes\n413690\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((-0.24252 43.58483, -0.24275 43.58706...\n9.354177e+09\n\n\n68\n24\nFrance\nDordogne\n413223\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((1.44824 45.01941, 1.44400 45.02011, ...\n9.210808e+09\n\n\n\n\n\n\n\n\n\nax = dep.plot(column=\"area\")\nax.set_axis_off()",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#op√©rations-sur-les-g√©om√©tries",
    "href": "content/manipulation/03_geopandas_tutorial.html#op√©rations-sur-les-g√©om√©tries",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "4.3 Op√©rations sur les g√©om√©tries",
    "text": "4.3 Op√©rations sur les g√©om√©tries\nOutre la repr√©sentation graphique simplifi√©e,\nsur laquelle nous reviendrons ult√©rieurement, l‚Äôint√©r√™t principal d‚Äôutiliser\nGeoPandas est l‚Äôexistence de m√©thodes efficaces pour\nmanipuler la dimension spatiale. Un certain nombre proviennent du\npackage\nShapely.\n\n\n Warning\nLes donn√©es sont en syst√®me de coordonn√©es WGS 84 ou pseudo-Mercator (epsg: 4326) et ne sont pas projet√©es.\nC‚Äôest un format appropri√© lorsqu‚Äôil s‚Äôagit d‚Äôutiliser un fonds\nde carte OpenStreetMap, Stamen, Google Maps, etc.\nMais ce n‚Äôest pas un\nformat sur lequel on d√©sire faire des calculs car les distances sont fauss√©es sans utiliser de projection. D‚Äôailleurs, geopandas refusera certaines op√©rations\nsur des donn√©es dont le crs est 4326. On reprojette ainsi les donn√©es\ndans la projection officielle pour la m√©tropole, le Lambert 93\n(epsg: 2154).\n\n\nComme indiqu√© ci-dessus, nous reprojetons les donn√©es\ndans le syst√®me Lambert 93 qui ne fausse pas les\ncalculs de distance et d‚Äôaires.\n\ncommunes = shp_communes.to_crs(2154)\nstations = stations.to_crs(2154)\n\nPar exemple, on peut recalculer la taille d‚Äôune commune ou d‚Äôarrondissement\navec la m√©thode area (et diviser par \\(10^6\\) pour avoir des \\(km^2\\) au lieu\ndes \\(m^2\\)):\n\ncommunes[\"superficie\"] = communes.area.div(10**6)\ncommunes.head(3)\n\n\n\n\n\n\n\n\n\nINSEE_DEP\nINSEE_REG\nID\nNOM\nINSEE_COM\nSTATUT\nPOPULATION\nAREA\nARR\nCV\n...\nCATEAAV2020\nBV2012\nLIBELLE_DEPARTEMENT\nLIBELLE_REGION\nPAYS\nSOURCE\ngeometry\nINSEE_COG\nsurface\nsuperficie\n\n\n\n\n1\n92\n11\nCOMMUNE_0000000009736037\nLevallois-Perret\n92044\nCommune simple\n66082\nmetropole\n922\n9216\n...\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((647761.400 6867306.900, 647531.300 6...\nNaN\n2.412607\n2.412607\n\n\n2\n92\n11\nCOMMUNE_0000000009736055\nBois-Colombes\n92009\nCommune simple\n28841\nmetropole\n922\n9211\n...\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((646224.700 6867615.800, 646122.500 6...\nNaN\n1.931211\n1.931211\n\n\n3\n92\n11\nCOMMUNE_0000000009736538\nMalakoff\n92046\nCommune simple\n30950\nmetropole\n921\n9218\n...\n12\n75056\nHauts-de-Seine\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nPOLYGON ((646995.300 6857373.400, 646723.300 6...\nNaN\n2.073708\n2.073708\n\n\n\n\n3 rows √ó 29 columns\n\n\n\n\nUne m√©thode qu‚Äôon utilise r√©guli√®rement est centroid qui, comme son nom l‚Äôindique,\nrecherche le centro√Øde de chaque polygone et transforme ainsi des donn√©es\nsurfaciques en donn√©es ponctuelles. Par exemple, pour\nrepr√©senter approximativement les centres des villages de la\nHaute-Garonne (31), apr√®s avoir t√©l√©charg√© le fonds de carte adapt√©,\nfera\n\ncommunes_31 = carti_download(\n    values=[\"31\"],\n    crs=4326,\n    borders=\"COMMUNE\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\n# on reprojete en 3857 pour le fond de carte\ncommunes_31 = communes_31.to_crs(3857)\n\n# on calcule le centroide\ndep_31 = communes_31.copy()\ncommunes_31[\"geometry\"] = communes_31[\"geometry\"].centroid\n\nax = communes_31.plot(figsize=(10, 10), color=\"red\", alpha=0.4, zorder=2)\ndep_31.to_crs(3857).plot(\n    ax=ax, zorder=1, edgecolor=\"black\", facecolor=\"none\", color=None\n)\n# ctx.add_basemap(ax, source = ctx.providers.Stamen.Toner)\nax.set_axis_off()\nax",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#joindre-des-donn√©es-sur-des-attributs",
    "href": "content/manipulation/03_geopandas_tutorial.html#joindre-des-donn√©es-sur-des-attributs",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "6.1 Joindre des donn√©es sur des attributs",
    "text": "6.1 Joindre des donn√©es sur des attributs\nCe type de jointure se fait entre un objet g√©ographique et un\ndeuxi√®me objet, g√©ographique ou non. A l‚Äôexception de la question\ndes g√©om√©tries, il n‚Äôy a pas de diff√©rence par rapport √† Pandas.\nLa seule diff√©rence avec Pandas est dans la dimension g√©ographique.\nSi on d√©sire conserver la dimension g√©ographique, il faut faire\nattention √† faire :\ngeopandas_object.merge(pandas_object)\nSi on utilise deux objets g√©ographiques mais ne d√©sire conserver qu‚Äôune seule\ndimension g√©ographique1, on fera\ngeopandas_object1.merge(geopandas_object2)\nSeule la g√©om√©trie de l‚Äôobjet de gauche\nsera conserv√©e, m√™me si on fait un right join.",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#prolongation-possible-joindre-des-donn√©es-sur-dimension-g√©ographique",
    "href": "content/manipulation/03_geopandas_tutorial.html#prolongation-possible-joindre-des-donn√©es-sur-dimension-g√©ographique",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "6.2 Prolongation possible : joindre des donn√©es sur dimension g√©ographique",
    "text": "6.2 Prolongation possible : joindre des donn√©es sur dimension g√©ographique\nLe chapitre suivant permettra de mettre en oeuvre des\njointures g√©ographiques.\n\n\n Hint\nLes jointures spatiales peuvent √™tre tr√®s gourmandes en ressources (car il peut √™tre n√©cessaire de croiser toutes les g√©om√©tries de x avec toutes les g√©om√©tries de y). Voici deux conseils qui peuvent vous aider :\n\nIl est pr√©f√©rable de tester les jointures g√©ographiques sur un petit √©chantillon de donn√©es, pour estimer le temps et les ressources n√©cessaires √† la r√©alisation de la jointure.\nIl est parfois possible d‚Äô√©crire une fonction qui r√©duit la taille du probl√®me. Exemple: vous voulez d√©terminer dans quelle commune se situe un logement dont vous connaissez les coordonn√©es et le d√©partement; vous pouvez √©crire une fonction qui r√©alise pour chaque d√©partement une jointure spatiale entre les logements situ√©s dans ce d√©partement et les communes de ce d√©partement, puis empiler les 101 tables de sorties.",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#informations-additionnelles",
    "href": "content/manipulation/03_geopandas_tutorial.html#informations-additionnelles",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\nce33d5d\n\n\n2024-01-16 15:47:22\n\n\nLino Galiana\n\n\nAdapte les exemples de code de cartiflette (#482)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n102ce9f\n\n\n2023-10-22 11:39:37\n\n\nThomas Faria\n\n\nRelecture Thomas, premi√®re partie (#438)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nf8831e7\n\n\n2023-10-09 10:53:34\n\n\nLino Galiana\n\n\nRelecture antuki geopandas (#429)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\na9198de\n\n\n2023-08-25 18:33:00\n\n\nLino Galiana\n\n\nGeopandas tutorial\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n8d81b5f\n\n\n2023-02-18 18:21:59\n\n\nLino Galiana\n\n\nChange source get_vectorfile (#355)\n\n\n\n\nd2eb6c2\n\n\n2023-02-18 17:15:35\n\n\nLino Galiana\n\n\nUpdate index.qmd\n\n\n\n\n3912a7e\n\n\n2023-02-07 17:18:25\n\n\nLino Galiana\n\n\nBack to IGN provider (#350)\n\n\n\n\n0312041\n\n\n2022-12-11 13:43:49\n\n\nLino Galiana\n\n\nreprend box de geopandas (#332)\n\n\n\n\n6662800\n\n\n2022-10-28 11:14:27\n\n\nLino Galiana\n\n\nChange IGN dataset provider (#308)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\n8df6bbc\n\n\n2022-10-12 11:50:57\n\n\nLino Galiana\n\n\nCorrige les tags du tuto geopandas (#295)\n\n\n\n\naf763cc\n\n\n2022-10-12 10:17:56\n\n\nLino Galiana\n\n\nReprise exercice geopandas (#294)\n\n\n\n\n1ef97df\n\n\n2022-10-11 12:14:03\n\n\nLino Galiana\n\n\nRelecture chapitre geopandas (#289)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n5cac236\n\n\n2021-12-16 19:46:43\n\n\nLino Galiana\n\n\nun petit mot sur mercator (#201)\n\n\n\n\n77120b8\n\n\n2021-11-01 20:28:28\n\n\nLino Galiana\n\n\nAjoute une section sur le geocodage (#173)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n735e677\n\n\n2021-10-19 09:46:12\n\n\nLino Galiana\n\n\nR√®gle probl√®me des cartes qui s‚Äôaffichent pas (#165)\n\n\n\n\n5ad057f\n\n\n2021-10-10 15:13:16\n\n\nLino Galiana\n\n\nRelectures pandas & geopandas (#159)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\nbadc492\n\n\n2020-09-22 18:36:33\n\n\nLino Galiana\n\n\nFinalize geopandas section (#48)\n\n\n\n\nffb05cf\n\n\n2020-09-10 17:18:15\n\n\nLino Galiana\n\n\nPartie sur les donn√©es spatiales (#20) :warning: pas fini\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nLes diff√©rents types de projection\nExemple de reprojection de pays depuis le site thetruesize.com\nImage emprunt√©e √† XKCD https://xkcd.com/2256/ qu‚Äôon peut √©galement trouver sur https://blog.chrislansdown.com/2020/01/17/a-great-map-projection-joke/",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#footnotes",
    "href": "content/manipulation/03_geopandas_tutorial.html#footnotes",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIl est techniquement possible d‚Äôavoir un DataFrame comportant plusieurs\ng√©ographies. Par exemple une g√©om√©trie polygone et une g√©om√©trie point\n(le centroid). C‚Äôest n√©anmoins souvent compliqu√© √† g√©rer et donc peu\nrecommandable.‚Ü©Ô∏é",
    "crumbs": [
      "Donn√©es spatiales : d√©couverte de geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html",
    "href": "content/manipulation/04a_webscraping_TP.html",
    "title": "Web scraping avec Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLe web scraping d√©signe les techniques d‚Äôextraction du contenu des sites internet.\nC‚Äôest une pratique tr√®s utile pour toute personne souhaitant travailler sur des informations disponibles en ligne, mais n‚Äôexistant pas forc√©ment sous la forme d‚Äôun tableau Excel.\nCe TP vous pr√©sente comment cr√©er et ex√©cuter des robots afin de recup√©rer rapidement des informations utiles √† vos projets actuels ou futurs.\nIl part de quelques cas d‚Äôusages concret.\nCe chapitre est tr√®s fortement inspir√© et r√©adapt√© √† partir de celui de Xavier Dupr√©, l‚Äôancien professeur de la mati√®re.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#la-zone-grise-de-la-l√©galit√©-du-web-scraping",
    "href": "content/manipulation/04a_webscraping_TP.html#la-zone-grise-de-la-l√©galit√©-du-web-scraping",
    "title": "Web scraping avec Python",
    "section": "1.1 La zone grise de la l√©galit√© du web scraping",
    "text": "1.1 La zone grise de la l√©galit√© du web scraping\nEn premier lieu, en ce qui concerne la question de la l√©galit√©\nde la r√©cup√©ration d‚Äôinformation par scraping, il existe\nune zone grise. Ce n‚Äôest pas parce qu‚Äôune information est\ndisponible sur internet, directement ou avec un peu de recherche,\nqu‚Äôelle peut √™tre r√©cup√©r√©e et r√©utilis√©e.\nL‚Äôexcellent cours d‚ÄôAntoine Palazzolo √©voque un certain nombre de cas\nm√©diatiques et judiciaires sur cette question.\nDans le champ fran√ßais, la CNIL a publi√© en 2020\nde nouvelles directives sur le web scraping repr√©cisant\nque toute donn√©e ne peut √™tre r√©utilis√©e √† l‚Äôinsu de la personne\n√† laquelle ces donn√©es appartiennent. Autrement dit, en principe,\nles donn√©es collect√©es par web scraping sont soumises au\nRGPD, c‚Äôest-√†-dire n√©cessitent le consentement des personnes\n√† partir desquelles la r√©utilisation des donn√©es est faite.\nIl est donc recommand√© d‚Äô√™tre vigilant avec les donn√©es r√©cup√©r√©es\npar web scraping pour ne pas se mettre en faute l√©galement.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#stabilit√©-et-fiabilit√©-des-informations-re√ßues",
    "href": "content/manipulation/04a_webscraping_TP.html#stabilit√©-et-fiabilit√©-des-informations-re√ßues",
    "title": "Web scraping avec Python",
    "section": "1.2 Stabilit√© et fiabilit√© des informations re√ßues",
    "text": "1.2 Stabilit√© et fiabilit√© des informations re√ßues\nLa r√©cup√©ration de donn√©es par web scraping\nest certes pratique mais elle ne correspond pas n√©cessairement\n√† un usage pens√©, ou d√©sir√©, par un fournisseur de donn√©es.\nLes donn√©es √©tant co√ªteuses √† collecter et √† mettre √† disposition,\ncertains sites ne d√©sirent pas n√©cessairement que celles-ci soient\nextraites gratuitement et facilement. A fortiori lorsque la donn√©e\npeut permettre √† un concurrent de disposer d‚Äôune information\nutile d‚Äôun point de vue commercial (prix d‚Äôun produit concurrent, etc.).\nLes acteurs mettent donc souvent en oeuvre des strat√©gies pour bloquer ou\nlimiter la quantit√© de donn√©es scrap√©es. La m√©thode la plus\nclassique est la d√©tection et le blocage\ndes requ√™tes faites par des robots plut√¥t que par des humains.\nPour des acteurs sp√©cialis√©s, cette d√©tection est tr√®s facile car\nde nombreuses preuves permettent d‚Äôidentifier si une visite du site web\nprovient d‚Äôun utilisateur\nhumain derri√®re un navigateur ou d‚Äôun robot. Pour ne citer que quelques indices :\nvitesse de la navigation entre pages, rapidit√© √† extraire la donn√©e,\nempreinte digitale du navigateur utilis√©, capacit√© √† r√©pondre √† des\nquestions al√©atoires (captcha)‚Ä¶\nLes bonnes pratiques, √©voqu√©es par la suite, ont pour objectif de faire\nen sorte qu‚Äôun robot se comporte de mani√®re civile en adoptant un comportement\nproche de celui de l‚Äôhumain mais sans contrefaire le fait qu‚Äôil ne s‚Äôagit\npas d‚Äôun humain.\nIl convient d‚Äôailleurs\nd‚Äô√™tre prudent quant aux informations re√ßues par web scraping.\nLa donn√©e √©tant au coeur du mod√®le √©conomique de certains acteurs, certains\nn‚Äôh√©sitent pas √† renvoyer des donn√©es fausses aux robots\nplut√¥t que les bloquer. C‚Äôest de bonne guerre !\nUne autre technique pi√®ge s‚Äôappelle le honey pot. Il s‚Äôagit de pages qu‚Äôun humain\nn‚Äôirait jamais visiter - par exemple parce qu‚Äôelles n‚Äôapparaissent pas dans\nl‚Äôinterface graphique - mais sur lesquelles un robot, en recherche automatique\nde contenu, va rester bloquer.\nSans aller jusqu‚Äô√† la strat√©gie de blocage du web scraping, d‚Äôautres raisons\npeuvent expliquer qu‚Äôune r√©cup√©ration de donn√©es ait fonctionn√© par\nle pass√© mais ne fonctionne plus. La plus fr√©quente est un changement dans la structure\nd‚Äôun site web. Le web scraping pr√©sente en effet l‚Äôinconv√©nient d‚Äôaller chercher\nde l‚Äôinformation dans une structure tr√®s hi√©rarchis√©e. Un changement dans cette structure\npeut suffire √† rendre un robot incapable de r√©cup√©rer du contenu. Or, pour rester\nattractifs, les sites web changent fr√©quemment ce qui peut facilement\nrendre inop√©rant un robot.\nDe mani√®re g√©n√©rale, l‚Äôun des principaux messages de ce\nchapitre, √† retenir, est que le\nweb scraping est une solution de dernier ressort, pour des r√©cup√©rations ponctuelles de donn√©es sans garantie de fonctionnement ult√©rieur. Il est pr√©f√©rable de privil√©gier les API lorsque celles-ci sont disponibles.\nCes derni√®res ressemblent √† un contrat (formel ou non) entre un fournisseur de donn√©es\net un utilisateur o√π sont d√©finis des besoins (les donn√©es) mais aussi des\nconditions d‚Äôacc√®s (nombre de requ√™tes, volum√©trie, authentification‚Ä¶) l√†\no√π le web scraping est plus proche du comportement dans le Far West.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#les-bonnes-pratiques",
    "href": "content/manipulation/04a_webscraping_TP.html#les-bonnes-pratiques",
    "title": "Web scraping avec Python",
    "section": "1.3 Les bonnes pratiques",
    "text": "1.3 Les bonnes pratiques\nLa possibilit√© de r√©cup√©rer des donn√©es par l‚Äôinterm√©diaire\nd‚Äôun robot ne signifie pas qu‚Äôon peut se permettre de ne pas √™tre\ncivilis√©. En effet, lorsqu‚Äôil est non-ma√Ætris√©, le\nweb scraping peut ressembler √† une attaque informatique\nclassique pour faire sauter un site web : le d√©ni de service.\nLe cours d‚ÄôAntoine Palazzolo revient\nsur certaines bonnes pratiques qui ont √©merg√© dans la communaut√©\ndes scrapeurs. Il est recommand√© de lire cette ressource\npour en apprendre plus sur ce sujet. Y sont √©voqu√©es\nplusieurs conventions, parmi lesquelles :\n\nSe rendre, depuis la racine du site,\nsur le fichier robots.txt pour v√©rifier les consignes\npropos√©es par les d√©veloppeurs du site web pour\ncadrer le comportement des robots ;\nEspacer chaque requ√™tes de plusieurs secondes, comme le ferait\nun humain, afin d‚Äô√©viter de surcharger le site web et de le\nfaire sauter par d√©ni de service ;\nFaire les requ√™tes dans les heures creuses de fr√©quentation du\nsite web s‚Äôil ne s‚Äôagit pas d‚Äôun site consult√© internationalement.\nPar exemple, pour un site en fran√ßais, lancer le robot\npendant la nuit en France m√©tropolitaine, est une bonne pratique.\nPour lancer un robot depuis Python √† une heure programm√©e\n√† l‚Äôavance, il existe les cronjobs.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#les-balises",
    "href": "content/manipulation/04a_webscraping_TP.html#les-balises",
    "title": "Web scraping avec Python",
    "section": "2.1 Les balises",
    "text": "2.1 Les balises\nSur une page web, vous trouverez toujours √† coup s√ªr des √©l√©ments comme &lt;head&gt;, &lt;title&gt;, etc. Il s‚Äôagit des codes qui vous permettent de structurer le contenu d‚Äôune page HTML et qui s‚Äôappellent des balises.\nCitons, par exemple, les balises &lt;p&gt;, &lt;h1&gt;, &lt;h2&gt;, &lt;h3&gt;, &lt;strong&gt; ou &lt;em&gt;.\nLe symbole &lt; &gt; est une balise : il sert √† indiquer le d√©but d‚Äôune partie. Le symbole &lt;/ &gt; indique la fin de cette partie. La plupart des balises vont par paires, avec une balise ouvrante et une balise fermante (par exemple &lt;p&gt; et &lt;/p&gt;).\nPar exemple, les principales balises\nd√©finissant la structure d‚Äôun tableau sont les suivantes :\n\n\n\nBalise\nDescription\n\n\n\n\n&lt;table&gt;\nTableau\n\n\n&lt;caption&gt;\nTitre du tableau\n\n\n&lt;tr&gt;\nLigne de tableau\n\n\n&lt;th&gt;\nCellule d‚Äôen-t√™te\n\n\n&lt;td&gt;\nCellule\n\n\n&lt;thead&gt;\nSection de l‚Äôen-t√™te du tableau\n\n\n&lt;tbody&gt;\nSection du corps du tableau\n\n\n&lt;tfoot&gt;\nSection du pied du tableau\n\n\n\nApplication : un tableau en HTML\nLe code HTML du tableau suivant :\n&lt;table&gt;\n&lt;caption&gt; Le Titre de mon tableau &lt;/caption&gt;\n\n   &lt;tr&gt;\n      &lt;th&gt;Pr√©nom&lt;/th&gt;\n      &lt;th&gt;Nom&lt;/th&gt;\n      &lt;th&gt;Profession&lt;/th&gt;\n   &lt;/tr&gt;\n   &lt;tr&gt;\n      &lt;td&gt;Mike &lt;/td&gt;\n      &lt;td&gt;Stuntman&lt;/td&gt;\n      &lt;td&gt;Cascadeur&lt;/td&gt;\n   &lt;/tr&gt;\n   &lt;tr&gt;\n      &lt;td&gt;Mister&lt;/td&gt;\n      &lt;td&gt;Pink&lt;/td&gt;\n      &lt;td&gt;Gangster&lt;/td&gt;\n   &lt;/tr&gt;\n&lt;/table&gt;\nDonnera dans le navigateur :\n\n\n\nLe Titre de mon tableau\n\n\nPr√©nom\nNom\nProfession\n\n\nMike\nStuntman\nCascadeur\n\n\nMister\nPink\nGangster\n\n\n\n\n\n\n2.1.1 Parent et enfant\nDans le cadre du langage HTML, les termes de parent (parent) et enfant (child) servent √† d√©signer des √©lements embo√Æt√©s les uns dans les autres. Dans la construction suivante, par exemple :\n&lt;div&gt; \n    &lt;p&gt;\n       bla,bla\n    &lt;/p&gt;\n&lt;/div&gt;\nSur la page web, cela apparaitra de la mani√®re suivante :\n\n \n    \n       bla,bla\n    \n\n\nOn dira que l‚Äô√©l√©ment &lt;div&gt; est le parent de l‚Äô√©l√©ment &lt;p&gt; tandis que l‚Äô√©l√©ment &lt;p&gt; est l‚Äôenfant de l‚Äô√©l√©ment &lt;div&gt;.\n\nMais pourquoi apprendre √ßa pour ‚Äúscraper‚Äù ?\n\nParce que, pour bien r√©cup√©rer les informations d‚Äôun site internet, il faut pouvoir comprendre sa structure et donc son code HTML. Les fonctions Python qui servent au scraping sont principalement construites pour vous permettre de naviguer entre les balises.\nAvec Python, vous allez en fait reproduire votre comportement manuel de recherche de mani√®re\n√† l‚Äôautomatiser.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#les-packages-disponibles",
    "href": "content/manipulation/04a_webscraping_TP.html#les-packages-disponibles",
    "title": "Web scraping avec Python",
    "section": "3.1 Les packages disponibles",
    "text": "3.1 Les packages disponibles\nDans la premi√®re partie de ce chapitre,\nnous allons essentiellement utiliser le package BeautifulSoup4,\nen conjonction avec urllib\nou requests. Ces deux derniers packages permettent de r√©cup√©rer le texte\nbrut d‚Äôune page qui sera ensuite\ninspect√© via BeautifulSoup4.\nBeautifulSoup sera suffisant quand vous voudrez travailler sur des pages HTML statiques. D√®s que les informations que vous recherchez sont g√©n√©r√©es via l‚Äôex√©cution de scripts Javascript, il vous faudra passer par des outils comme Selenium.\nDe m√™me, si vous ne connaissez pas l‚ÄôURL, il faudra passer par un framework comme Scrapy, qui passe facilement d‚Äôune page √† une autre. On appelle\ncette technique le ‚Äúweb crawling‚Äù. Scrapy est plus complexe √† manipuler que BeautifulSoup : si vous voulez plus de d√©tails, rendez-vous sur la page du tutoriel Scrapy.\nLe web scraping est un domaine o√π la reproductibilit√© est compliqu√©e √† mettre en oeuvre.\nUne page web √©volue\npotentiellement r√©guli√®rement et d‚Äôune page web √† l‚Äôautre, la structure peut\n√™tre tr√®s diff√©rente ce qui rend certains codes difficilement exportables.\nPar cons√©quent, la meilleure mani√®re d‚Äôavoir un programme fonctionnel est\nde comprendre la structure d‚Äôune page web et dissocier les √©l√©ments exportables\n√† d‚Äôautres cas d‚Äôusages des requ√™tes ad hoc.\n\n!pip install -q lxml\n\nimport bs4\nimport lxml\nimport pandas\nimport urllib\n\nfrom urllib import request\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n\n\n\n Note\nPour √™tre en mesure d‚Äôutiliser Selenium, il est n√©cessaire\nde faire communiquer Python avec un navigateur web (Firefox ou Chromium).\nLe package webdriver-manager permet de faire savoir √† Python o√π\nse trouve ce navigateur s‚Äôil est d√©j√† install√© dans un chemin standard.\nPour l‚Äôinstaller, le code de la cellule ci-dessous peut √™tre utilis√©.\n\n\nPour faire fonctionner Selenium, il faut utiliser un package\nnomm√© webdriver-manager:\n\n!pip install webdriver-manager\n\nRequirement already satisfied: webdriver-manager in /opt/mamba/lib/python3.11/site-packages (4.0.1)\nRequirement already satisfied: requests in /opt/mamba/lib/python3.11/site-packages (from webdriver-manager) (2.31.0)\nRequirement already satisfied: python-dotenv in /opt/mamba/lib/python3.11/site-packages (from webdriver-manager) (1.0.1)\nRequirement already satisfied: packaging in /opt/mamba/lib/python3.11/site-packages (from webdriver-manager) (23.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (1.26.18)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (2024.2.2)\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#r√©cup√©rer-le-contenu-dune-page-html",
    "href": "content/manipulation/04a_webscraping_TP.html#r√©cup√©rer-le-contenu-dune-page-html",
    "title": "Web scraping avec Python",
    "section": "3.2 R√©cup√©rer le contenu d‚Äôune page HTML",
    "text": "3.2 R√©cup√©rer le contenu d‚Äôune page HTML\nOn va commencer doucement. Prenons une page wikipedia,\npar exemple celle de la Ligue 1 de football, mill√©sime 2019-2020 : Championnat de France de football 2019-2020. On va souhaiter r√©cup√©rer la liste des √©quipes, ainsi que les url des pages Wikipedia de ces √©quipes.\nEtape 1Ô∏è‚É£ : se connecter √† la page wikipedia et obtenir le code source.\nPour cela, le plus simple est d‚Äôutiliser le package urllib ou, mieux, requests.\nNous allons ici utiliser la fonction request du package urllib:\n\nurl_ligue_1 = (\n    \"https://fr.wikipedia.org/wiki/Championnat_de_France_de_football_2019-2020\"\n)\n\nrequest_text = request.urlopen(url_ligue_1).read()\n# print(request_text[:1000])\n\n\ntype(request_text)\n\nbytes\n\n\nEtape 2Ô∏è‚É£ : utiliser le package BeautifulSoup\nqui permet de rechercher efficacement\nles balises contenues dans la chaine de caract√®res\nrenvoy√©e par la fonction request:\n\npage = bs4.BeautifulSoup(request_text, \"lxml\")\n\nSi on print l‚Äôobjet page cr√©√©e avec BeautifulSoup,\non voit que ce n‚Äôest plus une chaine de caract√®res mais bien une page HTML avec des balises.\nOn peut √† pr√©sent chercher des √©lements √† l‚Äôint√©rieur de ces balises.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-find",
    "href": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-find",
    "title": "Web scraping avec Python",
    "section": "3.3 La m√©thode find",
    "text": "3.3 La m√©thode find\nPar exemple, si on veut conna√Ætre le titre de la page, on utilise la m√©thode .find et on lui demande ‚Äútitle‚Äù\n\nprint(page.find(\"title\"))\n\n&lt;title&gt;Championnat de France de football 2019-2020 ‚Äî Wikip√©dia&lt;/title&gt;\n\n\nLa methode .find ne renvoie que la premi√®re occurence de l‚Äô√©l√©ment.\nPour vous en assurer vous pouvez :\n\ncopier le bout de code source obtenu lorsque vous chercher une table,\nle coller dans une cellule de votre notebook\net passer la cellule en ‚ÄúMarkdown‚Äù\n\nLa cellule avec le copier-coller du code source donne :\n\nprint(page.find(\"table\"))\n\n&lt;table&gt;&lt;caption style=\"background-color:#99cc99;color:#000000;\"&gt;G√©n√©ralit√©s&lt;/caption&gt;&lt;tbody&gt;&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Sport&lt;/th&gt;\n&lt;td&gt;\n&lt;a href=\"/wiki/Football\" title=\"Football\"&gt;Football&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Organisateur(s)&lt;/th&gt;\n&lt;td&gt;\n&lt;a href=\"/wiki/Ligue_de_football_professionnel_(France)\" title=\"Ligue de football professionnel (France)\"&gt;LFP&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;√âdition&lt;/th&gt;\n&lt;td&gt;\n&lt;abbr class=\"abbr\" title=\"Quatre-vingt-deuxi√®me (huitante-deuxi√®me / octante-deuxi√®me)\"&gt;82&lt;sup&gt;e&lt;/sup&gt;&lt;/abbr&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Lieu(x)&lt;/th&gt;\n&lt;td&gt;\n&lt;span class=\"datasortkey\" data-sort-value=\"France\"&gt;&lt;span class=\"flagicon\"&gt;&lt;span class=\"mw-image-border noviewer\" typeof=\"mw:File\"&gt;&lt;a class=\"mw-file-description\" href=\"/wiki/Fichier:Flag_of_France.svg\" title=\"Drapeau de la France\"&gt;&lt;img alt=\"Drapeau de la France\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"13\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/20px-Flag_of_France.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/30px-Flag_of_France.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/40px-Flag_of_France.svg.png 2x\" width=\"20\"/&gt;&lt;/a&gt;&lt;/span&gt; &lt;/span&gt;&lt;a href=\"/wiki/France\" title=\"France\"&gt;France&lt;/a&gt;&lt;/span&gt; et &lt;br/&gt;&lt;span class=\"datasortkey\" data-sort-value=\"Monaco\"&gt;&lt;span class=\"flagicon\"&gt;&lt;span class=\"mw-image-border noviewer\" typeof=\"mw:File\"&gt;&lt;a class=\"mw-file-description\" href=\"/wiki/Fichier:Flag_of_Monaco.svg\" title=\"Drapeau de Monaco\"&gt;&lt;img alt=\"Drapeau de Monaco\" class=\"mw-file-element\" data-file-height=\"800\" data-file-width=\"1000\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/20px-Flag_of_Monaco.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/30px-Flag_of_Monaco.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/40px-Flag_of_Monaco.svg.png 2x\" width=\"20\"/&gt;&lt;/a&gt;&lt;/span&gt; &lt;/span&gt;&lt;a href=\"/wiki/Monaco\" title=\"Monaco\"&gt;Monaco&lt;/a&gt;&lt;/span&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Date&lt;/th&gt;\n&lt;td&gt;\nDu &lt;time class=\"nowrap date-lien\" data-sort-value=\"2019-08-09\" datetime=\"2019-08-09\"&gt;&lt;a href=\"/wiki/9_ao%C3%BBt_en_sport\" title=\"9 ao√ªt en sport\"&gt;9&lt;/a&gt; &lt;a class=\"mw-redirect\" href=\"/wiki/Ao%C3%BBt_2019_en_sport\" title=\"Ao√ªt 2019 en sport\"&gt;ao√ªt&lt;/a&gt; &lt;a href=\"/wiki/2019_en_football\" title=\"2019 en football\"&gt;2019&lt;/a&gt;&lt;/time&gt;&lt;br/&gt;au &lt;time class=\"nowrap date-lien\" data-sort-value=\"2020-03-08\" datetime=\"2020-03-08\"&gt;&lt;a href=\"/wiki/8_mars_en_sport\" title=\"8 mars en sport\"&gt;8 mars&lt;/a&gt; &lt;a href=\"/wiki/2020_en_football\" title=\"2020 en football\"&gt;2020&lt;/a&gt;&lt;/time&gt; &lt;small&gt;(arr√™t d√©finitif)&lt;/small&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Participants&lt;/th&gt;\n&lt;td&gt;\n20 √©quipes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Matchs jou√©s&lt;/th&gt;\n&lt;td&gt;\n279 (sur 380 pr√©vus)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Site web officiel&lt;/th&gt;\n&lt;td&gt;\n&lt;cite class=\"ouvrage\" id=\"site_officiel\" style=\"font-style: normal;\"&gt;&lt;a class=\"external text\" href=\"https://www.ligue1.fr/\" rel=\"nofollow\"&gt;Site officiel&lt;/a&gt;&lt;/cite&gt;&lt;/td&gt;\n&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;\n\n\nce qui est le texte source permettant de g√©n√©rer le tableau suivant :\n\n\n\nG√©n√©ralit√©s\n\n\n\n\nSport\n\n\nFootball\n\n\n\n\nOrganisateur(s)\n\n\nLFP\n\n\n\n\n√âdition\n\n\n82e\n\n\n\n\nLieu(x)\n\n\n France et  Monaco\n\n\n\n\nDate\n\n\nDu 9 ao√ªt 2019au 8 mars 2020 (arr√™t d√©finitif)\n\n\n\n\nParticipants\n\n\n20 √©quipes\n\n\n\n\nMatchs jou√©s\n\n\n279 (sur 380 pr√©vus)\n\n\n\n\nSite web officiel\n\n\nSite officiel",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-findall",
    "href": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-findall",
    "title": "Web scraping avec Python",
    "section": "3.4 La m√©thode findAll",
    "text": "3.4 La m√©thode findAll\nPour trouver toutes les occurences, on utilise .findAll().\n\nprint(\n    \"Il y a\", len(page.findAll(\"table\")), \"√©l√©ments dans la page qui sont des &lt;table&gt;\"\n)\n\nIl y a 34 √©l√©ments dans la page qui sont des &lt;table&gt;",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#r√©cup√©ration-des-localisations-des-stades",
    "href": "content/manipulation/04a_webscraping_TP.html#r√©cup√©ration-des-localisations-des-stades",
    "title": "Web scraping avec Python",
    "section": "5.1 R√©cup√©ration des localisations des stades",
    "text": "5.1 R√©cup√©ration des localisations des stades\nEssayez de comprendre pas √† pas ce qui est fait dans les √©tapes qui suivent (la r√©cup√©ration d‚Äôinformations suppl√©mentaires en naviguant dans les pages des diff√©rents clubs).\n\nimport urllib\nimport pandas as pd\nimport bs4\n\ndivision = []\nequipe = []\nstade = []\nlatitude_stade = []\nlongitude_stade = []\n\nurl_list = [\n    \"http://fr.wikipedia.org/wiki/Championnat_de_France_de_football_2019-2020\",\n    \"http://fr.wikipedia.org/wiki/Championnat_de_France_de_football_de_Ligue_2_2019-2020\",\n]\n\nfor url_ligue in url_list:\n\n    print(url_ligue)\n    sock = urllib.request.urlopen(url_ligue).read()\n    page = bs4.BeautifulSoup(sock)\n\n    # Rechercher les liens des √©quipes dans la liste disponible sur wikipedia\n\n    for team in page.findAll(\"span\", {\"class\": \"toponyme\"}):\n\n        # Indiquer si c'est de la ligue 1 ou de la ligue 2\n\n        if url_ligue == url_list[0]:\n            division.append(\"L1\")\n        else:\n            division.append(\"L2\")\n\n        # Trouver le nom et le lien de l'√©quipe\n\n        if team.find(\"a\") != None:\n            team_url = team.find(\"a\").get(\"href\")\n            name_team = team.find(\"a\").get(\"title\")\n            equipe.append(name_team)\n            url_get_info = \"http://fr.wikipedia.org\" + team_url\n            print(url_get_info)\n\n            # aller sur la page de l'√©quipe\n\n            search = urllib.request.urlopen(url_get_info).read()\n            search_team = bs4.BeautifulSoup(search)\n\n            # trouver le stade\n            compteur = 0\n            for stadium in search_team.findAll(\"tr\"):\n                for x in stadium.findAll(\"th\", {\"scope\": \"row\"}):\n                    if x.contents[0].string == \"Stade\" and compteur == 0:\n                        compteur = 1\n                        # trouver le lien du stade et son nom\n                        url_stade = stadium.findAll(\"a\")[1].get(\"href\")\n                        name_stadium = stadium.findAll(\"a\")[1].get(\"title\")\n                        stade.append(name_stadium)\n                        url_get_stade = \"http://fr.wikipedia.org\" + url_stade\n                        print(url_get_stade)\n\n                        # Aller sur la page du stade et trouver ses coodronn√©es g√©ographiques\n\n                        search_stade = urllib.request.urlopen(url_get_stade).read()\n                        soup_stade = bs4.BeautifulSoup(search_stade)\n                        kartographer = soup_stade.find(\n                            \"a\", {\"class\": \"mw-kartographer-maplink\"}\n                        )\n                        if kartographer == None:\n                            latitude_stade.append(None)\n                            longitude_stade.append(None)\n                        else:\n                            for coordinates in kartographer:\n                                print(coordinates)\n                                liste = coordinates.split(\",\")\n                                latitude_stade.append(\n                                    str(liste[0]).replace(\" \", \"\") + \"'\"\n                                )\n                                longitude_stade.append(\n                                    str(liste[1]).replace(\" \", \"\") + \"'\"\n                                )\n\n\ndict = {\n    \"division\": division,\n    \"equipe\": equipe,\n    \"stade\": stade,\n    \"latitude\": latitude_stade,\n    \"longitude\": longitude_stade,\n}\ndata = pd.DataFrame(dict)\ndata = data.dropna()\n\n\ndata.head(5)\n\n\n\n\n\n\n\n\n\ndivision\nequipe\nstade\nlatitude\nlongitude\n\n\n\n\n0\nL1\nParis Saint-Germain Football Club\nParc des Princes\n48¬∞¬†50‚Ä≤¬†29‚Ä≥¬†N'\n2¬∞¬†15‚Ä≤¬†11‚Ä≥¬†E'\n\n\n1\nL1\nLOSC Lille\nStade Pierre-Mauroy\n50¬∞¬†36‚Ä≤¬†43‚Ä≥¬†N'\n3¬∞¬†07‚Ä≤¬†50‚Ä≥¬†E'\n\n\n2\nL1\nOlympique lyonnais\nParc Olympique lyonnais\n45¬∞¬†45‚Ä≤¬†55‚Ä≥¬†N'\n4¬∞¬†58‚Ä≤¬†55‚Ä≥¬†E'\n\n\n3\nL1\nAssociation sportive de Saint-√âtienne\nStade Geoffroy-Guichard\n45¬∞¬†27‚Ä≤¬†39‚Ä≥¬†N'\n4¬∞¬†23‚Ä≤¬†25‚Ä≥¬†E'\n\n\n4\nL1\nOlympique de Marseille\nStade V√©lodrome\n43¬∞¬†16‚Ä≤¬†11‚Ä≥¬†N'\n5¬∞¬†23‚Ä≤¬†45‚Ä≥¬†E'\n\n\n\n\n\n\n\n\nOn va transformer les coordonn√©es en degr√©s en coordonn√©es num√©riques\nafin d‚Äô√™tre en mesure de faire une carte.\n\nimport re\n\n\ndef dms2dd(degrees, minutes, seconds, direction):\n    dd = float(degrees) + float(minutes) / 60 + float(seconds) / (60 * 60)\n    if direction in (\"S\", \"O\"):\n        dd *= -1\n    return dd\n\n\ndef parse_dms(dms):\n    parts = re.split(\"[^\\d\\w]+\", dms)\n    lat = dms2dd(parts[0], parts[1], parts[2], parts[3])\n    # lng = dms2dd(parts[4], parts[5], parts[6], parts[7])\n    return lat\n\n\ndata[\"latitude\"] = data[\"latitude\"].apply(parse_dms)\ndata[\"longitude\"] = data[\"longitude\"].apply(parse_dms)\n\nTous les √©l√©ments sont en place pour faire une belle carte √† ce stade. On\nva utiliser folium pour celle-ci, qui est pr√©sent√© dans la partie\nvisualisation.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#cartes-stades-ligue1",
    "href": "content/manipulation/04a_webscraping_TP.html#cartes-stades-ligue1",
    "title": "Web scraping avec Python",
    "section": "5.2 Carte des stades avec folium",
    "text": "5.2 Carte des stades avec folium\n\nimport geopandas as gpd\nfrom pathlib import Path\nimport folium\n\ngdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data.longitude, data.latitude))\n\nPath(\"leaflet\").mkdir(parents=True, exist_ok=True)\n\ncenter = gdf[[\"latitude\", \"longitude\"]].mean().values.tolist()\nsw = gdf[[\"latitude\", \"longitude\"]].min().values.tolist()\nne = gdf[[\"latitude\", \"longitude\"]].max().values.tolist()\n\nm = folium.Map(location=center, tiles=\"openstreetmap\")\n\n# I can add marker one by one on the map\nfor i in range(0, len(gdf)):\n    folium.Marker(\n        [gdf.iloc[i][\"latitude\"], gdf.iloc[i][\"longitude\"]], popup=gdf.iloc[i][\"stade\"]\n    ).add_to(m)\n\nm.fit_bounds([sw, ne])\n\nLa carte obtenue doit ressembler √† la suivante :\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#version-non-guid√©e",
    "href": "content/manipulation/04a_webscraping_TP.html#version-non-guid√©e",
    "title": "Web scraping avec Python",
    "section": "6.1 Version non guid√©e",
    "text": "6.1 Version non guid√©e\n\n\n Exercice 2 : Les pokemon (version non guid√©e)\nPour cet exercice, nous vous demandons d‚Äôobtenir diff√©rentes informations sur les pok√©mons :\n\nles informations personnelles des 893 pokemons sur le site internet pokemondb.net.\nLes informations que nous aimerions obtenir au final dans un DataFrame sont celles contenues dans 4 tableaux :\n\n\nPok√©dex data\nTraining\nBreeding\nBase stats\n\n\nNous aimerions que vous r√©cup√©riez √©galement les images de chacun des pok√©mons et que vous les enregistriez dans un dossier\n\n\nPetit indice : utilisez les modules request et shutil\nPour cette question, il faut que vous cherchiez de vous m√™me certains √©l√©ments, tout n‚Äôest pas pr√©sent dans le TD.\n\n\n\nPour la question 1, l‚Äôobjectif est d‚Äôobtenir le code source d‚Äôun tableau comme\ncelui qui suit\n(Pokemon Nincada).\n\n\n\nPok√©dex data\n\n\n\n\n\nNational ‚Ññ\n\n\n290\n\n\n\n\nType\n\n\nBug Ground\n\n\n\n\nSpecies\n\n\nTrainee Pok√©mon\n\n\n\n\nHeight\n\n\n0.5¬†m (1‚Ä≤08‚Ä≥)\n\n\n\n\nWeight\n\n\n5.5¬†kg (12.1¬†lbs)\n\n\n\n\nAbilities\n\n\n1. Compound EyesRun Away (hidden ability)\n\n\n\n\nLocal ‚Ññ\n\n\n042 (Ruby/Sapphire/Emerald)111 (X/Y ‚Äî Central Kalos)043 (Omega Ruby/Alpha Sapphire)104 (Sword/Shield)\n\n\n\n\n\n\n\n\n\nTraining\n\n\n\n\n\nEV yield\n\n\n1 Defense\n\n\n\n\nCatch rate\n\n\n255 (33.3% with Pok√©Ball, full HP)\n\n\n\n\nBase Friendship\n\n\n70 (normal)\n\n\n\n\nBase Exp.\n\n\n53\n\n\n\n\nGrowth Rate\n\n\nErratic\n\n\n\n\n\n\n\nBreeding\n\n\n\n\n\nEgg Groups\n\n\nBug\n\n\n\n\nGender\n\n\n50% male, 50% female\n\n\n\n\nEgg cycles\n\n\n15 (3,599‚Äì3,855 steps)\n\n\n\n\n\n\n\n\n\n\n\n\nBase stats\n\n\n\n\n\n\nHP\n\n\n31\n\n\n\n\n\n\n\n172\n\n\n266\n\n\n\n\nAttack\n\n\n45\n\n\n\n\n\n\n\n85\n\n\n207\n\n\n\n\nDefense\n\n\n90\n\n\n\n\n\n\n\n166\n\n\n306\n\n\n\n\nSp. Atk\n\n\n30\n\n\n\n\n\n\n\n58\n\n\n174\n\n\n\n\nSp. Def\n\n\n30\n\n\n\n\n\n\n\n58\n\n\n174\n\n\n\n\nSpeed\n\n\n40\n\n\n\n\n\n\n\n76\n\n\n196\n\n\n\n\n\n\nTotal\n\n\n266\n\n\n\n\nMin\n\n\nMax\n\n\n\n\n\n\n\nPour la question 2, l‚Äôobjectif est d‚Äôobtenir\nles images des pokemon.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#version-guid√©e",
    "href": "content/manipulation/04a_webscraping_TP.html#version-guid√©e",
    "title": "Web scraping avec Python",
    "section": "6.2 Version guid√©e",
    "text": "6.2 Version guid√©e\nLes prochaines parties permettront de faire l‚Äôexercice ci-dessus\n√©tape par √©tape,\nde mani√®re guid√©e.\nNous souhaitons tout d‚Äôabord obtenir les\ninformations personnelles de tous\nles pokemons sur pokemondb.net.\nLes informations que nous aimerions obtenir au final pour les pokemons sont celles contenues dans 4 tableaux :\n\nPok√©dex data\nTraining\nBreeding\nBase stats\n\nNous proposons ensuite de r√©cup√©rer et afficher les images.\n\n6.2.1 Etape 1: constituer un DataFrame de caract√©ristiques\n\n\n Exercice 2b : Les pok√©mons (version guid√©e)\nPour r√©cup√©rer les informations, le code devra √™tre divis√© en plusieurs √©tapes :\n\nTrouvez la page principale du site et la transformer en un objet intelligible pour votre code.\nLes fonctions suivantes vous seront utiles :\n\n\nurllib.request.Request\nurllib.request.urlopen\nbs4.BeautifulSoup\n\n\nCr√©ez une fonction qui permet de r√©cup√©rer la page d‚Äôun pok√©mon √† partir de son nom.\nA partir de la page de bulbasaur, obtenez les 4 tableaux qui nous int√©ressent :\n\n\non va chercher l‚Äô√©l√©ment suivant : ('table', { 'class' : \"vitals-table\"})\npuis stocker ses √©l√©ments dans un dictionnaire\n\n\nR√©cup√©rez par ailleurs la liste de noms des pok√©mons qui nous permettra de faire une boucle par la suite. Combien trouvez-vous de pok√©mons ?\nEcrire une fonction qui r√©cup√®re l‚Äôensemble des informations sur les dix premiers pok√©mons de la liste et les int√®gre dans un DataFrame\n\n\n\nA l‚Äôissue de la question 3,\nvous devriez obtenir une liste de caract√©ristiques proche de celle-ci :\n\n\n{'National ‚Ññ': '0001',\n 'name': 'bulbasaur',\n 'Type': ' Grass Poison ',\n 'Species': 'Seed Pok√©mon',\n 'Height': '0.7\\xa0m (2‚Ä≤04‚Ä≥)',\n 'Weight': '6.9\\xa0kg (15.2\\xa0lbs)',\n 'Abilities': '1. OvergrowChlorophyll (hidden ability)',\n 'Local ‚Ññ': \"0001 (Red/Blue/Yellow)0226 (Gold/Silver/Crystal)0001 (FireRed/LeafGreen)0231 (HeartGold/SoulSilver)0080 (X/Y ‚Äî Central Kalos)0001 (Let's Go Pikachu/Let's Go Eevee)0068 (The Isle of Armor)0164 (The Indigo Disk)\",\n 'EV yield': ' 1 Sp. Atk ',\n 'Catch rate': ' 45 (5.9% with Pok√©Ball, full HP) ',\n 'Base Friendship': ' 50 (normal) ',\n 'Base Exp.': '64',\n 'Growth Rate': 'Medium Slow',\n 'Egg Groups': 'Grass, Monster',\n 'Gender': '87.5% male, 12.5% female',\n 'Egg cycles': '20 (4,884‚Äì5,140 steps) ',\n 'HP': '45',\n 'Attack': '49',\n 'Defense': '49',\n 'Sp. Atk': '65',\n 'Sp. Def': '65',\n 'Speed': '45'}\n\n\nLa structure est ici en dictionnaire, ce qui est pratique.\nEnfin, vous pouvez int√©grer les informations\ndes dix premiers pok√©mons √† un\nDataFrame, qui aura l‚Äôaspect suivant :\n\n\n\n\n\n\n\n\n\n\nNational ‚Ññ\nname\nType\nSpecies\nHeight\nWeight\nAbilities\nLocal ‚Ññ\nEV yield\nCatch rate\n...\nGrowth Rate\nEgg Groups\nGender\nEgg cycles\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\n\n\n\n\n0\n0001\nbulbasaur\nGrass Poison\nSeed Pok√©mon\n0.7¬†m (2‚Ä≤04‚Ä≥)\n6.9¬†kg (15.2¬†lbs)\n1. OvergrowChlorophyll (hidden ability)\n0001 (Red/Blue/Yellow)0226 (Gold/Silver/Crysta...\n1 Sp. Atk\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nGrass, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n45\n49\n49\n65\n65\n45\n\n\n1\n0002\nivysaur\nGrass Poison\nSeed Pok√©mon\n1.0¬†m (3‚Ä≤03‚Ä≥)\n13.0¬†kg (28.7¬†lbs)\n1. OvergrowChlorophyll (hidden ability)\n0002 (Red/Blue/Yellow)0227 (Gold/Silver/Crysta...\n1 Sp. Atk, 1 Sp. Def\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nGrass, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n60\n62\n63\n80\n80\n60\n\n\n2\n0003\nvenusaur\nGrass Poison\nSeed Pok√©mon\n2.0¬†m (6‚Ä≤07‚Ä≥)\n100.0¬†kg (220.5¬†lbs)\n1. OvergrowChlorophyll (hidden ability)\n0003 (Red/Blue/Yellow)0228 (Gold/Silver/Crysta...\n2 Sp. Atk, 1 Sp. Def\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nGrass, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n80\n82\n83\n100\n100\n80\n\n\n3\n0004\ncharmander\nFire\nLizard Pok√©mon\n0.6¬†m (2‚Ä≤00‚Ä≥)\n8.5¬†kg (18.7¬†lbs)\n1. BlazeSolar Power (hidden ability)\n0004 (Red/Blue/Yellow)0229 (Gold/Silver/Crysta...\n1 Speed\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nDragon, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n39\n52\n43\n60\n50\n65\n\n\n4\n0005\ncharmeleon\nFire\nFlame Pok√©mon\n1.1¬†m (3‚Ä≤07‚Ä≥)\n19.0¬†kg (41.9¬†lbs)\n1. BlazeSolar Power (hidden ability)\n0005 (Red/Blue/Yellow)0230 (Gold/Silver/Crysta...\n1 Sp. Atk, 1 Speed\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nDragon, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n58\n64\n58\n80\n65\n80\n\n\n\n\n5 rows √ó 22 columns\n\n\n\n\n\n\n6.2.2 Etape 2: r√©cup√©rer et afficher des photos de Pokemon\nNous aimerions que vous r√©cup√©riez √©galement les images des 5 premiers pok√©mons\net que vous les enregistriez dans un dossier.\n\n\n Exercice 2b : Les pok√©mons (version guid√©e)\n\nLes URL des images des pokemon prennent la forme ‚Äúhttps://img.pokemondb.net/artwork/{pokemon}.jpg‚Äù.\nUtiliser les modules requests et shutil pour t√©l√©charger\net enregistrer en local les images.\nImporter ces images stock√©es au format JPEG dans Python gr√¢ce √† la fonction imread du package skimage.io\n\n\n\n\n!pip install scikit-image\n\nRequirement already satisfied: scikit-image in /opt/mamba/lib/python3.11/site-packages (0.23.2)\nRequirement already satisfied: numpy&gt;=1.23 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (1.26.4)\nRequirement already satisfied: scipy&gt;=1.9 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (1.13.0)\nRequirement already satisfied: networkx&gt;=2.8 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (3.3)\nRequirement already satisfied: pillow&gt;=9.1 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (10.3.0)\nRequirement already satisfied: imageio&gt;=2.33 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (2.34.1)\nRequirement already satisfied: tifffile&gt;=2022.8.12 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (2024.4.24)\nRequirement already satisfied: packaging&gt;=21 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (23.2)\nRequirement already satisfied: lazy-loader&gt;=0.4 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (0.4)\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#premier-exemple-en-scrapant-un-moteur-de-recherche",
    "href": "content/manipulation/04a_webscraping_TP.html#premier-exemple-en-scrapant-un-moteur-de-recherche",
    "title": "Web scraping avec Python",
    "section": "7.1 Premier exemple en scrapant un moteur de recherche",
    "text": "7.1 Premier exemple en scrapant un moteur de recherche\nDans cet exemple, nous allons essayer d‚Äôaller sur le\nsite de Bing Actualit√©s\net entrer dans la barre de recherche un sujet donn√©.\nPour tester, nous allons faire une recherche avec le mot-cl√© ‚ÄúTrump‚Äù.\nL‚Äôinstallation de Selenium n√©cessite d‚Äôavoir Chromium qui est un\nnavigateur Google Chrome minimaliste.\nLa version de chromedriver\ndoit √™tre &gt;= 2.36 et d√©pend de la version de Chrome que vous avez sur votre environnement\nde travail. Pour installer cette version minimaliste de Chrome sur un environnement\nLinux, vous pouvez vous r√©f√©rer √† l‚Äôencadr√© d√©di√©.\n\n\n Installation de Selenium\nD‚Äôabord, il convient d‚Äôinstaller les d√©pendances.\nSur Colab, vous pouvez utiliser les commandes suivantes :\n\n!sudo apt-get update\n!sudo apt install -y unzip xvfb libxi6 libgconf-2-4 -y\n!sudo apt install chromium-chromedriver -y\n!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n\n\nSi vous √™tes sur le SSP Cloud, vous pouvez\nex√©cuter les commandes suivantes :\n\n!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -O /tmp/chrome.deb\n!sudo apt-get update\n!sudo -E apt-get install -y /tmp/chrome.deb\n!pip install chromedriver-autoinstaller selenium\n\nimport chromedriver_autoinstaller\nchromedriver_autoinstaller.install()\n\n\nVous pouvez ensuite installer Selenium.\nPar exemple, depuis une\ncellule de Notebook :\n\n\nApr√®s avoir install√© Chromium,\nil est n√©cessaire d‚Äôindiquer √† Python o√π\nle trouver. Si vous √™tes sur Linux et que vous\navez suivi les consignes pr√©c√©dentes, vous pouvez faire :\n\nimport selenium\nfrom webdriver_manager.chrome import ChromeDriverManager\n\npath_to_web_driver = ChromeDriverManager().install()\n\nEn premier lieu, il convient d‚Äôinitialiser le comportement\nde Selenium en r√©pliquant les param√®tres\ndu navigateur. Pour cela, on va d‚Äôabord initialiser\nnotre navigateur avec quelques options :\n\nimport time\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\nchrome_options = webdriver.ChromeOptions()\nchrome_options.add_argument(\"--headless\")\nchrome_options.add_argument(\"--no-sandbox\")\nchrome_options.add_argument(\"--disable-dev-shm-usage\")\n# chrome_options.add_argument('--verbose')\n\nPuis on lance le navigateur :\n\nfrom selenium.webdriver.chrome.service import Service\n\nservice = Service(executable_path=path_to_web_driver)\n\nbrowser = webdriver.Chrome(service=service, options=chrome_options)\n\nOn va sur le site de Bing Actualit√©s,\net on lui indique le mot cl√© que nous souhaitons chercher.\nEn l‚Äôoccurrence, on s‚Äôint√©resse aux actualit√©s de Donald Trump.\nApr√®s avoir inspect√© la page depuis les outils de d√©veloppement du navigateur,\non voit que la barre de recherche est un √©lement du code appel√© q (comme query).\nOn va ainsi demander √† selenium de chercher cet √©l√©ment:\n\nbrowser.get(\"https://www.bing.com/news\")\n\nsearch = browser.find_element(\"name\", \"q\")\nprint(search)\nprint([search.text, search.tag_name, search.id])\n\n# on envoie √† cet endroit le mot qu'on aurait tap√© dans la barre de recherche\nsearch.send_keys(\"Trump\")\n\nsearch_button = browser.find_element(\"xpath\", \"//input[@id='sb_form_go']\")\nsearch_button.click()\n\nSelenium permet de capturer l‚Äôimage qu‚Äôon verrait dans le navigateur\navec get_screenshot_as_png. Cela peut √™tre utile pour v√©rifier qu‚Äôon\na fait la bonne action :\n\n\n\n\n\n\n\n\n\nEnfin, on peut extraire les r√©sultats. Plusieurs\nm√©thodes sont disponibles. La m√©thode la plus\npratique, lorsqu‚Äôelle est disponible,\nest d‚Äôutiliser le XPath qui est un chemin\nnon ambigu pour acc√©der √† un √©lement. En effet,\nplusieurs √©l√©ments peuvent partager la m√™me classe ou\nle m√™me attribut ce qui peut faire qu‚Äôune recherche\nde ce type peut renvoyer plusieurs √©chos.\nPour d√©terminer le XPath d‚Äôun objet, les outils\nde d√©veloppeurs de votre site web sont pratiques.\nPar exemple, sous Firefox, une fois que vous\navez trouv√© un √©l√©ment dans l‚Äôinspecteur, vous\npouvez faire click droit &gt; Copier &gt; XPath.\nEnfin, pour mettre fin √† notre session, on demande\n√† Python de quitter le navigateur:\n\nbrowser.quit()\n\nOn a obtenu les r√©sultats suivants :\n\n\n['https://www.thedailybeast.com/trump-claimed-trial-interferes-with-his-campaign-but-on-his-day-off-he-went-golfing', 'https://www.msn.com/en-us/news/other/donald-trump-s-family-skipping-court-right-decision-legal-analyst-says/ar-AA1nFyBC', 'https://www.msn.com/en-us/news/other/scotus-sees-dangerous-precedent-in-trump-immunity-case-if-presidents-can-prosecute-rivals-experts/ar-AA1nFB6a', 'https://www.msn.com/en-us/news/politics/we-are-writing-a-rule-for-the-ages-supreme-court-justices-give-little-away-during-oral-arguments-on-scope-of-trump-s-presidential-immunity/ar-AA1nFDOI', 'https://www.msn.com/en-us/news/politics/trump-to-convene-donors-vice-president-hopefuls-in-palm-beach/ar-AA1nFIDc', 'https://www.msn.com/en-us/news/politics/trumps-lawyer-says-presidents-could-get-away-with-crimes-if-they-arent-discovered-until-after-they-leave-office/ar-AA1nFtSw', 'https://www.msn.com/en-us/news/crime/judge-upholds-83m-e-jean-carroll-defamation-award-against-donald-trump/ar-AA1nFFKL', 'https://www.al.com/news/2024/04/trump-could-have-absolute-immunity-for-assassinating-political-rival-attorney-suggests.html']\n\n\nLes autres m√©thodes utiles de Selenium:\n\n\n\n\n\n\n\nM√©thode\nR√©sultat\n\n\n\n\nfind_element(****).click()\nUne fois qu‚Äôon a trouv√© un √©l√©ment r√©actif, notamment un bouton, on peut cliquer dessus pour activer une nouvelle page\n\n\nfind_element(****).send_keys(\"toto\")\nUne fois qu‚Äôon a trouv√© un √©l√©ment, notamment un champ o√π s‚Äôauthentifier, on peut envoyer une valeur, ici ‚Äútoto‚Äù.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#utiliser-selenium-pour-jouer-√†-2048",
    "href": "content/manipulation/04a_webscraping_TP.html#utiliser-selenium-pour-jouer-√†-2048",
    "title": "Web scraping avec Python",
    "section": "7.2 Utiliser Selenium pour jouer √† 2048",
    "text": "7.2 Utiliser Selenium pour jouer √† 2048\nDans cet exemple, on utilise le module pour que Python\nappuie lui m√™me sur les touches du clavier afin de jouer √† 2048.\nNote : ce bout de code ne donne pas une solution √† 2048,\nil permet juste de voir ce qu‚Äôon peut faire avec Selenium.\n\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.common.keys import Keys\n\n# on ouvre la page internet du jeu 2048\nservice = Service(executable_path=path_to_web_driver)\n\nbrowser = webdriver.Chrome(service=service, options=chrome_options)\nbrowser.get(\"https://play2048.co//\")\n\n# Ce qu'on va faire : une boucle qui r√©p√®te inlassablement la m√™me chose : haut / droite / bas / gauche\n\n# on commence par cliquer sur la page pour que les touches sachent\nbutton = browser.find_element(\"class name\", \"grid-container\")\nbrowser.execute_script(\"arguments[0].click();\", button)\ntime.sleep(0.5)\n\ngrid = browser.find_element(\"tag name\", \"body\")\n\n# pour savoir quels coups faire √† quel moment, on cr√©e un dictionnaire\ndirection = {0: Keys.UP, 1: Keys.RIGHT, 2: Keys.DOWN, 3: Keys.LEFT}\ncount = 0\n\nwhile True:\n    try:  # on v√©rifie que le bouton \"Try again\" n'est pas l√† - sinon √ßa veut dire que le jeu est fini\n        retryButton = browser.find_element(\"link text\", \"Try again\")\n        scoreElem = browser.find_element(\"class name\", \"score-container\")\n        break\n    except:\n        # Do nothing.  Game is not over yet\n        pass\n    # on continue le jeu - on appuie sur la touche suivante pour le coup d'apr√®s\n    count += 1\n    grid.send_keys(direction[count % 4])\n    time.sleep(0.1)\n\nprint(\"Score final : {} en {} coups\".format(scoreElem.text, count))\nbrowser.quit()",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#exercice-suppl√©mentaire",
    "href": "content/manipulation/04a_webscraping_TP.html#exercice-suppl√©mentaire",
    "title": "Web scraping avec Python",
    "section": "7.3 Exercice suppl√©mentaire",
    "text": "7.3 Exercice suppl√©mentaire\nPour d√©couvrir une autre application possible du web scraping, vous pouvez √©galement vous lancer dans le sujet 5 de l‚Äô√©dition 2023 d‚Äôun hackathon non comp√©titif organis√© par l‚ÄôInsee :\n\nSur Github\nSur le SSPCloud\n\nLe contenu de la section NLP du cours pourra vous √™tre utile pour la seconde partie du sujet !",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#informations-additionnelles",
    "href": "content/manipulation/04a_webscraping_TP.html#informations-additionnelles",
    "title": "Web scraping avec Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n762f85a\n\n\n2023-10-23 18:12:15\n\n\nLino Galiana\n\n\nMise en forme du TP webscraping (#441)\n\n\n\n\n8071bbb\n\n\n2023-10-23 17:43:37\n\n\ntomseimandi\n\n\nMake minor changes to 02b, 03, 04a (#440)\n\n\n\n\n3eb0aeb\n\n\n2023-10-23 11:59:24\n\n\nThomas Faria\n\n\nRelecture jusqu‚Äôaux API (#439)\n\n\n\n\n102ce9f\n\n\n2023-10-22 11:39:37\n\n\nThomas Faria\n\n\nRelecture Thomas, premi√®re partie (#438)\n\n\n\n\nfbbf066\n\n\n2023-10-16 14:57:03\n\n\nAntoine Palazzolo\n\n\nCorrection TP scraping (#435)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\nb7f4d7e\n\n\n2023-09-17 17:03:14\n\n\nAntoine Palazzolo\n\n\nRenvoi vers sujet funathon pour partie scraping (#404)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8baf507\n\n\n2023-08-28 11:09:30\n\n\nLino Galiana\n\n\nLien mort formation webscraping\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n3560f1f\n\n\n2023-07-21 17:04:56\n\n\nLino Galiana\n\n\nBuild on smaller sized image (#384)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\n938f9bc\n\n\n2022-12-04 15:28:37\n\n\nLino Galiana\n\n\nTest selenium en int√©gration continue (#331)\n\n\n\n\n342b59b\n\n\n2022-12-04 11:55:00\n\n\nRomain Avouac\n\n\nProcedure to install selenium on ssp cloud (#330)\n\n\n\n\n037842a\n\n\n2022-11-22 17:52:25\n\n\nLino Galiana\n\n\nWebscraping exercice nom et age ministres (#326)\n\n\n\n\n738c074\n\n\n2022-11-17 12:23:29\n\n\nLino Galiana\n\n\nNettoie le TP scraping (#323)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\n43a863f\n\n\n2022-09-27 11:14:18\n\n\nLino Galiana\n\n\nChange notebook url (#283)\n\n\n\n\n25046de\n\n\n2022-09-26 18:08:19\n\n\nLino Galiana\n\n\nRectifie bug TP webscraping (#281)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\nbb38643\n\n\n2022-06-08 16:59:40\n\n\nLino Galiana\n\n\nR√©pare bug leaflet (#234)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n66e2837\n\n\n2021-12-24 16:54:45\n\n\nLino Galiana\n\n\nFix a few typos in the new pipeline tutorial (#208)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb138cf3\n\n\n2021-10-21 18:05:59\n\n\nLino Galiana\n\n\nMise √† jour TP webscraping et API (#164)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html",
    "href": "content/manipulation/04b_regex_TP.html",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#classes-de-caract√®res",
    "href": "content/manipulation/04b_regex_TP.html#classes-de-caract√®res",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "2.1 Classes de caract√®res",
    "text": "2.1 Classes de caract√®res\nLors d‚Äôune recherche, on s‚Äôint√©resse aux caract√®res et souvent aux classes de caract√®res : on cherche un chiffre, une lettre, un caract√®re dans un ensemble pr√©cis ou un caract√®re qui n‚Äôappartient pas √† un ensemble pr√©cis. Certains ensembles sont pr√©d√©finis, d‚Äôautres doivent √™tre d√©finis √† l‚Äôaide de crochets.\nPour d√©finir un ensemble de caract√®res, il faut √©crire cet ensemble entre crochets. Par exemple, [0123456789] d√©signe un chiffre. Comme c‚Äôest une s√©quence de caract√®res cons√©cutifs, on peut r√©sumer cette √©criture en [0-9].\nPar\nexemple, si on d√©sire trouver tous les pattern qui commencent par un c suivi\nd‚Äôun h puis d‚Äôune voyelle (a, e, i, o, u), on peut essayer\ncette expression r√©guli√®re.\n\nre.findall(\"[c][h][aeiou]\", \"chat, chien, veau, vache, ch√®vre\")\n\n['cha', 'chi', 'che']\n\n\nIl serait plus pratique d‚Äôutiliser Pandas dans ce cas pour isoler les\nlignes qui r√©pondent √† la condition logique (en ajoutant les accents\nqui ne sont pas compris sinon):\n\nimport pandas as pd\n\ntxt = pd.Series(\"chat, chien, veau, vache, ch√®vre\".split(\", \"))\ntxt.str.match(\"ch[ae√©√®iou]\")\n\n0     True\n1     True\n2    False\n3    False\n4     True\ndtype: bool\n\n\nCependant, l‚Äôusage ci-dessus des classes de caract√®res\nn‚Äôest pas le plus fr√©quent.\nOn privil√©gie celles-ci pour identifier des\npattern complexe plut√¥t qu‚Äôune suite de caract√®res litt√©raux.\nLes tableaux d‚Äôaide m√©moire illustrent une partie des\nclasses de caract√®res les plus fr√©quentes\n([:digit:] ou \\d‚Ä¶)",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#quantifieurs",
    "href": "content/manipulation/04b_regex_TP.html#quantifieurs",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "2.2 Quantifieurs",
    "text": "2.2 Quantifieurs\nNous avons rencontr√© les quantifieurs avec notre premi√®re expression\nr√©guli√®re. Ceux-ci contr√¥lent le nombre de fois\nqu‚Äôun pattern est rencontr√©.\nLes plus fr√©quents sont:\n\n? : 0 ou 1 match ;\n+ : 1 ou plus de matches ;\n* : 0 or more matches.\n\nPar exemple, colou?r permettra de matcher √† la fois l‚Äô√©criture am√©ricaine et anglaise\n\nre.findall(\"colou?r\", \"Did you write color or colour?\")\n\n['color', 'colour']\n\n\nCes quantifiers peuvent bien s√ªr √™tre associ√©s √†\nd‚Äôautres types de caract√®res, notamment les classes de caract√®res.\nCela peut √™tre extr√®mement pratique.\nPar exemple, \\d+ permettra de capturer un ou plusieurs chiffres, \\s?\npermettra d‚Äôajouter en option un espace,\n[\\w]{6,8} un mot entre six et huit lettres qu‚Äôon √©crira‚Ä¶\nIl est aussi possible de d√©finir le nombre de r√©p√©titions\navec {}:\n\n{n} matche exactement n fois ;\n{n,} matche au moins n fois ;\n{n,m} matche entre n et m fois.\n\nCependant, la r√©p√©tition des termes\nne s‚Äôapplique par d√©faut qu‚Äôau dernier\ncaract√®re pr√©c√©dent le quantifier.\nOn peut s‚Äôen convaincre avec l‚Äôexemple ci-dessus:\n\nprint(re.match(\"toc{4}\", \"toctoctoctoc\"))\n\nNone\n\n\nPour pallier ce probl√®me, il existe les parenth√®ses.\nLe principe est le m√™me qu‚Äôavec les r√®gles num√©riques:\nles parenth√®ses permettent d‚Äôintroduire une hi√©rarchie.\nPour reprendre l‚Äôexemple pr√©c√©dent, on obtient\nbien le r√©sultat attendu gr√¢ce aux parenth√®ses:\n\nprint(re.match(\"(toc){4}\", \"toctoctoctoc\"))\nprint(re.match(\"(toc){5}\", \"toctoctoctoc\"))\nprint(re.match(\"(toc){2,4}\", \"toctoctoctoc\"))\n\n&lt;re.Match object; span=(0, 12), match='toctoctoctoc'&gt;\nNone\n&lt;re.Match object; span=(0, 12), match='toctoctoctoc'&gt;\n\n\n\n\n Note\nL‚Äôalgorithme des expressions r√©guli√®res essaye toujours de faire correspondre le plus grand morceau √† l‚Äôexpression r√©guli√®re.\nPar exemple, soit une chaine de caract√®re HTML:\n\ns = \"&lt;h1&gt;Super titre HTML&lt;/h1&gt;\"\n\nL‚Äôexpression r√©guli√®re re.findall(\"&lt;.*&gt;\", s) correspond, potentiellement,\n√† trois morceaux :\n\n&lt;h1&gt;\n&lt;/h1&gt;\n&lt;h1&gt;Super titre HTML&lt;/h1&gt;\n\nC‚Äôest ce dernier qui sera choisi, car le plus grand. Pour\ns√©lectionner le plus petit,\nil faudra √©crire les multiplicateurs comme ceci : *?, +?.\nEn voici quelques exemples:\n\ns = \"&lt;h1&gt;Super titre HTML&lt;/h1&gt;\\n&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;\"\nprint(re.findall(\"&lt;.*&gt;\", s))\nprint(re.findall(\"&lt;p&gt;.*&lt;/p&gt;\", s))\nprint(re.findall(\"&lt;p&gt;.*?&lt;/p&gt;\", s))\nprint(re.compile(\"&lt;.*?&gt;\").findall(s))\n\n['&lt;h1&gt;Super titre HTML&lt;/h1&gt;', '&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;']\n['&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;']\n['&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;']\n['&lt;h1&gt;', '&lt;/h1&gt;', '&lt;p&gt;', '&lt;code&gt;', '&lt;/code&gt;', '&lt;/p&gt;']",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#aide-m√©moire",
    "href": "content/manipulation/04b_regex_TP.html#aide-m√©moire",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "2.3 Aide-m√©moire",
    "text": "2.3 Aide-m√©moire\nLe tableau ci-dessous peut servir d‚Äôaide-m√©moire\nsur les regex:\n\n\n\n\n\n\n\nExpression r√©guli√®re\nSignification\n\n\n\n\n\"^\"\nD√©but de la cha√Æne de caract√®res\n\n\n\"$\"\nFin de la cha√Æne de caract√®res\n\n\n\"\\\\.\"\nUn point\n\n\n\".\"\nN‚Äôimporte quel caract√®re\n\n\n\".+\"\nN‚Äôimporte quelle suite de caract√®res non vide\n\n\n\".*\"\nN‚Äôimporte quelle suite de caract√®res, √©ventuellement vi\n\n\n\"[:alnum:]\"\nUn caract√®re alphanum√©rique\n\n\n\"[:alpha:]\"\nUne lettre\n\n\n\"[:digit:]\"\nUn chiffre\n\n\n\"[:lower:]\"\nUne lettre minuscule\n\n\n\"[:punct:]\"\nUn signe de ponctuation\n\n\n\"[:space:]\"\nun espace\n\n\n\"[:upper:]\"\nUne lettre majuscule\n\n\n\"[[:alnum:]]+\"\nUne suite d‚Äôau moins un caract√®re alphanum√©rique\n\n\n\"[[:alpha:]]+\"\nUne suite d‚Äôau moins une lettre\n\n\n\"[[:digit:]]+\"\nUne suite d‚Äôau moins un chiffre\n\n\n\"[[:lower:]]+\"\nUne suite d‚Äôau moins une lettre minuscule\n\n\n\"[[:punct:]]+\"\nUne suite d‚Äôau moins un signe de ponctuation\n\n\n\"[[:space:]]+\"\nUne suite d‚Äôau moins un espace\n\n\n\"[[:upper:]]+\"\nUne suite d‚Äôau moins une lettre majuscule\n\n\n\"[[:alnum:]]*\"\nUne suite de caract√®res alphanum√©riques, √©ventuellement vide\n\n\n\"[[:alpha:]]*\"\nUne suite de lettres, √©ventuellement vide\n\n\n\"[[:digit:]]*\"\nUne suite de chiffres, √©ventuellement vide\n\n\n\"[[:lower:]]*\"\nUne suite de lettres minuscules, √©ventuellement vide\n\n\n\"[[:upper:]]*\"\nUne suite de lettres majuscules, √©ventuellement vide\n\n\n\"[[:punct:]]*\"\nUne suite de signes de ponctuation, √©ventuellement vide\n\n\n\"[^[:alpha:]]+\"\nUne suite d‚Äôau moins un caract√®re autre qu‚Äôune lettre\n\n\n\"[^[:digit:]]+\"\nUne suite d‚Äôau moins un caract√®re autre qu‚Äôun chiffre\n\n\n\"\\|\"\nL‚Äôune des expressions x ou y est pr√©sente\n\n\n[abyz]\nUn seul des caract√®res sp√©cifi√©s\n\n\n[abyz]+\nUn ou plusieurs des caract√®res sp√©cifi√©s (√©ventuellement r√©p√©t√©s)\n\n\n[^abyz]\nAucun des caract√®res sp√©cifi√©s n‚Äôest pr√©sent\n\n\n\nCertaines classes de caract√®res b√©n√©ficient d‚Äôune syntaxe plus l√©g√®re car\nelles sont tr√®s fr√©quentes. Parmi-celles:\n\n\n\n\n\n\n\nExpression r√©guli√®re\nSignification\n\n\n\n\n\\d\nN‚Äôimporte quel chiffre\n\n\n\\D\nN‚Äôimporte quel caract√®re qui n‚Äôest pas un caract√®re\n\n\n\\s\nN‚Äôimporte quel espace (espace, tabulation, retour √† la ligne)\n\n\n\\S\nN‚Äôimporte quel caract√®re qui n‚Äôest pas un espace\n\n\n\\w\nN‚Äôimporte quel type de mot (lettres et nombres)\n\n\n\\W\nN‚Äôimporte quel ensemble qui n‚Äôest pas un mot (lettres et nombres)\n\n\n\nDans l‚Äôexercice suivant, vous allez pouvoir mettre en pratique\nles exemples pr√©c√©dents sur une regex un peu plus compl√®te.\nCet exercice ne n√©cessite pas la connaissance des subtilit√©s\ndu package re, vous n‚Äôaurez besoin que de re.findall.\nCet exercice utilisera la chaine de caract√®re suivante :\n\ns = \"\"\"date 0 : 14/9/2000\ndate 1 : 20/04/1971     date 2 : 14/09/1913     date 3 : 2/3/1978\ndate 4 : 1/7/1986     date 5 : 7/3/47     date 6 : 15/10/1914\ndate 7 : 08/03/1941     date 8 : 8/1/1980     date 9 : 30/6/1976\"\"\"\ns\n\n'date 0 : 14/9/2000\\ndate 1 : 20/04/1971     date 2 : 14/09/1913     date 3 : 2/3/1978\\ndate 4 : 1/7/1986     date 5 : 7/3/47     date 6 : 15/10/1914\\ndate 7 : 08/03/1941     date 8 : 8/1/1980     date 9 : 30/6/1976'\n\n\n\n\n Exercice 1\n\nOn va d‚Äôabord s‚Äôoccuper d‚Äôextraire le jour de naissance.\n\nLe premier chiffre du jour est 0, 1, 2 ou 3. Traduire cela sous la forme d‚Äôune s√©quence [X-X]\nLe deuxi√®me chiffre du jour est lui entre 0 et 9. Traduire cela sous la s√©quence ad√©quate\nRemarquez que le premier jour est facultatif. Intercaler entre les deux classes de caract√®re ad√©quate\nle quantifieur qui convient\nAjouter le slash √† la suite du motif\nTester avec re.findall. Vous devriez obtenir beaucoup plus d‚Äô√©chos que n√©cessaire.\nC‚Äôest normal, √† ce stade la\nregex n‚Äôest pas encore finalis√©e\n\nSuivre la m√™me logique pour les mois en notant que les mois du calendrier gr√©gorien ne d√©passent\njamais la premi√®re dizaine. Tester avec re.findall\nDe m√™me pour les ann√©es de naissance en notant que jusqu‚Äô√† preuve du contraire, pour des personnes vivantes\naujourd‚Äôhui, les mill√©naires concern√©s sont restreints. Tester avec re.findall\nCette regex n‚Äôest pas naturelle, on pourrait tr√®s bien se satisfaire de classes de\ncaract√®res g√©n√©riques \\d m√™me si elles pourraient, en pratique, nous s√©lectionner des\ndates de naissance non possibles (43/78/4528 par exemple). Cela permettrait\nd‚Äôall√©ger la regex afin de la rendre plus intelligible. Ne pas oublier l‚Äôutilit√© des quantifieurs.\nComment adapter la regex pour qu‚Äôelle soit toujours valide pour nos cas mais permette aussi de\ncapturer les dates de type YYYY/MM/DD ? Tester sur 1998/07/12\n\n\n\nA l‚Äôissue de la question 1, vous devriez avoir ce r√©sultat :\n\n\n['14/',\n '9/',\n '20/',\n '04/',\n '14/',\n '09/',\n '2/',\n '3/',\n '1/',\n '7/',\n '7/',\n '3/',\n '15/',\n '10/',\n '08/',\n '03/',\n '8/',\n '1/',\n '30/',\n '6/']\n\n\nA l‚Äôissue de la question 2, vous devriez avoir ce r√©sultat, qui\ncommence √† prendre forme:\n\n\n['14/9',\n '20/04',\n '14/09',\n '2/3',\n '1/7',\n '7/3',\n '15/10',\n '08/03',\n '8/1',\n '30/6']\n\n\nA l‚Äôissue de la question 3, on parvient bien\n√† extraire les dates :\n\n\n['14/9/2000',\n '20/04/1971',\n '14/09/1913',\n '2/3/1978',\n '1/7/1986',\n '7/3/47',\n '15/10/1914',\n '08/03/1941',\n '8/1/1980',\n '30/6/1976']\n\n\nSi tout va bien, √† la question 5, votre regex devrait\nfonctionner:\n\n\n['14/9/2000',\n '20/04/1971',\n '14/09/1913',\n '2/3/1978',\n '1/7/1986',\n '7/3/47',\n '15/10/1914',\n '08/03/1941',\n '8/1/1980',\n '30/6/1976',\n '1998/07/12']",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#extraction-dadresses-email",
    "href": "content/manipulation/04b_regex_TP.html#extraction-dadresses-email",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "6.1 Extraction d‚Äôadresses email",
    "text": "6.1 Extraction d‚Äôadresses email\nIl s‚Äôagit d‚Äôun usage classique des regex\n\ntext_emails = (\n    \"Hello from toto@gmail.com to titi.grominet@yahoo.com about the meeting @2PM\"\n)\n\n\n\n Exercice : extraction d'adresses email\nUtiliser la structure d‚Äôune adresse mail [XXXX]@[XXXX] pour r√©cup√©rer\nce contenu\n\n\n\n\n['toto@gmail.com', 'titi.grominet@yahoo.com']",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#extraire-des-ann√©es-depuis-un-dataframe-pandas",
    "href": "content/manipulation/04b_regex_TP.html#extraire-des-ann√©es-depuis-un-dataframe-pandas",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "6.2 Extraire des ann√©es depuis un DataFrame Pandas",
    "text": "6.2 Extraire des ann√©es depuis un DataFrame Pandas\nL‚Äôobjectif g√©n√©ral de l‚Äôexercice est de nettoyer des colonnes d‚Äôun DataFrame en utilisant des expressions r√©guli√®res.\n\n\n Exercice\nLa base en question contient des livres de la British Library et quelques informations les concernant. Le jeu de donn√©es est disponible ici : https://raw.githubusercontent.com/realpython/python-data-cleaning/master/Datasets/BL-Flickr-Images-Book.csv\nLa colonne ‚ÄúDate de Publication‚Äù n‚Äôest pas toujours une ann√©e, il y a parfois d‚Äôautres informations. Le but de l‚Äôexercice est d‚Äôavoir une date de publication du livre propre et de regarder la distribution des ann√©es de publications.\nPour ce faire, vous pouvez :\n\nSoit choisir de r√©aliser l‚Äôexercice sans aide. Votre lecture de l‚Äô√©nonc√© s‚Äôarr√™te donc ici. Vous devez alors faire attention √† bien regarder vous-m√™me la base de donn√©es et la transformer avec attention.\nSoit suivre les diff√©rentes √©tapes qui suivent pas √† pas.\n\nVersion guid√©e üëá\n\nLire les donn√©es depuis l‚Äôurl https://raw.githubusercontent.com/realpython/python-data-cleaning/master/Datasets/BL-Flickr-Images-Book.csv. Attention au s√©parateur\nNe garder que les colonnes ['Identifier', 'Place of Publication', 'Date of Publication', 'Publisher', 'Title', 'Author']\nObserver la colonne ‚ÄòDate of Publication‚Äô et remarquer le probl√®me sur certaines lignes (par exemple la ligne 13)\nCommencez par regarder le nombre d‚Äôinformations manquantes. On ne pourra pas avoir mieux apr√®s la regex, et normalement on ne devrait pas avoir moins‚Ä¶\nD√©terminer la forme de la regex pour une date de publication. A priori, il y a 4 chiffres qui forment une ann√©e.\nUtiliser la m√©thode str.extract() avec l‚Äôargument expand = False (pour ne conserver que la premi√®re date concordant avec notre pattern)?\nOn a 2 NaN qui n‚Äô√©taient pas pr√©sents au d√©but de l‚Äôexercice. Quels sont-ils et pourquoi ?\nQuelle est la r√©partition des dates de publications dans le jeu de donn√©es ? Vous pouvez par exemple afficher un histogramme gr√¢ce √† la m√©thode plot avec l‚Äôargument kind =\"hist\".\n\n\n\n\nVoici par exemple le probl√®me qu‚Äôon demande de d√©tecter √† la question 3 :\n\n\n\n\n\n\n\n\n\n\nDate of Publication\nTitle\n\n\n\n\n13\n1839, 38-54\nDe Aardbol. Magazijn van hedendaagsche land- e...\n\n\n14\n1897\nCronache Savonesi dal 1500 al 1570 ... Accresc...\n\n\n15\n1865\nSee-Saw; a novel ... Edited [or rather, writte...\n\n\n16\n1860-63\nGeÃÅodeÃÅsie d'une partie de la Haute EÃÅthiopie,...\n\n\n17\n1873\n[With eleven maps.]\n\n\n18\n1866\n[Historia geograÃÅfica, civil y politica de la ...\n\n\n19\n1899\nThe Crisis of the Revolution, being the story ...\n\n\n\n\n\n\n\n\n\n\n181\n\n\nGr√¢ce √† notre regex (question 5), on obtient ainsi un DataFrame plus conforme √† nos attentes\n\n\n\n\n\n\n\n\n\n\nDate of Publication\nyear\n\n\n\n\n0\n1879 [1878]\n1879\n\n\n7\nNaN\nNaN\n\n\n13\n1839, 38-54\n1839\n\n\n16\n1860-63\n1860\n\n\n23\n1847, 48 [1846-48]\n1847\n\n\n...\n...\n...\n\n\n8278\n1883, [1884]\n1883\n\n\n8279\n1898-1912\n1898\n\n\n8283\n1831, 32\n1831\n\n\n8284\n[1806]-22\n1806\n\n\n8286\n1834-43\n1834\n\n\n\n\n1759 rows √ó 2 columns\n\n\n\n\nQuant aux nouveaux NaN,\nil s‚Äôagit de lignes qui ne contenaient pas de cha√Ænes de caract√®res qui ressemblaient √† des ann√©es :\n\n\n\n\n\n\n\n\n\n\nDate of Publication\nyear\n\n\n\n\n1081\n112. G. & W. B. Whittaker\nNaN\n\n\n7391\n17 vols. University Press\nNaN\n\n\n\n\n\n\n\n\nEnfin, on obtient l‚Äôhistogramme suivant des dates de publications:",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#informations-additionnelles",
    "href": "content/manipulation/04b_regex_TP.html#informations-additionnelles",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n62b2a7c\n\n\n2022-12-28 15:00:50\n\n\nLino Galiana\n\n\nSuite chapitre regex (#340)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb138cf3\n\n\n2021-10-21 18:05:59\n\n\nLino Galiana\n\n\nMise √† jour TP webscraping et API (#164)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\na5f4824\n\n\n2021-07-16 14:20:27\n\n\nLino Galiana\n\n\nExo suppl√©mentaire webscraping marmiton üçù (#121) (#124)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#footnotes",
    "href": "content/manipulation/04b_regex_TP.html#footnotes",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nN‚Äôimporte quel caract√®re √† part le retour √† la ligne (\\n). Ceci est √† garder en t√™te, j‚Äôai d√©j√† perdu des heures √† chercher pourquoi mon . ne capturait pas ce que je voulais qui s‚Äô√©talait sur plusieurs lignes‚Ä¶‚Ü©Ô∏é",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html",
    "href": "content/visualisation/matplotlib.html",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLa pratique de la visualisation se fera, dans ce cours, en r√©pliquant des graphiques qu‚Äôon peut trouver sur\nla page de l‚Äôopen data de la ville de Paris\nici.\nCe TP vise √† initier :\nNous verrons par la suite la mani√®re de construire des cartes facilement avec\ndes formats √©quivalents.\nSi vous √™tes int√©ress√©s par R ,\nune version tr√®s proche de ce TP est\ndisponible dans ce cours d‚Äôintroduction √† R pour l‚ÄôENS.\nNote\n√ätre capable de construire des visualisations de donn√©es\nint√©ressantes est une comp√©tence n√©cessaire √† tout\ndata scientist ou chercheur. Pour am√©liorer\nla qualit√© de ces visualisations, il est recommand√©\nde suivre certains conseils donn√©s par des sp√©cialistes\nde la dataviz sur la s√©miologie graphique.\nLes bonnes visualisations de donn√©es, comme celles du New York Times,\nreposent certes sur des outils adapt√©s (des librairies JavaScript)\nmais aussi sur certaines r√®gles de repr√©sentation qui permettent\nde comprendre en quelques secondes le message d‚Äôune visualisation.\nCe post de blog\nest une ressource qu‚Äôil est utile de consulter r√©guli√®rement.\nCe post de blog d‚ÄôAlbert Rapp montre bien comment construire graduellement une bonne visualisation\nde donn√©es.",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#contexte",
    "href": "content/visualisation/matplotlib.html#contexte",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "6.1 Contexte",
    "text": "6.1 Contexte\nL‚Äôinconv√©nient des figures avec ggplot est que celles-ci ne permettent\npas d‚Äôinteraction avec le lecteur. Toute l‚Äôinformation doit donc √™tre\ncontenue dans la figure ce qui peut la rendre difficile √† lire.\nSi la figure est bien faite, avec diff√©rents niveaux d‚Äôinformation, cela\npeut bien fonctionner.\nIl est n√©anmoins plus simple, gr√¢ce aux technologies web, de proposer des\nvisualisations √† plusieurs niveaux. Un premier niveau d‚Äôinformation, celui du\ncoup d‚Äôoeil, peut suffire √† assimiler les principaux messages de la\nvisualisation. Ensuite, un comportement plus volontaire de recherche\nd‚Äôinformation secondaire peut permettre d‚Äôen savoir plus. Les visualisations\nr√©actives, qui sont maintenant la norme dans le monde de la dataviz,\npermettent ce type d‚Äôapproche : le lecteur d‚Äôune visualisation peut passer\nsa souris √† la recherche d‚Äôinformation compl√©mentaire (par exemple les\nvaleurs exactes) ou cliquer pour faire appara√Ætre des informations compl√©mentaires\nsur la visualisation ou autour.\nCes visualisations reposent sur le m√™me triptyque que l‚Äôensemble de l‚Äô√©cosyst√®me\nweb : HTML, CSS et JavaScript. Les utilisateurs de Python\nne vont jamais manipuler directement ces langages, qui demandent une\ncertaine expertise, mais vont utiliser des librairies au niveau de R qui g√©n√®reront automatiquement tout le code HTML, CSS et JavaScript\npermettant de cr√©er la figure.",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#la-librairie-plotly",
    "href": "content/visualisation/matplotlib.html#la-librairie-plotly",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "6.2 La librairie Plotly",
    "text": "6.2 La librairie Plotly\nLe package Plotly est une surcouche √† la librairie Javascript\nPlotly.js qui permet de cr√©er et manipuler des objets graphiques de mani√®re\ntr√®s flexible afin de produire des objets r√©actifs sans avoir √† recourir\n√† Javascript.\nLe point d‚Äôentr√©e recommand√© est le module plotly.express\n(documentation ici) qui offre une arborescence\nriche mais n√©anmoins intuitive pour construire des graphiques\n(objets plotly.graph_objects.Figure) pouvant √™tre modifi√©s a posteriori\nsi besoin (par exemple pour customiser les axes).\n\n\n Visualiser les figures produites par Plotly\nDans un notebook Jupyter classique, les lignes suivantes de code permettent\nd‚Äôafficher le r√©sultat d‚Äôune commande Plotly sous un bloc de code :\nfrom plotly.offline import init_notebook_mode\n\ninit_notebook_mode(connected=True)\nPour JupyterLab, l‚Äôextension jupyterlab-plotly s‚Äôav√®re n√©cessaire:\n!jupyter labextension install jupyterlab-plotly",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#r√©plication-de-lexemple-pr√©c√©dent-avec-plotly",
    "href": "content/visualisation/matplotlib.html#r√©plication-de-lexemple-pr√©c√©dent-avec-plotly",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "6.3 R√©plication de l‚Äôexemple pr√©c√©dent avec Plotly",
    "text": "6.3 R√©plication de l‚Äôexemple pr√©c√©dent avec Plotly\nLes repr√©sentations fig√©es comme celles ci-dessus\nsont approri√©es pour des rapports ou articles.\nN√©anmoins\nLes modules suivants seront n√©cessaires pour construire des graphiques\navec plotly:\n\n\n Exercice 7: un barplot avec Plotly\nL‚Äôobjectif est de reconstuire le premier diagramme en barre rouge avec Plotly.\n\nR√©alisez le graphique en utilisant la fonction ad√©quate avec plotly.express et‚Ä¶\n\nNe pas prendre le\nth√®me par d√©faut mais un √† fond blanc, pour avoir un r√©sultat ressemblant\n√† celui propos√© sur le site de l‚Äôopen-data.\nPour la couleur rouge,\nvous pouvez utiliser l‚Äôargument color_discrete_sequence.\nNe pas oublier de nommer les axes\nPensez √† la couleur du texte de l‚Äôaxe inf√©rieur\n\nTester un autre th√®me, √† fond sombre. Pour les couleurs, faire un\ngroupe stockant les trois plus fortes valeurs puis les autres.\n\n\n\nLa premi√®re question permet de construire le graphique suivant :\n\n\n                                                \n\n\nAlors qu‚Äôavec le th√®me sombre (question 2), on obtient :\n\n\n                                                \n\n\nCette repr√©sentation montre bien le caract√®re sp√©cial de l‚Äôann√©e 2020. Pour\nrappeller au lecteur distrait la nature particuli√®re de la p√©riode, marqu√©e\npar un premier confinement qu‚Äôon voit bien dans les donn√©es, on pourrait,\navec l‚Äôaide de la documentation,\najouter deux barres verticales pour marquer les dates de d√©but et\nde fin de cette p√©riode.",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#informations-additionnelles",
    "href": "content/visualisation/matplotlib.html#informations-additionnelles",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\ncf91965\n\n\n2023-12-02 13:15:18\n\n\nlinogaliana\n\n\nhref in dataviz chapter\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\ndf01f01\n\n\n2023-10-10 15:55:04\n\n\nLino Galiana\n\n\nMenus automatis√©s (#432)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n057dae1\n\n\n2023-09-20 16:28:46\n\n\nLino Galiana\n\n\nChapitre visualisation (#406)\n\n\n\n\n1d0780c\n\n\n2023-09-18 14:49:59\n\n\nLino Galiana\n\n\nProbl√®me rendu chapitre matplotlib (#405)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n8df7cb2\n\n\n2023-07-20 17:16:03\n\n\nlinogaliana\n\n\nChange link\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf2e8922\n\n\n2023-06-12 14:54:20\n\n\nLino Galiana\n\n\nRemove spoiler shortcode (#364)\n\n\n\n\n2dc82e7\n\n\n2022-10-18 22:46:47\n\n\nLino Galiana\n\n\nRelec Kim (visualisation + API) (#302)\n\n\n\n\n03babc6\n\n\n2022-10-03 16:53:47\n\n\nLino Galiana\n\n\nParler des r√®gles de la dataviz (#291)\n\n\n\n\n89c10c3\n\n\n2022-08-25 08:30:22\n\n\nLino Galiana\n\n\nAdaptation du shortcode spoiler en notebook (#257)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n2812ef4\n\n\n2022-07-07 15:58:58\n\n\nLino Galiana\n\n\nPetite viz sympa des prenoms (#242)\n\n\n\n\na4e2426\n\n\n2022-06-16 19:34:18\n\n\nLino Galiana\n\n\nImprove style (#238)\n\n\n\n\n02ed1e2\n\n\n2022-06-09 19:06:05\n\n\nLino Galiana\n\n\nR√®gle probl√®me plotly (#235)\n\n\n\n\n299cff3\n\n\n2022-06-08 13:19:03\n\n\nLino Galiana\n\n\nProbl√®me code JS suite (#233)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\n66a5276\n\n\n2021-11-23 16:13:20\n\n\nLino Galiana\n\n\nRelecture partie visualisation (#181)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\na5b7c99\n\n\n2020-10-05 15:07:09\n\n\nLino Galiana\n\n\nDonne lien vers donn√©es compteurs\n\n\n\n\n18be8f4\n\n\n2020-10-01 17:08:53\n\n\nLino Galiana\n\n\nInt√©gration de box inspir√©es du th√®me pydata sphinx (#58)\n\n\n\n\n5ac3cbe\n\n\n2020-09-28 18:59:24\n\n\nLino Galiana\n\n\nContinue la partie graphiques (#54)\n\n\n\n\n94f39ec\n\n\n2020-09-24 21:25:32\n\n\nLino Galiana\n\n\nquelques mots sur vizu\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#footnotes",
    "href": "content/visualisation/matplotlib.html#footnotes",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJ‚Äôai retir√© la couleur sur l‚Äôaxe des ordonn√©es qui, je trouve,\napporte peu √† la figure voire d√©grade la compr√©hension du message.‚Ü©Ô∏é",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/modelisation/index.html",
    "href": "content/modelisation/index.html",
    "title": "Partie 3: mod√©liser",
    "section": "",
    "text": "Les data scientists sont souvent associ√©s √† la mise en oeuvre\nde mod√®les complexes d‚Äôintelligence artificielle.\nLe succ√®s m√©diatique de ce type d‚Äôoutils, notamment ChatGPT,\nn‚Äôy est pas pour rien. Cependant, la mod√©lisation n‚Äôest souvent\nqu‚Äôune\nphase du travail du data scientist, un peu comme la visualisation.\nD‚Äôailleurs, dans certaines organisations o√π la division des t√¢ches\nest plus pouss√©e, les data engineers sont au moins aussi\nimpliqu√©s dans la phase de mod√©lisation que les data scientists.\nC‚Äôest souvent un p√©ch√© de jeunesse de penser qu‚Äôon peut r√©sumer\nle travail du data scientist exclusivement √† la phase de mod√©lisation.\nCette derni√®re d√©pend tr√®s fortement de la qualit√© du travail de\nnettoyage et structuration des donn√©es mis en oeuvre en amont. La\nmise en oeuvre de mod√®les complexes, qui s‚Äôaccomodent de donn√©es\npeu structur√©es, est gourmande en ressources et co√ªteuse. Ce ne sont\ndonc qu‚Äôun nombre limit√© d‚Äôacteurs qui peuvent entra√Æner, ex nihilo,\ndes grands mod√®les de langage1, capables de d√©penser au moins 300 000 dollars\ndans l‚Äôentra√Ænement d‚Äôun mod√®le, avant m√™me toute phase d‚Äôinf√©rence (Izsak, Berchansky, and Levy 2021).\nCes besoins computationnels pour entra√Æner de grands mod√®les de langage sont\nd‚Äôailleurs assez gourmands en √©nergie, ce qui peut amener √†\ndes empreintes carbones non n√©gligeables (Strubell, Ganesh, and McCallum 2019; Arcep 2019).\nHeureusement, il est possible de mettre en oeuvre des mod√©lisations plus\nl√©g√®res (celles que nous pr√©senterons dans les prochains chapitres)\nou de r√©utiliser des mod√®les pr√©-entra√Æn√©s pour les sp√©cialiser\nsur un nouveau jeu de donn√©es (principe du fine tuning2).\nEn fait, pour √™tre plus pertinent que des approches plus parcimonieuses,\nles techniques de deep learning, notamment\nles r√©seaux de neurones, n√©cessitent soit des volumes de donn√©es tr√®s\nimportants (des millions voire dizaine de millions d‚Äôobservations) soit\ndes donn√©es √† la structure complexe comme le langage naturel ou les images.\nDans de nombreux cas, des mod√®les plus simples comme les techniques d‚Äôapprentissage\nautomatique (machine learning) suffisent largement.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#la-mod√©lisation-une-approche-au-coeur-de-la-statistique",
    "href": "content/modelisation/index.html#la-mod√©lisation-une-approche-au-coeur-de-la-statistique",
    "title": "Partie 3: mod√©liser",
    "section": "La mod√©lisation, une approche au coeur de la statistique",
    "text": "La mod√©lisation, une approche au coeur de la statistique\nUn mod√®le statistique\nest une repr√©sentation simplifi√©e et structur√©e d‚Äôun ph√©nom√®ne r√©el,\nconstruite √† partir d‚Äôobservations regroup√©es dans un ensemble partiel de donn√©es.\nUn mod√®le vise √† capturer les relations et les sch√©mas sous-jacents au sein de ces donn√©es, permettant ainsi de formuler des hypoth√®ses, d‚Äôeffectuer des pr√©dictions et d‚Äôextrapoler des conclusions au-del√†\nde l‚Äôensemble de donn√©es mesur√©es.\nLes mod√®les statistiques fournissent ainsi un cadre analytique pour explorer, comprendre et interpr√©ter les informations contenues dans les donn√©es.\nDans le domaine de la recherche √©conomique, ils peuvent servir √†\nassocier certains param√®tres structurants des mod√®les de comportement\n√©conomique √† des valeurs quantitatives.\nLes mod√®les statistiques, comme les mod√®les √©conomiques\npr√©sentent n√©anmoins toujours une part d‚Äôirr√©alisme (Friedman 1953; Salmon 2010)\net accepter de mani√®re trop litt√©rale les implications d‚Äôun mod√®le, m√™me s‚Äôil\na de bonnes performances pr√©dictives, peut √™tre dangereux et relever d‚Äôun biais\nscientiste. On s√©lectionne plut√¥t le moins mauvais mod√®le\nque le vrai processus g√©n√©rateur des donn√©es.\nRepr√©senter la r√©alit√© sous la forme d‚Äôun mod√®le est un principe √† la\nbase de la statistique comme discipline scientifique et ayant des\napplications dans de nombreux champs disciplinaires : √©conomie,\nsociologie, g√©ographique, biologie, physique, etc.\nSelon les disciplines, le nom donn√© peut varier mais on retrouve\nr√©guli√®rement la m√™me approche scientifique : le mod√©lisateur\nconstruit des relations entre plusieurs variables th√©oriques\nayant des contreparties empiriques afin d‚Äôexpliquer tel ou tel\nprocessus.\nDans l‚Äôenseignement de l‚ÄôENSAE ce type d‚Äôapproche empirique se retrouve\nprincipalement dans deux types d‚Äôapproches : le machine learning et\nl‚Äô√©conom√©trie. La diff√©rence est certes\ns√©mantique - la r√©gression lin√©aire peut √™tre consid√©r√©e comme une\ntechnique de machine learning ou d‚Äô√©conom√©trie - mais elle est\n√©galement conceptuelle :\n\nDans le domaine du machine learning,\nla structure impos√©e par le mod√©lisateur est minimale et ce sont plut√¥t\nles algorithmes qui, sur des crit√®res de performance statistique, vont\namener √† choisir une loi math√©matique qui correspond au mieux aux donn√©es ;\nEn √©conom√©trie,\nles hypoth√®ses de structure des lois sont plus fortes (m√™me dans un cadre semi ou non-param√©trique) et sont plus souvent impos√©es\npar le mod√©lisateur.\n\nDans cette partie du cours, nous allons principalement\nparler de machine learning car il s‚Äôagit d‚Äôune perspective\nplus op√©rationnelle que l‚Äô√©conom√©trie qui est plus directement associ√©e\n√† des concepts statistiques complexes comme la th√©orie asymptotique.\nL‚Äôadoption du machine learning dans la litt√©rature √©conomique a √©t√© longue\ncar la structuration des donn√©es est souvent le\npendant empirique d‚Äôhypoth√®ses th√©oriques sur le comportement des acteurs ou des march√©s (Athey and Imbens 2019; Charpentier, Flachaire, and Ly 2018).\nPour caricaturer, l‚Äô√©conom√©trie s‚Äôattacherait √† comprendre la causalit√© de certaines variables sur une autre.\nCela implique que ce qui int√©resse l‚Äô√©conom√®tre\nest principalement de l‚Äôestimation des param√®tres (et l‚Äôincertitude\nsur l‚Äôestimation de ceux-ci) qui permettent de quantifier l‚Äôeffet d‚Äôune\nvariation d‚Äôune variable sur une autre.\nToujours pour caricaturer,\nle machine learning se focaliserait\nsur un simple objectif pr√©dictif en exploitant les relations de corr√©lations entre les variables.\nDans cette perspective, l‚Äôimportant n‚Äôest pas la causalit√© mais le fait qu‚Äôune variation\nde \\(x\\)% d‚Äôune variable permette d‚Äôanticiper un changement de \\(\\beta x\\) de la variable\nd‚Äôint√©r√™t ; peu importe la raison.\nMullainathan and Spiess (2017) ont ainsi, pour simplifier, propos√© la diff√©rence fondamentale qui\nsuit : l‚Äô√©conom√©trie se pr√©occupe de \\(\\widehat{\\beta}\\) l√† o√π le machine learning\nse focalise sur \\(\\widehat{y}\\). Les deux sont bien s√ªr reli√©s dans un cadre\nlin√©aire mais cette diff√©rence d‚Äôapproche a des implications importantes\nsur la structure des mod√®les √©tudi√©s, notamment leur parcimonie3.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#quelques-d√©finitions",
    "href": "content/modelisation/index.html#quelques-d√©finitions",
    "title": "Partie 3: mod√©liser",
    "section": "Quelques d√©finitions",
    "text": "Quelques d√©finitions\nDans cette partie du cours nous allons employer un certain nombre\nde termes devenus familiers aux praticiens du machine learning\nmais qui m√©ritent d‚Äô√™tre explicit√©s.\n\nMachine learning et deep learning\nJusqu‚Äô√† pr√©sent nous avons beaucoup utilis√©, sans le d√©finir, le\nconcept de machine learning, dont la traduction fran√ßaise est\napprentissage automatique mais le terme anglo-saxon est suffisamment\nutilis√© pour √™tre consid√©r√© comme standard.\nLe machine learning est un ensemble de techniques algorithmiques\nqui permettent aux ordinateurs d‚Äôapprendre, √† partir d‚Äôexemples, √† ajuster un mod√®le\nsans avoir explicitement d√©fini celui-ci. A partir d‚Äôalgorithmes it√©ratifs et d‚Äôune\nm√©trique de performance, des r√®gles de classification ou de pr√©diction vont permettre\nde mettre en relation des caract√©ristiques (features) avec une variable d‚Äôint√©r√™t (label)4.\nDe nombreux algorithmes existent et se distinguent sur la mani√®re d‚Äôintroduire une structure plus ou\nmoins formelle dans la relation entre les variables observ√©es. Nous n‚Äôallons voir que quelques-uns\nde ces algorithmes : support vector machine (SVM), r√©gression logistique, arbres de d√©cision, for√™ts\nal√©atoires, etc. Simples √† mettre en oeuvre gr√¢ce √† la librairie Scikit-Learn, ils permettront\nd√©j√† de comprendre la d√©marche originale du machine learning que vous pourrez approfondir\nult√©rieurement.\nAu sein de la grande famille des algorithmes de machine learning, tendent de plus √† plus √† devenir\nautonomes les techniques de r√©seaux de neurone. Les techniques qui s‚Äôappuient sur les r√©seaux de neurones sont regroup√©s\ndans une famille qu‚Äôon\nappelle deep learning (apprentissage profond en Fran√ßais).\nCes r√©seaux sont inspir√©s du fonctionnement du cerveau humain et sont compos√©s de nombreuses couches de neurones interconnect√©s.\nLa structure canonique bien connue est illustr√©e dans la Figure¬†1.\nLe deep learning est int√©ressant pour cr√©er des mod√®les capables d‚Äôapprendre de repr√©sentations\nde donn√©es complexes et abstraites √† partir de donn√©es brutes,\nce qui √©vite parfois la complexe t√¢che de d√©finir manuellement des caract√©ristiques sp√©cifiques √† cibler.\nLes champs de l‚Äôanalyse d‚Äôimage (computer vision) ou du traitement du langage naturel sont les principaux\ncas d‚Äôapplication de ces m√©thodes.\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Exemple de structure d‚Äôun r√©seau de neurones (source: lebigdata.fr)\n\n\n\nNous n‚Äôallons pas vraiment parler dans ce cours de deep learning car ces mod√®les, pour √™tre pertinents, n√©cessitent\nsoit des donn√©es structur√©es d‚Äôun volume important (ce qui est rarement disponible\nen open data) soit des cas d‚Äôusage sp√©cifiques, plus avanc√©s que ne le permet\nun cours d‚Äôintroduction. L‚Äôorganisation HuggingFace, cr√©atrice de la\nplateforme du m√™me nom facilitant la r√©utilisation de mod√®les de deep learning\npropose d‚Äôexcellents cours sur le sujet, notamment sur\nle traitement du langage naturel (NLP).\nNous ferons du traitement du langage naturel dans la prochaine partie de ce cours mais\nde mani√®re plus modeste en revenant sur les concepts n√©cessaires avant de mettre en oeuvre\nune mod√©lisation sophistiqu√©e du langage.\n\n\nApprentissage supervis√© ou non supervis√©\nUne ligne de clivage importante entre les m√©thodes √† mettre en oeuvre est le fait d‚Äôobserver ou non\nle label (la variable \\(y\\)) qu‚Äôon d√©sire mod√©liser.\nPrenons par exemple un site de commerce qui dispose\nd‚Äôinformations sur ses clients comme l‚Äô√¢ge, le sexe, le lieu de r√©sidence.\nCe site peut d√©sirer\nexploiter cette information de diff√©rentes mani√®res pour mod√©liser le comportement d‚Äôachat.\nEn premier lieu, ce site peut d√©sirer\nanticiper le volume d‚Äôachat d‚Äôun nouveau client ayant certaines caract√©ristiques.\nDans ce cas, il est possible d‚Äôutiliser les montants d√©pens√©s par d‚Äôautres clients en fonction de leurs\ncaract√©ristiques. L‚Äôinformation pour notre nouveau client n‚Äôest pas mesur√©e mais elle peut s‚Äôappuyer\nsur un ensemble d‚Äôobservations de la m√™me variable.\nMais il est tout √† fait possible d‚Äôentra√Æner un mod√®le sur un label qu‚Äôon ne mesure pas, en supposant\nqu‚Äôil fasse sens. Par exemple notre site de commerce peut d√©sirer d√©terminer, en fonction des\ncaract√©ristiques de notre nouveau client et de sa client√®le existante, s‚Äôil appartient √† tel ou\ntel groupe de consommateurs : les d√©pensiers, les √©conomes‚Ä¶ Bien s√ªr on ne sait jamais a priori\n√† quel groupe appartient un consommateur mais le rapprochement entre consommateurs ayant un comportement\nsimilaire permettra de donner du sens √† cette cat√©gorie. Dans ce cas, l‚Äôalgorithme apprendra √† reconna√Ætre\nquelles caract√©ristiques sont structurantes dans la constitution de groupes au comportement similaire et\npermettra d‚Äôassocier tout nouveau consommateur √† un groupe.\nCes deux exemples illustrent l‚Äôapproche diff√©rente selon qu‚Äôon essaie de construire des mod√®les\nsur un label observ√© ou non. Cela constitue m√™me l‚Äôune des dualit√©s fondamentale dans les\ntechniques de machine learning :\n\nApprentissage supervis√© : la valeur cible est connue et peut √™tre utilis√©e pour √©valuer la qualit√© d‚Äôun mod√®le ;\nApprentissage non supervis√© : la valeur cible est inconnue et ce sont des crit√®res statistiques qui vont amener\n√† s√©lectionner la structure de donn√©es la plus plausible.\n\nCette partie du cours illustrera ces deux approches de mani√®re diff√©rente √† partir du m√™me\njeu de donn√©es, les r√©sultats des √©lections am√©ricaines.\nDans le cas de l‚Äôapprentissage supervis√©, nous chercherons √† mod√©liser directement\nle r√©sultat des candidats aux √©lections (soit le score soit le gagnant). Dans\nle cas de l‚Äôapprentissage non supervis√©, nous essaierons de regrouper les\nterritoires au comportement de vote similaire en fonction de facteurs\nsocio-d√©mographiques.\n\n\n0.0.1 Classification et r√©gression\nUne deuxi√®me dualit√© fondamentale qui est d√©terminante dans le choix de la m√©thode de machine learning\n√† mettre en oeuvre est la nature du label. S‚Äôagit-il d‚Äôune variable continue ou d‚Äôune variable\ndiscr√®te, c‚Äôest-√†-dire prenant un nombre limit√© de modalit√©s ?\nCette diff√©rence de nature entre les donn√©es am√®ne √† distinguer deux types d‚Äôapproche :\n\nDans les probl√©matiques de classification, o√π notre label \\(y\\) a un nombre fini de valeurs5,\non cherche √† pr√©dire dans quelle classe ou √† quel groupe il est possible de rattacher nos donn√©es.\nPar exemple, si vous prenez du caf√© le matin, faites-vous partie du groupe des personnes ronchons au lever ?\nLes m√©triques de performance utilisent g√©n√©ralement la proportion de bonnes ou mauvaises classifications\npour estimer la qualit√© d‚Äôun mod√®le.\nDans les probl√©matiques de r√©gression, o√π notre label est une grandeur num√©rique, on\ncherche √† pr√©dire directement la valeur de notre variable dans le mod√®le. Par exemple, si vous\navez tel ou tel √¢ge, quel est votre d√©pense quotidienne en fast food. Les m√©triques\nde performance sont g√©n√©ralement des moyennes plus ou moins sophistiqu√©es d‚Äô√©carts entre\nla pr√©diction et la valeur observ√©e.\n\nEn r√©sum√©, l‚Äôaide-m√©moire suivante, issue de l‚Äôaide de Scikit-Learn, peut d√©j√† donner de premiers enseignements sur les diff√©rentes familles de mod√®les :\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Une cheatsheet des algorithmes disponibles dans Scikit-Learn",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#donn√©es",
    "href": "content/modelisation/index.html#donn√©es",
    "title": "Partie 3: mod√©liser",
    "section": "Donn√©es",
    "text": "Donn√©es\nLa plupart des exemples de cette partie s‚Äôappuient sur les r√©sultats des\n√©lections US 2020 au niveau comt√©s. Plusieurs bases sont utilis√©es pour\ncela :\n\nLes donn√©es √©lectorales sont une reconstruction √† partir des donn√©es du MIT election lab\npropos√©es sur Github par tonmcg\nou directement disponibles sur le site du MIT Election Lab\nLes donn√©es socio√©conomiques (population, donn√©es de revenu et de pauvret√©,\ntaux de ch√¥mage, variables d‚Äô√©ducation) proviennent de l‚ÄôUSDA (source)\nLe shapefile vient des donn√©es du Census Bureau. Le fichier peut\n√™tre t√©l√©charg√© directement depuis cet url:\nhttps://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_county_20m.zip\n\nLe code pour construire une base unique √† partir de ces sources diverses\nest disponible ci-dessous :\n\n\n\nimport urllib\nimport urllib.request\nimport os\nimport zipfile\nfrom urllib.request import Request, urlopen\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\n\ndef download_url(url, save_path):\n    with urllib.request.urlopen(url) as dl_file:\n        with open(save_path, 'wb') as out_file:\n            out_file.write(dl_file.read())\n\n\ndef create_votes_dataframes():\n    \n  Path(\"data\").mkdir(parents=True, exist_ok=True)\n  \n  \n  download_url(\"https://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_county_20m.zip\", \"data/shapefile\")\n  with zipfile.ZipFile(\"data/shapefile\", 'r') as zip_ref:\n      zip_ref.extractall(\"data/counties\")\n  \n  shp = gpd.read_file(\"data/counties/cb_2019_us_county_20m.shp\")\n  shp = shp[~shp[\"STATEFP\"].isin([\"02\", \"69\", \"66\", \"78\", \"60\", \"72\", \"15\"])]\n  shp\n  \n  df_election = pd.read_csv(\"https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2020_US_County_Level_Presidential_Results.csv\")\n  df_election.head(2)\n  population = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/PopulationEstimates.xls?v=290.4\", header = 2).rename(columns = {\"FIPStxt\": \"FIPS\"})\n  education = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/Education.xls?v=290.4\", header = 4).rename(columns = {\"FIPS Code\": \"FIPS\", \"Area name\": \"Area_Name\"})\n  unemployment = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/Unemployment.xls?v=290.4\", header = 4).rename(columns = {\"fips_txt\": \"FIPS\", \"area_name\": \"Area_Name\", \"Stabr\": \"State\"})\n  income = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/PovertyEstimates.xls?v=290.4\", header = 4).rename(columns = {\"FIPStxt\": \"FIPS\", \"Stabr\": \"State\", \"Area_name\": \"Area_Name\"})\n  \n  \n  dfs = [df.set_index(['FIPS', 'State']) for df in [population, education, unemployment, income]]\n  data_county = pd.concat(dfs, axis=1)\n  df_election = df_election.merge(data_county.reset_index(), left_on = \"county_fips\", right_on = \"FIPS\")\n  df_election['county_fips'] = df_election['county_fips'].astype(str).str.lstrip('0')\n  shp['FIPS'] = shp['GEOID'].astype(str).str.lstrip('0')\n  votes = shp.merge(df_election, left_on = \"FIPS\", right_on = \"county_fips\")\n  \n  req = Request('https://dataverse.harvard.edu/api/access/datafile/3641280?gbrecs=false')\n  req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n  content = urlopen(req)\n  df_historical = pd.read_csv(content, sep = \"\\t\")\n  #df_historical = pd.read_csv('https://dataverse.harvard.edu/api/access/datafile/3641280?gbrecs=false', sep = \"\\t\")\n  \n  df_historical = df_historical.dropna(subset = [\"FIPS\"])\n  df_historical[\"FIPS\"] = df_historical[\"FIPS\"].astype(int)\n  df_historical['share'] = df_historical['candidatevotes']/df_historical['totalvotes']\n  df_historical = df_historical[[\"year\", \"FIPS\", \"party\", \"candidatevotes\", \"share\"]]\n  df_historical['party'] = df_historical['party'].fillna(\"other\")\n  \n  df_historical_wide = df_historical.pivot_table(index = \"FIPS\", values=['candidatevotes',\"share\"], columns = [\"year\",\"party\"])\n  df_historical_wide.columns = [\"_\".join(map(str, s)) for s in df_historical_wide.columns.values]\n  df_historical_wide = df_historical_wide.reset_index()\n  df_historical_wide['FIPS'] = df_historical_wide['FIPS'].astype(str).str.lstrip('0')\n  votes['FIPS'] = votes['GEOID'].astype(str).str.lstrip('0')\n  votes = votes.merge(df_historical_wide, on = \"FIPS\")\n  votes[\"winner\"] =  np.where(votes['votes_gop'] &gt; votes['votes_dem'], 'republican', 'democrats') \n\n  return votes\n\n\n\nCette partie n‚Äôest absolument pas exhaustive. Elle constitue un point\nd‚Äôentr√©e dans le sujet √† partir d‚Äôune s√©rie d‚Äôexemples sur un fil rouge.\nDe nombreux mod√®les plus approfondis, que ce soit en √©conom√©trie ou en machine learning\nm√©riteraient d‚Äô√™tre √©voqu√©s. Pour les personnes d√©sirant en savoir plus sur les\nmod√®les √©conom√©triques, qui seront moins √©voqu√©s que ceux de machine learning,\nje recommande la lecture de Turrell and contributors (2021).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#r√©f√©rences",
    "href": "content/modelisation/index.html#r√©f√©rences",
    "title": "Partie 3: mod√©liser",
    "section": "0.1 R√©f√©rences",
    "text": "0.1 R√©f√©rences\n\n\nArcep. 2019. ‚ÄúL‚Äôempreinte Carbone Du Num√©rique.‚Äù Rapport de l‚ÄôArcep.\n\n\nAthey, Susan, and Guido W Imbens. 2019. ‚ÄúMachine Learning Methods That Economists Should Know About.‚Äù Annual Review of Economics 11: 685‚Äì725.\n\n\nCharpentier, Arthur, Emmanuel Flachaire, and Antoine Ly. 2018. ‚ÄúEconometrics and Machine Learning.‚Äù Economie Et Statistique 505 (1): 147‚Äì69.\n\n\nFriedman, Milton. 1953. ‚ÄúThe Methodology of Positive Economics.‚Äù In Essays in Positive Economics. Chicago: The University of Chicago Press.\n\n\nIzsak, Peter, Moshe Berchansky, and Omer Levy. 2021. ‚ÄúHow to Train BERT with an Academic Budget.‚Äù https://arxiv.org/abs/2104.07705.\n\n\nMullainathan, Sendhil, and Jann Spiess. 2017. ‚ÄúMachine Learning: An Applied Econometric Approach.‚Äù Journal of Economic Perspectives 31 (2): 87‚Äì106. https://doi.org/10.1257/jep.31.2.87.\n\n\nSalmon, Pierre. 2010. ‚ÄúLe Probl√®me Du r√©alisme Des Hypoth√®ses En √©conomie Politique.‚Äù\n\n\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. ‚ÄúEnergy and Policy Considerations for Deep Learning in NLP.‚Äù https://arxiv.org/abs/1906.02243.\n\n\nTurrell, Arthur, and contributors. 2021. Coding for Economists. Online. https://aeturrell.github.io/coding-for-economists.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#informations-additionnelles",
    "href": "content/modelisation/index.html#informations-additionnelles",
    "title": "Partie 3: mod√©liser",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\ne52cc8a\n\n\n2023-12-19 21:40:01\n\n\nLino Galiana\n\n\nAutomatic black formatting for python examples (#477)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec (antuki?) partie modelisation (#183)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†1: Exemple de structure d‚Äôun r√©seau de neurones (source: lebigdata.fr)\nFigure¬†2: Une cheatsheet des algorithmes disponibles dans Scikit-Learn",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#footnotes",
    "href": "content/modelisation/index.html#footnotes",
    "title": "Partie 3: mod√©liser",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNous reviendrons de mani√®re √©pisodique\nsur ce principe des grands mod√®les de langage\nqui sont devenus, en quelques ann√©es,\ncentraux dans l‚Äô√©cosyst√®me de la data science mais sont √©galement\namen√©s √† devenir des outils grands publics, √† la mani√®re de ChatGPT.‚Ü©Ô∏é\nHistoriquement, cette approche n√©cessitait de disposer de donn√©es labellis√©es donc d‚Äô√™tre\ndans un cadre d‚Äôapprentissage supervis√©.\nCependant, avec l‚Äôutilisation de plus en plus\nfr√©quente de donn√©es non structur√©es, sans labels, a √©merg√© une approche int√©ressante\nqui ne n√©cessite plus forc√©ment de labelliser des volumes importants de donn√©es en amont :\nle reinforcement learning with human feedback.\nCet article d‚ÄôAndrew Ng revient sur la mani√®re dont cette approche\nchange la donne dans l‚Äôentra√Ænement ou le r√©-entra√Ænement de mod√®les.‚Ü©Ô∏é\nComme nous l‚Äôavons dit, cette diff√©renciation est un peu\ncaricaturale, notamment maintenant que les √©conomistes sont\nplus familiaris√©s aux concepts d‚Äô√©valuation de performance\npr√©dictive sur des sous-ensembles d‚Äôapprentissage et de test (mais\nl‚Äô√©volution est lente).\nLa recherche en machine learning est quant √† elle tr√®s dynamique\nsur la question de l‚Äôexplicabilit√© et de l‚Äôinterpr√©tabilit√©\ndes mod√®les de machine learning, notamment autour du concept\nde valeurs de Shapley.‚Ü©Ô∏é\nPour faire l‚Äôanalogie avec le cadre √©conom√©trique, les features sont les variables explicatives\nou covariates (la matrice \\(X\\)) et le label est la variable expliqu√©e (\\(y\\)).‚Ü©Ô∏é\nNous allons nous focaliser sur le cas binaire, le plus simple. Dans ce type de probl√®mes,\nla variable \\(y\\) a deux modalit√©s : gagnant-perdant, 0-1, oui-non‚Ä¶ N√©anmoins il existe de\nnombreux cas d‚Äôusage o√π la variable dispose de plus de modalit√©s, par exemples des\nscores de satisfaction entre 0 et 5 ou A et D. La mise en oeuvre de mod√®les est plus\ncomplexe mais l‚Äôid√©e g√©n√©rale est souvent de se ramener √† un ensemble de mod√®les dichotomiques\npour pouvoir appliquer des m√©triques simples et stables.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html",
    "href": "content/modelisation/1_modelevaluation.html",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nNous allons ici voir des m√©thodes g√©n√©rales permettant de s‚Äôassurer que le mod√®le\nde Machine Learning mobilis√© est de qualit√©. Ce chapitre ne pr√©sente pas\nd‚Äôexercice ou de code, il est l√† pour pr√©senter certains concepts\nque nous appliquerons dans les prochains chapitres.",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#classification",
    "href": "content/modelisation/1_modelevaluation.html#classification",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "4.1 Classification",
    "text": "4.1 Classification\nLa plupart des crit√®res de performance sont construits √† partir de la matrice de confusion :\n\n\n\nImage emprunt√©e √† https://www.lebigdata.fr/confusion-matrix-definition\n\n\nA partir des 4 coins de cette matrice, il existe plusieurs mesure de performance\n\n\n\n\n\n\n\n\nCrit√®re\nMesure\nCalcul\n\n\n\n\nAccuracy\nTaux de classification correcte\nDiagonale du tableau : \\(\\frac{TP+TN}{TP+FP+FN+FP}\\)\n\n\nPrecision\nTaux de vrais positifs\nLigne des pr√©dictions positives : \\(\\frac{TP}{TP+FP}\\)\n\n\nRecall (rappel)\nCapacit√© √† identifier les labels positifs\nColonne des pr√©dictions positives : \\(\\frac{TP}{TP+FN}\\)\n\n\nF1 Score\nMesure synth√©tique (moyenne harmonique) de la pr√©cision et du rappel\n\\(2 \\frac{precision \\times recall}{precision + recall}\\)\n\n\n\nEn pr√©sence de classes d√©sequilibr√©es, la\nF-mesure est plus pertinente pour √©valuer les\nperformances mais l‚Äôapprentissage restera\nmauvais si l‚Äôalgorithme est sensible √† ce\nprobl√®me. Notamment, si on d√©sire avoir une performance √©quivalente sur les classes minoritaires, il faut g√©n√©ralement les sur-pond√©rer (ou faire un √©chantillonnage stratifi√©) lors de la constitution de l‚Äô√©chantillon d‚Äôobservation.\nIl est possible de construire des mod√®les √† partir des probabilit√©s pr√©dites d‚Äôappartenir √† la classe d‚Äôint√©r√™t. Pour cela, on fixe un seuil \\(c\\) tel que\n\\[\n\\mathbb{P}(y_i=1|X_i) &gt; c \\Rightarrow \\widehat{y}_i = 1\n\\]\nPlus on augmente \\(c\\), plus on est s√©lectif sur le crit√®re d‚Äôappartenance √† la classe.\nLa pr√©cision, i.e.¬†le taux de vrais positifs parmi les pr√©dictions positives, augmente. Mais on augmente le nombre de positifs manqu√©s (autrement dit on diminue le rappel). Pour chaque valeur de \\(c\\) correspond une matrice de confusion et donc des mesures de performances.\nLa courbe ROC est un outil classique pour repr√©senter en un graphique l‚Äôensemble de ces\ninformations en faisant varier \\(c\\) de 0 √† 1:\n\nL‚Äôaire sous la courbe (AUC) permet d‚Äô√©valuer quantitativement le meilleur mod√®le au\nsens de ce crit√®re. L‚ÄôAUC repr√©sente la probabilit√© que le mod√®le soit capable de distinguer entre la classe positive et n√©gative.",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#r√©gression",
    "href": "content/modelisation/1_modelevaluation.html#r√©gression",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "4.2 R√©gression",
    "text": "4.2 R√©gression\nEn Machine Learning, les indicateurs de performance en r√©gression sont les suivants :\n\n\n\n\n\n\n\nNom\nFormule\n\n\n\n\nMean squared error\n\\(MSE = \\mathbb{E}\\left[(y - h_\\theta(X))^2\\right]\\)\n\n\nRoot Mean squared error\n\\(RMSE = \\sqrt{\\mathbb{E}\\left[(y - h_\\theta(X))^2\\right]}\\)\n\n\nMean Absolute Error\n\\(MAE = \\mathbb{E} \\bigg[ \\lvert y - h_\\theta(X) \\rvert \\bigg]\\)\n\n\nMean Absolute Percentage Error\n\\(MAE = \\mathbb{E}\\left[ \\left\\lvert \\frac{y - h_\\theta(X)}{y} \\right\\rvert \\right]\\)\n\n\n\nL‚Äô√©conom√®tre se focalise moins sur la qualit√© de la pr√©diction et utilisera\nd‚Äôautres crit√®res pour √©valuer la qualit√© d‚Äôun mod√®le (certains, comme le BIC, sont\n√† regarder aussi dans une optique Machine Learning) : \\(R^2\\), \\(BIC\\),\n\\(AIC\\), log-likelihood, etc.",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#informations-additionnelles",
    "href": "content/modelisation/1_modelevaluation.html#informations-additionnelles",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\nfd3c955\n\n\n2023-11-18 14:22:38\n\n\nLino Galiana\n\n\nFormattage des chapitres scikit (#453)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n6264438\n\n\n2022-06-29 14:53:05\n\n\nLino Galiana\n\n\nRetire typo math (#243)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nImage emprunt√©e √† https://www.lebigdata.fr/confusion-matrix-definition",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#footnotes",
    "href": "content/modelisation/1_modelevaluation.html#footnotes",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCette formule permet de bien comprendre la th√©orie statistique asymptotique, notamment le th√©or√®me de Cramer-Rao. Dans la classe des estimateurs sans biais, c‚Äôest-√†-dire dont le premier terme est nul, trouver l‚Äôestimateur √† variance minimale revient √† trouver l‚Äôestimateur qui minimise \\(\\mathbb{E}\\bigg[(y - h_\\theta(X))^2 \\bigg]\\). C‚Äôest la d√©finition m√™me de la r√©gression, ce qui, quand on fait des hypoth√®ses suppl√©mentaires sur le mod√®le statistique, explique le th√©or√®me de Cramer-Rao.‚Ü©Ô∏é",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html",
    "href": "content/modelisation/3_regression.html",
    "title": "R√©gression : une introduction",
    "section": "",
    "text": "Le pr√©c√©dent chapitre visait √† proposer un premier mod√®le pour comprendre\nles comt√©s o√π le parti R√©publicain l‚Äôemporte. La variable d‚Äôint√©r√™t √©tant\nbimodale (victoire ou d√©faite), on √©tait dans le cadre d‚Äôun mod√®le de\nclassification.\nMaintenant, sur les m√™mes donn√©es, on va proposer un mod√®le de r√©gression\npour expliquer le score du parti R√©publicain. La variable est donc continue.\nNous ignorerons le fait que ses bornes se trouvent entre 0 et 100 et donc\nqu‚Äôil faudrait, pour √™tre rigoureux, transformer l‚Äô√©chelle afin d‚Äôavoir\ndes donn√©es dans cet intervalle.\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nCe chapitre va utiliser plusieurs packages\nde mod√©lisation, les principaux √©tant Scikit et Statsmodels.\nVoici une suggestion d‚Äôimport pour tous ces packages.\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html#la-r√©gression-lin√©aire",
    "href": "content/modelisation/3_regression.html#la-r√©gression-lin√©aire",
    "title": "R√©gression : une introduction",
    "section": "1.1 La r√©gression lin√©aire",
    "text": "1.1 La r√©gression lin√©aire\nC‚Äôest la mani√®re la plus simple de repr√©senter la loi \\(h_\\theta(X)\\) comme\ncombinaison lin√©aire de variables \\(X\\) et de param√®tres \\(\\theta\\). Dans ce\ncas,\n\\[\n\\mathbb{E}_\\theta(Y|X) = X\\beta\n\\]\nCette relation est encore, sous cette formulation, th√©orique. Il convient\nde l‚Äôestimer √† partir des donn√©es observ√©es \\(y\\). La m√©thode des moindres\ncarr√©s consiste √† minimiser l‚Äôerreur quadratique entre la pr√©diction et\nles donn√©es observ√©es (ce qui explique qu‚Äôon puisse voir la r√©gression comme\nun probl√®me de Machine Learning). En toute g√©n√©ralit√©, la m√©thode des\nmoindres carr√©s consiste √† trouver l‚Äôensemble de param√®tres \\(\\theta\\)\ntel que\n\\[\n\\theta = \\arg \\min_{\\theta \\in \\Theta} \\mathbb{E}\\bigg[ \\left( y - h_\\theta(X) \\right)^2 \\bigg]\n\\]\nCe qui, dans le cadre de la r√©gression lin√©aire, s‚Äôexprime de la mani√®re suivante :\n\\[\n\\beta = \\arg\\min \\mathbb{E}\\bigg[ \\left( y - X\\beta \\right)^2 \\bigg]\n\\]\nLorsqu‚Äôon am√®ne le mod√®le th√©orique (\\(\\mathbb{E}_\\theta(Y|X) = X\\beta\\)) aux donn√©es,\non formalise le mod√®le de la mani√®re suivante :\n\\[\nY = X\\beta + \\epsilon\n\\]\nAvec une certaine distribution du bruit \\(\\epsilon\\) qui d√©pend\ndes hypoth√®ses faites. Par exemple, avec des\n\\(\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)\\) i.i.d., l‚Äôestimateur \\(\\beta\\) obtenu\nest √©quivalent √† celui du Maximum de Vraisemblance dont la th√©orie asymptotique\nnous assure l‚Äôabsence de biais, la variance minimale (borne de Cramer-Rao).\n\n\n Exercice 1a : R√©gression lin√©aire avec scikit\nCet exercice vise √† illustrer la mani√®re d‚Äôeffectuer une r√©gression lin√©aire avec scikit.\nDans ce domaine,\nstatsmodels est nettement plus complet, ce que montrera l‚Äôexercice suivant.\nL‚Äôint√©r√™t principal de faire\ndes r√©gressions avec scikit est de pouvoir comparer les r√©sultats d‚Äôune r√©gression lin√©aire\navec d‚Äôautres mod√®les de r√©gression. Cependant, le chapitre sur les\npipelines montrera qu‚Äôon peut tr√®s bien ins√©rer, avec quelques efforts\nde programmation orient√©e objet, une r√©gression statsmodels dans\nun pipeline scikit.\nL‚Äôobjectif est d‚Äôexpliquer le score des R√©publicains en fonction de quelques\nvariables. Contrairement au chapitre pr√©c√©dent, o√π on se focalisait sur\nun r√©sultat binaire (victoire/d√©faite des R√©publicains), cette\nfois on va chercher √† mod√©liser directement le score des R√©publicains.\n\nA partir de quelques variables, par exemple, ‚ÄòUnemployment_rate_2019‚Äô, ‚ÄòMedian_Household_Income_2019‚Äô, ‚ÄòPercent of adults with less than a high school diploma, 2015-19‚Äô, ‚ÄúPercent of adults with a bachelor‚Äôs degree or higher, 2015-19‚Äù, expliquer la variable per_gop √† l‚Äôaide d‚Äôun √©chantillon d‚Äôentra√Ænement X_train constitu√© au pr√©alable.\n\n‚ö†Ô∏è Utiliser la variable Median_Household_Income_2019\nen log sinon son √©chelle risque d‚Äô√©craser tout effet.\n\nAfficher les valeurs des coefficients, constante comprise\nEvaluer la pertinence du mod√®le avec le \\(R^2\\) et la qualit√© du fit avec le MSE.\nRepr√©senter un nuage de points des valeurs observ√©es\net des erreurs de pr√©diction. Observez-vous\nun probl√®me de sp√©cification ?\n\n\n\nVoici le nuage de points de nos erreurs:\n\n\n\n\n\n\n\n\n\nClairement, le mod√®le pr√©sente un probl√®me de sp√©cification.\n\n\n Exercice 1b : R√©gression lin√©aire avec statsmodels\nCet exercice vise √† illustrer la mani√®re d‚Äôeffectuer une r√©gression lin√©aire avec statsmodels qui offre des fonctionnalit√©s plus proches de celles de R, et moins orient√©es Machine Learning.\nL‚Äôobjectif est toujours d‚Äôexpliquer le score des R√©publicains en fonction de quelques\nvariables.\n\nA partir de quelques variables, par exemple, ‚ÄòUnemployment_rate_2019‚Äô, ‚ÄòMedian_Household_Income_2019‚Äô, ‚ÄòPercent of adults with less than a high school diploma, 2015-19‚Äô, ‚ÄúPercent of adults with a bachelor‚Äôs degree or higher, 2015-19‚Äù, expliquer la variable per_gop.\n‚ö†Ô∏è utiliser la variable Median_Household_Income_2019\nen log sinon son √©chelle risque d‚Äô√©craser tout effet.\nAfficher un tableau de r√©gression.\nEvaluer la pertinence du mod√®le avec le R^2.\nUtiliser l‚ÄôAPI formula pour r√©gresser le score des r√©publicains en fonction de la variable Unemployment_rate_2019, de Unemployment_rate_2019 au carr√© et du log de\nMedian_Household_Income_2019.\n\n\n\n\n\n Hint\nPour sortir une belle table pour un rapport sous \\(\\LaTeX\\), il est possible d‚Äôutiliser\nla m√©thode Summary.as_latex. Pour un rapport HTML, on utilisera Summary.as_html\n\n\n\n\n Note\nLes utilisateurs de R retrouveront des √©l√©ments tr√®s familiers avec statsmodels,\nnotamment la possibilit√© d‚Äôutiliser une formule pour d√©finir une r√©gression.\nLa philosophie de statsmodels est similaire √† celle qui a influ√© sur la construction\ndes packages stats et MASS de R: offrir une librairie g√©n√©raliste, proposant\nune large gamme de mod√®les. N√©anmoins, statsmodels b√©n√©ficie de sa jeunesse\npar rapport aux packages R. Depuis les ann√©es 1990, les packages R visant\n√† proposer des fonctionalit√©s manquantes dans stats et MASS se sont\nmultipli√©s alors que statsmodels, enfant des ann√©es 2010, n‚Äôa eu qu‚Äô√†\nproposer un cadre g√©n√©ral (les generalized estimating equations) pour\nenglober ces mod√®les.",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html#la-r√©gression-logistique",
    "href": "content/modelisation/3_regression.html#la-r√©gression-logistique",
    "title": "R√©gression : une introduction",
    "section": "1.2 La r√©gression logistique",
    "text": "1.2 La r√©gression logistique\nCe mod√®le s‚Äôapplique √† une distribution binaire.\nDans ce cas, \\(\\mathbb{E}_{\\theta} (Y|X) = \\mathbb{P}_{\\theta} (Y = 1|X)\\).\nLa r√©gression logistique peut √™tre vue comme un mod√®le lin√©aire en probabilit√© :\n\\[\n\\text{logit}\\bigg(\\mathbb{E}_{\\theta}(Y|X)\\bigg) = \\text{logit}\\bigg(\\mathbb{P}_{\\theta}(Y = 1|X)\\bigg) = X\\beta\n\\]\nLa fonction \\(\\text{logit}\\) est \\(]0,1[ \\to \\mathbb{R}: p \\mapsto \\log(\\frac{p}{1-p})\\).\nElle permet ainsi de transformer une probabilit√© dans \\(\\mathbb{R}\\).\nSa fonction r√©ciproque est la sigmo√Øde (\\(\\frac{1}{1 + e^{-x}}\\)),\nobjet central du Deep Learning.\nIl convient de noter que les probabilit√©s ne sont pas observ√©es, c‚Äôest l‚Äôoutcome\nbinaire (0/1) qui l‚Äôest. Cela am√®ne √† voir la r√©gression logistique de deux\nmani√®res diff√©rentes :\n\nEn √©conom√©trie, on s‚Äôint√©resse au mod√®le latent qui d√©termine le choix de\nl‚Äôoutcome. Par exemple, si on observe les choix de participer ou non au march√©\ndu travail, on va mod√©liser les facteurs d√©terminant ce choix ;\nEn Machine Learning, le mod√®le latent n‚Äôest n√©cessaire que pour classifier\ndans la bonne cat√©gorie les observations\n\nL‚Äôestimation des param√®tres \\(\\beta\\) peut se faire par maximum de vraisemblance\nou par r√©gression, les deux solutions sont √©quivalentes sous certaines\nhypoth√®ses.\n\n\n Note\nPar d√©faut, scikit applique une r√©gularisation pour p√©naliser les mod√®les\npeu parcimonieux (comportement diff√©rent\nde celui de statsmodels). Ce comportement par d√©faut est √† garder √† l‚Äôesprit\nsi l‚Äôobjectif n‚Äôest pas de faire de la pr√©diction.\n\n\n\n\n Exercice 2a : R√©gression logistique avec scikit\nAvec scikit, en utilisant √©chantillons d‚Äôapprentissage et d‚Äôestimation :\n\nEvaluer l‚Äôeffet des variables d√©j√† utilis√©es sur la probabilit√© des R√©publicains\nde gagner. Affichez la valeur des coefficients.\nD√©duire une matrice de confusion et\nune mesure de qualit√© du mod√®le.\nSupprimer la r√©gularisation gr√¢ce au param√®tre penalty. Quel effet sur les param√®tres estim√©s ?\n\n\n\n\n\n Exercice 2b : R√©gression logistique avec statmodels\nEn utilisant √©chantillons d‚Äôapprentissage et d‚Äôestimation :\n\nEvaluer l‚Äôeffet des variables d√©j√† utilis√©es sur la probabilit√© des R√©publicains\nde gagner.\nFaire un test de ratio de vraisemblance concernant l‚Äôinclusion de la variable de (log)-revenu.\n\n\n\n\n\n Hint\nLa statistique du test est :\n\\[\nLR = -2\\log\\bigg(\\frac{\\mathcal{L}_{\\theta}}{\\mathcal{L}_{\\theta_0}}\\bigg) = -2(\\mathcal{l}_{\\theta} - \\mathcal{l}_{\\theta_0})\n\\]",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html#informations-additionnelles",
    "href": "content/modelisation/3_regression.html#informations-additionnelles",
    "title": "R√©gression : une introduction",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n58c7128\n\n\n2023-06-11 21:32:03\n\n\nLino Galiana\n\n\nchange na subset (#362)\n\n\n\n\n2ed4aa7\n\n\n2022-11-07 15:57:31\n\n\nLino Galiana\n\n\nReprise 2e partie ML + R√®gle probl√®me mathjax (#319)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n59eadf5\n\n\n2020-11-12 16:41:46\n\n\nLino Galiana\n\n\nCorrection des typos partie ML (#81)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html",
    "href": "content/modelisation/5_clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nIl peut √©galement √™tre utile d‚Äôinstaller plotnine\npour r√©aliser des graphiques simplement:\n!pip install plotnine",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#principe",
    "href": "content/modelisation/5_clustering.html#principe",
    "title": "Clustering",
    "section": "2.1 Principe",
    "text": "2.1 Principe\nL‚Äôobjectif des k-means est de partitionner l‚Äôespace des observations en trouvant des points (centroids) jouant le r√¥le de centres de gravit√© pour lesquels les observations proches peuvent √™tre regroup√©es dans une classe homog√®ne.\nL‚Äôalgorithme k-means fonctionne par it√©ration, en initialisant les centro√Ødes puis en les mettant √† jour √† chaque\nit√©ration, jusqu‚Äô√† ce que les centro√Ødes se stabilisent. Quelques exemples de clusters issus de la m√©thode k-means :\n\n\n\n Hint\nL‚Äôobjectif des k-means est de trouver une partition des donn√©es \\(S=\\{S_1,...,S_K\\}\\) telle que\n\\[\n\\arg\\min_{S} \\sum_{i=1}^K \\sum_{x \\in S_i} ||x - \\mu_i||^2\n\\]\navec \\(\\mu_i\\) la moyenne des \\(x_i\\) dans l‚Äôensemble de points \\(S_i\\)\n\n\nDans ce chapitre nous allons principalement\nutiliser Scikit. Voici n√©anmoins une proposition\nd‚Äôimports de packages, pour gagner du temps.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nfrom sklearn.cluster import KMeans  # pour kmeans\nimport seaborn as sns  # pour scatterplots\n\n\n\n Exercice 1 : Principe des k-means\n\nImporter les donn√©es et se restreindre aux variables 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Percent of adults with less than a high school diploma, 2015-19', \"Percent of adults with a bachelor's degree or higher, 2015-19\" et bien s√ªr 'per_gop'. Appelez cette base restreinte df2 et enlevez les valeurs manquantes.\nFaire un k-means avec \\(k=4\\).\nCr√©er une variable label dans votes stockant le r√©sultat de la typologie\nAfficher cette typologie sur une carte.\nChoisir les variables Median_Household_Incomme_2019 et Unemployment_rate_2019 et repr√©senter le nuage de points en colorant diff√©remment\nen fonction du label obtenu. Quel est le probl√®me ?\nRefaire les questions 2 √† 5 en standardisant les variables en amont\nRepr√©senter la distribution du vote pour chaque cluster\n\n\n\nLa carte obtenue √† la question 4, qui permet de\nrepr√©senter spatialement nos groupes, est\nla suivante :\n\n\n\n\n\n\n\n\n\nLe nuage de point de la question 5, permettant de repr√©senter\nla relation entre Median_Household_Income_2019\net Unemployment_rate_2019, aura l‚Äôaspect suivant :\n\n\n\n\n\n\n\n\n\nLa classification appara√Æt un peu trop nettement dans cette figure.\nCela sugg√®re que la variable de revenu (Median_Household_Income_2019)\nexplique un peu trop bien le partitionnement produit par notre\nmod√®le pour que ce soit normal. C‚Äôest probablement le fait\nde la variance forte du revenu par rapport aux autres variables.\nDans ce type de sitution, comme cela a √©t√© √©voqu√©, il est\nrecommand√© de standardiser les variables.\n\n\n\n\n\n\n\n\n\nOn obtient ainsi la carte suivante √† la question 5:\n\n\n\n\n\n\n\n\n\nEt le nuage de point de la question 5 pr√©sente un aspect moins\nd√©terministe, ce qui est pr√©f√©rable :\n\n\n\n\n\n\n\n\n\nEnfin, en ce qui concerne la question 6, on obtient cet\nhistogramme des votes pour chaque cluster :\n\n\n/opt/mamba/lib/python3.11/site-packages/plotnine/stats/stat_bin.py:109: PlotnineWarning: 'stat_bin()' using 'bins = 31'. Pick better value with 'binwidth'.\n\n\n\n\n\n\n\n\n\n\n\n Hint\nIl faut noter plusieurs points sur l‚Äôalgorithme impl√©ment√© par d√©faut par scikit-learn, que l‚Äôon peut lire dans\nla documentation :\n\nl‚Äôalgorithme impl√©ment√© par d√©faut est kmeans ++ (cf.¬†param√®tre init). Cela signifie que\nl‚Äôinitialisation des centro√Ødes est faite de mani√®re intelligente pour que les centro√Ødes initiaux soient choisis\nafin de ne pas √™tre trop proches.\nl‚Äôalgorithme va √™tre d√©marr√© avec n_init centro√Ødes diff√©rents et le mod√®le va choisir la meilleure initialisation\nen fonction de l‚Äôinertie du mod√®le, par d√©faut √©gale √† 10.\n\nLe mod√®le renvoie les cluster_centers_, les labels labels_, l‚Äôinertie inertia_ et le nombre d‚Äôit√©rations\nn_iter_.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#choisir-le-nombre-de-clusters",
    "href": "content/modelisation/5_clustering.html#choisir-le-nombre-de-clusters",
    "title": "Clustering",
    "section": "2.2 Choisir le nombre de clusters",
    "text": "2.2 Choisir le nombre de clusters\nLe nombre de clusters est fix√© par le mod√©lisateur.\nIl existe plusieurs fa√ßons de fixer ce nombre :\n\nconnaissance a priori du probl√®me ;\nanalyse d‚Äôune m√©trique sp√©cifique pour d√©finir le nombre de clusters √† choisir ;\netc.\n\nIl y a un arbitrage √† faire\nentre biais et variance :\nun trop grand nombre de clusters implique une variance\nintra-cluster tr√®s faible (sur-apprentissage, m√™me s‚Äôil n‚Äôest jamais possible de d√©terminer\nle vrai type d‚Äôune observation puisqu‚Äôon est en apprentissage non supervis√©).\nSans connaissance a priori du nombre de clusters, on peut recourir √† deux familles de m√©thodes :\n\nLa m√©thode du coude (elbow method) : On prend le point d‚Äôinflexion de la courbe\nde performance du mod√®le. Cela repr√©sente le moment o√π ajouter un cluster\n(complexit√© croissante du mod√®le) n‚Äôapporte que des gains mod√©r√©s dans la\nmod√©lisation des donn√©es.\nLe score de silhouette : On mesure la similarit√© entre un point et les autres points\ndu cluster par rapport aux autres clusters. Plus sp√©cifiquement :\n\n\nSilhouette value is a measure of how similar an object is to its own cluster\n(cohesion) compared to other clusters (separation). The silhouette ranges\nfrom ‚àí1 to +1, where a high value indicates that the object is\nwell matched to its own cluster and poorly matched to neighboring\nclusters. If most objects have a high value, then the clustering\nconfiguration is appropriate. If many points have a low or negative\nvalue, then the clustering configuration may have too many or too few clusters\nSource: Wikipedia\n\nLe score de silhouette d‚Äôune observation est donc √©gal √†\n(m_nearest_cluster - m_intra_cluster)/max( m_nearest_cluster,m_intra_cluster)\no√π m_intra_cluster est la moyenne des distances de l‚Äôobservation aux observations du m√™me cluster\net m_nearest_cluster est la moyenne des distances de l‚Äôobservation aux observations du cluster le plus proche.\nLe package yellowbrick fournit une extension utile √† scikit pour repr√©senter\nfacilement la performance en clustering.\n\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\n\nvisualizer = KElbowVisualizer(model, k=(2, 12))\nvisualizer.fit(df2[xvars])  # Fit the data to the visualizer\n\n\n\n&lt;Axes: title={'center': 'Distortion Score Elbow for KMeans Clustering'}, xlabel='k', ylabel='distortion score'&gt;\n\n\n&lt;Figure size 768x528 with 0 Axes&gt;\n\n\n\nPour la m√©thode du coude, la courbe\nde performance du mod√®le marque un coude l√©ger √† \\(k=4\\). Le mod√®le initial\nsemblait donc appropri√©.\nyellowbrick permet √©galement de repr√©senter des silhouettes mais\nl‚Äôinterpr√©tation est moins ais√©e et le co√ªt computationnel plus √©lev√© :\n\nfrom yellowbrick.cluster import SilhouetteVisualizer\n\nfig, ax = plt.subplots(2, 2, figsize=(15, 8))\nj = 0\nfor i in [3, 4, 6, 10]:\n    j += 1\n    \"\"\"\n    Create KMeans instance for different number of clusters\n    \"\"\"\n    km = KMeans(\n        n_clusters=i, init=\"k-means++\", n_init=10, max_iter=100, random_state=42\n    )\n    q, mod = divmod(j, 2)\n    \"\"\"\n    Create SilhouetteVisualizer instance with KMeans instance\n    Fit the visualizer\n    \"\"\"\n    visualizer = SilhouetteVisualizer(km, colors=\"yellowbrick\", ax=ax[q - 1][mod])\n    ax[q - 1][mod].set_title(\"k = \" + str(i))\n    visualizer.fit(df2[xvars])\n\n\nLe score de silhouette offre une repr√©sentation plus riche que la courbe coud√©e.\nSur ce graphique, les barres verticales en rouge et en pointill√© repr√©sentent le score de silhouette\nglobal pour chaque k choisi. On voit par exemple que pour tous les k repr√©sent√©s ici, le\nscore de silhouette se situe entre 0.5 et 0.6 et varie peu.\nEnsuite, pour un k donn√©, on va avoir la repr√©sentation des scores de silhouette de chaque\nobservation, regroup√©es par cluster.\nPar exemple, pour k = 4, ici, on voit bien quatre couleurs diff√©rentes qui sont les 4 clusters mod√©lis√©s.\nLes ordonn√©es sont toutes les observations clusteris√©es et en abscisses on a le score de silhouette de\nchaque observation. Si au sein d‚Äôun cluster, les observations ont un score de silhouette plus faible que le\nscore de silhouette global (ligne verticale en rouge), cela signifie que les observations du clusters sont\ntrop proches des autres clusters.\nGr√¢ce √† cette repr√©sentation, on peut aussi se rendre compte de la taille relative des clusters. Par exemple,\navec k = 3, on voit qu‚Äôon a deux clusters cons√©quents et un plus ‚Äúpetit‚Äù cluster relativement aux deux autres.\nCela peut nous permettre de choisir des clusters de tailles homog√®nes ou non.\nEnfin, quand le score de silhouette est n√©gatif, cela signifie que la moyenne des distances de l‚Äôobservation\naux observations du cluster le plus proche est inf√©rieure √† la moyenne des distances de l‚Äôobservation aux\nobservations de son cluster. Cela signifie que l‚Äôobservation est mal class√©e.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#autres-m√©thodes-de-clustering",
    "href": "content/modelisation/5_clustering.html#autres-m√©thodes-de-clustering",
    "title": "Clustering",
    "section": "2.3 Autres m√©thodes de clustering",
    "text": "2.3 Autres m√©thodes de clustering\nIl existe de nombreuses autres m√©thodes de clustering. Parmi les plus connues, on peut citer trois exemples en particulier :\n\nLe clustering ascendant hi√©rarchique\nDBSCAN\nles m√©langes de Gaussiennes\n\n\n2.3.1 Clustering Ascendant Hi√©rarchique (CAH)\nQuel est le principe ?\n\nOn commence par calculer la dissimilarit√© entre nos N individus, i.e. leur distance deux √† deux dans l‚Äôespace de nos variables\nPuis on regroupe les deux individus dont le regroupement minimise un crit√®re d‚Äôagr√©gation donn√©, cr√©ant ainsi une classe comprenant ces deux individus.\nOn calcule ensuite la dissimilarit√© entre cette classe et les N-2 autres individus en utilisant le crit√®re d‚Äôagr√©gation.\nPuis on regroupe les deux individus ou classes d‚Äôindividus dont le regroupement minimise le crit√®re d‚Äôagr√©gation.\nOn continue ainsi jusqu‚Äô√† ce que tous les individus soient regroup√©s.\n\nCes regroupements successifs produisent un arbre binaire de classification (dendrogramme), dont la racine correspond √† la classe regroupant l‚Äôensemble des individus. Ce dendrogramme repr√©sente une hi√©rarchie de partitions. On peut alors choisir une partition en tronquant l‚Äôarbre √† un niveau donn√©, le niveau d√©pendant soit des contraintes de l‚Äôutilisateur, soit de crit√®res plus objectifs.\nPlus d‚Äôinformations ici.\n\n\n2.3.2 DBSCAN\nL‚Äôalgorithme DBSCAN est impl√©ment√© dans sklearn.cluster.\nIl peut √™tre utilis√© pour faire de la d√©tection d‚Äôanomalies\nnotamment.\nEn effet, cette m√©thode repose sur le clustering en r√©gions o√π la densit√©\ndes observations est continue, gr√¢ce √† la notion de voisinage selon une certaine distance epsilon.\nPour chaque observation, on va regarder si dans son voisinage selon une distance epsilon, il y a des voisins. S‚Äôil y a au\nmoins min_samples voisins, alors l‚Äôobservation sera une core instance.\nLes observations qui ne sont pas des core instances et qui n‚Äôen ont pas dans leur voisinage selon une distance espilon\nvont √™tre d√©tect√©es comme des anomalies.\n\n\n2.3.3 Les m√©langes de gaussiennes\nEn ce qui concerne la th√©orie, voir le cours Probabilit√©s num√©riques et statistiques computationnelles, M1 Jussieu, V.Lemaire et T.Rebafka\nSe r√©f√©rer notamment aux notebooks pour l‚Äôalgorithme EM pour m√©lange gaussien.\nDans sklearn, les m√©langes gaussiens sont impl√©ment√©s dans sklearn.mixture comme GaussianMixture.\nLes param√®tres importants sont alors le nombre de gaussiennes n_components et le nombre d‚Äôinitiatisations n_init.\nIl est possible de faire de la d√©tection d‚Äôanomalie savec les m√©langes de gaussiennes.\n\n\n Pour aller plus loin\nIl existe de nombreuses autres m√©thodes de clustering :\n\nLocal outlier factor ;\nBayesian gaussian mixture models ;\nD‚Äôautres m√©thodes de clustering hi√©rarchique ;\netc.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#pour-la-visualisation-de-clusters",
    "href": "content/modelisation/5_clustering.html#pour-la-visualisation-de-clusters",
    "title": "Clustering",
    "section": "3.1 Pour la visualisation de clusters",
    "text": "3.1 Pour la visualisation de clusters\nLa m√©thode la plus simple pour visualiser les clusters, peu importe la m√©thode avec laquelles ils ont √©t√© obtenus, serait de repr√©senter chaque individu dans l‚Äôespace √† N dimensions des variables de la table, et colorier chaque individu en fonction de son cluster.\nOn pourrait alors bien diff√©rencier les variables les plus discrimantes et les diff√©rents groupes.\nUn seul probl√®me ici : d√®s que N &gt; 3, nous avons du mal √† repr√©senter le r√©sultat de fa√ßon intelligible‚Ä¶\nC‚Äôest l√† qu‚Äôintervient l‚ÄôAnalyse en Composantes Principales (ACP), qui permet de projeter notre espace √† haute dimension dans un espace de dimension plus petite.\nLa contrainte majeure de la projection est de pouvoir conserver le maximum d‚Äôinformation (mesur√©e par la variance totale de l‚Äôensemble de donn√©es) dans notre nombre r√©duit de dimensions, appel√©es composantes principales.\nEn se limitant √† 2 ou 3 dimensions, on peut ainsi se repr√©senter visuellement les relations entre les observations avec une perte de fiabilit√© minimale.\nOn peut g√©n√©ralement esp√©rer que les clusters d√©termin√©s dans notre espace √† N dimensions se diff√©rencient bien sur notre projection par ACP, et que la composition des composantes principales en fonction des variables initiales permette d‚Äôinterpr√©ter les clusters obtenus.\nEn effet, la combinaison lin√©aire des colonnes donnant naissance √† nos nouveaux axes a souvent un ‚Äúsens‚Äù dans le monde r√©el :\n\nSoit parce qu‚Äôune petite poign√©e de variables repr√©sente la majorit√© de la composante\nSoit parce que la plupart des colonnes intervenant dans la composante somm√©e se combinent bien pour former une interpr√©tation naturelle.\n\nPour mettre en pratique les m√©thodes de cr√©ation de clusters, de la base brute jusqu‚Äô√† la visualisation par ACP, vous pouvez consulter la partie 2 du sujet 3 du funathon 2023, Explorer les habitudes alimentaires de nos compatriotes, sur le SSP Cloud ou sur Github.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#pour-la-r√©duction-de-dimension",
    "href": "content/modelisation/5_clustering.html#pour-la-r√©duction-de-dimension",
    "title": "Clustering",
    "section": "3.2 Pour la r√©duction de dimension",
    "text": "3.2 Pour la r√©duction de dimension\nL‚ÄôACP est √©galement tr√®s utile dans le champ de la r√©duction du nombre de variables pour de nombreux types de mod√©lisations, comme par exemple les r√©gressions lin√©aires.\nIl est ainsi possible de projeter l‚Äôespace des variables explicatives dans un espace de dimension donn√©e plus faible, pour notamment limiter les risques d‚Äôoverfitting.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#informations-additionnelles",
    "href": "content/modelisation/5_clustering.html#informations-additionnelles",
    "title": "Clustering",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n98112c0\n\n\n2023-12-11 09:35:53\n\n\nLino Galiana\n\n\nAjoute une standardisation de variables dans la partie clustering (#471)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf5ad021\n\n\n2022-11-15 17:40:16\n\n\nLino Galiana\n\n\nRelec clustering et lasso (#322)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n7058752\n\n\n2022-03-04 15:35:17\n\n\nLino Galiana\n\n\nRelecture Word2Vec (#216)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\nc6fa115\n\n\n2021-05-12 18:54:53\n\n\nRaphaele Adjerad\n\n\nEl√©ments compl√©mentaires clustering (#107)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n59eadf5\n\n\n2020-11-12 16:41:46\n\n\nLino Galiana\n\n\nCorrection des typos partie ML (#81)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/7_mlapi.html",
    "href": "content/modelisation/7_mlapi.html",
    "title": "Mettre √† disposition un mod√®le par le biais d‚Äôune API",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre pr√©sente la deuxi√®me application\nd‚Äôune journ√©e de cours que j‚Äôai\ndonn√© √† l‚ÄôUniversit√© Dauphine dans le cadre\ndes PSL Data Week.\nL‚Äôobjectif de ce chapitre est d‚Äôamener √† d√©velopper\nune API du type de celle-ci.\nLe chapitre pr√©c√©dent constituait une introduction √† la cr√©ation\nde pipelines de machine learning.\nCe chapitre va aller plus loin en montrant la d√©marche pour le rendre\ndisponible √† plus grande √©chelle par le biais d‚Äôune API pouvant\n√™tre consomm√©e avec de nouvelles donn√©es. L‚Äôobjectif de celle-ci est\nde ne pas contraindre les r√©utilisateurs d‚Äôun mod√®le\n√† disposer d‚Äôun environnement technique complexe\npour pouvoir utiliser le m√™me mod√®le que celui entra√Æn√© pr√©c√©demment.",
    "crumbs": [
      "Mettre √† disposition un mod√®le par le biais d'une API"
    ]
  },
  {
    "objectID": "content/modelisation/7_mlapi.html#informations-additionnelles",
    "href": "content/modelisation/7_mlapi.html#informations-additionnelles",
    "title": "Mettre √† disposition un mod√®le par le biais d‚Äôune API",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\ne4642ee\n\n\n2023-11-27 17:02:05\n\n\nLino Galiana\n\n\nDeploy ML model as API (#460)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Mettre √† disposition un mod√®le par le biais d'une API"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html",
    "href": "content/NLP/01_intro.html",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette partie est une introduction\n√† la question du nettoyage de donn√©es textuelles.\nIl s‚Äôagit de montrer la logique, quelques exemples\navec Python \net s‚Äôamuser avec comme base d‚Äôexemple un livre formidable üìñ :\nLe Comte de Monte Cristo.\nL‚Äôobjectif est de d√©couvrir les principaux enjeux du nettoyage de donn√©es en NLP\net les enjeux de l‚Äôanalyse de fr√©quence.",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#objectif",
    "href": "content/NLP/01_intro.html#objectif",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "2.1 Objectif",
    "text": "2.1 Objectif\nLe natural language processing (NLP) ou\ntraitement automatis√© du langage (TAL) en Fran√ßais,\nvise √† extraire de l‚Äôinformation de textes √† partir d‚Äôune analyse statistique du contenu.\nCette d√©finition permet d‚Äôinclure de nombreux champs d‚Äôapplications au sein\ndu NLP (traduction, analyse de sentiment, recommandation, surveillance, etc. ).\nCette approche implique de transformer un texte, qui est une information compr√©hensible par un humain, en un nombre, information appropri√©e pour un ordinateur dans le cadre d‚Äôune approche statistique ou algorithmique.\nTransformer une information textuelle en valeurs num√©riques propres √† une analyse statistique n‚Äôest pas une t√¢che √©vidente. Les donn√©es textuelles sont non structur√©es puisque l‚Äôinformation cherch√©e, qui est propre √† chaque analyse, est perdue au milieu d‚Äôune grande masse d‚Äôinformations qui doit, de plus, √™tre interpr√©t√©e dans un certain contexte (un m√™me mot ou une phrase n‚Äôayant pas la m√™me signification selon le contexte).\nSi cette t√¢che n‚Äô√©tait pas assez difficile comme √ßa, on peut ajouter d‚Äôautres difficult√©s propres √† l‚Äôanalyse textuelle car ces donn√©es sont :\n\nbruit√©es : ortographe, fautes de frappe‚Ä¶\nchangeantes : la langue √©volue avec de nouveaux mots, sens‚Ä¶\ncomplexes : structures variables, accords‚Ä¶\nambigu√´s : synonymie, polys√©mie, sens cach√©‚Ä¶\npropres √† chaque langue : il n‚Äôexiste pas de r√®gle de passage unique entre deux langues\nde grande dimension : des combinaisons infinies de s√©quences de mots",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#m√©thode",
    "href": "content/NLP/01_intro.html#m√©thode",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "2.2 M√©thode",
    "text": "2.2 M√©thode\nL‚Äôanalyse textuelle vise √† transformer le texte en donn√©es\nnum√©riques manipulables. Pour cela il est n√©cessaire de se fixer\nune unit√© s√©mantique minimale.\nCette unit√© textuelle peut √™tre le mot ou encore une s√©quence de n\nmots (un n-gramme) ou encore une cha√Æne de caract√®res (e.g.¬†la\nponctuation peut √™tre signifiante). On parle de token.\nOn peut ensuite utiliser diverses techniques (clustering,\nclassification supervis√©e) suivant l‚Äôobjectif poursuivi pour exploiter\nl‚Äôinformation transform√©e. Mais les √©tapes de nettoyage de texte sont indispensables.\nSinon un algorithme sera incapable de d√©tecter une information pertinente dans l‚Äôinfini des possibles.",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#tokenisation",
    "href": "content/NLP/01_intro.html#tokenisation",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "3.1 Tokenisation",
    "text": "3.1 Tokenisation\n\n\n Hint\nLors de la premi√®re utilisation de NLTK, il est n√©cessaire de t√©l√©charger\nquelques √©l√©ments n√©cessaires √† la tokenisation, notamment la ponctuation.\nPour cela, il est recommand√© d‚Äôutiliser la commande suivante :\nimport nltk\n\nnltk.download(\"punkt\")\n\n\n\nimport nltk\n\nnltk.download(\"punkt\")\n\n[nltk_data] Downloading package punkt to /github/home/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n\n\nTrue\n\n\nLa tokenisation consiste √† d√©couper un texte en morceaux. Ces morceaux\npourraient √™tre des phrases, des chapitres, des n-grammes ou des mots. C‚Äôest\ncette derni√®re option que l‚Äôon va choisir, plus simple pour retirer les\nstop words :\n\nimport nltk\n\nwords = nltk.word_tokenize(dumas, language=\"french\")\nwords[1030:1050]\n\n['que',\n 'voulez-vous',\n ',',\n 'monsieur',\n 'edmond',\n ',',\n 'reprit',\n \"l'armateur\",\n 'qui',\n 'paraissait',\n 'se',\n 'consoler',\n 'de',\n 'plus',\n 'en',\n 'plus',\n ',',\n 'nous',\n 'sommes',\n 'tous']\n\n\nOn remarque que les mots avec apostrophes sont li√©s en un seul, ce qui est\npeut-√™tre faux sur le plan de la grammaire mais peu avoir un sens pour une\nanalyse statistique. Il reste des signes de ponctuation qu‚Äôon peut √©liminer\navec la m√©thode isalpha:\n\nwords = [word for word in words if word.isalpha()]\nwords[1030:1050]\n\n['assez',\n 'sombre',\n 'obs√©quieux',\n 'envers',\n 'ses',\n 'sup√©rieurs',\n 'insolent',\n 'envers',\n 'ses',\n 'subordonn√©s',\n 'aussi',\n 'outre',\n 'son',\n 'titre',\n 'comptable',\n 'qui',\n 'est',\n 'toujours',\n 'un',\n 'motif']",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#retirer-les-stop-words",
    "href": "content/NLP/01_intro.html#retirer-les-stop-words",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "3.2 Retirer les stop words",
    "text": "3.2 Retirer les stop words\nLe jeu de donn√©es est maintenant propre. On peut d√©sormais retirer les\nmots qui n‚Äôapportent pas de sens et servent seulement √† faire le\nlien entre deux pr√©positions. On appelle ces mots des\nstop words dans le domaine du NLP.\n\n\n Hint\nLors de la premi√®re utilisation de NLTK, il est n√©cessaire de t√©l√©charger\nles stop words.\nimport nltk\n\nnltk.download(\"stopwords\")\n\n\nComme indiqu√© ci-dessus, pour t√©l√©charger\nle corpus de stop words1, il est\nn√©cessaire d‚Äôex√©cuter la ligne de\ncommande suivante :\n\nimport nltk\n\nnltk.download(\"stopwords\")\n\n[nltk_data] Downloading package stopwords to /github/home/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\nTrue\n\n\n\nfrom nltk.corpus import stopwords\n\nprint(stopwords.words(\"french\"))\n\nstop_words = set(stopwords.words(\"french\"))\n\n\nwords = [w for w in words if not w in stop_words]\nprint(words[1030:1050])\n\n['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'm√™me', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', '√†', 'm', 'n', 's', 't', 'y', '√©t√©', '√©t√©e', '√©t√©es', '√©t√©s', '√©tant', '√©tante', '√©tants', '√©tantes', 'suis', 'es', 'est', 'sommes', '√™tes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', '√©tais', '√©tait', '√©tions', '√©tiez', '√©taient', 'fus', 'fut', 'f√ªmes', 'f√ªtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'f√ªt', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'e√ªmes', 'e√ªtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'e√ªt', 'eussions', 'eussiez', 'eussent']\n['celui', 'dant√®s', 'a', 'd√©pos√©', 'passant', 'comment', 'paquet', 'd√©poser', 'danglars', 'rougit', 'passais', 'devant', 'porte', 'capitaine', 'entrouverte', 'vu', 'remettre', 'paquet', 'cette', 'lettre']\n\n\nCes retraitements commencent √† porter leurs fruits puisque des mots ayant plus\nde sens commencent √† se d√©gager, notamment les noms des personnages\n(Fernand, Merc√©d√®s, Villefort, etc.)\n\nwc = make_wordcloud(\" \".join(words))\n\nfig = plt.figure()\n\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis(\"off\")",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#stemming",
    "href": "content/NLP/01_intro.html#stemming",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "3.3 Stemming",
    "text": "3.3 Stemming\nPour r√©duire la complexit√© d‚Äôun texte, on peut tirer partie de\n‚Äúclasses d‚Äô√©quivalence‚Äù : on peut\nconsid√©rer que diff√©rentes formes d‚Äôun m√™me mot (pluriel,\nsingulier, conjugaison) sont √©quivalentes et les remplacer par une\nm√™me forme dite canonique. Il existe deux approches dans le domaine :\n\nla lemmatisation qui requiert la connaissance des statuts\ngrammaticaux (exemple : chevaux devient cheval)\nla racinisation (stemming) plus fruste mais plus rapide, notamment\nen pr√©sence de fautes d‚Äôorthographes. Dans ce cas, chevaux peut devenir chev\nmais √™tre ainsi confondu avec chevet ou cheveux\n\nLa racinisation est plus simple √† mettre en oeuvre car elle peut s‚Äôappuyer sur\ndes r√®gles simples pour extraire la racine d‚Äôun mot.\nPour r√©duire un mot dans sa forme ‚Äúracine‚Äù, c‚Äôest-√†-dire en s‚Äôabstrayant des\nconjugaisons ou variations comme les pluriels, on applique une m√©thode de\nstemming. Le but du stemming est de regrouper de\nnombreuses variantes d‚Äôun mot comme un seul et m√™me mot.\nPar exemple, une fois que l‚Äôon applique un stemming, ‚Äúchats‚Äù et ‚Äúchat‚Äù\ndeviennent un m√™me mot.\nCette approche a l‚Äôavantage de r√©duire la taille du vocabulaire √† ma√Ætriser\npour l‚Äôordinateur et le mod√©lisateur. Il existe plusieurs algorithmes de\nstemming, notamment le Porter Stemming Algorithm ou le\nSnowball Stemming Algorithm. Nous pouvons utiliser ce dernier en Fran√ßais :\n\nfrom nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer(language=\"french\")\n\nstemmed = [stemmer.stem(word) for word in words]\nprint(stemmed[1030:1050])\n\n['celui', 'dantes', 'a', 'd√©pos', 'pass', 'comment', 'paquet', 'd√©pos', 'danglar', 'roug', 'pass', 'dev', 'port', 'capitain', 'entrouvert', 'vu', 'remettr', 'paquet', 'cet', 'lettr']\n\n\nA ce niveau, les mots commencent √† √™tre moins intelligibles par un humain.\nLa machine prendra le relais, on lui a pr√©par√© le travail.\n\n\n Note\nIl existe aussi le stemmer suivant :\nfrom nltk.stem.snowball import FrenchStemmer\n\nstemmer = FrenchStemmer()",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#informations-additionnelles",
    "href": "content/NLP/01_intro.html#informations-additionnelles",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n4c060a1\n\n\n2023-12-01 17:44:17\n\n\nLino Galiana\n\n\nUpdate book image location\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na1ab3d9\n\n\n2023-11-24 10:57:02\n\n\nLino Galiana\n\n\nReprise des chapitres NLP (#459)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\na9b384e\n\n\n2023-07-18 18:07:16\n\n\nLino Galiana\n\n\nS√©pare les notebooks (#373)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n164fa68\n\n\n2022-11-30 09:13:45\n\n\nLino Galiana\n\n\nTravail partie NLP (#328)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n3299f1d\n\n\n2022-01-08 16:50:11\n\n\nLino Galiana\n\n\nClean NLP notebooks (#215)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n04f8b8f\n\n\n2021-09-08 11:55:35\n\n\nLino Galiana\n\n\necho = FALSE sur la page tuto NLP\n\n\n\n\n048e3dd\n\n\n2021-09-02 18:36:23\n\n\nLino Galiana\n\n\nFix problem with Dumas corpus (#134)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n49e2826\n\n\n2021-05-13 18:11:20\n\n\nLino Galiana\n\n\nCorrige quelques images n‚Äôapparaissant pas (#108)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n48ed9d2\n\n\n2021-05-01 08:58:58\n\n\nLino Galiana\n\n\nlien mort corrig√©\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†3.1: Nuage de mot produit √† partir du Comte de Monte Cristo\nOpenFoodFacts avant nettoyage\nScanner-data avant nettoyage\nOpenFoodFacts apr√®s nettoyage\nScanner-data apr√®s nettoyage",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#footnotes",
    "href": "content/NLP/01_intro.html#footnotes",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe corpus de stop words de NLTK\nest relativement limit√©. Il est recommand√©\nde privil√©gier celui de SpaCy, plus\ncomplet, pour √©liminer plus de mots\nvalises.‚Ü©Ô∏é",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/03_lda.html",
    "href": "content/NLP/03_lda.html",
    "title": "Latent Dirichlet Allocation (LDA)",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page approfondit les exercices pr√©sent√©s dans la\nsection pr√©c√©dente.\nOn va ainsi continuer notre exploration de la litt√©rature anglophones :\nLes donn√©es sont disponibles dans la base de\ndonn√©es spooky.csv et peuvent √™tre\nimport√©es par Python en utilisant directement l‚Äôurl\nhttps://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv.\nLe but va √™tre dans un premier temps de regarder dans le d√©tail les termes les plus fr√©quents utilis√©s par les auteurs, et les repr√©senter graphiquement.\nCe notebook est librement inspir√© de :\nLa LDA est une technique d‚Äôestimation bay√©sienne.\nLe cours d‚ÄôAlberto Brietti\nsur le sujet constitue une tr√®s bonne ressource pour comprendre\nles fondements de cette technique.",
    "crumbs": [
      "Latent Dirichlet Allocation (LDA)"
    ]
  },
  {
    "objectID": "content/NLP/03_lda.html#informations-additionnelles",
    "href": "content/NLP/03_lda.html#informations-additionnelles",
    "title": "Latent Dirichlet Allocation (LDA)",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\nd2a2773\n\n\n2023-07-07 15:59:36\n\n\nLino Galiana\n\n\nRetour du wordcloud (#372)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n934149d\n\n\n2023-02-13 11:45:23\n\n\nLino Galiana\n\n\nget_feature_names is deprecated in scikit 1.0.X versions (#351)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\nbb38643\n\n\n2022-06-08 16:59:40\n\n\nLino Galiana\n\n\nR√©pare bug leaflet (#234)\n\n\n\n\n299cff3\n\n\n2022-06-08 13:19:03\n\n\nLino Galiana\n\n\nProbl√®me code JS suite (#233)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\ne94c1c5\n\n\n2021-12-23 21:34:46\n\n\nLino Galiana\n\n\nUn tutoriel sur les pipelines :tada: (#203)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nf4e61ed\n\n\n2020-12-10 15:00:12\n\n\nLino Galiana\n\n\nAjout partie LDA (#88)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Latent Dirichlet Allocation (LDA)"
    ]
  },
  {
    "objectID": "content/NLP/05_exo_supp.html",
    "href": "content/NLP/05_exo_supp.html",
    "title": "Exercices suppl√©mentaires",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page approfondit certains aspects pr√©sent√©s dans les autres tutoriels.\nIl s‚Äôagit d‚Äôune suite d‚Äôexercice, avec corrections, pour pr√©senter d‚Äôautres aspects du NLP ou pratiquer sur des donn√©es diff√©rentes.",
    "crumbs": [
      "Exercices suppl√©mentaires"
    ]
  },
  {
    "objectID": "content/NLP/05_exo_supp.html#informations-additionnelles",
    "href": "content/NLP/05_exo_supp.html#informations-additionnelles",
    "title": "Exercices suppl√©mentaires",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Exercices suppl√©mentaires"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html",
    "href": "content/modern-ds/continuous_integration.html",
    "title": "Int√©gration continue avec Python",
    "section": "",
    "text": "Cette page sera actualis√©e prochainement, une version plus √† jour et plus compl√®te peut √™tre trouv√©e sur https://ensae-reproductibilite.github.io/website/\nL‚Äôun des apports principaux des innovations\nr√©centes de la data science est la\nmani√®re dont des projets, malgr√©\nleur complexit√©, peuvent facilement\n√™tre converti en projets p√©rennes\n√† partir\nd‚Äôun prototype bien construit.\nEn s‚Äôinspirant de l‚Äôapproche devops ,\nm√©thode de travail qui consiste √† adopter un certain\nnombre de gestes pour\nautomatiser la production de livrables ou de tests\nd√®s la\nconception du produit, les data scientists\nont adopt√© une m√©thode de travail tr√®s efficace\npour favoriser la r√©utilisation de leur travail\npar d‚Äôautres √©quipes que celles √† l‚Äôorigine de\nla conception du protype initial.\nCette approche devops a √©t√© reprise et √©tendue\npour donner un autre buzz-word, le MLops.\nIl s‚Äôagit d‚Äôune approche qui vise √† cr√©er\net mettre √† disposition des mod√®les de machine\nlearning de mani√®re fiable et automatis√©e\n√† chaque nouvelle √©tape du projet, en parall√®le\nde la mise √† jour du code ayant produit ces\noutput.\nCes nouvelles m√©thodes de travail permettent\ndes gains substantiels de productivit√©\npour les √©quipes d√©veloppant des mod√®les\net r√©duit fortement le co√ªt de reprise d‚Äôun\ncode par une √©quipe en charge de sa\np√©renisation. Ce co√ªt est en effet le principal\nfrein √† la mise en production de nouveaux\nprojets ce qui peut repr√©senter un g√¢chis\nnon n√©gligeable de temps et de ressources.\nComme nous l‚Äôexpliquons avec Romain Avouac\ndans un cours de derni√®re ann√©e de l‚ÄôENSAE\n(https://ensae-reproductibilite.github.io/website/),\nl‚Äôadoption de certaines bonnes pratiques\nde d√©veloppement de code et d‚Äôune d√©marche\nexploitant les derni√®res innovations de\nla data science peut substantiellement\naugmenter les chances d‚Äôun succ√®s\nd‚Äôun projet. Le nouveau paradigme, qui\nconsiste √† int√©grer en amont du projet\ncertaines contraintes de la production\net tester continuellement la mani√®re dont les\nlivrables √©voluent, √©vite que la mise\nen production d‚Äôun projet, qui est co√ªteuse\nen temps et en ressources, n‚Äôaboutisse qu‚Äôau\nmoment o√π le projet est d√©j√† caduc\n(car les donn√©es ou les besoins ont √©volu√©s‚Ä¶).",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#fonctionnement-des-actions-github",
    "href": "content/modern-ds/continuous_integration.html#fonctionnement-des-actions-github",
    "title": "Int√©gration continue avec Python",
    "section": "3.1 Fonctionnement des actions Github",
    "text": "3.1 Fonctionnement des actions Github\nLes actions Github fonctionnent par couches successives au sein desquelles\non effectue un certain nombre d‚Äôinstructions.\nLa meilleure mani√®re d‚Äôapprendre les actions Github est, certes, de lire la\ndocumentation officielle mais surtout,\n√† mon avis, de regarder quelques pipelines pour comprendre la d√©marche.\nL‚Äôun des int√©r√™ts des Github Actions est la possibilit√© d‚Äôavoir un pipeline\nproposant une intrication de langages diff√©rents pour avoir une chaine de\nproduction qui propose les outils les plus efficaces pour r√©pondre √† un\nobjectif en limitant les verrous techniques.\nPar exemple, le pipeline de ce cours, disponible\nsur Github {{&lt; githubrepo  &gt;}} propose une intrication des langages\nPython et R avec des technologies Anaconda (pour contr√¥ler\nl‚Äôenvironnement Python comme expliqu√© dans les chapitres pr√©c√©dents)\net Javascript (pour le d√©ploiement d‚Äôun site web avec le service tiers\nNetlify)2. Cette cha√Æne de production multi-langage permet que\nles m√™mes fichiers sources g√©n√®rent un site web et des notebooks disponibles\nsur plusieurs environnements.\n\n\nname: Production deployment\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  docker:\n    if: \"!contains(github.event.commits[0].message, '[skip ci]')\"\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Set up QEMU\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        uses: docker/setup-qemu-action@v1\n      -\n        name: Set up Docker Buildx\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        uses: docker/setup-buildx-action@v1\n      -\n        name: Login to DockerHub\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        uses: docker/login-action@v1 \n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        id: docker_build\n        uses: docker/build-push-action@v2\n        env:\n          GITHUB_PAT: ${{ secrets.PAT }}\n        with:\n          file: \"docker/Dockerfile\"\n          push: true\n          tags: linogaliana/python-datascientist:latest\n      -\n        name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}  \n  pages:\n    name: Render-Blog\n    runs-on: ubuntu-latest\n    container: linogaliana/python-datascientist:latest\n    needs: docker\n    if: ${{ !github.event.pull_request.head.repo.fork }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n          ref: ${{ github.event.pull_request.head.ref }}\n          repository: ${{github.event.pull_request.head.repo.full_name}}\n      - name: Configure safe.directory  # Workaround for actions/checkout#760\n        run: git config --global --add safe.directory /__w/python-datascientist/python-datascientist\n      - name: Render website\n        run: |\n          rm -f _quarto.yml\n          cp _quarto-prod.yml _quarto.yml\n          python build/append_environment.py\n          quarto render --to html\n      - name: Publish to Pages\n        if: github.ref == 'refs/heads/master'\n        run: |\n          git config --global user.email quarto-github-actions-publish@example.com\n          git config --global user.name \"Quarto GHA Workflow Runner\"\n          quarto publish gh-pages . --no-render --no-browser\n  enonces:\n    name: Render notebooks\n    runs-on: ubuntu-latest\n    container: linogaliana/python-datascientist:latest\n    needs: docker\n    if: ${{ !github.event.pull_request.head.repo.fork }}    \n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n          ref: ${{ github.event.pull_request.head.ref }}\n      - name: Configure safe.directory  # Workaround for actions/checkout#760\n        run: |\n          git config --global --add safe.directory /__w/python-datascientist/python-datascientist\n          git config --global --add safe.directory /__w/python-datascientist/python-datascientist-notebooks\n      - shell: bash\n        run: |\n          ls\n          conda info\n          conda list\n      - name: Convert in ipynb with Quarto\n        run: |\n         rm -f _quarto.yml\n         cp _quarto-prod.yml _quarto.yml\n         find content -type f -name \"*.qmd\" &gt;&gt; diff\n         cat diff\n         python build/tweak_render.py\n         python build/pimp_notebook.py\n         quarto render content --to ipynb\n         mkdir -p temp_notebooks\n         mkdir -p temp_notebooks/notebooks\n         python build/move_files.py temp_notebooks/notebooks\n         quarto render content --to ipynb --execute -M echo:true\n         mkdir -p temp_notebooks/corrections\n         python build/move_files.py temp_notebooks/corrections\n      - uses: actions/upload-artifact@v2\n        with:\n          name: Source enonce\n          path: content/\n      - uses: actions/upload-artifact@v2\n        with:\n          name: Enonces\n          path: temp_notebooks/notebooks/\n      - uses: actions/upload-artifact@v2\n        with:\n          name: Enonces\n          path: temp_notebooks/corrections/\n      - name: Pushes to another repository\n        uses: linogaliana/github-action-push-to-another-repository@main\n        env:\n          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}\n        with:\n          source-directory: 'temp_notebooks/'\n          destination-repository-username: 'linogaliana'\n          destination-repository-name: 'python-datascientist-notebooks'\n          user-email: lino.galiana@insee.fr\n          destination-github-username: linogaliana\n          #target-branch: test\n          create-target-branch-if-needed: true\n          reset-repo: true\n\n\n\nLes couches qui constituent les √©tapes du pipeline\nportent ainsi le nom de steps. Un step peut comporter un certain\nnombre d‚Äôinstructions ou ex√©cuter des instructions pr√©-d√©finies.\nL‚Äôune de ces instructions pr√©d√©finies est, par exemple,\nl‚Äôinstallation de Python\nou l‚Äôinitialisation d‚Äôun environnement conda.\nLa documentation officielle de Github propose un\nfichier qui peut servir de mod√®le\npour tester un script Python voire l‚Äôuploader de mani√®re automatique\nsur Pypi.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#int√©gration-continue-avec-python-tester-un-notebook",
    "href": "content/modern-ds/continuous_integration.html#int√©gration-continue-avec-python-tester-un-notebook",
    "title": "Int√©gration continue avec Python",
    "section": "3.2 Int√©gration continue avec Python: tester un notebook",
    "text": "3.2 Int√©gration continue avec Python: tester un notebook\nCette section n‚Äôest absolument pas exhaustive. Au contraire, elle ne fournit\nqu‚Äôun exemple minimal pour expliquer la logique de l‚Äôint√©gration continue. Il\nne s‚Äôagit ainsi pas d‚Äôune garantie absolue de reproductibilit√© d‚Äôun notebook.\nGithub propose une action officielle pour utiliser Python dans un\npipeline d‚Äôint√©gration continue. Elle est disponible sur le\nMarketPlace Github.\nIl s‚Äôagit d‚Äôun bon point de d√©part, √† enrichir.\nLe fichier qui contr√¥le les instructions ex√©cut√©es dans l‚Äôenvironnement Actions\ndoit se trouver dans le dossier .github/workflows/\n(:warning: ne pas oublier le point au d√©but du\nnom du dossier). Il doit √™tre au format YAML avec une extension .yml\nou .yaml.\nIl peut avoir n‚Äôimporte quel nom n√©anmoins il\nvaut mieux lui donner un nom signifiant,\npar exemple prod.yml pour un fichier contr√¥lant une cha√Æne de production.\n\n3.2.1 Lister les d√©pendances\nAvant d‚Äô√©crire les instructions √† ex√©cuter par Github, il faut d√©finir un\nenvironnement d‚Äôex√©cution car Github ne conna√Æt pas la configuration Python\ndont vous avez besoin.\nIl convient ainsi de lister les d√©pendances n√©cessaires dans un fichier\nrequirements.txt (si on utilise un environnement virtuel)\nou un fichier environment.yml (si on pr√©f√®re\nutiliser un environnement conda).\nBien que le principe sous-jacent soit l√©g√®rement diff√©rent,\nces fichiers ont la m√™me fonction :\npermettre la cr√©ation d‚Äôun environnement ex-nihilo\navec un certain nombre de d√©pendances pr√©-install√©es3.\nSi on fait le choix de l‚Äôoption environment.yml,\nle fichier prendra ainsi la forme\nsuivante, √† enrichir en fonction de la\nrichesse de l‚Äôenvironnement souhait√©. :\nchannels:\n  - conda-forge\n\ndependencies:\n  - python&gt;=3.10\n  - jupyter\n  - jupytext\n  - matplotlib\n  - nbconvert\n  - numpy\n  - pandas\n  - scipy\n  - seaborn\nLe m√™me fichier sous le format requirements.txt aura\nla forme suivante :\njupyter\njupytext\nmatplotlib\nnbconvert\nnumpy\npandas\nscipy\nseaborn\nSous leur apparente √©quivalence, au-del√† de\nla question du formatage, ces fichiers ont\ndeux diff√©rences principales :\n\nla version minimale de Python est d√©finie dans\nle fichier environment.yml alors qu‚Äôelle ne l‚Äôest\npas dans un fichier requirements.txt. C‚Äôest\nparce que le second installe les d√©pendances dans\nun environnement d√©j√† existant par ailleurs alors\nque le premier peut servir √† cr√©er l‚Äôenvironnement\navec une certaine configuration de Python ;\nle mode d‚Äôinstallation des packages n‚Äôest pas le\nm√™me. Avec un environment.yml on installera des\npackages via conda alors qu‚Äôavec un requirements.txt\non privil√©giera plut√¥t pip4.\n\nDans le cas de l‚Äôenvironnement conda,\nle choix du channel conda-forge vise √† contr√¥ler le d√©p√¥t utilis√© par\nAnaconda.\n\n\n Hint\nLa conda forge est un d√©p√¥t de package alternatif\nau canal par d√©faut d‚ÄôAnaconda qui est maintenu par\nl‚Äô√©quipe de d√©veloppeurs officiels d‚ÄôAnaconda.\nComme cette derni√®re cherche en priorit√© √†\nassurer la stabilit√© de l‚Äô√©cosyst√®me Anaconda,\nles versions de package √©voluent moins vite\nque le rythme voulu par les d√©veloppeurs de\npackages. Pour cette raison, un d√©p√¥t\nalternatif, o√π les mont√©es de version sont\nplus simples parce qu‚Äôelles d√©pendent des\nd√©veloppeurs de chaque package, a √©merg√©.\nIl s‚Äôagit de la conda forge. Lorsqu‚Äôon\nd√©sire utiliser des fonctionalit√©s r√©centes\nde l‚Äô√©cosyst√®me de la data science,\nil est conseill√© de l‚Äôutiliser.\n\n\nNe pas oublier de mettre ce fichier sous contr√¥le de version et de l‚Äôenvoyer\nsur le d√©p√¥t par un push.\n\n\n3.2.2 Cr√©er un environnement reproductible dans Github Actions\nDeux approches sont possibles √† ce niveau, selon le degr√©\nde reproductibilit√© d√©sir√©5:\n\nCr√©er l‚Äôenvironnement via une action existante. L‚Äôaction\nconda-incubator/setup-miniconda@v2\nest un bon point de d√©part.\nCr√©er l‚Äôenvironnement dans une image Docker.\n\nLa deuxi√®me solution permet de contr√¥ler de mani√®re\nbeaucoup plus fine l‚Äôenvironnement dans lequel\nPython s‚Äô√©x√©cutera ainsi que la mani√®re dont\nl‚Äôenvironnement sera cr√©√©6. N√©anmoins, elle n√©cessite\ndes connaissances plus pouss√©es dans la principe\nde la conteneurisation qui peuvent √™tre co√ªteuses\n√† acqu√©rir. Selon l‚Äôambition du projet, notamment\nles r√©utilisation qu‚Äôil d√©sire,\nun data scientist pourra privil√©gier\ntelle ou telle option. Les deux solutions sont pr√©sent√©es\ndans l‚Äôexemple fil-rouge du cours que nous\ndonnons avec Romain Avouac\n(https://ensae-reproductibilite.github.io/website/application/).\n\n\n3.2.3 Tester un notebook myfile.ipynb\nDans cette partie, on va supposer que le notebook √† tester s‚Äôappelle myfile.ipynb\net se trouve √† la racine du d√©p√¥t. Les\nd√©pendances pour l‚Äôex√©cuter sont\nlist√©es dans un fichier requirements.txt.\nLe mod√®le suivant, expliqu√© en dessous, fournit un mod√®le de recette pour\ntester un notebook. Supposons que ce fichier soit pr√©sent\ndans un chemin .github/workflows/test-notebook.yml\n\n\nEnvironnement virtuel\n\nname: Test notebook execution using Github Actions\n\non: [push]\n\njobs:\n  build-linux:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Python 3.10\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.10'\n      - shell: bash\n      run: |\n        python --version\n    - name: Install dependencies\n      run:\n        pip install -r requirements.txt\n        pip install jupyter nbconvert\n    - name: Test jupyter from command line\n      run:\n        jupyter nbconvert --execute --to notebook --inplace myfile.ipynb\n    - uses: actions/upload-artifact@v3\n      with:\n        name: Notebook\n        path: myfile.ipynb\n        retention-days: 5\n\n\n\nEnvironnement conda\n\nname: Test notebook execution using Github Actions\n\non: [push]\n\njobs:\n  build-linux:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Python 3.10\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.10'\n    - name: Add conda to system path\n      run: |\n        # $CONDA is an environment variable pointing to the root of the miniconda directory\n        echo $CONDA/bin &gt;&gt; $GITHUB_PATH\n    - name: Install dependencies\n      run: |\n        conda env update --file environment.yml --name base\n        conda install jupyter nbconvert\n    - name: Test jupyter from command line\n      run:\n        jupyter nbconvert --execute --to notebook --inplace myfile.ipynb\n    - uses: actions/upload-artifact@v3\n      with:\n        name: Notebook\n        path: myfile.ipynb\n        retention-days: 5\n\nDans les deux cas, la d√©marche est la m√™me:\n\non r√©cup√®re les fichiers pr√©sents dans le d√©p√¥t\n(action checkout) ;\non installe Python ;\non installe les d√©pendances pour ex√©cuter le code.\nDans l‚Äôapproche conda, il est √©galement n√©cessaire\nde faire quelques configurations suppl√©mentaires (notamment\najouter conda aux logiciels reconnus par la ligne\nde commande) ;\non teste le notebook en ligne de commande et remplace\ncelui existant, sur la machine temporaire, par la version\nproduite sur cet environnement neutre.\non rend possible le t√©l√©chargement du\nnotebook produit automatiquement pendant 5 jours7. Ceci\nrepose sur les artefacts qui sont un √©l√©ment r√©cup√©r√©\ndes machines temporaires qui n‚Äôexistent plus d√®s que le\ncode a fini d‚Äô√™tre ex√©cut√©.\n\nCes actions sont ex√©cut√©es √† chaque interaction avec\nle d√©p√¥t distant (push), quelle que soit la\nbranche. A partir de ce mod√®le, il est possible de\nraffiner pour, par exemple, automatiquement\nfaire un commit du notebook valid√© et le pusher\nvia le robot Github8",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#les-services-de-mise-√†-disposition-de-github-et-gitlab",
    "href": "content/modern-ds/continuous_integration.html#les-services-de-mise-√†-disposition-de-github-et-gitlab",
    "title": "Int√©gration continue avec Python",
    "section": "4.1 Les services de mise √† disposition de Github et Gitlab",
    "text": "4.1 Les services de mise √† disposition de Github et Gitlab\nGithub et Gitlab, les deux plateformes de partage\nde code, proposent non seulement des services\ngratuits d‚Äôint√©gration continue mais aussi des services\nde mise √† disposition de sites web pleinement int√©gr√©s\naux services de stockage de code.\nCes services, Gitlab Pages et Github Pages, auxquels\non peut associer le service externe Netlify qui r√©pond\nau m√™me principe9 permettent, √† chaque modification\ndu code source d‚Äôun projet, de reconstruire le site web (le livrable)\nqui peut √™tre directement produit √† partir de certains fichiers\n(des slides revealJS par exemple) ou qui\nsert d‚Äôoutput √† l‚Äôint√©gration continue apr√®s compilation\nde fichiers plus complexes (des fichiers quarto par exemple).\nChaque d√©p√¥t sur Github ou Gitlab peut ainsi √™tre associ√©\n√† un URL de d√©ploiement disponible sur internet. A chaque\ncommit sur le d√©p√¥t, le site web qui sert de livrable\nest ainsi mis √† jour. La version d√©ploy√©e √† partir de la\nbranche principale peut ainsi √™tre consid√©r√©e\ncomme la version de production alors que les branches\nsecondaires peuvent servir d‚Äôespace bac √† sable pour\nv√©rifier que des changements dans le code source\nne mettent pas en p√©ril le livrable. Cette m√©thode,\nqui s√©curise la production d‚Äôun livrable sous forme\nde site web, est ainsi particuli√®rement appr√©ciable.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#les-services-externes-disponibles-sans-infrastructure-sp√©ciale",
    "href": "content/modern-ds/continuous_integration.html#les-services-externes-disponibles-sans-infrastructure-sp√©ciale",
    "title": "Int√©gration continue avec Python",
    "section": "4.2 Les services externes disponibles sans infrastructure sp√©ciale",
    "text": "4.2 Les services externes disponibles sans infrastructure sp√©ciale\nPour fonctionner, l‚Äôint√©gration continue\nn√©cessite de mettre en oeuvre des environnements normalis√©s.\nComme √©voqu√© pr√©c√©demment,\nla technologie sous-jacente est celle de la conteneurisation.\nLes images qui servent de point de d√©part au lancement\nd‚Äôun conteneur sont elles-m√™mes mises √† disposition\ndans des espaces communautaires (des registres d‚Äôimages).\nIl en existe plusieurs, les plus connus √©tant\nle dockerhub ou le registry de Gitlab.\nCes registres servent d‚Äôespaces de stockage pour des images,\nqui sont des objets volumineux (potentiellement plusieurs\nGigas) mais aussi d‚Äôespace de mutualisation en permettant\n√† d‚Äôautres de r√©utiliser une image pr√™te √† l‚Äôemploi ou,\nau contraire, √† partir de\nlaquelle on peut ajouter un certain nombre de couches\npour obtenir l‚Äôenvironnement minimal\nde reproductibilit√©.\nIl est possible d‚Äôutiliser certaines actions Github\npr√™te √† l‚Äôemploi pour constuire une image Docker\n√† partir d‚Äôun fichier Dockerfile. Apr√®s avoir\ncr√©e une connexion entre un compte sur la\nplateforme Github et l‚Äôautre sur DockerHub,\nune mise √† disposition automatis√©e d‚Äôun livrable\nsous forme d‚Äôimage Docker est ainsi possible.\nUne image Docker peut offrir une grande vari√©t√©\nd‚Äôoutput. Elle peut servir uniquement √†\nmettre √† disposition un environnement de\nreproductibilit√© mais elle peut servir √† mettre\n√† disposition, pour les personnes ma√Ætrisant\nDocker, des output plus raffin√©s. Par exemple,\ndans le cours que nous donnons √† l‚ÄôENSAE, nous\nmontrons comment docker peut servir √†\nmettre √† disposition √† un utilisateur tiers\nune application minimaliste (construite avec flask)\nqu‚Äôil fera tourner\nsur son ordinateur.\nSi une image Docker peut √™tre tr√®s utile pour la mise\n√† disposition, elle n√©cessite pour sa r√©utilisation\nun niveau avanc√© d‚Äôexpertise en programmation.\nCela ne conviendra pas √† tous les publics. Certains\nne d√©sireront que b√©n√©ficier d‚Äôune application interactive\no√π ils pourrons visualiser certains r√©sultats en fonction\nd‚Äôactions comme des filtres sur des sous-champs ou le choix\nde certaines plages de donn√©es. D‚Äôautres publics seront\nplut√¥t int√©ress√© par la r√©utilisation d‚Äôun programme\nou des r√©sultats d‚Äôun mod√®le sous forme d‚ÄôAPI mais n‚Äôauront\npas l‚Äôinfrastructure interne pour faire tourner le code\nd‚Äôorigine ou une image Docker. C‚Äôest pour r√©pondre √† ces\nlimites qu‚Äôil peut devenir int√©ressant, pour une √©quipe\nde data science de d√©velopper une architecture\nkubernetes interne, si l‚Äôorganisation en a les moyens, ou\nde payer un fournisseur de service, comme AWS, qui permet\ncela.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#kubernetes-le-sommet-de-la-pente-du-d√©ploiement",
    "href": "content/modern-ds/continuous_integration.html#kubernetes-le-sommet-de-la-pente-du-d√©ploiement",
    "title": "Int√©gration continue avec Python",
    "section": "4.3 Kubernetes: le sommet de la pente du d√©ploiement",
    "text": "4.3 Kubernetes: le sommet de la pente du d√©ploiement\nKubernetes est une technologie qui pousse la logique\nde la conteneurisation √† son paroxysme.\nIl s‚Äôagit d‚Äôun syst√®me open-source, d√©velopp√©\npar Google, permettant\nd‚Äôautomatiser le d√©ploiement, la mise √† l‚Äô√©chelle\net la gestion d‚Äôapplications conteneuris√©es.\nGr√¢ce √† Kubernetes, une application, par exemple\nun site web proposant de la r√©activit√©,\npeut √™tre mise √† disposition et reporter les calculs,\nlorsqu‚Äôils sont n√©cessaires, sur\nun serveur. L‚Äôutilisation de Kubernetes dans\nun projet de data science permet ainsi\nd‚Äôanticiper √† la fois l‚Äôinterface d‚Äôune application\nvalorisant un projet mais aussi le fonctionnement\ndu back-office, par exemple en testant la capacit√©\nde charge de cette application. Une introduction\n√† Kubernetes orient√© donn√©e peut √™tre trouv√©e dans\nle cours d√©di√© √† la mise en production\nque nous donnons avec Romain Avouac et dans ce\npost de blog tr√®s bien fait.\nDans les grandes organisations, o√π les r√¥les sont\nplus sp√©cialis√©s que dans les petites structures,\nce ne sont pas n√©cessairement les data scientists\nqui devront ma√Ætriser Kubernetes mais plut√¥t\nles data-architect ou les data-engineer. N√©anmoins,\nles data scientists devront √™tre capable de\ndialoguer avec eux et mettre en oeuvre une m√©thode\nde travail adapt√©e (celle-ci reposera en principe sur\nl‚Äôapproche CI/CD). Dans les petites structures, les\ndata scientist peuvent √™tre en mesure\nde mettre en oeuvre le d√©ploiement en continu. En\nrevanche, il est plus rare, dans ces structures,\no√π les moyens humains de maintenance sont limit√©s,\nque les serveurs sur lesquels fonctionnent Kubernetes\nsoient d√©tenus en propres. En g√©n√©ral, ils sont lou√©s\ndans des services de paiement √† la demande de type\nAWS.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#informations-additionnelles",
    "href": "content/modern-ds/continuous_integration.html#informations-additionnelles",
    "title": "Int√©gration continue avec Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n7adbea4\n\n\n2023-06-12 11:25:40\n\n\nLino Galiana\n\n\nUpdate CI elements\n\n\n\n\n23cd4a1\n\n\n2022-07-05 10:31:03\n\n\nLino Galiana\n\n\nPr√©cisions suppl√©mentaires dans la partie CI/CD (#246)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#footnotes",
    "href": "content/modern-ds/continuous_integration.html#footnotes",
    "title": "Int√©gration continue avec Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCes services d‚Äôint√©gration continue √©taient utilis√©s lorsque Github\nne proposait pas encore de service int√©gr√©, comme le faisait Gitlab.\nIls sont de moins en moins fr√©quemment utilis√©s.‚Ü©Ô∏é\nPour r√©duire le temps n√©cessaire pour construire le site web, ce\npipeline s‚Äôappuie sur un environnement Docker construit sur un autre d√©p√¥t\ndisponible √©galement sur Github\n.\nCelui-ci part d‚Äôune configuration syst√®me Linux et construit un environnement\nAnaconda √† partir d‚Äôun fichier environment.yml qui liste toutes les d√©pendances\nn√©cessaires pour ex√©cuter les morceaux de code du site web.\nCet environnement Anaconda est construit gr√¢ce √† l‚Äôoutil mamba qui permet\nd‚Äôaller beaucoup plus vite dans la constitution d‚Äôenvironnements que ne le\npermet conda.‚Ü©Ô∏é\nSur la diff√©rence entre les environnements virtuels\net les environnements conda, voir\ncette partie de cours\nplus avanc√© que nous donnons\navec Romain Avouac sur la mise en production\nde projets data science.‚Ü©Ô∏é\nIl est possible d‚Äôinstaller une partie des packages\navec pip en d√©finissant un champ pip dans le\nfichier environment.yml. N√©anmoins, les concepteurs\nd‚ÄôAnaconda recommandent d‚Äô√™tre prudent avec cette m√©thode\nqui pr√©sente certes l‚Äôavantage d‚Äôacc√©l√©rer le temps de\ncr√©ation de l‚Äôenvironnement mais peut cr√©er des\ndifficult√©s avec des librairies n√©cessitant d‚Äôautres\nlangages syst√®me comme le C.‚Ü©Ô∏é\nLe point de vue que nous d√©fendons avec\nRomain Avouac dans notre cours sur la reproductibilit√©\nest qu‚Äôil s‚Äôagit d‚Äôun continuum dans lequel on investit\nplus ou moins en fonction de ses contraintes, de ses\nbesoins, de ses comp√©tences, du temps humain qu‚Äôon\npeut d√©dier √† d√©velopper des output reproductibles\net le temps gagn√© en d√©veloppant une telle approche.\nSelon o√π on se trouve sur ce cursus, en fonction\ndes solutions d√©j√† existantes qu‚Äôon peut trouver\nsur internet, on va plus ou moins raffiner\nnotre int√©gration et nos d√©ploiements\ncontinus.‚Ü©Ô∏é\nIl est recommand√© de ne pas garder la p√©riode de r√©tention\ndes artefacts par d√©faut car celle-ci est assez longue (90 jours).\nLes output pouvant √™tre assez volumineux et expirant rapidement\n(en g√©n√©ral ce qui nous int√©resse est la derni√®re ou l‚Äôavant\nderni√®re version de l‚Äô_output), pour des raisons √©cologiques,\nil est recommand√© de fixer des p√©riodes courtes. Cela peut √™tre\nfait directement dans le fichier configurant l‚Äôint√©gration\ncontinue comme ici ou dans les param√®tres par d√©faut\ndu d√©p√¥t pour que cette r√®gle s‚Äôapplique √† toutes les\nproductions faites par int√©gration continue.‚Ü©Ô∏é\nIl est recommand√© de ne pas garder la p√©riode de r√©tention\ndes artefacts par d√©faut car celle-ci est assez longue (90 jours).\nLes output pouvant √™tre assez volumineux et expirant rapidement\n(en g√©n√©ral ce qui nous int√©resse est la derni√®re ou l‚Äôavant\nderni√®re version de l‚Äô_output), pour des raisons √©cologiques,\nil est recommand√© de fixer des p√©riodes courtes. Cela peut √™tre\nfait directement dans le fichier configurant l‚Äôint√©gration\ncontinue comme ici ou dans les param√®tres par d√©faut\ndu d√©p√¥t pour que cette r√®gle s‚Äôapplique √† toutes les\nproductions faites par int√©gration continue.‚Ü©Ô∏é\nIl s‚Äôagit du service utilis√©, par exemple,\npour ce cours. Netlify est un service de mise √† disposition\nqui offre des fonctionalit√©s plus compl√®tes que celles\npermises par Gitlab Pages et Github Pages. Outre cet\navantage, il est plus facile √† configurer que Github Pages\nqui n√©cessite l‚Äôusage d‚Äôune branche d√©di√©e nomm√©e gh-pages,\nce qui peut\nrebutant.‚Ü©Ô∏é\nIl s‚Äôagit du service utilis√©, par exemple,\npour ce cours. Netlify est un service de mise √† disposition\nqui offre des fonctionalit√©s plus compl√®tes que celles\npermises par Gitlab Pages et Github Pages. Outre cet\navantage, il est plus facile √† configurer que Github Pages\nqui n√©cessite l‚Äôusage d‚Äôune branche d√©di√©e nomm√©e gh-pages,\nce qui peut\nrebutant.‚Ü©Ô∏é",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html",
    "href": "content/modern-ds/s3.html",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre est une introduction √† la question\ndu stockage des donn√©es et aux innovations\nr√©centes dans ce domaine. L‚Äôobjectif\nest d‚Äôabord de pr√©senter les avantages\ndu format Parquet et la mani√®re dont\non peut utiliser les\nlibrairies pyarrow\nou duckdb pour traiter\nde mani√®re efficace des donn√©es volumineuses\nau format Parquet. Ensuite, on pr√©sentera\nla mani√®re dont ce format parquet s‚Äôint√®gre\nbien avec des syst√®mes de stockage cloud,\nqui tendent √† devenir la norme dans le monde\nde la data science.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#principe-du-stockage-de-la-donn√©e",
    "href": "content/modern-ds/s3.html#principe-du-stockage-de-la-donn√©e",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "1.1 Principe du stockage de la donn√©e",
    "text": "1.1 Principe du stockage de la donn√©e\nPour comprendre les apports du format Parquet, il est n√©cessaire\nde faire un d√©tour pour comprendre la mani√®re dont une information\nest stock√©e et accessible √† un langage de traitement de la donn√©e.\nIl existe deux approches dans le monde du stockage de la donn√©e.\nLa premi√®re est celle de la base de donn√©es relationnelle. La seconde est le\nprincipe du fichier.\nLa diff√©rence entre les deux est dans la mani√®re dont l‚Äôacc√®s aux\ndonn√©es est organis√©.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#les-fichiers",
    "href": "content/modern-ds/s3.html#les-fichiers",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "1.2 Les fichiers",
    "text": "1.2 Les fichiers\nDans un fichier, les donn√©es sont organis√©es selon un certain format et\nle logiciel de traitement de la donn√©e va aller chercher et structurer\nl‚Äôinformation en fonction de ce format. Par exemple, dans un fichier\n.csv, les diff√©rentes informations seront stock√©es au m√™me niveau\navec un caract√®re pour les s√©parer (la virgule , dans les .csv anglosaxons, le point virgule dans les .csv fran√ßais, la tabulation dans les .tsv). Le fichier suivant\nnom ; profession \nAst√©rix ; \nOb√©lix ; Tailleur de menhir ;\nAssurancetourix ; Barde\nsera ainsi organis√© naturellement sous forme tabul√©e par Python\n\n\n\n\n\n\n\n\n\n\nnom\nprofession\n\n\n\n\n0\nAst√©rix\n\n\n\n1\nOb√©lix\nTailleur de menhir\n\n\n2\nAssurancetourix\nBarde\n\n\n\n\n\n\n\n\nA propos des fichiers de ce type, on parle de fichiers plats car\nles enregistrements relatifs √† une observation sont stock√©s ensemble,\nsans hi√©rarchie.\nCertains formats de donn√©es vont permettre d‚Äôorganiser les informations\nde mani√®re diff√©rente. Par exemple, le format JSON va\nhi√©rarchiser diff√©remment la m√™me information [^1]:\n[\n  {\n    \"nom\": \"Ast√©rix\"\n  },\n  {\n    \"nom\": \"Ob√©lix\",\n    \"profession\": \"Tailleur de menhir\"\n  },\n  {\n    \"nom\": \"Assurancetourix\",\n    \"profession\": \"Barde\"\n  }\n]\n\n\n Hint \nLa diff√©rence entre le CSV et le format JSON va au-del√† d‚Äôun simple ‚Äúformattage‚Äù des donn√©es.\nPar sa nature non tabulaire, le format JSON permet des mises √† jour beaucoup plus facile de la donn√©e dans les entrep√¥ts de donn√©es.\nPar exemple, un site web qui collecte de nouvelles donn√©es n‚Äôaura pas √† mettre √† jour l‚Äôensemble de ses enregistrements ant√©rieurs\npour stocker la nouvelle donn√©e (par exemple pour indiquer que pour tel ou tel client cette donn√©e n‚Äôa pas √©t√© collect√©e)\nmais pourra la stocker dans\nun nouvel item. Ce sera √† l‚Äôoutil de requ√™te (Python ou un autre outil)\nde cr√©er une relation entre les enregistrements stock√©s √† des endroits\ndiff√©rents.\nCe type d‚Äôapproche flexible est l‚Äôun des fondements de l‚Äôapproche NoSQL,\nsur laquelle nous allons revenir, qui a permis l‚Äô√©mergence de technologies au coeur de l‚Äô√©cosyst√®me actuel du big-data comme Hadoop ou ElasticSearch.\n\n\nCette fois, quand on n‚Äôa pas d‚Äôinformation, on ne se retrouve pas avec nos deux s√©parateurs accol√©s (cf.¬†la ligne ‚ÄúAst√©rix‚Äù) mais l‚Äôinformation\nn‚Äôest tout simplement pas collect√©e.\n\n\n Note\nIl se peut tr√®s bien que l‚Äôinformation sur une observation soit diss√©min√©e\ndans plusieurs fichiers dont les formats diff√®rent.\nPar exemple, dans le domaine des donn√©es g√©ographiques,\nlorsqu‚Äôune donn√©e est disponible sous format de fichier(s), elle peut l‚Äô√™tre de deux mani√®res!\n\nSoit la donn√©e est stock√©e dans un seul fichier qui m√©lange contours g√©ographiques et valeurs attributaires\n(la valeur associ√©e √† cette observation g√©ographique, par exemple le taux d‚Äôabstention). Ce principe est celui du geojson.\nSoit la donn√©e est stock√©e dans plusieurs fichiers qui sont sp√©cialis√©s : un fichier va stocker les contours g√©ographiques,\nl‚Äôautre les donn√©es attributaires et d‚Äôautres fichiers des informations annexes (comme le syst√®me de projection). Ce principe est celui du shapefile.\nC‚Äôest alors le logiciel qui requ√™te\nles donn√©es (Python par exemple) qui saura o√π aller chercher l‚Äôinformation\ndans les diff√©rents fichiers et associer celle-ci de mani√®re coh√©rente.\n\n\n\nUn concept suppl√©mentaire dans le monde du fichier est celui du file system. Le file system est\nle syst√®me de localisation et de nommage des fichiers.\nPour simplifier, le file system est la mani√®re dont votre ordinateur saura\nretrouver, dans son syst√®me de stockage, les bits pr√©sents dans tel ou tel fichier\nappartenant √† tel ou tel dossier.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#les-bases-de-donn√©es",
    "href": "content/modern-ds/s3.html#les-bases-de-donn√©es",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "1.3 Les bases de donn√©es",
    "text": "1.3 Les bases de donn√©es\nLa logique des bases de donn√©es est diff√©rente. Elle est plus syst√©mique.\nUn syst√®me de gestion de base de donn√©es (Database Management System)\nest un logiciel qui g√®re √† la fois le stockage d‚Äôun ensemble de donn√©es reli√©e,\npermet de mettre √† jour celle-ci (ajout ou suppression d‚Äôinformations, modification\ndes caract√©ristiques d‚Äôune table‚Ä¶)\net qui g√®re √©galement\nles modalit√©s d‚Äôacc√®s √† la donn√©e (type de requ√™te, utilisateurs\nayant les droits en lecture ou en √©criture‚Ä¶).\nLa relation entre les entit√©s pr√©sentes dans une base de donn√©es\nprend g√©n√©ralement la forme d‚Äôun sch√©ma en √©toile. Une base va centraliser\nles informations disponibles qui seront ensuite d√©taill√©es dans des tables\nd√©di√©es.\n\nSource: La documentation Databricks sur le sch√©ma en √©toile\nLe logiciel associ√© √† la base de donn√©es fera ensuite le lien\nentre ces tables √† partir de requ√™tes SQL. L‚Äôun des logiciels les plus efficaces dans ce domaine\nest PostgreSQL. Python est tout √† fait\nutilisable pour passer une requ√™te SQL √† un gestionnaire de base de donn√©es.\nLes packages sqlalchemy et psycopg2\npeuvent servir √† utiliser PostgreSQL pour requ√™ter une\nbase de donn√©e ou la mettre √† jour.\nLa logique de la base de donn√©es est donc tr√®s diff√©rente de celle du fichier.\nCes derniers sont beaucoup plus l√©gers pour plusieurs raisons.\nD‚Äôabord, parce qu‚Äôils sont moins adh√©rents √†\nun logiciel gestionnaire. L√† o√π le fichier ne n√©cessite, pour la gestion,\nqu‚Äôun file system, install√© par d√©faut sur\ntout syst√®me d‚Äôexploitation, une base de donn√©es va n√©cessiter un\nlogiciel sp√©cialis√©. L‚Äôinconv√©nient de l‚Äôapproche fichier, sous sa forme\nstandard, est qu‚Äôelle\nne permet pas une gestion fine des droits d‚Äôacc√®s et am√®ne g√©n√©ralement √† une\nduplication de la donn√©e pour √©viter que la source initiale soit\nr√©-√©crite (involontairement ou de mani√®re intentionnelle par un utilisateur malveillant).\nR√©soudre ce probl√®me est l‚Äôune des\ninnovations des syst√®mes cloud, sur lesquelles nous reviendrons en √©voquant le\nsyst√®me S3.\nUn deuxi√®me inconv√©nient de l‚Äôapproche base de donn√©es par\nrapport √† l‚Äôapproche fichier, pour un utilisateur de Python,\nest que les premiers n√©cessitent l‚Äôinterm√©diation du logiciel de gestion\nde base de donn√©es l√† o√π, dans le second cas, on va se contenter d‚Äôune\nlibrairie, donc un syst√®me beaucoup plus l√©ger,\nqui sait comment transformer la donn√©e brute en DataFrame.\nPour ces raisons, entre autres, les bases de donn√©es sont donc moins √† la\nmode dans l‚Äô√©cosyst√®me r√©cent de la data science que les fichiers.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#lire-un-parquet-en-python-la-librairie-pyarrow",
    "href": "content/modern-ds/s3.html#lire-un-parquet-en-python-la-librairie-pyarrow",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "2.1 Lire un parquet en Python: la librairie pyarrow",
    "text": "2.1 Lire un parquet en Python: la librairie pyarrow\nLa librairie pyarrow permet la lecture et l‚Äô√©criture\nde fichiers parquet avec Python1. Elle repose\nsur un type particulier de dataframe, le pyarrow.Table\nqui peut √™tre utilis√© en substitut ou en compl√©ment\ndu DataFrame\nde pandas. Il est recommand√© de r√©guli√®rement\nconsulter la documentation officielle de pyarrow\nconcernant la lecture et √©criture de fichiers et celle relative\naux manipulations de donn√©es.\nPour illustrer les fonctionalit√©s de pyarrow,\nrepartons de notre CSV initial que nous allons\nenrichir d‚Äôune nouvelle variable num√©rique\net que nous\nallons\nconvertir en objet pyarrow avant de l‚Äô√©crire au format parquet:\n\nimport pandas as pd\nfrom io import StringIO\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\ns = \"\"\"\nnom;cheveux;profession\nAst√©rix;blond;\nOb√©lix;roux;Tailleur de menhir\nAssurancetourix;blond;Barde\n\"\"\"\n\nsource = StringIO(s)\n\ndf = pd.read_csv(source, sep=\";\", index_col=False)\ndf[\"taille\"] = [155, 190, 175]\ntable = pa.Table.from_pandas(df)\n\ntable\n\npq.write_table(table, \"example.parquet\")\n\n\n\n Hint \nL‚Äôutilisation des noms pa pour pyarrow et pq pour\npyarrow.parquet est une convention communautaire\nqu‚Äôil est recommand√© de suivre.\n\n\nPour importer et traiter ces donn√©es, on peut conserver\nles donn√©es sous le format pyarrow.Table\nou transformer en pandas.DataFrame. La deuxi√®me\noption est plus lente mais pr√©sente l‚Äôavantage\nde permettre ensuite d‚Äôappliquer toutes les\nmanipulations offertes par l‚Äô√©cosyst√®me\npandas qui est g√©n√©ralement mieux connu que\ncelui d‚ÄôArrow.\nSupposons qu‚Äôon ne s‚Äôint√©resse qu‚Äô√† la taille et √† la couleur\nde cheveux de nos gaulois.\nIl n‚Äôest pas n√©cessaire d‚Äôimporter l‚Äôensemble de la base, cela\nferait perdre du temps pour rien. On appelle\ncette approche le column pruning qui consiste √†\nne parcourir, dans le fichier, que les colonnes qui nous\nint√©ressent. Du fait du stockage orient√© colonne du parquet,\nil suffit de ne consid√©rer que les blocs qui nous\nint√©ressent (alors qu‚Äôavec un CSV il faudrait scanner tout\nle fichier avant de pouvoir √©liminer certaines colonnes).\nCe principe du column pruning se mat√©rialise avec\nl‚Äôargument columns dans parquet.\nEnsuite, avec pyarrow, on pourra utiliser pyarrow.compute pour\neffectuer des op√©rations directement sur une table\nArrow :\n\nimport pyarrow.compute as pc\n\ntable = pq.read_table(\"example.parquet\", columns=[\"taille\", \"cheveux\"])\n\ntable.group_by(\"cheveux\").aggregate([(\"taille\", \"mean\")])\n\nLa mani√®re √©quivalente de proc√©der en passant\npar l‚Äôinterm√©diaire de pandas est\n\ntable = pq.read_table(\"example.parquet\", columns=[\"taille\", \"cheveux\"])\n\ntable.to_pandas().groupby(\"cheveux\")[\"taille\"].mean()\n\ncheveux\nblond    165.0\nroux     190.0\nName: taille, dtype: float64\n\n\nIci, comme les donn√©es sont peu volumineuses, deux des\navantages du parquet par rapport\nau CSV (donn√©es moins\nvolumineuses et vitesse de l‚Äôimport)\nne s‚Äôappliquent pas vraiment.\n\n\n Note\nUn autre principe d‚Äôoptimisation de la performance qui est\nau coeur de la librairie Arrow est le filter pushdown\n(ou predicate pushdown).\nQuand on ex√©cute un filtre de s√©lection de ligne\njuste apr√®s avoir charg√© un jeu de donn√©es,\nArrow va essayer de le mettre en oeuvre lors de l‚Äô√©tape de lecture\net non apr√®s. Autrement dit, Arrow va modifier le plan\nd‚Äôex√©cution pour pousser le filtre en amont de la s√©quence d‚Äôex√©cution\nafin de ne pas essayer de lire les lignes inutiles.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#quest-ce-que-le-syst√®me-de-stockage-s3",
    "href": "content/modern-ds/s3.html#quest-ce-que-le-syst√®me-de-stockage-s3",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.1 Qu‚Äôest-ce que le syst√®me de stockage S3 ?",
    "text": "4.1 Qu‚Äôest-ce que le syst√®me de stockage S3 ?\nDans les entreprises et administrations,\nun nombre croissant de donn√©es sont\ndisponibles depuis un syst√®me de stockage\nnomm√© S3.\nLe syst√®me S3 (Simple Storage System) est un syst√®me de stockage d√©velopp√©\npar Amazon et qui est maintenant devenu une r√©f√©rence pour le stockage en ligne.\nIl s‚Äôagit d‚Äôune architecture √† la fois\ns√©curis√©e (donn√©es crypt√©es, acc√®s restreints) et performante.\nLe concept central du syst√®me S3 est le bucket.\nUn bucket est un espace (priv√© ou partag√©) o√π on peut stocker une\narborescence de fichiers. Pour acc√©der aux fichiers figurant\ndans un bucket priv√©, il faut des jetons d‚Äôacc√®s (l‚Äô√©quivalent d‚Äôun mot de passe)\nreconnus par le serveur de stockage. On peut alors lire et √©crire dans le bucket.\n::: {.cell .markdown}\n\n Note\nLes exemples suivants seront r√©plicables pour les utilisateurs de la plateforme\nSSP Cloud\n\n\nIls peuvent √©galement l‚Äô√™tre pour des utilisateurs ayant un\nacc√®s √† AWS, il suffit de changer l‚ÄôURL du endpoint\npr√©sent√© ci-dessous.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#comment-faire-avec-python",
    "href": "content/modern-ds/s3.html#comment-faire-avec-python",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.2 Comment faire avec Python ?",
    "text": "4.2 Comment faire avec Python ?\n\n4.2.1 Les librairies principales\nL‚Äôinteraction entre ce syst√®me distant de fichiers et une session locale de Python\nest possible gr√¢ce √† des API. Les deux principales librairies sont les suivantes :\n\nboto3, une librairie cr√©√©e et maintenue par Amazon ;\ns3fs, une librairie qui permet d‚Äôinteragir avec les fichiers stock√©s √† l‚Äôinstar d‚Äôun filesystem classique.\n\nLa librairie pyarrow que nous avons d√©j√† pr√©sent√©e permet √©galement\nde traiter des donn√©es stock√©es sur le cloud comme si elles\n√©taient sur le serveur local. C‚Äôest extr√™mement pratique\net permet de fiabiliser la lecture ou l‚Äô√©criture de fichiers\ndans une architecture cloud.\nUn exemple, assez court, est disponible\ndans la documentation officielle\nIl existe √©galement d‚Äôautres librairies permettant de g√©rer\ndes pipelines de donn√©es (chapitre √† venir) de mani√®re\nquasi indiff√©rente entre une architecture locale et une architecture\ncloud. Parmi celles-ci, nous pr√©senterons quelques exemples\navec snakemake.\nEn arri√®re-plan, snakemake\nva utiliser boto3 pour communiquer avec le syst√®me\nde stockage.\nEnfin, selon le m√™me principe du comme si les donn√©es\n√©taient en local, il existe l‚Äôoutil en ligne de commande\nmc (Minio Client) qui permet de g√©rer par des lignes\nde commande Linux les d√©p√¥ts distants comme s‚Äôils √©taient\nlocaux.\nToutes ces librairies offrent la possibilit√© de se connecter depuis Python,\n√† un d√©p√¥t de fichiers distant, de lister les fichiers disponibles dans un\nbucket, d‚Äôen t√©l√©charger un ou plusieurs ou de faire de l‚Äôupload\nNous allons pr√©senter quelques-unes des op√©rations les plus fr√©quentes,\nen mode cheatsheet.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#connexion-√†-un-bucket",
    "href": "content/modern-ds/s3.html#connexion-√†-un-bucket",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.3 Connexion √† un bucket",
    "text": "4.3 Connexion √† un bucket\nPar la suite, on va utiliser des alias pour les trois valeurs suivantes, qui servent\n√† s‚Äôauthentifier.\nkey_id = \"MY_KEY_ID\"\naccess_key = \"MY_ACCESS_KEY\"\ntoken = \"MY_TOKEN\"\nCes valeurs peuvent √™tre √©galement disponibles dans\nles variables d‚Äôenvironnement de Python. Comme il s‚Äôagit d‚Äôune information\nd‚Äôauthentification personnelle, il ne faut pas stocker les vraies valeurs de ces\nvariables dans un projet, sous peine de partager des traits d‚Äôidentit√© sans le\nvouloir lors d‚Äôun partage de code.\n\nboto3 üëá\nAvec boto3, on cr√©√© d‚Äôabord un client puis on ex√©cute des requ√™tes dessus.\nPour initialiser un client, il suffit, en supposant que l‚Äôurl du d√©p√¥t S3 est\n\"https://minio.lab.sspcloud.fr\", de faire:\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\n\n\n\nS3FS üëá\nLa logique est identique avec s3fs.\nSi on a des jetons d‚Äôacc√®s √† jour et dans les variables d‚Äôenvironnement\nad√©quates:\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n\n\n\nArrow üëá\nLa logique d‚ÄôArrow est proche de celle de s3fs. Seuls les noms\nd‚Äôarguments changent\nSi on a des jetons d‚Äôacc√®s √† jour et dans les variables d‚Äôenvironnement\nad√©quates:\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\n\n\nSnakemake üëá\nLa logique de Snakemake est, quant √† elle,\nplus proche de celle de boto3. Seuls les noms\nd‚Äôarguments changent\nSi on a des jetons d‚Äôacc√®s √† jour et dans les variables d‚Äôenvironnement\nad√©quates:\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n\nS3 = S3RemoteProvider(host=\"https://\" + os.getenv(\"AWS_S3_ENDPOINT\"))\n\n\nIl se peut que la connexion √† ce stade soit refus√©e (HTTP error 403).\nCela peut provenir\nd‚Äôune erreur dans l‚ÄôURL utilis√©. Cependant, cela refl√®te plus g√©n√©ralement\ndes param√®tres d‚Äôauthentification erron√©s.\n\nboto3 üëá\nLes param√®tres d‚Äôauthentification sont des arguments suppl√©mentaires:\nimport boto3\n\ns3 = boto3.client(\n    \"s3\",\n    endpoint_url=\"https://minio.lab.sspcloud.fr\",\n    aws_access_key_id=key_id,\n    aws_secret_access_key=access_key,\n    aws_session_token=token,\n)\n\n\n\nS3FS üëá\nLa logique est la m√™me, seuls les noms d‚Äôarguments diff√®rent\nimport s3fs\n\nfs = s3fs.S3FileSystem(\n    client_kwargs={\"endpoint_url\": \"https://\" + \"minio.lab.sspcloud.fr\"},\n    key=key_id,\n    secret=access_key,\n    token=token,\n)\n\n\n\nArrow üëá\nTout est en argument cette fois:\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(\n    access_key=key_id,\n    secret_key=access_key,\n    session_token=token,\n    endpoint_override=\"https://\" + \"minio.lab.sspcloud.fr\",\n    scheme=\"https\",\n)\n\n\n\nSnakemake üëá\nLa logique est la m√™me, seuls les noms d‚Äôarguments diff√®rent\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n\nS3 = S3RemoteProvider(\n    host=\"https://\" + os.getenv(\"AWS_S3_ENDPOINT\"),\n    access_key_id=key_id,\n    secret_access_key=access_key,\n)\n\n\n\n\n Note\nDans le SSP Cloud,\nlorsque l‚Äôinitialisation du service Jupyter du SSP Cloud est r√©cente\n(moins de 12 heures), il est possible d‚Äôutiliser\nautomatiquement les jetons stock√©s automatiquement √† la cr√©ation du d√©p√¥t.\nSi on d√©sire acc√©der aux donn√©es du SSP Cloud depuis une session Python du\ndatalab (service VSCode, Jupyter‚Ä¶),\nil faut remplacer l‚Äôurl par http://minio.lab.sspcloud.fr",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#lister-les-fichiers",
    "href": "content/modern-ds/s3.html#lister-les-fichiers",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.4 Lister les fichiers",
    "text": "4.4 Lister les fichiers\nS‚Äôil n‚Äôy a pas d‚Äôerreur √† ce stade, c‚Äôest que la connexion est bien effective.\nPour le v√©rifier, on peut essayer de faire la liste des fichiers disponibles\ndans un bucket auquel on d√©sire acc√©der.\nPar exemple, on peut vouloir\ntester l‚Äôacc√®s aux bases FILOSOFI (donn√©es de revenu localis√©es disponibles\nsur https://www.insee.fr) au sein du bucket donnees-insee.\n\nboto3 üëá\nPour cela,\nla m√©thode list_objects offre toutes les options n√©cessaires:\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\nfor key in s3.list_objects(Bucket=\"donnees-insee\", Prefix=\"diffusion/FILOSOFI\")[\n    \"Contents\"\n]:\n    print(key[\"Key\"])\n\n\n\nS3FS üëá\nPour lister les fichiers, c‚Äôest la m√©thode ls (celle-ci ne liste pas par\nd√©faut les fichiers de mani√®re r√©cursive comme boto3):\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\nfs.ls(\"donnees-insee/diffusion\")\n\n\n\nArrow üëá\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(endpoint_override=\"https://\" + \"minio.lab.sspcloud.fr\")\ns3.get_file_info(fs.FileSelector(\"donnees-insee/diffusion\", recursive=True))\n\n\n\nmc üëá\nmc ls -r",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#t√©l√©charger-un-fichier-depuis-s3-pour-lenregistrer-en-local",
    "href": "content/modern-ds/s3.html#t√©l√©charger-un-fichier-depuis-s3-pour-lenregistrer-en-local",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.5 T√©l√©charger un fichier depuis S3 pour l‚Äôenregistrer en local",
    "text": "4.5 T√©l√©charger un fichier depuis S3 pour l‚Äôenregistrer en local\nCette m√©thode n‚Äôest en g√©n√©ral pas recommand√©e car, comme on va le voir\npar la suite, il est possible de lire √† la vol√©e des fichiers. Cependant,\nt√©l√©charger un fichier depuis le cloud pour l‚Äô√©crire sur le disque\nlocal peut parfois √™tre utile (par exemple, lorsqu‚Äôil est n√©cessaire\nde d√©zipper un fichier).\n\nboto3 üëá\nOn utilise cette fois la m√©thode download_file\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\ns3.download_file(\n    \"donnees-insee\", \"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\", \"data.csv\"\n)\n\n\n\nS3FS üëá\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\nfs.download(\"donnees-insee/diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\", \"test.csv\")\n\n\n\nSnakemake üëá\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\nS3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\nbucket = \"mon-bucket\"\n\nrule ma_super_regle_s3:\n    input:\n        fichier = S3.remote(f'{bucket}/moninput.csv')\n    output:\n        fichier='mon_dossier_local/monoutput.csv'\n    run:\n        shell(\"cp {input[0]} {output[0]}\")\n\n\n\nmc üëá\nmc cp \"donnees-insee/FILOSOFI/2014/FILOSOFI_COM.csv\" 'data.csv'",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#lire-un-fichier-directement",
    "href": "content/modern-ds/s3.html#lire-un-fichier-directement",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.6 Lire un fichier directement",
    "text": "4.6 Lire un fichier directement\nLa m√©thode pr√©c√©dente n‚Äôest pas optimale. En effet, l‚Äôun des int√©r√™ts des API\nest qu‚Äôon peut traiter un fichier sur S3 comme s‚Äôil s‚Äôagissait d‚Äôun fichier\nsur son PC. Cela est d‚Äôailleurs une mani√®re plus s√©curis√©e de proc√©der puisqu‚Äôon\nlit les donn√©es √† la vol√©e, sans les √©crire dans un filesystem local.\n\nboto3 üëá\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\nobj = s3.get_object(\n    Bucket=\"donnees-insee\", Key=\"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\"\n)\ndf = pd.read_csv(obj[\"Body\"], sep=\";\")\ndf.head(2)\n\n\n\nS3FS üëá\nLe code suivant devrait permettre d‚Äôeffectuer la m√™me op√©ration avec s3fs\nimport pandas as pd\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\ndf = pd.read_csv(\n    fs.open(\n        \"{}/{}\".format(\"donnees-insee\", \"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\"),\n        mode=\"rb\",\n    ),\n    sep=\";\",\n)\n\ndf.head(2)\n\n\n\nSnakemake üëá\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\nS3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\nbucket = \"mon-bucket\"\n\nrule ma_super_regle_s3:\n    input:\n        fichier = S3.remote(f'{bucket}/moninput.csv')\n    run:\n        import pandas as pd\n        df = pd.read_csv(input.fichier)\n        # PLUS D'OPERATIONS\n\n\n\nArrow üëá\nArrow est une librairie qui permet de lire des CSV.\nIl est n√©anmoins\nbeaucoup plus pratique d‚Äôutiliser le format parquet avec arrow.\nDans un premier temps, on configure le filesystem avec les\nfonctionalit√©s d‚ÄôArrow (cf.¬†pr√©c√©demment).\n\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\nPour lire un csv, on fera:\nfrom pyarrow import fs\nfrom pyarrow import csv\n\ns3 = fs.S3FileSystem(endpoint_override=\"https://\" + \"minio.lab.sspcloud.fr\")\n\nwith s3.open_input_file(\n    \"donnees-insee/diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\"\n) as file:\n    df = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\nPour un fichier au format parquet, la d√©marche est plus simple gr√¢ce √† l‚Äôargument\nfilesystem dans pyarrow.parquet.ParquetDataset :\nimport pyarrow.parquet as pq\n\n# bucket = \"\"\n# parquet_file=\"\"\ndf = (\n    pq.ParquetDataset(f\"{bucket}/{parquet_file}\", filesystem=s3)\n    .read_pandas()\n    .to_pandas()\n)",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#uploader-un-fichier",
    "href": "content/modern-ds/s3.html#uploader-un-fichier",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.7 Uploader un fichier",
    "text": "4.7 Uploader un fichier\n\nboto3 üëá\ns3.upload_file(file_name, bucket, object_name)\n\n\n\nS3FS üëá\nfs.put(filepath, f\"{bucket}/{object_name}\", recursive=True)\n\n\n\nArrow üëá\nSupposons que df soit un pd.DataFrame\nDans un syst√®me local, on convertirait\nen table Arrow puis on √©crirait en parquet\n(voir la documentation officielle).\nQuand on est sur un syst√®me S3, il s‚Äôagit seulement d‚Äôajouter\nnotre connexion √† S3 dans l‚Äôargument filesystem\n(voir la page sur ce sujet dans la documentation Arrow)\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\ntable = pa.Table.from_pandas(df)\npq.write_table(table, f\"{bucket}/{path}\", filesystem=s3)\n\n\n\nSnakemake üëá\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\nS3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\nbucket = \"mon-bucket\"\n\nrule ma_super_regle_s3:\n    input:\n        fichier='mon_dossier_local/moninput.csv'\n    output:\n        fichier=S3.remote(f'{bucket}/monoutput.csv')\n    run:\n        shell(\"cp output.fichier input.fichier\")\n\n\n\nmc üëá\nmc cp 'data.csv' \"MONBUCKET/monoutput.csv\"",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#pour-aller-plus-loin",
    "href": "content/modern-ds/s3.html#pour-aller-plus-loin",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.8 Pour aller plus loin",
    "text": "4.8 Pour aller plus loin\n\nLa documentation sur MinIO du SSPCloud",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#informations-additionnelles",
    "href": "content/modern-ds/s3.html#informations-additionnelles",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n8556b79\n\n\n2023-09-27 17:29:23\n\n\nJulien PRAMIL\n\n\nTypo chapitre S3 (#415)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n3f60d55\n\n\n2023-02-02 18:59:16\n\n\nLino Galiana\n\n\nWIP: Change path S3 (#349)\n\n\n\n\n9000723\n\n\n2023-01-22 12:01:25\n\n\nLino Galiana\n\n\nCorrige code s3fs upload (#345)\n\n\n\n\n1fe65ac\n\n\n2022-12-25 21:39:51\n\n\nLino Galiana\n\n\nDark boxes (#336)\n\n\n\n\n2227f8e\n\n\n2022-12-25 18:56:57\n\n\nLino Galiana\n\n\nFix problem s3 chapter (#335)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\n688cc15\n\n\n2022-09-01 18:38:59\n\n\nLino Galiana\n\n\nUpdate index.qmd\n\n\n\n\n2117d2c\n\n\n2022-09-01 08:54:38\n\n\nLino Galiana\n\n\nAjoute des √©l√©ments sur arrow (#262)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\naa945cb\n\n\n2022-03-31 09:28:14\n\n\nLino Galiana\n\n\ncorrige une ou deux typos (#225)\n\n\n\n\n34b08ec\n\n\n2022-03-24 16:37:37\n\n\nLino Galiana\n\n\nAjoute code sur write_parquet dans S3\n\n\n\n\nc51a87b\n\n\n2022-03-24 16:29:39\n\n\nLino Galiana\n\n\nretire typo nom bucket (#223)\n\n\n\n\n3b1d9ff\n\n\n2022-03-09 10:38:15\n\n\nLino Galiana\n\n\nAjoute d√©tails arrow dans la partie S3 (#220)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#footnotes",
    "href": "content/modern-ds/s3.html#footnotes",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nElle permet aussi la lecture et l‚Äô√©criture\nde .csv.‚Ü©Ô∏é\nD‚Äôailleurs, les g√©n√©rations n‚Äôayant connu nativement\nque ce type de stockage ne sont pas familiaris√©es\nau concept de file system et pr√©f√®rent\npayer le temps de recherche. Voir\ncet article\nsur le sujet.‚Ü©Ô∏é\nD‚Äôailleurs, les g√©n√©rations n‚Äôayant connu nativement\nque ce type de stockage ne sont pas familiaris√©es\nau concept de file system et pr√©f√®rent\npayer le temps de recherche. Voir\ncet article\nsur le sujet.‚Ü©Ô∏é\nD‚Äôailleurs, les g√©n√©rations n‚Äôayant connu nativement\nque ce type de stockage ne sont pas familiaris√©es\nau concept de file system et pr√©f√®rent\npayer le temps de recherche. Voir\ncet article\nsur le sujet.‚Ü©Ô∏é",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html",
    "href": "content/modern-ds/elastic_intro.html",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre a √©t√© √©crit avec Milena Suarez-Castillo\net pr√©sente quelques √©l√©ments qui servent de base √† un travail en cours\nsur les in√©galit√©s socio√©conomiques dans les\nchoix de consommation alimentaire.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#r√©plication-de-ce-chapitre",
    "href": "content/modern-ds/elastic_intro.html#r√©plication-de-ce-chapitre",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "1.1 R√©plication de ce chapitre",
    "text": "1.1 R√©plication de ce chapitre\nCe chapitre est plus exigeant en termes d‚Äôinfrastructures que les pr√©c√©dents.\nSi la premi√®re partie de ce chapitre peut √™tre men√©e avec une\ninstallation standard de Python, ce n‚Äôest pas le cas de la\ndeuxi√®me qui n√©cessite un serveur ElasticSearch. Les utilisateurs du\nSSP Cloud pourront r√©pliquer les exemples de ce cours\ncar cette technologie est disponible (que ce soit pour indexer une base ou\npour requ√™ter une base existante).\n‚ö†Ô∏è Ce\nchapitre n√©cessite une version particuli√®re du\npackage ElasticSearch pour tenir compte de l‚Äôh√©ritage de la version 7 du moteur Elastic.\nPour cela, faire\n\n!pip install elasticsearch==8.2.0\n!pip install unidecode\n!pip install rapidfuzz\n!pip install xlrd\n\nLa premi√®re partie de ce tutoriel ne n√©cessite pas d‚Äôarchitecture particuli√®re et\npeut ainsi √™tre ex√©cut√©e en utilisant les packages suivants :\n\nimport time\nimport pandas as pd\n\nLe script functions.py, disponible sur Github,\nregroupe un certain nombre de fonctions utiles permettant\nd‚Äôautomatiser certaines t√¢ches de nettoyage classiques\nen NLP.\n\n\n Hint\nPlusieurs m√©thodes peuvent √™tre mises en oeuvre pour r√©cup√©rer\nle script d‚Äôutilitaires. Vous pouvez trouver en dessous\nde cet encadr√© une m√©thode qui va chercher la derni√®re\nversion sur le d√©p√¥t Github du cours\n\n\n\nimport requests\n\nurl = \"https://github.com/linogaliana/python-datascientist/raw/master/content/modern-ds/functions.py\"\nr = requests.get(url, allow_redirects=True)\n\nopen(\"functions.py\", \"wb\").write(r.content)\n\nApr√®s l‚Äôavoir r√©cup√©r√© (cf.¬†encadr√© d√©di√©),\nil convient d‚Äôimporter les fonctions sous forme de module:\n\nimport functions as fc",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#cas-dusage",
    "href": "content/modern-ds/elastic_intro.html#cas-dusage",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "1.2 Cas d‚Äôusage",
    "text": "1.2 Cas d‚Äôusage\nCe notebook recense et propose d‚Äôappr√©hender quelques outils utilis√©s\npour le papier pr√©sent√© aux\nJourn√©es de M√©thodologie Statistiques 2022: Galiana and Suarez-Castillo, ‚ÄúFuzzy matching on big-data: an illustration with scanner data and crowd-sourced nutritional data‚Äù\n(travail en cours!)\nOn va partir du cas d‚Äôusage suivant :\n\nCombien de calories dans ma recette de cuisine de ce soir? Combien de calories dans mes courses de la semaine?\n\nL‚Äôobjectif est de reconstituer, √† partir de libell√©s de produits, les caract√©ristiques nutritionnelles d‚Äôune recette.\nLe probl√®me est que les libell√©s des tickets de caisse ne sont pas des champs textuels tr√®s propres, ils contiennent,\npar exemple, beaucoup d‚Äôabbr√©viations, toutes n‚Äô√©tant pas √©videntes.\nVoici par exemple une s√©rie de noms de produits qu‚Äôon va utiliser par la suite:\n\nticket = [\n    \"CROISSANTS X6 400G\",\n    \"MAQUEREAUX MOUTAR.\",\n    \"IGP OC SAUVIGNON B\",\n    \"LAIT 1/2 ECRM UHT\",\n    \"6 OEUFS FRAIS LOCA\",\n    \"ANANAS C2\",\n    \"L POMME FUDJI X6 CAL 75/80 1KG ENV\",\n    \"PLT MIEL\",\n    \"STELLA ARTOIS X6\",\n    \"COTES DU LUBERON AIGUEBRUN 75C\",\n]\n\nA ces produits, s‚Äôajoutent les ingr√©dients suivants, issus de la\nrecette du velout√© de potiron et carottes de Marmiton\nqui sera notre plat principal :\n\ningredients = [\n    \"500 g de carottes\",\n    \"2 pommes de terre\",\n    \"1 gousse d'ail\",\n    \"1/2 l de lait\",\n    \"1/2 l de bouillon de volaille\",\n    \"1 cuill√®re √† soupe de huile d'olive\",\n    \"1 kg de potiron\",\n    \"1 oignon\",\n    \"10 cl de cr√®me liquide (facultatif)\",\n]\n\nEssayer de r√©cup√©rer par web scraping cette liste est un bon exercice pour r√©viser\nles concepts vus pr√©c√©demment\nOn va donc cr√©er une liste de course compilant\nces deux\nlistes h√©t√©rog√®nes de noms de produits:\n\nlibelles = ticket + ingredients\n\nOn part avec cette liste dans notre supermarch√© virtuel. L‚Äôobjectif sera de trouver\nune m√©thode permettant de passer √† l‚Äô√©chelle:\nautomatiser les traitements, effectuer des recherches efficaces, garder une certaine g√©n√©ralit√© et flexibilit√©.\nCe chapitre montrera par l‚Äôexemple l‚Äôint√©r√™t d‚ÄôElastic par rapport √† une solution\nqui n‚Äôutiliserait que du Python.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#les-bases-offrant-des-informations-nutritionnelles",
    "href": "content/modern-ds/elastic_intro.html#les-bases-offrant-des-informations-nutritionnelles",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "2.1 Les bases offrant des informations nutritionnelles",
    "text": "2.1 Les bases offrant des informations nutritionnelles\nPour un nombre restreint de produits, on pourrait bien s√ªr chercher √†\nla main les caract√©ristiques des produits en utilisant les\nfonctionalit√©s d‚Äôun moteur de recherche:\n\nCependant, cette approche serait tr√®s fastidieuse et\nn√©cessiterait de r√©cuperer, √† la main, chaque caract√©ristique\npour chaque produit. Ce n‚Äôest donc pas envisageable.\nLes donn√©es disponibles sur Google viennent de l‚ÄôUSDA,\nl‚Äô√©quivalent am√©ricain de notre Minist√®re de l‚ÄôAgriculture.\nCependant, pour des recettes comportant des noms de produits fran√ßais, ainsi que\ndes produits potentiellement transform√©s, ce n‚Äôest pas tr√®s pratique d‚Äôutiliser\nune base de donn√©es de produits agricoles en Fran√ßais. Pour cette raison,\nnous proposons d‚Äôutiliser les deux bases suivantes,\nqui servent de base au travail de\nGaliana and Suarez Castillo (2022)\n\nL‚ÄôOpenFoodFacts database qui est une base\ncollaborative fran√ßaise de produits alimentaires. Issue d‚Äôun projet Data4Good, il s‚Äôagit d‚Äôune\nalternative opensource et opendata √† la base de donn√©es de l‚Äôapplication Yuka.\nLa table de composition nutritionnelle Ciqual produite par l‚ÄôAnses. Celle-ci\npropose la composition nutritionnelle moyenne des aliments les plus consomm√©s en France. Il s‚Äôagit d‚Äôune base de donn√©es\nenrichie par rapport √† celle de l‚ÄôUSDA puisqu‚Äôelle ne se cantonne pas aux produits agricoles non transform√©s.\nAvec cette base, il ne s‚Äôagit pas de trouver un produit exact mais essayer de trouver un produit type proche du produit\ndont on d√©sire conna√Ætre les caract√©ristiques.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#import",
    "href": "content/modern-ds/elastic_intro.html#import",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "2.2 Import",
    "text": "2.2 Import\nQuelques fonctions utiles sont regroup√©es dans le script functions.py et import√©es dans le notebook.\nLa base OpenFood peut √™tre r√©cup√©r√©e en ligne\nvia la fonction fc.import_openfood. N√©anmoins, cette op√©ration n√©cessitant\nun certain temps (les donn√©es brutes faisant autour de 2Go), nous proposons une m√©thode\npour les utilisateurs du SSP Cloud o√π une version est disponible sur\nl‚Äôespace de stockage.\nLa base Ciqual, qui plus l√©g√®re, est r√©cup√©r√©e elle directement en ligne\nvia la fonction fc.import_ciqual.\n\n# Pour les utilisateurs du SSP Cloud\nopenfood = fc.import_openfood_s3()\n# Pour les utilisateurs hors du SSP Cloud\n# openfood = fc.import_openfood()\nciqual = fc.import_ciqual()\n\n\nopenfood.head()\n\n\nciqual.head()",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#quest-ce-quelastic",
    "href": "content/modern-ds/elastic_intro.html#quest-ce-quelastic",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "3.1 Qu‚Äôest-ce qu‚ÄôElastic ?",
    "text": "3.1 Qu‚Äôest-ce qu‚ÄôElastic ?\nElasticSearch c‚Äôest un logiciel qui fournit un moteur de recherche install√© sur\nun serveur (ou une machine personnelle) qu‚Äôil est possible de requ√™ter depuis un client\n(une session Python par exemple).\nC‚Äôest un moteur de recherche\ntr√®s performant, puissant et flexible, extr√™mement utilis√© dans le domaine de la datascience\nsur donn√©es textuelles.\nUn cas d‚Äôusage est par exemple de trouver,\ndans un corpus de grande dimension\n(plusieurs sites web, livres‚Ä¶), un certain texte en s‚Äôautorisant des termes voisins\n(verbes conjugu√©s, fautes de frappes‚Ä¶).\nUn index est une collection de documents dans lesquels on souhaite chercher, pr√©alablement ing√©r√©s dans un moteur de recherche les documents sont les √©tablissements.\nL‚Äôindexation consiste √† pr√©-r√©aliser les traitements des termes des documents pour gagner en efficacit√© lors de la phase de recherche.\nL‚Äôindexation est faite une fois pour de nombreuses recherches potentielles, pour lesquelles la rapidit√© de r√©ponse peut √™tre cruciale.\nApr√®s avoir index√© une base, on effectuera des requ√™tes qui sont des recherches\nd‚Äôun document dans la base index√© (√©quivalent de notre web) √† partir de\ntermes de recherche normalis√©s.\nLe principe est le m√™me que celui d‚Äôun moteur de recherche du web comme Google.\nD‚Äôun c√¥t√©, l‚Äôensemble √† parcourir est index√© pour √™tre en\nmesure de parcourir de mani√®re efficace l‚Äôensemble du corpus.\nDe l‚Äôautre c√¥t√©, la phase de recherche permet de retrouver l‚Äô√©l√©ment du corpus le\nplus coh√©rent avec la requ√™te de recherche.\nL‚Äôindexation consiste, par exemple,\n√† pr√©-d√©finir des traitements des termes du corpus pour gagner en efficacit√©\nlors de la phase de recherche. En effet, l‚Äôindexation est une op√©ration peu fr√©quente\npar rapport √† la recherche. Pour cette derni√®re, l‚Äôefficacit√© est cruciale (un site web\nqui prend plusieurs secondes √† interpr√©ter une requ√™te simple ne sera pas utilis√©). Mais, pour\nl‚Äôindexation, ceci est moins crucial.\nLes documents sont constitu√©s de variables, les champs (‚Äòfields‚Äô),\ndont le type est sp√©cifi√© (‚Äútext‚Äù, ‚Äúkeywoard‚Äù, ‚Äúgeo_point‚Äù, ‚Äúnumeric‚Äù‚Ä¶) √† l‚Äôindexation.\nElasticSearch propose une interface graphique nomm√©e Kibana.\nCelle-ci est pratique\npour tester des requ√™tes et pour superviser le serveur Elastic. Cependant,\npour le passage √† l‚Äô√©chelle, notamment pour mettre en lien une base index√©e dans\nElastic avec une autre source de donn√©es, les API propos√©es par ElasticSearch\nsont beaucoup plus pratiques. Ces API permettent de connecter une session Python (idem pour R)\n√† un serveur Elastic afin de communiquer avec lui\n(√©changer des flux via une API REST).",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#elasticsearch-et-python",
    "href": "content/modern-ds/elastic_intro.html#elasticsearch-et-python",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "3.2 ElasticSearch et Python",
    "text": "3.2 ElasticSearch et Python\nEn Python, le package officiel est elasticsearch.\nCe dernier permet de configurer les param√®tres pour interagir avec un serveur, indexer\nune ou plusieurs bases, envoyer de mani√®re automatis√©e un ensemble de requ√™tes\nau serveur, r√©cup√©rer les r√©sultats directement dans une session Python‚Ä¶",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#premier-essai-les-produits-ciqual-les-plus-similaires-aux-produits-de-la-recette",
    "href": "content/modern-ds/elastic_intro.html#premier-essai-les-produits-ciqual-les-plus-similaires-aux-produits-de-la-recette",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "4.1 Premier essai: les produits Ciqual les plus similaires aux produits de la recette",
    "text": "4.1 Premier essai: les produits Ciqual les plus similaires aux produits de la recette\nOn pourrait √©crire une fonction qui prend en argument\nune liste de libell√©s d‚Äôint√©r√™t et une liste de candidat au match et\nrenvoie le libell√© le plus proche.\nCependant, le risque est que cet algorithme soit relativement lent s‚Äôil n‚Äôest pas cod√©\nparfaitement.\nIl est, √† mon avis, plus simple, quand\non est habitu√© √† la logique Pandas,\nde faire un produit cart√©sien pour obtenir un vecteur mettant en miroir\nchaque produit de notre recette avec l‚Äôensembles des produits Ciqual et ensuite comparer les deux vecteurs pour prendre,\npour chaque produit, le meilleur match.\nLes bases √©tant de taille limit√©e, le produit cart√©sien n‚Äôest pas probl√©matique.\nAvec des bases plus cons√©quentes, une strat√©gie plus parcimonieuse en m√©moire devrait √™tre envisag√©e.\nPour faire cette op√©ration, on va utiliser la fonction match_product de\nnote script d‚Äôutilitaires.\n\ndist_leven = fc.match_product(libelles, ciqual)\ndist_leven\n\nCette premi√®re √©tape na√Øve est d√©cevante √† plusieurs √©gards:\n\nCertes, on a des matches coh√©rent (par exemple ‚ÄúOignon rouge, cru‚Äù et ‚Äú1 oignon‚Äù)\nmais on a plus de couples incoh√©rents ;\nLe temps de calcul peut appara√Ætre faible mais le passage √† l‚Äô√©chelle risque d‚Äô√™tre compliqu√© ;\nLes besoins m√©moires sont potentiellement importants lors de l‚Äôappel √†\nrapidfuzz.process.extract ce qui peut bloquer le passage √† l‚Äô√©chelle ;\nLa distance textuelle n‚Äôest pas n√©cessairement la plus pertinente.\n\nOn a, en fait, n√©glig√© une √©tape importante: la normalisation (ou nettoyage des textes) pr√©sent√©e dans la\npartie NLP, notamment:\n\nharmonisation de la casse, suppression des accents‚Ä¶\nsuppressions des mots outils (e.g.¬†ici on va d‚Äôabord n√©gliger les quantit√©s pour trouver la nature de l‚Äôaliment, en particulier pour Ciqual)\n\n\n\n\n\n\n\n\n\n\nScanner-data avant nettoyage\n\n\n\n\n\n\n\nOpenFood data avant nettoyage\n\n\n\n\n\n\n\n\n\nScanner-data apr√®s nettoyage\n\n\n\n\n\n\n\nOpenFood data apr√®s nettoyage\n\n\n\n\n\nFaisons donc en apparence un retour en arri√®re qui sera\nn√©anmoins salvateur pour am√©liorer\nla pertinence des liens faits entre nos\nbases de donn√©es.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#objectif",
    "href": "content/modern-ds/elastic_intro.html#objectif",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.1 Objectif",
    "text": "5.1 Objectif\nLe preprocessing correspond √† l‚Äôensemble des op√©rations\nayant lieu avant l‚Äôanalyse √† proprement parler.\nIci, ce preprocessing est int√©ressant √† plusieurs\n√©gards:\n\nIl r√©duit le bruit dans nos jeux de donn√©es (par exemple des mots de liaisons) ;\nIl permet de normaliser et harmoniser les syntaxes dans nos diff√©rentes sources.\n\nL‚Äôobjectif est ainsi de r√©duire nos noms de produits √† la substantifique moelle\npour am√©liorer la pertinence de la recherche.\nPour √™tre pertinent, le preprocessing comporte g√©n√©ralement deux types de\ntraitements. En premier lieu, ceux qui sont g√©n√©raux et applicables\n√† tous types de corpus textuels: retrait des stopwords, de la ponctuation, etc.\nles m√©thodes disponibles dans la partie NLP.\nEnsuite, il est n√©cessaire de mettre en oeuvre des nettoyages plus sp√©cifiques √† chaque corpus.\nPar exemple dans la source Ciqual,\nla cuisson est souvent renseign√©e et bruite les appariemments.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#d√©marche",
    "href": "content/modern-ds/elastic_intro.html#d√©marche",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.2 D√©marche",
    "text": "5.2 D√©marche\n\n\n Exercice 1: preprocessing\n\nPour transformer les lettres avec accents en leur √©quivalent\nsans accent, la fonction unidecode\n(du package du m√™me nom) est pratique.\nLa tester sur le jeu de donn√©es ciqual en cr√©ant une nouvelle\ncolonne nomm√©e libel_clean\nLa casse diff√©rente selon les jeux de donn√©es peut √™tre p√©nalisante\npour trouver des produits similaires. Pour √©viter ces probl√®mes,\nmettre tout en majuscule.\nLes informations sur les quantit√©s ou le packaging peuvent apporter\ndu bruit dans notre comparaison. Nous allons retirer ces mots,\n√† travers la liste ['KG','CL','G','L','CRUE?S?', 'PREEMBALLEE?S?'],\nqu‚Äôon peut consid√©rer comme un dictionnaire de stop-words m√©tier.\nPour cela, il convient d‚Äôutiliser une expression r√©guli√®re dans la m√©thode\nstr.replace de Pandas.\nAvec ceux-ci, on va utiliser la liste des stop-words de\nla librairie nltk pour retirer les stop-words classiques (_‚Äúle‚Äù,‚Äúla‚Äù, etc.).\nLa librairie SpaCy, plus riche, pourrait √™tre utilis√©e ; nous laissons\ncela sous la forme d‚Äôexercice suppl√©mentaire.\nOn a encore des signes de ponctuation ou des chiffres qui peuvent\npoluer la comparaison. Les retirer gr√¢ce √† la m√©thode replace et\nune regex [^a-zA-Z]\nEnfin, par s√©curit√©, on peut supprimer les espaces multiples.\nUtiliser la regex '([ ]{2,})' pour cela. Observer le r√©sultat\nfinal.\n(Optionnel). Comme exercice suppl√©mentaire, faire la m√™me chose avec les\npipelines SpaCy.\n\n\n\nA l‚Äôissue de la question 1, le jeu de donn√©es ciqual devrait\nressembler √† celui-ci :\nApr√®s avoir mis en majuscule, on se retrouve avec le jeu de donn√©es\nsuivant :\nApr√®s retrait des stop-words, nos libell√©s prennent\nla forme suivante :\nLa regex pour √©liminer les caract√®res de ponctuation permet ainsi d‚Äôobtenir:\nEnfin, √† l‚Äôissue de la question 5, le DataFrame obtenu est le suivant :\nCes √©tapes de nettoyage ont ainsi permis de concentrer l‚Äôinformation\ndans les noms de produits sur ce qui l‚Äôidentifie vraiment.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#approche-syst√©matique",
    "href": "content/modern-ds/elastic_intro.html#approche-syst√©matique",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.3 Approche syst√©matique",
    "text": "5.3 Approche syst√©matique\nPour syst√©matiser cette approche √† nos diff√©rents DataFrame, rien de mieux\nqu‚Äôune fonction. Celle-ci est pr√©sente dans le module functions\nsous le nom clean_libelle.\n\nfrom functions import clean_libelle\n\nPour r√©sumer l‚Äôexercice pr√©c√©dent, cette fonction va :\n\nHarmoniser la casse et retirer les accents (voir functions.py) ;\nRetirer tout les caract√®res qui ne sont pas des lettres (chiffres, ponctuations) ;\nRetirer les caract√®res isol√©s.\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nnltk.download(\"stopwords\")\n\nstop_words = [\"KG\", \"CL\", \"G\", \"L\", \"CRUE?S?\", \"PREEMBALLEE?S?\"]\nstop_words += [l.upper() for l in stopwords.words(\"french\")]\n\nreplace_regex = {r\"[^A-Z]\": \" \", r\"\\b[A-Z0-9]{1,2}?\\b\": \" \"}  #\n\nCela permet d‚Äôobtenir les bases nettoy√©es suivantes :\n\nciqual = clean_libelle(\n    ciqual, yvar=\"alim_nom_fr\", replace_regex=replace_regex, stopWords=stop_words\n)\nciqual.sample(10)\n\n\nopenfood = clean_libelle(\n    openfood, yvar=\"product_name\", replace_regex=replace_regex, stopWords=stop_words\n)\nopenfood.sample(10)\n\n\ncourses = pd.DataFrame(libelles, columns=[\"libel\"])\ncourses = clean_libelle(\n    courses, yvar=\"libel\", replace_regex=replace_regex, stopWords=stop_words\n)\ncourses.sample(10)\n\nLes noms de produits sont d√©j√† plus harmonis√©s.\nVoyons voir si cela permet de trouver un\nmatch dans l‚ÄôOpenfood database:\n\ndist_leven_openfood = fc.match_product(courses[\"libel_clean\"], openfood, \"libel_clean\")\ndist_leven_openfood.sample(10)\n\nPas encore parfait, mais on progresse sur les produits appari√©s!\nConcernant le temps de calcul, les quelques secondes n√©cessaires √†\nce calcul peuvent appara√Ætre un faible prix √† payer. Cependant,\nil convient de rappeler que le nombre de produits dans l‚Äôensemble\nde recherche est faible. Cette solution n‚Äôest donc pas g√©n√©ralisable.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#r√©duire-les-temps-de-recherche",
    "href": "content/modern-ds/elastic_intro.html#r√©duire-les-temps-de-recherche",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.4 R√©duire les temps de recherche",
    "text": "5.4 R√©duire les temps de recherche\nFinalement, l‚Äôid√©al serait de disposer d‚Äôun moteur de recherche adapt√© √† notre besoin,\ncontenant les produits candidats, que l‚Äôon pourrait interroger, rapide en lecture, capable de classer les √©chos renvoy√©s par pertinence, que l‚Äôon pourrait requ√™ter de mani√®re flexible.\nPar exemple, on pourrait vouloir signaler qu‚Äôun\n√©cho nous int√©resse seulement si la donn√©e calorique n‚Äôest pas manquante.\nOn pourrait m√™me vouloir qu‚Äôil effectue pour nous des pr√©traitements sur les donn√©es.\nCela para√Æt beaucoup demander. Mais c‚Äôest exactement ce que fait ElasticSearch.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#cr√©er-un-cluster-elastic-sur-le-datalab",
    "href": "content/modern-ds/elastic_intro.html#cr√©er-un-cluster-elastic-sur-le-datalab",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.1 Cr√©er un cluster Elastic sur le DataLab",
    "text": "6.1 Cr√©er un cluster Elastic sur le DataLab\nPour lancer un service Elastic, il faut cliquer sur ce lien.\nUne fois cr√©√©, vous pouvez explorer l‚Äôinterface graphique Kibana.\nCependant, gr√¢ce √† l‚ÄôAPI Elastic\nde Python, on se passera de celle-ci. Donc, en pratique,\nune fois lanc√©, pas besoin d‚Äôouvrir ce service Elastic pour continuer √† suivre1.\nDans un terminal, vous pouvez aussi v√©rifier que vous √™tes en mesure de dialoguer avec votre cluster Elastic,\nqui est pr√™t √† vous √©couter:\nkubectl get statefulset\nPasser par la ligne de commande serait peu commode pour industrialiser notre\nrecherche.\nNous allons utiliser la librairie elasticsearch pour dialoguer avec notre moteur de recherche Elastic.\nLes instructions ci-dessous indiquent comment √©tablir la connection.\n\nfrom elasticsearch import Elasticsearch\n\nHOST = \"elasticsearch-master\"\n\n\ndef elastic():\n    \"\"\"Connection avec Elastic sur le data lab\"\"\"\n    es = Elasticsearch(\n        [{\"host\": HOST, \"port\": 9200, \"scheme\": \"http\"}],\n        http_compress=True,\n        request_timeout=200,\n    )\n    return es\n\n\nes = elastic()\n\n&lt;Elasticsearch([{'host': 'elasticsearch-master', 'port': 9200}])&gt;\nMaintenant que la connection est √©tablie, deux √©tapes nous attendent:\n\nIndexation Envoyer les documents parmi lesquels on veut chercher des echos pertinents dans notre elastic. Un index est une collection de document. Nous pourrions en cr√©er deux : un pour les produits ciqual, un pour les produits openfood\nRequ√™te Chercher les documents les plus pertinents suivant une recherche textuelle flexible. Nous allons rechercher les libell√©s de notre recette et de notre liste de course.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#premi√®re-indexation",
    "href": "content/modern-ds/elastic_intro.html#premi√®re-indexation",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.2 Premi√®re indexation",
    "text": "6.2 Premi√®re indexation\nOn cr√©e donc nos deux index:\n\nif not es.indices.exists(index=\"openfood\"):\n    es.indices.create(index=\"openfood\")\nif not es.indices.exists(index=\"ciqual\"):\n    es.indices.create(index=\"ciqual\")\n\nPour l‚Äôinstant, nos index sont vides! Ils contiennent 0 documents.\n\nes.count(index=\"openfood\")\n\n{'count': 0, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\nNous allons en rajouter quelques-uns !\n\nes.create(\n    index=\"openfood\",\n    id=1,\n    body={\n        \"product_name\": \"Tarte noix de coco\",\n        \"product_name_clean\": \"TARTE NOIX COCO\",\n    },\n)\nes.create(\n    index=\"openfood\",\n    id=2,\n    body={\"product_name\": \"Noix de coco\", \"product_name_clean\": \"NOIX COCO\"},\n)\nes.create(\n    index=\"openfood\",\n    id=3,\n    body={\"product_name\": \"Beurre doux\", \"product_name_clean\": \"BEURRE DOUX\"},\n)\n\n\nes.count(index=\"openfood\")\n\n{'count': 3, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\nDans l‚Äôinterface graphique Kibana,\non peut v√©rifier que l‚Äôindexation\na bien eue lieu en allant dans Management &gt; Stack Management",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#premi√®re-recherche",
    "href": "content/modern-ds/elastic_intro.html#premi√®re-recherche",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.3 Premi√®re recherche",
    "text": "6.3 Premi√®re recherche\nFaisons notre premi√®re recherche: cherchons des noix de p√©can!\n\nes.search(index=\"openfood\", q=\"noix de p√©can\")\n\nObjectApiResponse({'took': 116, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 2, 'relation': 'eq'}, 'max_score': 0.9400072, 'hits': [{'_index': 'openfood', '_type': '_doc', '_id': '2', '_score': 0.9400072, '_source': {'product_name': 'Noix de coco', 'product_name_clean': 'NOIX COCO'}}, {'_index': 'openfood', '_type': '_doc', '_id': '1', '_score': 0.8272065, '_source': {'product_name': 'Tarte noix de coco', 'product_name_clean': 'TARTE NOIX COCO'}}]}})\nInt√©ressons nous aux hits (r√©sultats pertinents, ou echos) : nous en avons 2.\nLe score maximal parmi les hits est mentionn√© dans max_score et correspond √† celui du deuxi√®me document index√©.\nElastic nous fournit ici un score de pertinence dans notre recherche d‚Äôinformation, et classe ainsi les documents renvoy√©s.\nIci nous utilisons la configuration par d√©faut. Mais comment est calcul√© ce score? Demandons √† Elastic de nous expliquer le score du document 2 dans la requ√™te \"noix de p√©can\".\n\nes.explain(index=\"openfood\", id=2, q=\"noix de p√©can\")\n\nObjectApiResponse({'_index': 'openfood', '_type': '_doc', '_id': '2', 'matched': True, 'explanation': {'value': 0.9400072, 'description': 'max of:', 'details': [{'value': 0.49917626, 'description': 'sum of:', 'details': [{'value': 0.49917626, 'description': 'weight(product_name_clean:noix in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.49917626, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.48275858, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 2.0, 'description': 'dl, length of field', 'details': []}, {'value': 2.3333333, 'description': 'avgdl, average length of field', 'details': []}]}]}]}]}, {'value': 0.9400072, 'description': 'sum of:', 'details': [{'value': 0.4700036, 'description': 'weight(product_name:noix in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.4700036, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.45454544, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 3.0, 'description': 'dl, length of field', 'details': []}, {'value': 3.0, 'description': 'avgdl, average length of field', 'details': []}]}]}]}, {'value': 0.4700036, 'description': 'weight(product_name:de in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.4700036, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.45454544, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 3.0, 'description': 'dl, length of field', 'details': []}, {'value': 3.0, 'description': 'avgdl, average length of field', 'details': []}]}]}]}]}]}})\nElastic nous explique donc que le score 0.9400072 est le maximum entre deux sous-scores, 0.4991 et 0.9400072.\nPour chacun de ces sous-scores, le d√©tail de son calcul est donn√©.\nLe premier sous-score n‚Äôa accord√© un score que par rapport au premier mot (noix), tandis que le second a accord√© un score sur la base des deux mots d√©j√† connu dans les documents (‚Äúnoix‚Äù et ‚Äúde‚Äù). Il a ignor√© p√©can! Jusqu‚Äô√† pr√©sent, ce terme n‚Äôest pas connu dans l‚Äôindex.\nLa pertinence d‚Äôun mot pour notre recherche est construite sur une variante de la TF-IDF,\nconsid√©rant qu‚Äôun terme est pertinent s‚Äôil est souvent pr√©sent dans le document (Term Frequency)\nalors qu‚Äôil est peu fr√©quent dans les autres document (inverse document frequency).\nIci les notations des documents 1 et 2 sont tr√®s proches, la diff√©rence est d√ªe √† des IDF plus faibles dans le document 1,\nqui est p√©nalis√© pour √™tre l√©g√©rement plus long.\nBref, tout √ßa est un peu lourd, mais assez efficace,\nen tout cas moins rudimentaire que les distances caract√®res √† caract√®res pour ramener des echos pertinents.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#limite-de-cette-premi√®re-indexation",
    "href": "content/modern-ds/elastic_intro.html#limite-de-cette-premi√®re-indexation",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.4 Limite de cette premi√®re indexation",
    "text": "6.4 Limite de cette premi√®re indexation\nPour l‚Äôinstant, Elastic n‚Äôa pas l‚Äôair de g√©rer les fautes de frappes!\nPas le droit √† l‚Äôerreur dans la requ√™te:\n\nes.search(index=\"openfood\", q=\"TART NOI\")\n\nObjectApiResponse({'took': 38, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}})\nCela s‚Äôexplique par la repr√©sentation des champs (‚Äòproduct_name‚Äô par exemple) qu‚ÄôElastic a inf√©r√©,\npuisque nous n‚Äôavons rien sp√©cifi√©.\nLa repr√©sentation d‚Äôune variable conditionne la fa√ßon dont les champs sont analys√©s pour calculer la pertinence.\nPar exemple, regardons la repr√©sentation du champ product_name\n\nes.indices.get_field_mapping(index=\"openfood\", fields=\"product_name\")\n\nObjectApiResponse({'openfood': {'mappings': {'product_name': {'full_name': 'product_name', 'mapping': {'product_name': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}}}})\nElastic a compris qu‚Äôil s‚Äôagissait d‚Äôun champ textuel.\nEn revanche, le type est keyword n‚Äôautorise pas des analyses approximatives donc\nne permet pas de tenir compte de fautes de frappes.\nPour qu‚Äôun echo remonte, un des termes doit matcher exactement. Dommage !\nMais c‚Äôest parce qu‚Äôon a utilis√© le mapping par d√©faut.\nEn r√©alit√©, il est assez simple de pr√©ciser un mapping plus riche,\nautorisant une analyse ‚Äúfuzzy‚Äù ou ‚Äúflou‚Äù.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#nos-premi√®res-requ√™tes",
    "href": "content/modern-ds/elastic_intro.html#nos-premi√®res-requ√™tes",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "7.1 Nos premi√®res requ√™tes",
    "text": "7.1 Nos premi√®res requ√™tes\nV√©rifions qu‚Äôon recup√®re quelques tartes aux noix m√™me si l‚Äôon fait plein de fautes:\n\nes.search(index=\"openfood\", q=\"TART NOI\", size=3)\n\nObjectApiResponse({'took': 60, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10000, 'relation': 'gte'}, 'max_score': 22.837925, 'hits': [{'_index': 'openfood', '_type': '_doc', '_id': '405332', '_score': 22.837925, '_source': {'product_name': 'Tarte noix', 'libel_clean': 'TARTE NOIX', 'energy_100g': 1833.0, 'nutriscore_score': 23.0}}, {'_index': 'openfood', '_type': '_doc', '_id': '1103594', '_score': 22.82367, '_source': {'product_name': 'Tarte aux noix', 'libel_clean': 'TARTE NOIX', 'energy_100g': 4.0, 'nutriscore_score': 4.0}}, {'_index': 'openfood', '_type': '_doc', '_id': '1150755', '_score': 22.82367, '_source': {'product_name': 'Tarte aux noix', 'libel_clean': 'TARTE NOIX', 'energy_100g': 1929.0, 'nutriscore_score': 21.0}}]}})\nSi on pr√©f√®re sous une forme de DataFrame:\n\ndf = pd.json_normalize(\n    es.search(index=\"openfood\", q=\"TART NOI\", size=3)[\"hits\"][\"hits\"]\n)\ndf.columns = df.columns.str.replace(\"_source.\", \"\", regex=False)\ndf.head(2)\n\n\\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n_index_type_id_scoreproduct_namelibel_cleanenergy_100gnutriscore_score0openfood_doc40533222.837925Tarte noixTARTE NOIX1833.023.01openfood_doc110359422.823670Tarte aux noixTARTE NOIX4.04.02openfood_doc115075522.823670Tarte aux noixTARTE NOIX1929.021.0\nPour automatiser l‚Äôenvoi de requ√™tes et la r√©cup√©ration du meilleur\n√©cho, on peut d√©finir la fonction suivante\n\ndef matchElastic(libelles):\n    start_time = time.time()\n    matches = {}\n    for l in libelles:\n        response = es.search(index=\"openfood\", q=l, size=1)\n        if len(response[\"hits\"][\"hits\"]) &gt; 0:\n            matches[l] = pd.json_normalize(response[\"hits\"][\"hits\"])\n    print(80 * \"-\")\n    print(f\"Temps d'ex√©cution total : {(time.time() - start_time):.2f} secondes ---\")\n\n    return matches\n\n\nmatches = matchElastic(courses[\"libel_clean\"])\nmatches = pd.concat(matches)\nmatches.sample(3)\n\n\\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n_index_type_id_score_source.product_name_source.libel_clean_source.energy_100g_source.nutriscore_scoreGOUSSE AIL0openfood_doc198206257.93140Gousse d\\'ailGOUSSE AIL498.05.0IGP SAUVIGNON0openfood_doc180140696.55756vin blanc SauvignonVIN BLANC SAUVIGNON66.31.0POTIRON0openfood_doc104396175.96385PotironPOTIRON172.00.0\nEt voil√†, on a un outil tr√®s rapide de requ√™te !\nLa pertinence des r√©sultats est encore douteuse.\nPour cela, il conviendrait de pr√©ciser des requ√™tes plus sophistiqu√©es!2\n\nreq = {\n    \"bool\": {\n        \"should\": [\n            {\"match\": {\"libel_clean\": {\"query\": \"HUILE OLIVE\", \"boost\": 10}}},\n            {\"match\": {\"libel_clean.ngr\": \"HUILE OLIVE\"}},\n        ],\n        \"minimum_should_match\": 1,\n        \"filter\": [{\"range\": {\"nutriscore_score\": {\"gte\": 10, \"lte\": 20}}}],\n    }\n}\n\n\nout = es.search(index=\"openfood\", query=req, size=1)\npd.json_normalize(out[\"hits\"][\"hits\"])\n\n\\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n_index_type_id_score_source.product_name_source.libel_clean_source.energy_100g_source.nutriscore_score0openfood_doc960041174.27896Huile d oliveHUILE OLIVE3761.011.0\nQu‚Äôa-t-on demand√© ici?\n- De renvoyer 1 et 1 seul echo (\"size\":\"1\") et seulement si celui ci a:\n+ \"should\": Au moins un (\"minimum_should_match\":\"1\") des termes des deux champs libel_clean et libel_clean.ngr qui matche sur un terme de HUILE OLIVE, l‚Äôanalyse (la d√©finition du ‚Äúterme‚Äù) √©tant r√©alis√© soit en tant que text (‚Äúlibel_clean‚Äù) soit en tant que n-gramme ngr (‚Äúlibel_clean.ngr‚Äù, une analyse que nous avons sp√©cifi√© dans le mapping)\n+ \"filter\": Le champ float nutriscore_score doit √™tre compris entre 10 et 20 (‚Äúfilter‚Äù).\nA noter :\n\nLes clauses (\"should\"+\"minimum_should_match\":\"1\") peuvent √™tre remplac√© par un \"must\". Auquel cas, l‚Äô√©cho doit obligatoirement matcher sur chaque clause.\nPr√©ciser dans \"filter\" (plut√¥t que dans \"should\") une condition signifie que celle-ci ne participe pas au score de pertinence.\n\nOn n‚Äôa pas encore un appariemment tr√®s satisfaisant, en particulier sur les boissons. Comment faire ? La r√©ponse est dans Galiana and Suarez Castillo (2022)\n\nA vous, de calculer le nombre de calories de notre recette de course !",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#informations-additionnelles",
    "href": "content/modern-ds/elastic_intro.html#informations-additionnelles",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\ndf6a66b\n\n\n2023-11-05 10:56:31\n\n\nJulien PRAMIL\n\n\nPb redirection snippet elastic (#445)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n003a625\n\n\n2022-10-28 18:53:05\n\n\nLino Galiana\n\n\nRebuild (#311)\n\n\n\n\ne3a6b2d\n\n\n2022-10-28 08:01:32\n\n\nLino Galiana\n\n\nProposition utilisation minio pour download openfood (#307)\n\n\n\n\n044abdb\n\n\n2022-10-25 13:57:53\n\n\nLino Galiana\n\n\nFinalise tuto elastic (#306)\n\n\n\n\n3e26719\n\n\n2022-10-24 19:09:22\n\n\nLino Galiana\n\n\nTutoriel Elastic reprise (#305)\n\n\n\n\n1f1668a\n\n\n2022-10-24 10:02:16\n\n\nLino Galiana\n\n\nCorrige tutoriel Elastic (#303)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb5615b4\n\n\n2021-09-09 16:52:47\n\n\nLino Galiana\n\n\nUn petit tuto Elastic (#135)\n\n\n\n\n8166e22\n\n\n2021-09-09 11:06:20\n\n\nLino Galiana\n\n\nWordcloud du site (#136)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nScanner-data avant nettoyage\nOpenFood data avant nettoyage\nScanner-data apr√®s nettoyage\nOpenFood data apr√®s nettoyage",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#footnotes",
    "href": "content/modern-ds/elastic_intro.html#footnotes",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe lancement du service a cr√©√© dans votre NAMESPACE Kubernetes (l‚Äôensemble de tout vos services) un cluster Elastic.\nVous n‚Äôavez droit qu‚Äô√† un cluster par namespace (ou compte d‚Äôutilisateur).\nVotre service Jupyter, VSCode, RStudio, etc. est associ√© au m√™me namespace.\nDe m√™me qu‚Äôil n‚Äôest pas n√©cessaire de comprendre comment fonctionne le moteur d‚Äôune voiture pour conduire,\nil n‚Äôest pas n√©cessaire de comprendre la mani√®re dont tout ce beau monde dialogue pour pouvoir utiliser le SSP Cloud.‚Ü©Ô∏é\nVous pouvez aussi explorer les possibilit√©s de requ√™tes via la doc Elastic et vous entrainer √† un √©crire avec votre index tout neuf.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/git/introgit.html",
    "href": "content/git/introgit.html",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page reprend des √©l√©ments pr√©sents dans\nun cours d√©di√© fait avec Romain Avouac.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#les-probl√®mes-classiques",
    "href": "content/git/introgit.html#les-probl√®mes-classiques",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "1.1 Les probl√®mes classiques",
    "text": "1.1 Les probl√®mes classiques\nDans un projet, il est commun de se demander (ou de demander √† quelqu‚Äôun) :\n\nquelle √©tait la bonne version d‚Äôun programme ?\nqui √©tait l‚Äôauteur d‚Äôun bout de code en particulier ?\nsi un changement √©tait important ou juste un essai ?\no√π retrouver des traces d‚Äôun vieil essai abandonn√© mais potentiellement finalement prometteur ?\ncomment fusionner des programmes √©crits par plusieurs personnes ?\netc.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#la-solution-le-contr√¥le-de-version",
    "href": "content/git/introgit.html#la-solution-le-contr√¥le-de-version",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "1.2 La solution: le contr√¥le de version",
    "text": "1.2 La solution: le contr√¥le de version\nIl existe un outil informatique puissant qui r√©pond √† tous ces besoins :\nla gestion de version (version control system (VCS) en anglais). Ses avantages sont incontestables et permettent de facilement :\n\nenregistrer l‚Äôhistorique des modifications d‚Äôun ensemble de fichiers ;\nrevenir √† des versions pr√©c√©dentes d‚Äôun ou plusieurs fichiers ;\nrechercher les modifications qui ont pu cr√©er des erreurs ;\npartager ses modifications et r√©cup√©rer celles des autres ;\nproposer des modifications, les discuter, sans pour autant modifier d‚Äôembl√©e la derni√®re version existante ;\nidentifier les auteurs et la date des modifications.\n\nEn outre, ces outils fonctionnent avec tous les langages\ninformatiques (texte, R, Python, Markdown, LaTeX, Java, etc.)\ncar reposent sur la comparaison des lignes et des caract√®res des programmes.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#avantages-du-contr√¥le-de-version",
    "href": "content/git/introgit.html#avantages-du-contr√¥le-de-version",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "1.3 Avantages du contr√¥le de version",
    "text": "1.3 Avantages du contr√¥le de version\nOn peut ainsi r√©sumer les principaux avantages du contr√¥le de version\nde la mani√®re suivante :\n\nConserver et archiver l‚Äôensemble des versions d‚Äôun code ou d‚Äôune documentation\nTravailler efficacement en √©quipe\nAm√©liorer la qualit√© des codes\nSimplifier la communication autour d‚Äôun projet\n\n\n1.3.1 Conserver et archiver du code\nUne des principales fonctionnalit√©s de la gestion de version est de conserver\nl‚Äôensemble des fichiers de fa√ßon s√©curis√©e et de proposer un archivage\nstructur√© des codes. Les fichiers sont stock√©s dans un d√©p√¥t, qui constitue le projet.\nTout repose dans la gestion et la pr√©sentation de l‚Äôhistorique des modifications.\nChaque modification (ajout, suppression ou changement) sur un ou plusieurs fichiers est identifi√©e par son auteur,\nsa date et un bref descriptif1.\nChaque changement est donc unique et ais√©ment identifiable quand les modifications sont class√©es par ordre chronologique. Les groupes de modifications transmis au d√©p√¥t sont appel√©es commit.\nAvec des outils graphiques, on peut v√©rifier l‚Äô\nensemble des √©volutions d‚Äôun fichier (history),\nou l‚Äôhistoire d‚Äôun d√©p√¥t.\nOn peut aussi\nse concentrer sur une modification particuli√®re d‚Äôun fichier ou v√©rifier, pour un fichier, la\nmodification qui a entra√Æn√© l‚Äôapparition de telle ou telle ligne (blame)\nSur son poste de travail, les dizaines (voire centaines) de programmes organis√©s √† la main n‚Äôexistent plus. Tout est regroup√© dans un seul dossier, rassemblant les √©l√©ments du d√©p√¥t. Au sein du d√©p√¥t, tout l‚Äôhistorique est stock√© et accessible rapidement. Si on souhaite travailler sur la derni√®re version des programmes (ou sur une ancienne version sp√©cifique), il n‚Äôy a plus besoin de conserver les autres fichiers car ils sont dans l‚Äôhistorique du projet. Il est alors possible de choisir sur quelle version on veut travailler (la derni√®re commune √† tout le monde, la sienne en train d‚Äô√™tre d√©velopp√©e, celle de l‚Äôann√©e derni√®re, etc.).\n\n\n1.3.2 Travailler efficacement en √©quipe\nLe deuxi√®me avantage de la gestion de version repr√©sente une am√©lioration notable du travail en √©quipe sur des codes en commun.\nLa gestion de version permet de collaborer simplement et avec m√©thode. De fa√ßon organis√©e, elle permet de :\n\ntravailler en parall√®le et fusionner facilement du code\npartager une documentation des programmes gr√¢ce :\n\naux commentaires des modifications\n√† la possibilit√© d‚Äôune documentation commune et collaborative\n\ntrouver rapidement des erreurs et en diffuser rapidement la\ncorrection\n\nA ces avantages s‚Äôajoutent les fonctionalit√©s collaboratives des forges\nqui sont des plateformes o√π peuvent √™tre stock√©s des d√©p√¥ts.\nN√©anmoins, ces forges proposent aujourd‚Äôhui beaucoup de fonctionalit√©s\nqui vont au-del√† de l‚Äôarchivage de code :\ninteragir via\ndes issues,\nfaire des suggestions de modifications, ex√©cuter du code dans des\nenvironnements normalis√©s, etc.\nIl faut vraiment les voir comme des r√©seaux sociaux du code.\nLes principales plateformes dans ce domaine √©tant Github et Gitlab.\nL‚Äôusage individuel, c‚Äôest-√†-dire seul sur son projet,\npermet aussi de ‚Äútravailler en √©quipe avec soi-m√™me‚Äù car il permet de retrouver des mois plus tard le contenu et le contexte des modifications. Cela est notamment pr√©cieux lors des changements de poste ou des travaux r√©guliers mais espac√©s dans le temps (par exemple, un mois par an chaque ann√©e). M√™me lorsqu‚Äôon travaille tout seul, on collabore avec un moi futur qui peut ne plus se souvenir de la modification des fichiers.\n\n\n1.3.3 Am√©liorer la qualit√© des codes\nLe fonctionnement de la gestion de version, reposant sur l‚Äôarchivage structur√© des modifications et les commentaires les accompagnant, renforce la qualit√© des programmes informatiques. Ils sont plus document√©s, plus riches et mieux structur√©s. C‚Äôest pour cette raison que le contr√¥le de version ne doit pas √™tre consid√©r√© comme un outil r√©serv√© √† des d√©veloppeurs : toute personne travaillant sur des programmes informatiques gagne √† utiliser du contr√¥le de version.\nLes services d‚Äôint√©gration continue permettent de faire des tests automatiques\nde programmes informatiques, notamment de packages, qui renforcent la\nr√©plicabilit√© des programmes. Mettre en place des m√©thodes de travail fond√©es\nsur l‚Äôint√©gration continue rend les programmes plus robustes en for√ßant\nceux-ci √† tourner sur des machines autres que celles du d√©veloppeur du code.\n\n\n1.3.4 Simplifier la communication autour d‚Äôun projet\nLes sites de d√©p√¥ts Github et Gitlab permettent de faire beaucoup plus\nque seulement archiver des codes. Les fonctionalit√©s de d√©ploiement\nen continu permettent ainsi de :\n\ncr√©er des sites web pour valoriser des projets (par exemple les sites\nreadthedocs en python)\nd√©ployer de la documentation en continu\nrendre visible la qualit√© d‚Äôun projet avec des services de code coverage,\nde tests automatiques ou d‚Äôenvironnements int√©gr√©s de travail (binder, etc.)\nqu‚Äôon rend g√©n√©ralement visible au moyen de badges\n(exemple ici)",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#copies-de-travail-et-d√©p√¥t-collectif",
    "href": "content/git/introgit.html#copies-de-travail-et-d√©p√¥t-collectif",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "3.1 Copies de travail et d√©p√¥t collectif",
    "text": "3.1 Copies de travail et d√©p√¥t collectif\nGit est un syst√®me d√©centralis√© et asynchrone de gestion de version.\nCela signifie que:\n\nChaque membre d‚Äôun projet travaille sur une copie locale du d√©p√¥t\n(syst√®me decentralis√©). Cette copie de travail s‚Äôappelle un clone.\nCela signifie qu‚Äôon n‚Äôa pas une coh√©rence en continu de notre version\nde travail avec le d√©p√¥t ; on peut tr√®s bien ne jamais vouloir les\nmettre en coh√©rence (par exemple, si on teste une piste qui s‚Äôav√®re\ninfructueuse) ;\nC‚Äôest lorsqu‚Äôon propose la publication de modifications sur le d√©p√¥t\ncollectif qu‚Äôon doit s‚Äôassurer de la coh√©rence avec la version disponible\nen ligne (syst√®me asynchrone).\n\nLe d√©p√¥t distant est g√©n√©ralement stock√© sur\nune forge logicielle (Github ou Gitlab) et sert √† centraliser la version\ncollective d‚Äôun projet. Les copies locales sont des copies de travail\nqu‚Äôon utilise pour faire √©voluer un projet :\nIl est tout √† fait possible de faire du contr√¥le de version sans\nmettre en place de d√©p√¥t distant. Cependant,\n\nc‚Äôest dangereux puisque le d√©p√¥t distant fait office de sauvegarde\nd‚Äôun projet. Sans d√©p√¥t distant, on peut tout perdre en cas de probl√®me\nsur la copie locale de travail ;\nc‚Äôest d√©sirer √™tre moins efficace car, comme nous allons le montrer, les\nfonctionalit√©s des plateformes Github et Gitlab sont √©galement tr√®s\nb√©n√©fiques lorsqu‚Äôon travaille tout seul.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#principe",
    "href": "content/git/introgit.html#principe",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "3.2 Principe",
    "text": "3.2 Principe\nLes trois manipulations les plus courantes sont les suivantes et repr√©sent√©es sur le diagramme ci-apr√®s :\n\ncommit : je valide les modifications que j‚Äôai faites en local avec un message qui les explique\npull : je r√©cup√®re la derni√®re version des codes du d√©p√¥t distant\npush : je transmets mes modifications valid√©es au d√©p√¥t distant\n\n\nLes deux derni√®res manipulations correspondent aux interactions (notamment\nla mise en coh√©rence) avec\nle d√©p√¥t commun alors que la premi√®re manipulation commit correspond √†\nla modification des fichiers faite pour faire √©voluer un projet.\nDe mani√®re plus pr√©cise, il y a trois √©tapes avant d‚Äôenvoyer les modifications valid√©es (commit) au d√©p√¥t. Elles se d√©finissent en fonction des commandes qui permettent de les appliquer quand Git est utilis√© en lignes de commandes :\n\ndiff : inspection des modifications. Cela permet de comparer les fichiers modifi√©s et de distinguer les fichiers ajout√©s ou supprim√©s.\nstaging area : s√©lection des modifications.\ncommit : validation des modifications s√©lectionn√©es (avec commentaire).\n\n\nLors des √©tapes de push et pull, des conflits peuvent appara√Ætre, par exemple lorsque deux personnes ont modifi√© le m√™me programme simultan√©ment. Le terme conflit peut faire peur mais en fait c‚Äôest\nl‚Äôun des apports principaux de Git que de faciliter √©norm√©ment la gestion\nde versions diff√©rentes. Les exercices du chapitre suivant l‚Äôillustreront.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#les-branches",
    "href": "content/git/introgit.html#les-branches",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "3.3 Les branches",
    "text": "3.3 Les branches\nC‚Äôest une des fonctionnalit√©s les plus pratiques de la gestion de version.\nLa cr√©ation de branches dans un projet (qui devient ainsi un arbre)\npermet de d√©velopper en parall√®le des correctifs ou une nouvelle fonctionnalit√©\nsans modifier le d√©p√¥t commun.\nCela permet de s√©parer le nouveau d√©veloppement et de faire cohabiter plusieurs versions, pouvant √©voluer s√©par√©ment ou pouvant √™tre facilement rassembl√©es. Git est optimis√© pour le travail sur les branches.\nDans un projet collaboratif, une branche dite master joue le r√¥le du tronc.\nC‚Äôest autour d‚Äôelle que vont pousser ou se greffer les branches.\nL‚Äôun des avantages de Git est qu‚Äôon peut toujours revenir en arri√®re. Ce\nfilet de s√©curit√© permet d‚Äôoser des exp√©rimentations, y compris au sein\nd‚Äôune branche. Il faut √™tre pr√™t √† aller dans la ligne de commande pour cela\nmais c‚Äôest extr√™mement confortable.\n\n\n Note\nComment nommer les branches ? L√† encore, il y a √©norm√©ment de conventions diff√©rentes. Une fr√©quemment observ√©e est :\n\npour les nouvelles fonctionnalit√©s : feature/nouvelle-fonctionnalite o√π nouvelle-fontionnalite est un nom court r√©sumant la fonctionnalit√©\npour les corrections de bug : issue-num o√π num est le num√©ro de l‚Äôissue\n\nN‚Äôh√©sitez pas √† aller encore plus loin dans la normalisation !",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#informations-additionnelles",
    "href": "content/git/introgit.html#informations-additionnelles",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\ne3f1ef1\n\n\n2023-11-13 11:53:50\n\n\nThomas Faria\n\n\nRelecture git (#448)\n\n\n\n\n1229936\n\n\n2023-11-10 11:02:28\n\n\nlinogaliana\n\n\ngitignore\n\n\n\n\n57f108f\n\n\n2023-11-10 10:59:36\n\n\nlinogaliana\n\n\nIntro git\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n5ab34aa\n\n\n2023-10-04 14:54:20\n\n\nKim A\n\n\nRelecture Kim pandas & git (#416)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\n34cc32c\n\n\n2022-10-14 22:05:47\n\n\nLino Galiana\n\n\nRelecture Git (#300)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\nf95b174\n\n\n2021-11-03 12:08:34\n\n\nLino Galiana\n\n\nEnrichi la section sur la gestion des d√©pendances (#175)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n283e8e9\n\n\n2020-10-02 18:54:30\n\n\nLino Galiana\n\n\nPremi√®re partie des exos git (#61)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#footnotes",
    "href": "content/git/introgit.html#footnotes",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPlus pr√©cis√©ment, chaque modification est identifi√©e de mani√®re unique par un code SHA auquel est associ√© l‚Äôauteur, l‚Äôhorodatage et des m√©tadonn√©es (par exemple le message descriptif associ√©).‚Ü©Ô∏é",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html",
    "href": "content/annexes/evaluation.html",
    "title": "Evaluation",
    "section": "",
    "text": "R√©sum√© :",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#attentes-du-projet",
    "href": "content/annexes/evaluation.html#attentes-du-projet",
    "title": "Evaluation",
    "section": "0.1 Attentes du projet",
    "text": "0.1 Attentes du projet\nLe projet est une probl√©matique √† laquelle vous souhaitez r√©pondre √†\nl‚Äôaide d‚Äôun ou de plusieurs jeu(s) de donn√©es.\nIl faut donc dans un premier temps se pencher sur la recherche de probl√©matisation et de contextualisation. Nous vous recommandons de prendre un sujet qui vous int√©resse pour int√©resser √©galement le lecteur.\nTrois dimensions doivent √™tre pr√©sentes dans le projet.\nPour chacune de ces parties, il est possible d‚Äôaller plus ou moins loin. Il est recommand√© d‚Äôaller loin sur au moins une des 3 dimensions.\n\n0.1.1 La r√©cup√©ration et le traitement des donn√©es\nCes donn√©es peuvent √™tre directement disponibles sous la forme de fichiers txt, csv ‚Ä¶ ou provenir de sites internet (scraping, API). Plus le travail sur la r√©cup√©ration de donn√©es est important (par exemple scraping sur plusieurs sites), plus la partie obtiendra de points. Si le jeu de donn√©es utilis√© est un t√©l√©chargement d‚Äôun jeu propre existant, il faudra chercher √† le compl√©ter d‚Äôune mani√®re ou d‚Äôune autre pour obtenir des points sur cette partie.\nVous obtiendrez vraisemblablement des donn√©es qui ne sont pas ¬´ propres ¬ª du premier coup : mettez en place des protocoles de nettoyage pour obtenir √† la fin de cette √©tape un ou des jeux de donn√©es fiable et robuste pour mener ensuite votre analyse. C‚Äôest √©galement le moment de cr√©er des variables plus appr√©hendables, mieux identifi√©es etc.\n\n\n0.1.2 L‚Äôanalyse descriptive et la repr√©sentation graphique\nLa pr√©sence de statistiques descriptives est indispensable dans le projet. De la description de la base aux premi√®res grandes tendances des donn√©es, cette partie permet d‚Äôavoir une vision globale des donn√©es : le lien avec la probl√©matique, comment elle permet d‚Äôy r√©pondre, quels sont les premiers √©l√©ments de r√©ponse‚Ä¶ Chaque r√©sultat doit √™tre interpr√©t√© : pas la peine de faire un describe et de ne pas le commenter.\nEn termes de repr√©sentation graphique, plusieurs niveaux sont envisageables. Vous pouvez simplement repr√©senter vos donn√©es en utilisant matplotlib, aller plus loin avec seaborn ou scikit-plot, (voire D3.js pour les plus motiv√©s). La base d‚Äôune bonne visualisation est de trouver le type de graphique ad√©quat pour ce que vous voulez montrer (faut-il un scatter ou un line pour repr√©senter une √©volution ?) et de le rendre visible : une l√©gende qui a du sens, des axes avec des noms etc. Encore une fois, il faudra commenter votre graphique, qu‚Äôest ce qu‚Äôil montre, en quoi cela valide / contredit votre argumentaire ?\n\n\n0.1.3 La mod√©lisation\nVient ensuite la phase de mod√©lisation : un mod√®le peut √™tre le bienvenu quand des statistiques descriptives ne suffisent pas √† apporter une solution compl√®te √† votre probl√©matique ou pour compl√©ter / renforcer l‚Äôanalyse descriptive. Le mod√®le importe peu (r√©gression lin√©aire, random forest ou autre) : il doit √™tre appropri√© (r√©pondre √† votre probl√©matique) et justifi√©.\nVous pouvez aussi confronter plusieurs mod√®les qui n‚Äôont pas la m√™me vocation : par exemple une CAH pour cat√©goriser et cr√©er des nouvelles variables / faire des groupes puis une r√©gression.\nM√™me si le projet n‚Äôest pas celui du cours de stats, il faut que la d√©marche soit scientifique et que les r√©sultats soient interpr√©t√©s.",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#format-du-rendu",
    "href": "content/annexes/evaluation.html#format-du-rendu",
    "title": "Evaluation",
    "section": "0.2 Format du rendu",
    "text": "0.2 Format du rendu\nSur le format du rendu, vous devrez :\n\n√âcrire un rapport sous forme de Notebook (quelques exceptions √† cette r√®gle peuvent exister, par exemple si vous d√©velopper une appli Dash)\nAvoir un r√©pertoire Github avec le rapport. Les donn√©es utilis√©es doivent √™tre accessibles √©galement, dans le d√©p√¥t ou sur internet.\nLes d√©p√¥ts Github o√π seul un upload du projet a √©t√© r√©alis√© seront p√©nalis√©s. A l‚Äôinverse, les d√©p√¥ts dans lequels le contr√¥le de version et le travail collaboratif ont √©t√© activement pratiqu√©s (commits fr√©quents, pull requests, ..) seront valoris√©s.\nLe code contenu dans le rapport devra √™tre un maximum propre (pas de copier coller de cellule, pr√©f√©rez des fonctions)\n\nCe post donne\nquelques conseils pour avoir des notebooks agr√©ables √† lire. N‚Äôoubliez pas cette r√®gle :\n\ncode is read much more often than written\n\nLors de l‚Äô√©valuation, une attention particuli√®re sera donn√©e √† la reproductibilit√© de votre projet.\nChaque √©tape (r√©cup√©ration et traitement des donn√©es, analyses descriptives, mod√©lisation) doit pouvoir √™tre reproduite √† partir du notebook final. Pour les op√©rations qui prennent du temps (ex : web scraping massif, requ√™tage d‚ÄôAPI avec des limites de nombre de requ√™tes, entra√Ænement de mod√®le, etc.), vous devez inclure l‚Äôoutput (base de donn√©es, mod√®le entra√Æn√©..) dans le d√©p√¥t, afin que les √©tapes suivantes puissent s‚Äô√©xecuter sans probl√®me.\nLe test √† r√©aliser : faire tourner toutes les cellules de votre notebook et ne pas avoir d‚Äôerreur est une condition sine qua non pour avoir la moyenne.",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#bar√®me-approximatif",
    "href": "content/annexes/evaluation.html#bar√®me-approximatif",
    "title": "Evaluation",
    "section": "0.3 Bar√®me approximatif",
    "text": "0.3 Bar√®me approximatif\n\nDonn√©es (collecte et nettoyage) : 4 points\nAnalyse descriptive : 4 points\nMod√©lisation : 2 points\nD√©marche scientifique et reproductibilit√© du projet : 4 points\nFormat du code (code propre et github) : 2 points\nSoutenance : 4 points\n\nLe projet doit √™tre r√©alis√© en groupe de trois, voire deux.",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#projets-men√©s-par-les-√©tudiants",
    "href": "content/annexes/evaluation.html#projets-men√©s-par-les-√©tudiants",
    "title": "Evaluation",
    "section": "0.4 Projets men√©s par les √©tudiants",
    "text": "0.4 Projets men√©s par les √©tudiants\n\n\n\n\n\n\n\n\n\nProjet\nAuteurs\nURL projet \nTags\n\n\n\n\nGPS v√©lo int√©grant les bornes V√©lib, les accidents, la congestion et la m√©t√©o\nVinciane Desbois ; Imane Fares ; Romane Gajdos\nhttps://github.com/ImaneFa/Projet_Python\nV√©lib ; Pistes cyclables ; Accidents ; Folium\n\n\nQuiz Generator\nAdrien Servi√®re ; M√©lissa Tamine\nhttps://github.com/taminemelissa/quiz-generator\nMachine Learning ; Natural Language Processing ; Question Generation ; Word2Vec\n\n\nAnalyse de sentiments sur les vaccins COVID administr√©s en France\nKOAGNE FONGUIENG Florette ; KONKOBO Idrissa\nhttps://github.com/kidrissa/projetpy\nAPI ; NLP ; Wordcloud ; Mod√©lisation pr√©dictive\n\n\nEstimation de l‚Äôempreinte carbone d‚Äôune recette de cuisine\nJean-Baptiste Laval ; Hadrien Lolivier ; Sirine Louati\nhttps://github.com/sirinelouati/Plat_CO2\nscraping ; Dashboard ; Empreinte carbone ; Alimentation\n\n\nLe ‚Äúbon sens du boucher-charcutier de Tourcoing vaut-il mieux que les enqu√™tes de victimation ?‚Äù\nConrad Thiounn ; Gaston Vermersch\nhttps://github.com/cthiounn/python-datascience-ENSAE-2A\nAPI ; Open-data ; ACP ; CAH ; LASSO\n\n\nPr√©diction du revenu g√©n√©r√© par un film en fonction de ses caract√©ristiques\nDmitri Lebrun ; Corentin Pernot ; Nina Stizi\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nScrapping ; Cin√©ma ; Machine Learning\n\n\nAnalyse du r√©seau ferr√© de la SNCF: Comment expliquer les retards permanents de la compagnie fran√ßaise ?\nDiego Renaud ; Victor Parent ; Marion Chabrol\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nAPI ; SNCF ; LASSO\n\n\nLe ‚Äúbon sens du boucher-charcutier de Tourcoing vaut-il mieux que les enqu√™tes de victimation ?‚Äù\nConrad Thiounn ; Gaston Vermersch\nhttps://github.com/cthiounn/python-datascience-ENSAE-2A\nAPI ; Open-data ; ACP ; CAH ; LASSO\n\n\nPr√©diction du revenu g√©n√©r√© par un film en fonction de ses caract√©ristiques\nDmitri Lebrun ; Corentin Pernot ; Nina Stizi\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nScrapping ; Cin√©ma ; Machine Learning\n\n\nAnalyse du r√©seau ferr√© de la SNCF: Comment expliquer les retards permanents de la compagnie fran√ßaise ?\nDiego Renaud ; Victor Parent ; Marion Chabrol\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nAPI ; SNCF ; LASSO",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#informations-additionnelles",
    "href": "content/annexes/evaluation.html#informations-additionnelles",
    "title": "Evaluation",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\nc812322\n\n\n2023-11-29 10:13:21\n\n\nlbaudin\n\n\nDates d‚Äô√©valuation (#462)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n3276558\n\n\n2023-10-17 11:09:45\n\n\nRomain Avouac\n\n\nmore example projects (#436)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n202e7dc\n\n\n2023-08-11 15:52:52\n\n\nlinogaliana\n\n\nOrder execution\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n25adfdc\n\n\n2022-09-22 16:20:12\n\n\nLino Galiana\n\n\nSlides version 2022 (#275)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\n2360ff7\n\n\n2022-08-02 16:29:57\n\n\nLino Galiana\n\n\nTest wowchemy update (#247)\n\n\n\n\n3e919f9\n\n\n2022-03-28 10:00:49\n\n\njblaval\n\n\nAjoute projet √©l√®ve (#224)\n\n\n\n\ndece5e4\n\n\n2022-03-21 10:10:39\n\n\nM√©lissa Tamine\n\n\nAjoute projet √©l√®ves (#222)\n\n\n\n\n0601666\n\n\n2022-03-21 10:05:12\n\n\nIdrissa KONKOBO\n\n\nAjoute projet √©l√®ve (#221)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6cc6d81\n\n\n2021-12-31 09:40:17\n\n\nLino Galiana\n\n\nLien pour avoir des notebooks propres\n\n\n\n\n81ce124\n\n\n2021-09-20 15:36:05\n\n\nRomain Avouac\n\n\nQuelques √©l√©ments sur la reproductibilit√© (#148)\n\n\n\n\nbf5ebc5\n\n\n2021-09-01 14:41:17\n\n\nLino Galiana\n\n\nFix problem import pynsee (#128)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n8781c83\n\n\n2021-03-05 15:32:43\n\n\nromanegajdos\n\n\nProjet GPS v√©lo (#96)\n\n\n\n\nacfb010\n\n\n2021-03-03 18:50:32\n\n\nLino Galiana\n\n\nInt√©gration d‚Äôun endroit o√π lister les projets des √©l√®ves (#95)\n\n\n\n\n72092d7\n\n\n2020-11-10 17:43:52\n\n\nLino Galiana\n\n\nAjout dates rendu\n\n\n\n\nb47e1ae\n\n\n2020-11-09 14:58:18\n\n\nLino Galiana\n\n\nSection sur l‚Äôint√©gration continue (#77)\n\n\n\n\ne644cc7\n\n\n2020-10-21 15:48:12\n\n\nLino Galiana\n\n\nActualise la partie √©valuation (#73)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#informations-additionnelles-1",
    "href": "content/annexes/evaluation.html#informations-additionnelles-1",
    "title": "Evaluation",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-04-25\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.6.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.14.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.1\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.5.0\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.1\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.1\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.0\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.1\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.4\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.15.10\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.20.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.4.24\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.8\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.0\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebcolors\n1.13\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\nc812322\n\n\n2023-11-29 10:13:21\n\n\nlbaudin\n\n\nDates d‚Äô√©valuation (#462)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n3276558\n\n\n2023-10-17 11:09:45\n\n\nRomain Avouac\n\n\nmore example projects (#436)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n202e7dc\n\n\n2023-08-11 15:52:52\n\n\nlinogaliana\n\n\nOrder execution\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n25adfdc\n\n\n2022-09-22 16:20:12\n\n\nLino Galiana\n\n\nSlides version 2022 (#275)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\n2360ff7\n\n\n2022-08-02 16:29:57\n\n\nLino Galiana\n\n\nTest wowchemy update (#247)\n\n\n\n\n3e919f9\n\n\n2022-03-28 10:00:49\n\n\njblaval\n\n\nAjoute projet √©l√®ve (#224)\n\n\n\n\ndece5e4\n\n\n2022-03-21 10:10:39\n\n\nM√©lissa Tamine\n\n\nAjoute projet √©l√®ves (#222)\n\n\n\n\n0601666\n\n\n2022-03-21 10:05:12\n\n\nIdrissa KONKOBO\n\n\nAjoute projet √©l√®ve (#221)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6cc6d81\n\n\n2021-12-31 09:40:17\n\n\nLino Galiana\n\n\nLien pour avoir des notebooks propres\n\n\n\n\n81ce124\n\n\n2021-09-20 15:36:05\n\n\nRomain Avouac\n\n\nQuelques √©l√©ments sur la reproductibilit√© (#148)\n\n\n\n\nbf5ebc5\n\n\n2021-09-01 14:41:17\n\n\nLino Galiana\n\n\nFix problem import pynsee (#128)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n8781c83\n\n\n2021-03-05 15:32:43\n\n\nromanegajdos\n\n\nProjet GPS v√©lo (#96)\n\n\n\n\nacfb010\n\n\n2021-03-03 18:50:32\n\n\nLino Galiana\n\n\nInt√©gration d‚Äôun endroit o√π lister les projets des √©l√®ves (#95)\n\n\n\n\n72092d7\n\n\n2020-11-10 17:43:52\n\n\nLino Galiana\n\n\nAjout dates rendu\n\n\n\n\nb47e1ae\n\n\n2020-11-09 14:58:18\n\n\nLino Galiana\n\n\nSection sur l‚Äôint√©gration continue (#77)\n\n\n\n\ne644cc7\n\n\n2020-10-21 15:48:12\n\n\nLino Galiana\n\n\nActualise la partie √©valuation (#73)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Evaluation"
    ]
  }
]