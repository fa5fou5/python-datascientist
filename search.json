[
  {
    "objectID": "content/annexes/corrections.html",
    "href": "content/annexes/corrections.html",
    "title": "Corrections",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink, nbviewerLink;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/tree/main`;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/blob/main/${notebook}`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n    let downloadLink;\n    if (type === \"md\") {\n        downloadLink = `[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath})`;\n    } else {\n        downloadLink = `&lt;a href=\"https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter\" alt=\"Download\"&gt;&lt;/a&gt;`;\n    }\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    let visualizeLink;\n    if (type === \"md\") {\n        visualizeLink = `[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](${nbviewerLink})`;\n    } else {\n        visualizeLink = `&lt;a href=\"${nbviewerLink}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter\" alt=\"nbviewer\"&gt;&lt;/a&gt;`;\n    }\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink, downloadLink,\n        visualizeLink, sspcloudJupyterLink,\n        sspcloudVscodeLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink, vscodeLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nSeules les chapitres dont les corrections ne sont pas apparentes sont listés sur cette page."
  },
  {
    "objectID": "content/annexes/corrections.html#partie-1-manipuler-des-données",
    "href": "content/annexes/corrections.html#partie-1-manipuler-des-données",
    "title": "Corrections",
    "section": "Partie 1: manipuler des données",
    "text": "Partie 1: manipuler des données\n\nRetour sur Numpy\n\n\nhtml`${printBadges({fpath: \"content/manipulation/01_numpy.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices Pandas\n\n\nhtml`${printBadges({fpath: \"content/manipulation/02b_pandas_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices Geopandas :\n\n\nhtml`${printBadges({fpath: \"content/manipulation/03_geopandas_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices webscraping\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04a_webscraping_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices expressions régulières\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04b_regex_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices API\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04c_API_TP.qmd\", correction: true})}`"
  },
  {
    "objectID": "content/annexes/corrections.html#partie-2-visualiser-les-données",
    "href": "content/annexes/corrections.html#partie-2-visualiser-les-données",
    "title": "Corrections",
    "section": "Partie 2: visualiser les données",
    "text": "Partie 2: visualiser les données\n\nExercices graphiques classiques\n\n\nhtml`${printBadges({fpath: \"content/manipulation/matplotlib.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la cartographie\n\n\nhtml`${printBadges({fpath: \"content/manipulation/maps.qmd\", correction: true})}`"
  },
  {
    "objectID": "content/annexes/corrections.html#partie-3-modéliser",
    "href": "content/annexes/corrections.html#partie-3-modéliser",
    "title": "Corrections",
    "section": "Partie 3: modéliser",
    "text": "Partie 3: modéliser\n\nExercices sur le preprocessing\n\n\nhtml`${printBadges({fpath: \"content/manipulation/0_preprocessing.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur l’évaluation des modèles\n\n\nhtml`${printBadges({fpath: \"content/manipulation/1_modelevaluation.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la classification\n\n\nhtml`${printBadges({fpath: \"content/manipulation/2_SVM.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la régression\n\n\nhtml`${printBadges({fpath: \"content/manipulation/3_regression.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la sélection de variables\n\n\nhtml`${printBadges({fpath: \"content/manipulation/4_featureselection.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur le clustering\n\n\nhtml`${printBadges({fpath: \"content/manipulation/5_clustering.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur les pipelines\n\n\nhtml`${printBadges({fpath: \"content/manipulation/6_pipeline.qmd\", correction: true})}`"
  },
  {
    "objectID": "content/annexes/corrections.html#partie-4-natural-language-processing-nlp",
    "href": "content/annexes/corrections.html#partie-4-natural-language-processing-nlp",
    "title": "Corrections",
    "section": "Partie 4: Natural Language Processing (NLP)",
    "text": "Partie 4: Natural Language Processing (NLP)\nCorrections à venir\n\nhtml`${printBadges({fpath: \"content/manipulation/01_intro.qmd\", correction: true})}`\n\n\n\n\n\n\n\nhtml`${printBadges({fpath: \"content/manipulation/02_exoclean.qmd\", correction: true})}`\n\n\n\n\n\n\n\nhtml`${printBadges({fpath: \"content/manipulation/03_lda.qmd\", correction: true})}`\n\n\n\n\n\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04_word2vec.qmd\", correction: true})}`\n\n\n\n\n\n\n\nhtml`${printBadges({fpath: \"content/manipulation/05_exo_supp.qmd\", correction: true})}`"
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html",
    "href": "content/getting-started/07_rappels_classes.html",
    "title": "Les classes en Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink, nbviewerLink;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/tree/main`;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/blob/main/${notebook}`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n    let downloadLink;\n    if (type === \"md\") {\n        downloadLink = `[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath})`;\n    } else {\n        downloadLink = `&lt;a href=\"https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter\" alt=\"Download\"&gt;&lt;/a&gt;`;\n    }\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    let visualizeLink;\n    if (type === \"md\") {\n        visualizeLink = `[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](${nbviewerLink})`;\n    } else {\n        visualizeLink = `&lt;a href=\"${nbviewerLink}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter\" alt=\"nbviewer\"&gt;&lt;/a&gt;`;\n    }\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink, downloadLink,\n        visualizeLink, sspcloudJupyterLink,\n        sspcloudVscodeLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink, vscodeLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}"
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#quest-ce-que-la-programmation-orientée-objet",
    "href": "content/getting-started/07_rappels_classes.html#quest-ce-que-la-programmation-orientée-objet",
    "title": "Les classes en Python",
    "section": "Qu’est-ce que la programmation orientée objet ?",
    "text": "Qu’est-ce que la programmation orientée objet ?\nLe langage Python se base sur des objets et définit pour eux des actions.\nSelon le type d’objet, les actions seront différentes.\nOn parle à ce propos de langage orienté objet ce qui signifie\nque la syntaxe du langage Python permet de définir de manière conceptuelle\ndes objets et appliquer des traitements cohérents avec leur structure interne.\nPar exemple,\npour manipuler des données textuelles ou numériques, on aura\nbesoin d’appliquer des méthodes différentes. Prenons l’exemple\nde l’opération +. Pour des données numériques, il s’agit\nde l’addition. Pour des données textuelles, l’addition n’a pas de sens\nmais on peut envisager d’appliquer cette opération pour faire de la\nconcaténation.\nChaque type d’objet se verra donc appliquer des actions\nadaptées. Cela offre une grande flexibilité au langage Python car on\npeut définir une méthode générique (par exemple l’addition) et l’adapter\nà différents types d’objets.\nLe fait que Python soit un langage orienté objet a une influence sur la\nsyntaxe. On retrouvera régulière la syntaxe objet.method qui est au coeur\nde Python. Par exemple pd.DataFrame.mean se traduit par\nappliquer la méthode mean a un objet de type pd.DataFrame.\n\nQuand utilise-t-on cela dans le domaine de la data science ?\nLes réseaux de neurones programmés avec Keras ou PyTorch fonctionnent de\ncette manière. On part d’une structure de base et modifie les attributs (par\nexemple le nombre de couches) ou les méthodes."
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#la-définition-dun-objet",
    "href": "content/getting-started/07_rappels_classes.html#la-définition-dun-objet",
    "title": "Les classes en Python",
    "section": "La définition d’un objet",
    "text": "La définition d’un objet\nPour définir un objet, il faut lui donner des caractéristiques et des actions, ce qu’il est, ce qu’il peut faire.\nAvec une liste, on peut ajouter des éléments par exemple avec l’action .append(). On peut créer autant d’objets “liste” qu’on le souhaite.\nUne classe regroupe des fonctions et des attributs qui définissent un objet.\nUn objet est une instance d’une classe, c’est-à-dire un exemplaire issu de la classe. L’objet avec un comportement et un état, tous deux définis par la classe. On peut créer autant d’objets que l’on désire avec une classe donnée.\nIci nous allons essayer de créer une classe chat, avec des attributs pour caractériser le chat et des actions, pour voir ce qu’il peut faire avec un objet de la classe chat."
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#exemple-la-classe-chat",
    "href": "content/getting-started/07_rappels_classes.html#exemple-la-classe-chat",
    "title": "Les classes en Python",
    "section": "Exemple : la Classe chat()",
    "text": "Exemple : la Classe chat()\n\nLes attributs de la classe chat\n\nClasse chat version 1 - premiers attributs\nOn veut pouvoir créer un objet chat() qui nous permettra à terme de créer une colonie de chats (on sait\njamais ca peut servir …).\nPour commencer, on va définir un chat avec des attributs de base : une couleur et un nom.\n\nclass chat: # Définition de notre classe chat\n    \"\"\"Classe définissant un chat caractérisé par :\n    - son nom\n    - sa couleur \"\"\"\n    \n    def __init__(self): # Notre méthode constructeur - \n        # self c'est notre objet qu'on est en train de créer\n        \"\"\"Pour l'instant, on ne va définir que deux attributs - nom et couleur \"\"\"\n        self.couleur = \"Noir\"   \n        self.nom = \"Aucun nom\"\n\n\nmon_chat = chat()\n\nprint(type(mon_chat), mon_chat.couleur ,\",\", mon_chat.nom) \n\n&lt;class '__main__.chat'&gt; Noir , Aucun nom\n\n\nOn nous dit bien que Mon chat est défini à partir de la classe chat,\nc’est ce que nous apprend la fonction type.\nPour l’instant il n’a pas de nom\n\n\nClasse chat version 2 - autres attributs\nAvec un nom et une couleur, on ne va pas loin. On peut continuer à définir des attributs pour la classe chat\nde la même façon que précédemment.\n\nclass chat: # Définition de notre classe chat\n    \"\"\"Classe définissant un chat caractérisé par :\n    - sa couleur\n    - son âge\n    - son caractère\n    - son poids\n    - son maitre\n    - son nom \"\"\"\n\n    \n    def __init__(self): # Notre méthode constructeur - \n        #self c'est notre objet qu'on est en train de créer\n        self.couleur = \"Noir\"    \n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        self.nom = \"Aucun nom\"\n\n\nhelp(chat) \n# si on veut savoir ce que fait la classe \"chat\" on appelle l'aide\n\nHelp on class chat in module __main__:\n\nclass chat(builtins.object)\n |  Classe définissant un chat caractérisé par :\n |  - sa couleur\n |  - son âge\n |  - son caractère\n |  - son poids\n |  - son maitre\n |  - son nom\n |  \n |  Methods defined here:\n |  \n |  __init__(self)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n\n\n\nmon_chat = chat()\nprint(\"L'âge du chat est\", mon_chat.age,\"ans\") \n# on avait défini l'attribut age de la classe chat comme étant égal à 10\n#, si on demande l'attribut age de notre Martin on obtient 10\n\nL'âge du chat est 10 ans\n\n\nPar défaut, les attributs de la classe Chat seront toujours les mêmes à chaque création de chat à partir\nde la classe Chat.\nMais une fois qu’une instance de classe est créée (ici mon chat est une instance de classe) on peut décider\nde changer la valeur de ses attributs.\n\n\nUn nouveau poids\n\nprint(mon_chat.poids)\n# si on veut changer le poids de mon chat, parce qu'il a un peu grossi après les fêtes\nmon_chat.poids = 3.5\nprint(mon_chat.poids) # maintenant le poids est 3.5\n\n3\n3.5\n\n\n\n\nUn nouveau nom\n\n# on veut aussi lui donner un nom \nmon_chat.nom = \"Martin\"\nmon_chat.nom\n\n'Martin'\n\n\n\n\nUne autre instance de la classe Chat\nOn peut aussi créer d’autres objets chat à partir de la classe chat :\n\n# on appelle la classe\nl_autre_chat = chat()\n# on change les attributs qui nous intéressent\nl_autre_chat.nom = \"Ginette\"\nl_autre_chat.maitre = \"Roger\"\n# les attributs inchangés donnent la même chose \n# que ceux définis par défaut pour la classe\nprint(l_autre_chat.couleur)\n\nNoir\n\n\n\n\n\nLes méthodes de la classe chat\nLes attributs sont des variables propres à notre objet, qui servent à le caractériser.\nLes méthodes sont plutôt des actions, comme nous l’avons vu dans la partie précédente, agissant sur l’objet.\nPar exemple, la méthode append de la classe list permet d’ajouter un élément dans l’objet list manipulé.\n\nClasse chat version 3 - première méthode\nOn peut définir une première méthode : nourrir\n\nclass chat: # Définition de notre classe chat\n    \"\"\"Classe définissant un chat caractérisé par :\n    - sa couleur\n    - son âge\n    - son caractère\n    - son poids\n    - son maitre\n    - son nom \n    \n    L'objet chat a une méthode : nourrir \"\"\"\n\n    \n    def __init__(self): # Notre méthode constructeur - \n        #self c'est notre objet qu'on est en train de créer\n        self.couleur = \"Noir\"    \n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        self.nom = \"Aucun nom\"\n        \n        \"\"\"Par défaut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n        \n    def nourrir(self, nourriture):\n        \"\"\"Méthode permettant de donner à manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"       \n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n\nmon_chat = chat()\nmon_chat.nom = \"Martin\"\nmon_chat.ventre # On n'a rien donné à Martin, son ventre est vide\n\n''\n\n\n\n# on appelle la méthode \"nourrir\" de la classe chat, \n# on lui donne un élément, ici des croquettes\nmon_chat.nourrir('Croquettes')\nprint(\"Le contenu du ventre de martin : \",mon_chat.ventre)\n\nLe contenu du ventre de martin :  Croquettes\n\n\n\nmon_chat.nourrir('Saumon')\nprint(\"Le contenu du ventre de martin : \",mon_chat.ventre)\n\nLe contenu du ventre de martin :  Croquettes,Saumon\n\n\n\n\nClasse chat version 4 - autre méthode\nAvec un chat, on peut imaginer plein de méthodes. Ici on va définir une action “nourrir” et une autre action\n“litiere”, qui consiste à vider l’estomac du chat.\n\nclass chat: # Définition de notre classe Personne\n    \"\"\"Classe définissant un chat caractérisé par :\n    - sa couleur\n    - son âge\n    - son caractère\n    - son poids\n    - son maitre\n    - son nom \n    \n    L'objet chat a deux méthodes : nourrir et litiere \"\"\"\n\n    \n    def __init__(self): # Notre méthode constructeur - \n        #self c'est notre objet qu'on est en train de créer\n        self.nom = \"\"\n        self.couleur = \"Roux\"    \n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        \"\"\"Par défaut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n        \n    def nourrir(self, nourriture):\n        \"\"\"Méthode permettant de donner à manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"       \n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n    def litiere(self) : \n        \"\"\" Méthode permettant au chat d'aller à sa litière : \n        en conséquence son ventre est vide \"\"\"       \n        self.ventre = \"\"\n        print(self.nom,\"a le ventre vide\")\n\n\n# on définit Martin le chat\nmon_chat = chat()\nmon_chat.nom = \"Martin\"\n# on le nourrit avec des croquettes\nmon_chat.nourrir('croquettes')\nprint(\"Le contenu du ventre de martin\", mon_chat.ventre)\n\n\n# Il va dans sa litiere\nmon_chat.litiere()\n\nLe contenu du ventre de martin croquettes\nMartin a le ventre vide\n\n\n\nhelp(mon_chat.nourrir)\nhelp(mon_chat.litiere)\n\nHelp on method nourrir in module __main__:\n\nnourrir(nourriture) method of __main__.chat instance\n    Méthode permettant de donner à manger au chat.\n    Si le ventre n'est pas vide, on met une virgule avant de rajouter\n    la nourriture\n\nHelp on method litiere in module __main__:\n\nlitiere() method of __main__.chat instance\n    Méthode permettant au chat d'aller à sa litière : \n    en conséquence son ventre est vide\n\n\n\n\n\nLes méthodes spéciales (facultatif)\nSi on reprend notre classe chat, il y a en réalité des méthodes spéciales que nous n’avons pas définies mais\nqui sont implicites.\nPython comprend seul ce que doivent faire ces méthodes. Il a une idée préconcue de ce qu’elles doivent\neffectuer comme opération. Si vous ne redéfinissez par une méthode spéciale pour qu’elle fasse ce que vous\nsouhaitez, ca peut donner des r\u0013esultats inattendus.\nElles servent à plusieurs choses :\n\nà initialiser l’objet instancié : __init__\nà modifier son affichage : __repr__\n\n\n\n# pour avoir la valeur de l'attribut \"nom\"\n\nprint(mon_chat.__getattribute__(\"nom\"))\n# on aurait aussi pu faire plus simple :\nprint(mon_chat.nom)\n\nMartin\nMartin\n\n\n# si l'attribut n'existe pas : on a une erreur\n# Python recherche l'attribut et, s'il ne le trouve pas dans l'objet et si une méthode __getattr__ est spécifiée, \n# il va l'appeler en lui passant en paramètre le nom de l'attribut recherché, sous la forme d'une chaîne de caractères.\n\nprint(mon_chat.origine)\n## Error in py_call_impl(callable, dots$args, dots$keywords): AttributeError: 'chat' object has no attribute 'origine'\n## \n## Detailed traceback: \n##   File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nMais on peut modifier les méthodes spéciales de notre classe chat pour éviter d’avoir des erreurs d’attributs. On va aussi en profiter pour modifier la représentation de l’instance chat qui pour l’instant donne &lt;_main_.chat object at 0x0000000005AB4C50&gt;\n\n\nClasse chat version 5 - méthode spéciale\n\nclass chat: # Définition de notre classe Personne\n    \"\"\"Classe définissant un chat caractérisé par :\n    - sa couleur\n    - son âge\n    - son caractère\n    - son poids\n    - son maitre\n    - son nom \n    \n    L'objet chat a deux méthodes : nourrir et litiere \"\"\"\n\n    \n    def __init__(self): # Notre méthode constructeur - \n        #self c'est notre objet qu'on est en train de créer\n        self.nom = \"\"\n        self.couleur = \"Roux\"    \n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        \"\"\"Par défaut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n        \n    def nourrir(self, nourriture):\n        \"\"\"Méthode permettant de donner à manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"       \n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n    def litiere(self) : \n        \"\"\" Méthode permettant au chat d'aller à sa litière : \n        en conséquence son ventre est vide \"\"\"       \n        self.ventre = \"\"\n        print(self.nom,\"a le ventre vide\")\n    \n    def __getattribute__(self, key):\n            return print(key,\"n'est pas un attribut de la classe chat\")   \n            \n    def __repr__(self):\n            return \"Je suis une instance de la classe chat\"\n\n\n# j'ai gardé l'exemple chat défini selon la classe version 4\n# Martin, le chat\n# on a vu précédemment qu'il n'avait pas d'attribut origine\n# et que cela levait une erreur AttributeError\nprint(mon_chat.nom)\n\n\n# on va définir un nouveau chat avec la version 5\n# on appelle à nouveau un attribut qui n'existe pas \"origine\"\n# on a bien le message défini par la méthode spéciale _gettattribute\n\nmon_chat_nouvelle_version = chat()\nmon_chat_nouvelle_version.origine\n\n# Maintenant on a aussi une définition de l'objet plus clair\nprint(mon_chat)\nprint(mon_chat_nouvelle_version)\n\nMartin\norigine n'est pas un attribut de la classe chat\n&lt;__main__.chat object at 0x7fd794ce55e0&gt;\nJe suis une instance de la classe chat\n\n\n\n\n\n\nConclusion sur les classes : ce qu’on retient\n\nLes méthodes se définissent comme des fonctions, sauf qu’elles se trouvent dans le corps de la classe.\nOn définit les attributs d’une instance dans le constructeur de sa classe, en suivant cette syntaxe : self.nom_attribut = valeur.\nfacultatif : Les méthodes d’instance prennent en premier paramètre “self”, l’instance de l’objet manipulé.\nfacultatif : On construit une instance de classe en appelant son constructeur, une méthode d’instance appelée init."
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html",
    "href": "content/getting-started/05_rappels_types.html",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink, nbviewerLink;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/tree/main`;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/blob/main/${notebook}`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n    let downloadLink;\n    if (type === \"md\") {\n        downloadLink = `[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath})`;\n    } else {\n        downloadLink = `&lt;a href=\"https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter\" alt=\"Download\"&gt;&lt;/a&gt;`;\n    }\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    let visualizeLink;\n    if (type === \"md\") {\n        visualizeLink = `[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](${nbviewerLink})`;\n    } else {\n        visualizeLink = `&lt;a href=\"${nbviewerLink}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter\" alt=\"nbviewer\"&gt;&lt;/a&gt;`;\n    }\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink, downloadLink,\n        visualizeLink, sspcloudJupyterLink,\n        sspcloudVscodeLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink, vscodeLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nPandas et Numpy sont\nessentiels pour manipuler les données.\nNéanmoins, il est nécessaire de ne pas faire l’impasse sur les fondements\ndu langage Python. Une bonne compréhension des éléments structurants le\nlangage entraîne une plus grande productivité et liberté.\nCe chapitre est inspiré du matériel qui était proposé\npar Xavier Dupré,\nle précédent professeur de ce cours.\nVoir aussi Essential Cheat Sheets for Machine Learning and Deep Learning Engineers."
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-quelques-règles-de-python",
    "href": "content/getting-started/05_rappels_types.html#les-quelques-règles-de-python",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Les quelques règles de Python",
    "text": "Les quelques règles de Python\nPython est un peu susceptible et protocolaire, plus formaliste que ne l’est R.\nIl y a ainsi quelques règles à respecter :\nRègle 1: L’indentation est primordiale : un code mal indenté provoque une erreur.\nL’indentation indique à l’interpréteur où se trouvent les\nséparations entre des blocs d’instructions. Un peu comme des points dans un\ntexte.\nSi les lignes ne sont pas bien alignées, l’interpréteur ne sait plus à quel\nbloc associer la ligne. Par exemple, le corps d’une fonction doit être indenté\nd’un niveau ; les éléments dans une clause logique (if, else, etc.) également.\nRègle 2: On commence à compter à 0, comme dans beaucoup de langages\n(C++, java…). Python diffère dans ce domaine de R où on commence\nà compter à 1.\nLe premier élément d’une liste est ainsi, en Python, le 0-ème.\nRègle 3: Comme dans une langue naturelle, les marques de\nponctuation sont importantes :\n\nPour une liste : []\nPour un dictionnaire : {}\nPour un tuple : ()\nPour séparer des éléments : ,\nPour commenter un bout de code : #\nPour aller à la ligne dans un bloc d’instructions : \\\nLes majuscules et minuscules sont importantes\nPar contre l’usage des ' ou des \" est indifférent.\nIl faut juste avoir les mêmes début et fin.\nPour documenter une fonction ou une classe ““” mon texte de documentation “““"
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-outputs-de-python-lopération-le-print-et-le-return",
    "href": "content/getting-started/05_rappels_types.html#les-outputs-de-python-lopération-le-print-et-le-return",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Les outputs de Python : l’opération, le print et le return",
    "text": "Les outputs de Python : l’opération, le print et le return\nQuand Python réalise des opérations, il faut lui préciser ce qu’il doit en faire :\n\nest-ce qu’il doit juste faire l’opération,\nafficher le résultat de l’opération,\ncréer un objet avec le résultat de l’opération ?\n\n\n\n Note\nDans l’environnement Jupyter Notebook, le dernier élement d’une cellule\nest automatiquement affiché (print), qu’on lui demande ou non de le faire.\nCe comportement est particulièrement pratique pour afficher des figures\ngénérées via matplotlib ou seaborn.\nCe comportement\nn’est pas le cas dans un éditeur classique comme VisualStudio,\nSpyder ou PyCharm. Pour afficher un résultat dans la console,\nil faut utiliser\nprint ou la commande consacrée (par exemple plt.show()\npour afficher la dernière figure générée par matplotlib)\n\n\n\nLe print\n\n# on calcule : dans le cas d'une opération par exemple une somme\n2+3 # Python calcule le résultat mais n'affiche rien dans la sortie\n\n# le print : on affiche\n\nprint(2+3) # Python calcule et on lui demande juste de l'afficher\n# le résultat est en dessous du code\n\n5\n\n\n\n# le print dans une fonction \n\ndef addition_v1(a,b) : \n    print(a+b)\n\nresultat_print = addition_v1(2,0) \nprint(type(resultat_print))\n\n# dans la sortie on a l'affichage du résultat, car la sortie de la fonction est un print \n# en plus on lui demande quel est le type du résultat. Un print ne renvoie aucun type, ce n'est ni un numérique,\n# ni une chaine de charactères, le résultat d'un print n'est pas un format utilisable\n\n2\n&lt;class 'NoneType'&gt;\n\n\nLe résultat de l’addition est affiché\ncar la fonction addition_v1 effectue un print\nPar contre, l’objet créé n’a pas de type, il n’est pas un chiffre,\nce n’est qu’un affichage.\n\n\nLe return\nPour créer un objet avec le résultat de la fonction, il faut utiliser return\n\n# le return dans une fonction\ndef addition_v2(a,b) : \n    return a+b\n\nresultat_return = addition_v2(2,5) # \nprint(type(resultat_return))\n## là on a bien un résultat qui est du type \"entier\"\n\n&lt;class 'int'&gt;\n\n\nLe résultat de addition_v2 n’est pas affiché comme dans addition_v1\nPar contre, la fonction addition_v2 permet d’avoir un objet de type int,\nun entier donc."
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-types-de-base-variables-listes-dictionnaires",
    "href": "content/getting-started/05_rappels_types.html#les-types-de-base-variables-listes-dictionnaires",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Les types de base : variables, listes, dictionnaires…",
    "text": "Les types de base : variables, listes, dictionnaires…\nPython permet de manipuler différents types de base. Nous en\nverrons des extensions dans la suite du cours (np.array par exemple)\nqui, d’une manière ou d’une autre, s’appuient sur ces types de base.\nOn distingue deux types de variables : les immuables (immutables)\nqui ne peuvent être\nmodifiés et les modifiables (mutables)\n\nLes variables immuables\nLes variables immuables ne peuvent être modifiées\n\nNone : ce type est une convention de programmation pour dire que la valeur n’est pas calculée\nbool : un booléen\nint : un entier\nfloat : un réel\nstr : une chaine de caractères\ntuple : un vecteur\n\n\ni = 3         # entier = type numérique (type int)\nr = 3.3       # réel   = type numérique (type float)\ns = \"exemple\" # chaîne de caractères = type str \nn = None      # None signifie que la variable existe mais qu'elle ne contient rien\n              # elle est souvent utilisée pour signifier qu'il n'y a pas de résultat\na = (1,2)     # tuple\n\nprint(i,r,s,n,a)         \n\n3 3.3 exemple None (1, 2)\n\n\nSi on essaie de changer le premier élément de la chaine de caractères s on va avoir un peu de mal.\nPar exemple si on voulait mettre une majuscule à “exemple”,\non aurait envie d’écrire que le premier élément de la chaine s est “E” majuscule\nMais Python ne va pas nous laisser faire, il nous dit que les objets “chaine de caractère” ne peuvent être modifiés\n\ns[0] = \"E\"  # déclenche une exception\n\nTypeError: 'str' object does not support item assignment\n\n\nTout ce qu’on peut faire avec une variable immuable,\nc’est la réaffecter à une autre valeur : elle ne peut pas être modifiée.\nPour s’en convaincre, utilisons la fonction id() qui donne un identifiant à chaque objet.\n\nprint(s)\nid(s)\n\nexemple\n\n\n140625225748400\n\n\n\ns = \"autre_mot\"\nid(s)\n\n140623983340080\n\n\nOn voit bien que s a changé d’identifiant : il peut avoir le même nom, ce n’est plus le même objet\n\n\nLes types modifiable : listes et dictionnaires\nHeureusement, il existe des variables modifiables comme les listes et les dictionnaires.\n\nLes listes - elles s’écrivent entre [ ]\nLes listes sont des élements très utiles, notamment quand vous souhaitez faire des boucles.\nPour faire appel aux élements d’une liste, on donne leur position dans la liste : le 1er est le 0, le 2ème est le 1 …\n\nma_liste = [1,2,3,4]\n\n\nprint(\"La longueur de ma liste est de\", len(ma_liste))\nprint(\"Le premier élément de ma liste est :\", ma_liste[0])\nprint(\"Le dernier élément de ma liste est :\", ma_liste[3])\nprint(\"Le dernier élément de ma liste est :\", ma_liste[-1])\n\nLa longueur de ma liste est de 4\nLe premier élément de ma liste est : 1\nLe dernier élément de ma liste est : 4\nLe dernier élément de ma liste est : 4\n\n\nPour effectuer des boucles sur les listes, la méthode la plus lisible\nest d’utiliser les list comprehension. Cette approche consiste\nà itérer les éléments d’une liste à la volée.\nPar exemple, si on reprend cet exemple,\nun code qui repose sur les list comprehension sera le suivant :\n\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = [x for x in fruits if \"a\" in x]\nprint(newlist)\n\n['apple', 'banana', 'mango']\n\n\nLe même code, ne reposant pas sur les compréhensions de liste, sera beaucoup\nmoins concis et ainsi inutilement verbeux:\n\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = []\n\nfor x in fruits:\n  if \"a\" in x:\n    newlist.append(x)\n\nprint(newlist) \n\n['apple', 'banana', 'mango']\n\n\n\n\nLes dictionnaires - ils s’écrivent entre accolades {}\nUn dictionnaire associe à une clé un autre élément, appelé une valeur : un chiffre, un nom, une liste, un autre dictionnaire etc.\nLe format d’un dictionnaire est le suivant : {Clé : valeur}. Il s’agit\nd’un objet très pratique pour la recherche, beaucoup plus que les listes\nqui ne permettent pas de stocker de l’information diverse de manière\nhiérarchisée.\n\n\nDictionnaire avec des valeurs int\nOn peut par exemple associer à un nom, un nombre\n\nmon_dictionnaire_notes = { 'Nicolas' : 18 , 'Pimprenelle' : 15} \n# un dictionnaire qui à chaque nom associe un nombre\n# à Nicolas, on associe 18\n\nprint(mon_dictionnaire_notes) \n\n{'Nicolas': 18, 'Pimprenelle': 15}\n\n\n\n\nDictionnaire avec des valeurs qui sont des listes\nPour chaque clé d’un dictionnaire, il ne faut pas forcément garder la même forme de valeur\nDans l’exemple, la valeur de la clé “Nicolas” est une liste, alors que celle de “Philou” est une liste de liste\n\nmon_dictionnaire_loisirs =  \\\n{ 'Nicolas' : ['Rugby','Pastis','Belote'] , \n  'Pimprenelle' : ['Gin Rami','Tisane','Tara Jarmon','Barcelone','Mickey Mouse'],\n  'Philou' : [['Maths','Jeux'],['Guillaume','Jeanne','Thimothée','Adrien']]}\n\nPour accéder à un élément du dictionnaire, on fait appel à la clé et non plus à la position, comme c’était le cas dans les listes.\nC’est beaucoup plus pratique pour rechercher de l’information:\n\nprint(mon_dictionnaire_loisirs['Nicolas']) # on affiche une liste\n\n['Rugby', 'Pastis', 'Belote']\n\n\n\nprint(mon_dictionnaire_loisirs['Philou']) # on affiche une liste de listes\n\n[['Maths', 'Jeux'], ['Guillaume', 'Jeanne', 'Thimothée', 'Adrien']]\n\n\nSi on ne veut avoir que la première liste des loisirs de Philou, on demande le premier élément de la liste\n\nprint(mon_dictionnaire_loisirs['Philou'][0]) # on affiche alors juste la première liste\n\n['Maths', 'Jeux']\n\n\nOn peut aussi avoir des valeurs qui sont des int et des list\n\nmon_dictionnaire_patchwork_good = \\\n{ 'Nicolas' : ['Rugby','Pastis','Belote'] ,\n  'Pimprenelle' : 18 }\n\n\n\n\nA retenir\n\nL’indentation du code est importante (4 espaces et pas une tabulation)\nUne liste est entre [] et on peut appeler les positions par leur place\nUn dictionnaire, clé x valeur, s’écrit entre {} et on appelle un élément en fonction de la clé"
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#questions-pratiques",
    "href": "content/getting-started/05_rappels_types.html#questions-pratiques",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Questions pratiques :",
    "text": "Questions pratiques :\n\n\n\n Exercice\n\nQuelle est la position de 7 dans la liste suivante\n\n\nliste_nombres = [1,2,7,5,3]\n\n\nCombien de clés a ce dictionnaire ?\n\n\ndictionnaire_evangile = {\"Marc\" : \"Lion\", \"Matthieu\" : [\"Ange\",\"Homme ailé\"] , \n                          \"Jean\" : \"Aigle\" , \"Luc\" : \"Taureau\"}\n\n\nQue faut-il écrire pour obtenir “Ange” en résultat à partir du dictionnaire_evangile ?"
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#effectuer-des-opérations-sur-les-objets-de-base-python",
    "href": "content/getting-started/05_rappels_types.html#effectuer-des-opérations-sur-les-objets-de-base-python",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Effectuer des opérations sur les objets de base Python",
    "text": "Effectuer des opérations sur les objets de base Python\nMaintenant qu’on a vu quels objets existent en Python,\nnous allons\nvoir comment nous en servir.\nPour comprendre comment modifier un objet, il convient\nde distinguer deux concepts, développés plus amplement\ndans le chapitre dédié : les attributs et les méthodes :\n\nLes attributs décrivent la structure interne d’un objet. Par exemple,\nla taille d’un objet, sa langue, etc.\nNous n’allons pas trop développer ce concept ici. Le chapitre dédié au sujet\npermettra de plus développer ce concept.\nLes méthodes correspondent à des actions qui s’appliqueront à l’objet et s’adaptent à sa structure.\nLa même méthode (par exemple append) fonctionnera ainsi de manière différente selon le type d’objet.\n\n\nPremiers exemples de méthodes\nAvec les éléments définis dans la partie 1\n(les listes, les dictionnaires) on peut faire appel à des méthodes qui sont directement liées à ces objets.\n\nUne méthode pour les listes\nPour ajouter un élément (item) dans une liste : on va utiliser la méthode .append()\n\nma_liste = [\"Nicolas\",\"Michel\",\"Bernard\"]\n\nma_liste.append(\"Philippe\")\n\nprint(ma_liste)\n\n['Nicolas', 'Michel', 'Bernard', 'Philippe']\n\n\n\n\nUne méthode pour les dictionnaires\nPour connaitre l’ensemble des clés d’un dictionnaire, on appelle la méthode .keys()\n\nmon_dictionnaire = {\"Marc\" : \"Lion\", \"Matthieu\" : [\"Ange\",\"Homme ailé\"] , \n                          \"Jean\" : \"Aigle\" , \"Luc\" : \"Taureau\"}\n\nprint(mon_dictionnaire.keys())\n\ndict_keys(['Marc', 'Matthieu', 'Jean', 'Luc'])\n\n\n\n\n\nConnaitre les méthodes d’un objet\nPour savoir quelles sont les méthodes d’un objet vous pouvez :\n\ntaper help(mon_objet) ou mon_objet? dans la console Python\ntaper mon_objet. + touche tabulation dans la console Python ou dans le Notebook.\nPython permet la complétion, c’est-à-dire que vous pouvez faire appaître la liste\ndes méthodes possibles."
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-opérations-et-méthodes-classiques-des-listes",
    "href": "content/getting-started/05_rappels_types.html#les-opérations-et-méthodes-classiques-des-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Les opérations et méthodes classiques des listes",
    "text": "Les opérations et méthodes classiques des listes\n\nCréer une liste\nPour créer un objet de la classe list, il suffit de le déclarer. Ici on affecte à x une liste\n\nx = [4, 5] # création d’une liste composée de deux entiers\nx = [\"un\", 1, \"deux\", 2] # création d’une liste composée de 2 chaînes de caractères\n# et de deux entiers, l’ordre d’écriture est important\nx = [3] # création d’une liste d’un élément, sans la virgule,\nx = [ ] # crée une liste vide\nx = list () # crée une liste vide\n\n\n\nUn premier test sur les listes\nSi on veut tester la présence d’un élément dans une liste, on l’écrit de la manière suivante :\n\n# Exemple \n\nx = \"Marcel\"\n\nl = [\"Marcel\",\"Edith\",\"Maurice\",\"Jean\"]\n\nprint(x in l)\n\n#vrai si x est un des éléments de l\n\nTrue\n\n\n\n\n+: une méthode pour concaténer deux listes\nOn utilise le symbole +\n\nt = [\"Antoine\",\"David\"]\nprint(l + t) #concaténation de l et t\n\n['Marcel', 'Edith', 'Maurice', 'Jean', 'Antoine', 'David']\n\n\n\n\nPour trouver certains éléments d’une liste\nPour chercher des élements dans une liste, on utilise la position dans la liste.\n\nl[1] # donne l'élément qui est en 2ème position de la liste\n\n'Edith'\n\n\n\nl[1:3] # donne les éléments de la 2ème position de la liste à la 4ème exclue\n\n['Edith', 'Maurice']\n\n\n\n\nQuelques fonctions des listes\nLes listes embarquent ainsi nativement un certain nombre de méthodes\nqui sont pratiques. Cependant, pour avoir certaines informations\nsur une liste, il faut parfois plutôt passer par\ndes fonctions natives comme les suivantes :\n\nlongueur = len(l) # nombre d’éléments de l\nminimum = min(l) # plus petit élément de l, ici par ordre alphabétique\nmaximum = max(l) # plus grand élément de l, ici par ordre alphabétique\nprint(longueur,minimum,maximum)\n\n4 Edith Maurice\n\n\n\ndel l[0 : 2] # supprime les éléments entre la position 0 et 2 exclue\nprint(l)\n\n['Maurice', 'Jean']\n\n\n\n\nLes méthodes des listes\nOn les trouve dans l’aide de la liste.\nOn distingue les méthodes et les méthodes spéciales : visuellement,\nles méthodes spéciales sont celles qui précédées et suivis de deux caractères de soulignement,\nles autres sont des méthodes classiques.\n\nhelp(l)\n\nHelp on list object:\n\nclass list(object)\n |  list(iterable=(), /)\n |  \n |  Built-in mutable sequence.\n |  \n |  If no argument is given, the constructor creates a new empty list.\n |  The argument must be an iterable if specified.\n |  \n |  Methods defined here:\n |  \n |  __add__(self, value, /)\n |      Return self+value.\n |  \n |  __contains__(self, key, /)\n |      Return key in self.\n |  \n |  __delitem__(self, key, /)\n |      Delete self[key].\n |  \n |  __eq__(self, value, /)\n |      Return self==value.\n |  \n |  __ge__(self, value, /)\n |      Return self&gt;=value.\n |  \n |  __getattribute__(self, name, /)\n |      Return getattr(self, name).\n |  \n |  __getitem__(...)\n |      x.__getitem__(y) &lt;==&gt; x[y]\n |  \n |  __gt__(self, value, /)\n |      Return self&gt;value.\n |  \n |  __iadd__(self, value, /)\n |      Implement self+=value.\n |  \n |  __imul__(self, value, /)\n |      Implement self*=value.\n |  \n |  __init__(self, /, *args, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __iter__(self, /)\n |      Implement iter(self).\n |  \n |  __le__(self, value, /)\n |      Return self&lt;=value.\n |  \n |  __len__(self, /)\n |      Return len(self).\n |  \n |  __lt__(self, value, /)\n |      Return self&lt;value.\n |  \n |  __mul__(self, value, /)\n |      Return self*value.\n |  \n |  __ne__(self, value, /)\n |      Return self!=value.\n |  \n |  __repr__(self, /)\n |      Return repr(self).\n |  \n |  __reversed__(self, /)\n |      Return a reverse iterator over the list.\n |  \n |  __rmul__(self, value, /)\n |      Return value*self.\n |  \n |  __setitem__(self, key, value, /)\n |      Set self[key] to value.\n |  \n |  __sizeof__(self, /)\n |      Return the size of the list in memory, in bytes.\n |  \n |  append(self, object, /)\n |      Append object to the end of the list.\n |  \n |  clear(self, /)\n |      Remove all items from list.\n |  \n |  copy(self, /)\n |      Return a shallow copy of the list.\n |  \n |  count(self, value, /)\n |      Return number of occurrences of value.\n |  \n |  extend(self, iterable, /)\n |      Extend list by appending elements from the iterable.\n |  \n |  index(self, value, start=0, stop=9223372036854775807, /)\n |      Return first index of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  insert(self, index, object, /)\n |      Insert object before index.\n |  \n |  pop(self, index=-1, /)\n |      Remove and return item at index (default last).\n |      \n |      Raises IndexError if list is empty or index is out of range.\n |  \n |  remove(self, value, /)\n |      Remove first occurrence of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  reverse(self, /)\n |      Reverse *IN PLACE*.\n |  \n |  sort(self, /, *, key=None, reverse=False)\n |      Sort the list in ascending order and return None.\n |      \n |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the\n |      order of two equal elements is maintained).\n |      \n |      If a key function is given, apply it once to each list item and sort them,\n |      ascending or descending, according to their function values.\n |      \n |      The reverse flag can be set to sort in descending order.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  __class_getitem__(...) from builtins.type\n |      See PEP 585\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  __new__(*args, **kwargs) from builtins.type\n |      Create and return a new object.  See help(type) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None\n\n\n\n\n\nA retenir et questions\nA retenir :\n\nChaque objet Python a des attributs et des méthodes\nVous pouvez créer des classes avec des attributs et des méthodes\nLes méthodes des listes et des dictionnaires qui sont les plus utilisées :\n\nlist.count()\nlist.sort()\nlist.append()\ndict.keys()\ndict.items()\ndict.values()\n\n\n\n\n Exercice 2\n\nDéfinir la liste allant de 1 à 10, puis effectuez les actions suivantes :\n\n\ntriez et affichez la liste\najoutez l’élément 11 à la liste et affichez la liste\nrenversez et affichez la liste\naffichez l’élément d’indice 7\nenlevez l’élément 9 et affichez la liste\naffichez la sous-liste du 2e au 3e éléments inclus ;\naffichez la sous-liste du début au 2e élément inclus ;\naffichez la sous-liste du 3e élément à la fin de la liste ;\n\n\nConstruire le dictionnaire des 6 premiers mois de l’année avec comme valeurs le nombre de jours respectif.\n\n\nRenvoyer la liste des mois\nRenvoyer la liste des jours\nAjoutez la clé du mois de Juillet"
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#passer-des-listes-dictionnaires-à-pandas",
    "href": "content/getting-started/05_rappels_types.html#passer-des-listes-dictionnaires-à-pandas",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Passer des listes, dictionnaires à pandas",
    "text": "Passer des listes, dictionnaires à pandas\nSupposons que la variable ‘data’ est une liste qui contient nos données.\nUne observation correspond à un dictionnaire qui contient le nom, le type, l’ambiance et la note d’un restaurant.\nIl est aisé de transformer cette liste en dataframe grâce à la fonction ‘DataFrame’.\n\nimport pandas \n\ndata = [{\"nom\": \"Little Pub\", \"type\" : \"Bar\", \"ambiance\": 9, \"note\": 7},\n     {\"nom\": \"Le Corse\", \"type\" : \"Sandwicherie\", \"ambiance\": 2, \"note\": 8},\n     {\"nom\": \"Café Caumartin\", \"type\" : \"Bar\", \"ambiance\": 1}]\n\ndf = pandas.DataFrame(data)\n\nprint(data)\ndf\n\n[{'nom': 'Little Pub', 'type': 'Bar', 'ambiance': 9, 'note': 7}, {'nom': 'Le Corse', 'type': 'Sandwicherie', 'ambiance': 2, 'note': 8}, {'nom': 'Café Caumartin', 'type': 'Bar', 'ambiance': 1}]\n\n\n\n\n\n\n\n\n\nnom\ntype\nambiance\nnote\n\n\n\n\n0\nLittle Pub\nBar\n9\n7.0\n\n\n1\nLe Corse\nSandwicherie\n2\n8.0\n\n\n2\nCafé Caumartin\nBar\n1\nNaN"
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html",
    "href": "content/getting-started/03_data_analysis.html",
    "title": "Comment aborder un jeu de données",
    "section": "",
    "text": "Pour bien débuter des travaux sur une base de données,\nil est nécessaire de se poser quelques questions de bon sens\net de suivre une démarche scientifique dont un certain\nnombre de gestes sont assez simple.\nDans un projet sur des jeux de données, on peut schématiquement\nséparer les étapes en quatre grandes parties :\n\nLa récupération et structuration des données ;\nL’analyse de celle-ci, notamment la production de statistiques descriptives indispensables pour orienter les exploitations ultérieures ;\nLa modélisation ;\nLa valorisation finale des étapes précédentes et la communication de résultats ou la mise en oeuvre d’une chaine de production.\n\nCe cours explore ces différentes étapes de manière progressive grâce à\nl’écosystème Python qui est très complet. Chaque chapitre du cours\npeut être vu comme une manière de progresser dans ce fil conducteur.\nDans ce chapitre, nous allons plutôt mettre en avant quelques réflexions\nà avoir avant de se lancer dans chaque étape.\n\n\n\n\nLa phase de constitution de son jeu de données sous-tend tout le projet qui suit.\nLa première question à se poser est\n“de quelles données ai-je besoin pour répondre à ma problématique ?”.\nCette problématique pourra éventuellement\nêtre affinée en fonction des besoins mais les travaux sont généralement\nde meilleure qualité lorsque la problématique amène à la réflexion sur les données\ndisponibles plutôt que l’inverse.\nEnsuite, “qui produit et met à disposition ces données” ?\nLes sources disponibles sur internet sont-elles fiables ?\nPar exemple, les sites d’open data gouvernementaux sont par exemple assez fiables mais autorisent parfois l’archivage de données restructurées par des tiers et non des producteurs officiels. A l’inverse, sur Kaggle ou sur Github la source de certains jeux de données n’est pas tracée ce qui rend compliquée la confiance sur la qualité de la donnée\nUne fois identifié une ou plusieurs sources de données,\nest-ce que je peux les compléter avec d’autres données ?\n(dans ce cas, faire attention à avoir des niveaux de granularité adéquats).\n\n\n\nVient ensuite la phase de mise en forme et nettoyage des jeux de données récupérés.\nCette étape est primordiale et est généralement celle qui mobilise le plus\nde temps. Pendant quelques années, on parlait de data cleaning. Cependant,\ncela a pu, implicitement, laisser penser qu’il s’agissait d’une tâche\nsubalterne. On commence à lui préférer le concept de feature engineering\nqui souligne bien qu’il s’agit d’une compétence qui nécessite beaucoup\nde compétences.\nUn jeu de données propre est un jeu de données dont la structure est\nadéquate et n’entraînera pas d’erreur, visible ou non,\nlors de la phase d’analyse. Voici quelques éléments structurants\nd’un jeu de données propre :\n\nles informations manquantes sont bien comprises et traitées. numpy et\npandas proposent un certain formalisme sur le sujet qu’il est utile\nd’adopter en remplaçant par NaN les observations manquantes. Cela\nimplique de faire attention à la manière dont certains producteurs\ncodent les valeurs manquantes : certains ont la facheuse tendance à\nêtre imaginatifs sur les codes pour valeurs manquantes : “-999”, “XXX”, “NA”\nles variables servant d’identifiants sont bien les mêmes d’une table à l’autre (notamment dans le cas de jointure) : même format, même modalités\npour des variables textuelles, qui peuvent etre mal saisies, avoir corrigé les éventuelles fautes (ex “Rolland Garros” -&gt; “Roland Garros”)\ncréer des variables qui synthétisent l’information dont vous avez besoin\nsupprimer les éléments inutiles (colonne ou ligne vide)\nrenommer les colonnes avec des noms compréhensibles\n\n\n\n\n\nUne fois les jeux de données nettoyés, vous pouvez plus sereinement\nétudier l’information présente dans les données.\nCette phase et celle du nettoyage ne sont pas séquentielles,\nen réalité vous devrez régulièrement passer de votre nettoyage à quelques statistiques descriptives qui vous montreront un problème, retourner au nettoyage etc.\nLes questions à se poser pour “challenger” le jeu de données :\n\nEst-ce que mon échantillon est bien représentatif de ce qui m’intéresse ? N’avoir que 2000 communes sur les 35000 n’est pas nécessairement un problème mais il est bon de s’être posé la question.\nEst-ce que les ordres de grandeur sont bons ? Pour cela, confronter vos premieres stats desc à vos recherches internet. Par exemple trouver que les maisons vendues en France en 2020 font en moyenne 400 m² n’est pas un ordre de grandeur réaliste.\nEst-ce que je comprends toutes les variables de mon jeu de données ? Est-ce qu’elles se “comportent” de la bonne façon ? A ce stade, il est parfois utile de se faire un dictionnaire de variables (qui explique comment elles sont construites ou calculées). On peut également mener des études de corrélation entre nos variables.\nEst-ce que j’ai des outliers, i.e. des valeurs aberrantes pour certains individus ? Dans ce cas, il faut décider quel traitement on leur apporte (les supprimer, appliquer une transformation logarithmique, les laisser tel quel) et surtout bien le justifier.\nEst-ce que j’ai des premiers grands messages sortis de mon jeu de données ? Est-ce que j’ai des résultats surprenants ? Si oui, les ai-je creusé suffisamment pour voir si les résultats tiennent toujours ou si c’est à cause d’un souci dans la construction du jeu de données (mal nettoyées, mauvaise variable…)\n\n\n\n\nA cette étape, l’analyse descriptive doit voir avoir donné quelques premières pistes pour savoir dans quelle direction vous voulez mener votre modèle.\nUne erreur de débutant est de se lancer directement dans la modélisation parce\nqu’il s’agirait d’une compétence plus poussée. Cela amène généralement\nà des analyses de pauvre qualité : la modélisation tend généralement à confirmer\nles intuitions issues de l’analyse descriptive. Sans cette dernière,\nl’interprétation des résultats d’un modèle peu s’avérer inutilement complexe.\nVous devrez plonger dans vos autres cours (Econométrie 1, Series Temporelles, Sondages, Analyse des données etc.) pour trouver le modèle le plus adapté à votre question.\nLa méthode sera guidée par l’objectif.\n\nEst-ce que vous voulez expliquer ou prédire ? https://hal-cnam.archives-ouvertes.fr/hal-02507348/document\nEst-ce que vous voulez classer un élément dans une catégorie (classification ou clustering) ou prédire une valeur numérique (régression) ?\n\nEn fonction des modèles que vous aurez déjà vu en cours et des questions que vous souhaiterez résoudre sur votre jeu de données, le choix du modèle sera souvent assez direct.\nVous pouvez également vous référez à la démarche proposée par Xavier Dupré\nhttp://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/debutermlprojet.html#l-debutermlprojet\nPour aller plus loin (mais de manière simplifiée) sur les algorithmes de Machine Learning :\nhttps://datakeen.co/8-machine-learning-algorithms-explained-in-human-language/\n\n\nLa mise à disposition de code sur Github ou Gitlab est une incitation\ntrès forte pour produire du code de qualité. Il est ainsi recommandé de\nsystématiquement utiliser ces plateformes pour la mise à disposition de\ncode. Cependant, il ne s’agit que d’une petite partie des gains à\nl’utiliser.\nLe cours que je donne avec Romain Avouac en troisième année d’ENSAE\n(ensae-reproductibilite.github.io/website/) évoque\nl’un des principaux gains à utiliser ces plateformes, à savoir\nla possibilité de mettre à disposition automatiquement différents livrables\npour valoriser son travail auprès de différents publics.\nSelon le public visé, la communication ne sera pas identique. Le code peut\nintéresser les personnes désirant avoir des détails sur la méthodologie mise\nen oeuvre en pratique mais il peut s’agir d’un format rebutant pour d’autres\npublics. Une visualisation de données dynamiques parlera à des publics\nmoins experts de la donnée mais est plus dure à mettre en oeuvre\nqu’un graphique standard.\n\n\n\nLes Notebooks Jupyter ont eu beaucoup de succès dans le monde de\nla data science pour valoriser des travaux. Pourtant il ne s’agit\npas forcément toujours du meilleur format. En effet, beaucoup\nde notebooks tentent à empiler des pavés de code et du texte, ce\nqui les rend difficilement lisibles.\nSur un projet conséquent, il vaut mieux reporter le plus de code\npossible dans des scripts bien structurés et avoir un notebook\nqui appelle ces scripts pour produire des outputs. Ou alors ne\npas utiliser un notebook et privilégier un autre format (un\ntableau de bord, un site web, une appli réactive…).\nDans le cours de dernière année de\nl’ENSAE, Mise en production de projets data science, Romain\nAvouac et moi revenons sur les moyens de communication et de partage de code alternatifs au notebook.\n\n\n\n\n\n\n\n\nLes données sont une représentation synthétique de la réalité et les\nconclusions de certaines analyses peuvent avoir un vrai impact sur\nla vie des citoyens. Les chiffres erronés de\nReinhart et Rogoff ont ainsi pu servir de justification théorique à des\npolitiques d’austérité qui ont pu avoir des conséquences violentes\npour certains citoyens de\npays en crise1. En Grande-Bretagne, le recensement des personnes\ncontaminées par le Covid en 2020, et donc de leurs proches pour le\nsuivi de l’épidémie,\na été incomplet à cause de\ntroncatures dues à l’utilisation d’un format non adapté de stockage\ndes données (tableur Excel)2.\nDernier exemple avec le credit scoring mis en oeuvre aux Etats-Unis.\nLa citation ci-dessous, issue de l’article de Hurley and Adebayo (2016),\nillustre très bien les conséquences et les aspects problématiques\nd’un système de construction automatisée d’un score de crédit :\n\nConsumers have limited ability to identify and contest unfair credit\ndecisions, and little chance to understand what steps they\nshould take to improve their credit. Recent studies have also\nquestioned the accuracy of the data used by these tools, in some\ncases identifying serious flaws that have a substantial bearing\non lending decisions. Big-data tools may also risk creating a\nsystem of “creditworthinessby association” in which consumers’\nfamilial, religious, social, and other affiliations determine their\neligibility for an affordable loan.\nHurley and Adebayo (2016)\n\n\n\n\nLa transparence sur les intérêts et limites d’une méthode mise en oeuvre\nest donc importante.\nCette exigence de la recherche, parfois oubliée à cause de la course\naux résultats novateurs, mérite également d’être appliquée\nen entreprise ou administration.\nMême sans intention manifeste de la part de la personne qui analyse des données,\nune mauvaise interprétation est toujours possible. Tout en valorisant un\nrésultat, il est possible d’alerter sur certaines limites. Il est important,\ndans ses recherches comme dans les discussions avec d’autres interlocuteurs,\nde faire attention au biais de confirmation qui consiste\nà ne retenir que l’information qui correspond à nos conceptions a priori et\nà ne pas considérer celles qui pourraient aller à l’encontre de celles-ci:\n\n\n\n\n\nCertaines représentations de données sont à exclure car des biais cognitifs\npeuvent amener à des interprétations erronées3. Dans le domaine de la\nvisualisation de données, les camemberts (pie chart) ou les diagrammes\nradar sont par exemple\nà exclure car l’oeil humain perçoit mal ces formes circulaires. Pour une raison\nsimilaire, les cartes avec aplat de couleur (cartes\nchoroplèthes) sont trompeuses.\nLes posts de blog pour datawrapper\nde Lisa Charlotte Muth ou ceux d’Eric Mauvière sont d’excellentes ressources\npour apprendre les bonnes et mauvaises pratiques de\nvisualisation (voir la partie visualisation de ce cours\npour plus de détails).\n\n\n\nLe cadre réglementaire de protection des données a évolué ces dernières\nannées avec le RGPD. Cette réglementation a permis de mieux faire\nsaisir le fait que la collecte de données se justifie au nom\nde finalités plus ou moins bien identifiées. Prendre conscience que\nla confidentialité des données se justifie pour éviter la dissémination\nnon contrôlée d’informations sur une personne est important.\nDes données particulièrement sensibles, notamment les données de santé,\npeuvent être plus contraignantes à traiter que des données peu sensibles.\nEn Europe, par exemple, les agents du service statistique public\n(Insee ou services statistiques ministériels) sont tenus au secret professionnel\n(article L121-6 du Code général de la fonction publique),\nqui leur interdit la communication des informations confidentielles\ndont ils sont dépositaires au titre de leurs missions ou fonctions,\nsous peine des sanctions prévues par l’article 226-13 du Code pénal\n(jusqu’à un an d’emprisonnement et 15 000 € d’amende).\nLe secret statistique, défini dans une loi de 1951,\nrenforce cette obligation dans le cas de données détenues pour des usages statistiques.\nIl interdit strictement la communication de données individuelles\nou susceptibles d’identifier les personnes,\nissues de traitements à finalités statistiques,\nque ces traitements proviennent d’enquêtes ou de bases de données.\nLe secret statistique exclut par principe de diffuser des données\nqui permettraient l’identification des personnes concernées,\npersonnes physiques comme personnes morales.\nCette obligation limite la finesse des informations disponibles en diffusion\nCe cadre contraignant s’explique par l’héritage de la Seconde Guerre Mondiale\net le désir de ne plus revivre une situation où la collecte d’information\nsert une action publique basée sur la discrimination entre catégories\nde la population.\n\n\n\nUn article récent de Nature,\nqui reprend les travaux d’une équipe d’épidémiologistes (Gabelica, Bojčić, and Puljak 2022)\névoque le problème de l’accès aux données pour des chercheurs désirant reproduire\nune étude. Même dans les articles scientifiques où il est mentionné que les\ndonnées peuvent être mises à disposition d’autres chercheurs, le partage\nde celles-ci est rare :\n\nGraphique issu de l’article de Nature\nCe constat, quelque peu inquiétant, est confirmé par une étude récente\nde Samuel and Mietchen (2023) qui a tenté d’exécuter un peu moins de\n30 000 notebooks associés à des études scientifiques. Seuls 3%\ndes notebooks reproduisent les résultats espérés.\nAfin de partager les moyens de reproduire des publications sans diffuser des\ndonnées potentiellement confidentielles, les jeux de données synthétiques\nsont de plus en plus utilisés. Par le biais de modèles de deep learning,\nil est ainsi possible de générer des jeux de données synthétiques complexes\nqui permettent de reproduire les principales caractéristiques d’un jeu de données\ntout en évitant, si le modèle a été bien calibré, de diffuser une information\nindividuelle.\nDans l’administration française, les codes sources sont\nconsidérés comme des documents administratifs et peuvent\ndonc être mis à disposition de tout citoyen sur demande à la\nCommission d’accès aux documents administratifs (CADA):\n\n« Sont considérés comme documents administratifs, au sens des titres Ier, III et IV du présent livre, quels que soient leur date, leur lieu de conservation, leur forme et leur support, les documents produits ou reçus, dans le cadre de leur mission de service public, par l’État, les collectivités territoriales ainsi que par les autres personnes de droit public ou les personnes de droit privé chargées d’une telle mission. Constituent de tels documents notamment les dossiers, rapports, études, comptes rendus, procès-verbaux, statistiques, instructions, circulaires, notes et réponses ministérielles, correspondances, avis, prévisions, codes sources et décisions. »\nAvis 20230314 - Séance du 30/03/2023 de la Commission d’accès aux documents administratifs\n\nEn revanche, les poids des modèles utilisés par l’administration, notamment ceux\ndes modèles de machine learning ne sont pas réglementés de la même\nmanière (Avis 20230314 de la CADA).\nEn effet, comme il existe toujours\nun risque de rétro-ingénierie amenant à une révélation partielle\ndes données\nd’entraînement lors d’un partage de modèle, les modèles\nentraînés sur des données\nsensibles (comme les décisions de justice étudiées\npar (l’avis 20230314 de la CADA))\nn’ont pas vocation à être partagés.\n\n\n\nLe numérique constitue une part croissante des\némissions de gaz à effet de serre.\nReprésentant aujourd’hui 4 % des émissions mondiales\nde CO2, cette part devrait encore croître (Arcep 2019).\nLe monde de la data science est également\nconcerné.\nL’utilisation de données de plus en\nplus massives, notamment la constitution\nde corpus monumentaux de textes,\nrécupérés par scraping, est une première source\nde dépense d’énergie. De même, la récupération\nen continu de nouvelles traces numériques\nnécessite d’avoir des serveurs fonctionnels\nen continu. A cette première source de\ndépense d’énergie, s’ajoute l’entraînement\ndes modèles qui peut prendre des jours,\ny compris sur des architectures très\npuissantes. Strubell, Ganesh, and McCallum (2019)\nestime que l’entraînement d’un modèle à\nl’état de l’art dans le domaine du\nNLP nécessite autant d’énergie que ce que\nconsommeraient cinq voitures, en moyenne,\nau cours de l’ensemble de leur\ncycle de vie.\nL’utilisation accrue de l’intégration\ncontinue, qui permet de mettre en oeuvre de manière\nautomatisée l’exécution de certains scripts ou\nla production de livrables en continu,\namène également à une dépense d’énergie importante.\nIl convient donc d’essayer de limiter l’intégration\ncontinue à la production d’output vraiment nouveaux.\n\n\n\nPar exemple, cet ouvrage utilise de manière intensive\ncette approche. Néanmoins, pour essayer de limiter\nles effets pervers de la production en continu d’un\nouvrage extensif, seuls les chapitres modifiés\nsont produits lors des prévisualisations mises en\noeuvre à chaque pull request sur le dépôt\nGithub.\n\n\nLes data scientists doivent être conscients\ndes implications de leur usage intensif de\nressources et essayer de minimiser leur\nimpact. Par exemple, plutôt que ré-estimer\nun modèle de NLP,\nla méthode de l’apprentissage par transfert,\nqui permet de transférer les poids d’apprentissage\nd’un modèle à une nouvelle source, permet\nde réduire les besoins computationnels.\nDe même, il peut être utile, pour prendre\nconscience de l’effet d’un code trop long,\nde convertir le temps de calcul en\némissions de gaz à effet de serre.\nLe package codecarbon\npropose cette solution en adaptant l’estimation\nen fonction du mix énergétique du pays\nen question. Mesurer étant le\nprérequis pour prendre conscience puis comprendre,\nce type d’initiatives peut amener à responsabiliser\nles data scientists et ainsi permettre un\nmeilleur partage des ressources.\n\n\n\n\n\n\nArcep. 2019. “L’empreinte Carbone Du Numérique.” Rapport de l’Arcep.\n\n\nGabelica, Mirko, Ružica Bojčić, and Livia Puljak. 2022. “Many Researchers Were Not Compliant with Their Published Data Sharing Statement: Mixed-Methods Study.” Journal of Clinical Epidemiology.\n\n\nHurley, Mikella, and Julius Adebayo. 2016. “Credit Scoring in the Era of Big Data.” Yale JL & Tech. 18: 148.\n\n\nSamuel, Sheeba, and Daniel Mietchen. 2023. “Computational Reproducibility of Jupyter Notebooks from Biomedical Publications.” https://arxiv.org/abs/2308.07333.\n\n\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. “Energy and Policy Considerations for Deep Learning in NLP.” https://arxiv.org/abs/1906.02243."
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#lors-de-la-récupération-des-données",
    "href": "content/getting-started/03_data_analysis.html#lors-de-la-récupération-des-données",
    "title": "Comment aborder un jeu de données",
    "section": "",
    "text": "La phase de constitution de son jeu de données sous-tend tout le projet qui suit.\nLa première question à se poser est\n“de quelles données ai-je besoin pour répondre à ma problématique ?”.\nCette problématique pourra éventuellement\nêtre affinée en fonction des besoins mais les travaux sont généralement\nde meilleure qualité lorsque la problématique amène à la réflexion sur les données\ndisponibles plutôt que l’inverse.\nEnsuite, “qui produit et met à disposition ces données” ?\nLes sources disponibles sur internet sont-elles fiables ?\nPar exemple, les sites d’open data gouvernementaux sont par exemple assez fiables mais autorisent parfois l’archivage de données restructurées par des tiers et non des producteurs officiels. A l’inverse, sur Kaggle ou sur Github la source de certains jeux de données n’est pas tracée ce qui rend compliquée la confiance sur la qualité de la donnée\nUne fois identifié une ou plusieurs sources de données,\nest-ce que je peux les compléter avec d’autres données ?\n(dans ce cas, faire attention à avoir des niveaux de granularité adéquats).\n\n\n\nVient ensuite la phase de mise en forme et nettoyage des jeux de données récupérés.\nCette étape est primordiale et est généralement celle qui mobilise le plus\nde temps. Pendant quelques années, on parlait de data cleaning. Cependant,\ncela a pu, implicitement, laisser penser qu’il s’agissait d’une tâche\nsubalterne. On commence à lui préférer le concept de feature engineering\nqui souligne bien qu’il s’agit d’une compétence qui nécessite beaucoup\nde compétences.\nUn jeu de données propre est un jeu de données dont la structure est\nadéquate et n’entraînera pas d’erreur, visible ou non,\nlors de la phase d’analyse. Voici quelques éléments structurants\nd’un jeu de données propre :\n\nles informations manquantes sont bien comprises et traitées. numpy et\npandas proposent un certain formalisme sur le sujet qu’il est utile\nd’adopter en remplaçant par NaN les observations manquantes. Cela\nimplique de faire attention à la manière dont certains producteurs\ncodent les valeurs manquantes : certains ont la facheuse tendance à\nêtre imaginatifs sur les codes pour valeurs manquantes : “-999”, “XXX”, “NA”\nles variables servant d’identifiants sont bien les mêmes d’une table à l’autre (notamment dans le cas de jointure) : même format, même modalités\npour des variables textuelles, qui peuvent etre mal saisies, avoir corrigé les éventuelles fautes (ex “Rolland Garros” -&gt; “Roland Garros”)\ncréer des variables qui synthétisent l’information dont vous avez besoin\nsupprimer les éléments inutiles (colonne ou ligne vide)\nrenommer les colonnes avec des noms compréhensibles"
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#lors-de-lanalyse-descriptive",
    "href": "content/getting-started/03_data_analysis.html#lors-de-lanalyse-descriptive",
    "title": "Comment aborder un jeu de données",
    "section": "",
    "text": "Une fois les jeux de données nettoyés, vous pouvez plus sereinement\nétudier l’information présente dans les données.\nCette phase et celle du nettoyage ne sont pas séquentielles,\nen réalité vous devrez régulièrement passer de votre nettoyage à quelques statistiques descriptives qui vous montreront un problème, retourner au nettoyage etc.\nLes questions à se poser pour “challenger” le jeu de données :\n\nEst-ce que mon échantillon est bien représentatif de ce qui m’intéresse ? N’avoir que 2000 communes sur les 35000 n’est pas nécessairement un problème mais il est bon de s’être posé la question.\nEst-ce que les ordres de grandeur sont bons ? Pour cela, confronter vos premieres stats desc à vos recherches internet. Par exemple trouver que les maisons vendues en France en 2020 font en moyenne 400 m² n’est pas un ordre de grandeur réaliste.\nEst-ce que je comprends toutes les variables de mon jeu de données ? Est-ce qu’elles se “comportent” de la bonne façon ? A ce stade, il est parfois utile de se faire un dictionnaire de variables (qui explique comment elles sont construites ou calculées). On peut également mener des études de corrélation entre nos variables.\nEst-ce que j’ai des outliers, i.e. des valeurs aberrantes pour certains individus ? Dans ce cas, il faut décider quel traitement on leur apporte (les supprimer, appliquer une transformation logarithmique, les laisser tel quel) et surtout bien le justifier.\nEst-ce que j’ai des premiers grands messages sortis de mon jeu de données ? Est-ce que j’ai des résultats surprenants ? Si oui, les ai-je creusé suffisamment pour voir si les résultats tiennent toujours ou si c’est à cause d’un souci dans la construction du jeu de données (mal nettoyées, mauvaise variable…)"
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#lors-de-la-modélisation",
    "href": "content/getting-started/03_data_analysis.html#lors-de-la-modélisation",
    "title": "Comment aborder un jeu de données",
    "section": "",
    "text": "A cette étape, l’analyse descriptive doit voir avoir donné quelques premières pistes pour savoir dans quelle direction vous voulez mener votre modèle.\nUne erreur de débutant est de se lancer directement dans la modélisation parce\nqu’il s’agirait d’une compétence plus poussée. Cela amène généralement\nà des analyses de pauvre qualité : la modélisation tend généralement à confirmer\nles intuitions issues de l’analyse descriptive. Sans cette dernière,\nl’interprétation des résultats d’un modèle peu s’avérer inutilement complexe.\nVous devrez plonger dans vos autres cours (Econométrie 1, Series Temporelles, Sondages, Analyse des données etc.) pour trouver le modèle le plus adapté à votre question.\nLa méthode sera guidée par l’objectif.\n\nEst-ce que vous voulez expliquer ou prédire ? https://hal-cnam.archives-ouvertes.fr/hal-02507348/document\nEst-ce que vous voulez classer un élément dans une catégorie (classification ou clustering) ou prédire une valeur numérique (régression) ?\n\nEn fonction des modèles que vous aurez déjà vu en cours et des questions que vous souhaiterez résoudre sur votre jeu de données, le choix du modèle sera souvent assez direct.\nVous pouvez également vous référez à la démarche proposée par Xavier Dupré\nhttp://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/debutermlprojet.html#l-debutermlprojet\nPour aller plus loin (mais de manière simplifiée) sur les algorithmes de Machine Learning :\nhttps://datakeen.co/8-machine-learning-algorithms-explained-in-human-language/\n\n\nLa mise à disposition de code sur Github ou Gitlab est une incitation\ntrès forte pour produire du code de qualité. Il est ainsi recommandé de\nsystématiquement utiliser ces plateformes pour la mise à disposition de\ncode. Cependant, il ne s’agit que d’une petite partie des gains à\nl’utiliser.\nLe cours que je donne avec Romain Avouac en troisième année d’ENSAE\n(ensae-reproductibilite.github.io/website/) évoque\nl’un des principaux gains à utiliser ces plateformes, à savoir\nla possibilité de mettre à disposition automatiquement différents livrables\npour valoriser son travail auprès de différents publics.\nSelon le public visé, la communication ne sera pas identique. Le code peut\nintéresser les personnes désirant avoir des détails sur la méthodologie mise\nen oeuvre en pratique mais il peut s’agir d’un format rebutant pour d’autres\npublics. Une visualisation de données dynamiques parlera à des publics\nmoins experts de la donnée mais est plus dure à mettre en oeuvre\nqu’un graphique standard.\n\n\n\nLes Notebooks Jupyter ont eu beaucoup de succès dans le monde de\nla data science pour valoriser des travaux. Pourtant il ne s’agit\npas forcément toujours du meilleur format. En effet, beaucoup\nde notebooks tentent à empiler des pavés de code et du texte, ce\nqui les rend difficilement lisibles.\nSur un projet conséquent, il vaut mieux reporter le plus de code\npossible dans des scripts bien structurés et avoir un notebook\nqui appelle ces scripts pour produire des outputs. Ou alors ne\npas utiliser un notebook et privilégier un autre format (un\ntableau de bord, un site web, une appli réactive…).\nDans le cours de dernière année de\nl’ENSAE, Mise en production de projets data science, Romain\nAvouac et moi revenons sur les moyens de communication et de partage de code alternatifs au notebook."
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#ethique-et-responsabilité-du-data-scientist",
    "href": "content/getting-started/03_data_analysis.html#ethique-et-responsabilité-du-data-scientist",
    "title": "Comment aborder un jeu de données",
    "section": "",
    "text": "Les données sont une représentation synthétique de la réalité et les\nconclusions de certaines analyses peuvent avoir un vrai impact sur\nla vie des citoyens. Les chiffres erronés de\nReinhart et Rogoff ont ainsi pu servir de justification théorique à des\npolitiques d’austérité qui ont pu avoir des conséquences violentes\npour certains citoyens de\npays en crise1. En Grande-Bretagne, le recensement des personnes\ncontaminées par le Covid en 2020, et donc de leurs proches pour le\nsuivi de l’épidémie,\na été incomplet à cause de\ntroncatures dues à l’utilisation d’un format non adapté de stockage\ndes données (tableur Excel)2.\nDernier exemple avec le credit scoring mis en oeuvre aux Etats-Unis.\nLa citation ci-dessous, issue de l’article de Hurley and Adebayo (2016),\nillustre très bien les conséquences et les aspects problématiques\nd’un système de construction automatisée d’un score de crédit :\n\nConsumers have limited ability to identify and contest unfair credit\ndecisions, and little chance to understand what steps they\nshould take to improve their credit. Recent studies have also\nquestioned the accuracy of the data used by these tools, in some\ncases identifying serious flaws that have a substantial bearing\non lending decisions. Big-data tools may also risk creating a\nsystem of “creditworthinessby association” in which consumers’\nfamilial, religious, social, and other affiliations determine their\neligibility for an affordable loan.\nHurley and Adebayo (2016)\n\n\n\n\nLa transparence sur les intérêts et limites d’une méthode mise en oeuvre\nest donc importante.\nCette exigence de la recherche, parfois oubliée à cause de la course\naux résultats novateurs, mérite également d’être appliquée\nen entreprise ou administration.\nMême sans intention manifeste de la part de la personne qui analyse des données,\nune mauvaise interprétation est toujours possible. Tout en valorisant un\nrésultat, il est possible d’alerter sur certaines limites. Il est important,\ndans ses recherches comme dans les discussions avec d’autres interlocuteurs,\nde faire attention au biais de confirmation qui consiste\nà ne retenir que l’information qui correspond à nos conceptions a priori et\nà ne pas considérer celles qui pourraient aller à l’encontre de celles-ci:\n\n\n\n\n\nCertaines représentations de données sont à exclure car des biais cognitifs\npeuvent amener à des interprétations erronées3. Dans le domaine de la\nvisualisation de données, les camemberts (pie chart) ou les diagrammes\nradar sont par exemple\nà exclure car l’oeil humain perçoit mal ces formes circulaires. Pour une raison\nsimilaire, les cartes avec aplat de couleur (cartes\nchoroplèthes) sont trompeuses.\nLes posts de blog pour datawrapper\nde Lisa Charlotte Muth ou ceux d’Eric Mauvière sont d’excellentes ressources\npour apprendre les bonnes et mauvaises pratiques de\nvisualisation (voir la partie visualisation de ce cours\npour plus de détails).\n\n\n\nLe cadre réglementaire de protection des données a évolué ces dernières\nannées avec le RGPD. Cette réglementation a permis de mieux faire\nsaisir le fait que la collecte de données se justifie au nom\nde finalités plus ou moins bien identifiées. Prendre conscience que\nla confidentialité des données se justifie pour éviter la dissémination\nnon contrôlée d’informations sur une personne est important.\nDes données particulièrement sensibles, notamment les données de santé,\npeuvent être plus contraignantes à traiter que des données peu sensibles.\nEn Europe, par exemple, les agents du service statistique public\n(Insee ou services statistiques ministériels) sont tenus au secret professionnel\n(article L121-6 du Code général de la fonction publique),\nqui leur interdit la communication des informations confidentielles\ndont ils sont dépositaires au titre de leurs missions ou fonctions,\nsous peine des sanctions prévues par l’article 226-13 du Code pénal\n(jusqu’à un an d’emprisonnement et 15 000 € d’amende).\nLe secret statistique, défini dans une loi de 1951,\nrenforce cette obligation dans le cas de données détenues pour des usages statistiques.\nIl interdit strictement la communication de données individuelles\nou susceptibles d’identifier les personnes,\nissues de traitements à finalités statistiques,\nque ces traitements proviennent d’enquêtes ou de bases de données.\nLe secret statistique exclut par principe de diffuser des données\nqui permettraient l’identification des personnes concernées,\npersonnes physiques comme personnes morales.\nCette obligation limite la finesse des informations disponibles en diffusion\nCe cadre contraignant s’explique par l’héritage de la Seconde Guerre Mondiale\net le désir de ne plus revivre une situation où la collecte d’information\nsert une action publique basée sur la discrimination entre catégories\nde la population.\n\n\n\nUn article récent de Nature,\nqui reprend les travaux d’une équipe d’épidémiologistes (Gabelica, Bojčić, and Puljak 2022)\névoque le problème de l’accès aux données pour des chercheurs désirant reproduire\nune étude. Même dans les articles scientifiques où il est mentionné que les\ndonnées peuvent être mises à disposition d’autres chercheurs, le partage\nde celles-ci est rare :\n\nGraphique issu de l’article de Nature\nCe constat, quelque peu inquiétant, est confirmé par une étude récente\nde Samuel and Mietchen (2023) qui a tenté d’exécuter un peu moins de\n30 000 notebooks associés à des études scientifiques. Seuls 3%\ndes notebooks reproduisent les résultats espérés.\nAfin de partager les moyens de reproduire des publications sans diffuser des\ndonnées potentiellement confidentielles, les jeux de données synthétiques\nsont de plus en plus utilisés. Par le biais de modèles de deep learning,\nil est ainsi possible de générer des jeux de données synthétiques complexes\nqui permettent de reproduire les principales caractéristiques d’un jeu de données\ntout en évitant, si le modèle a été bien calibré, de diffuser une information\nindividuelle.\nDans l’administration française, les codes sources sont\nconsidérés comme des documents administratifs et peuvent\ndonc être mis à disposition de tout citoyen sur demande à la\nCommission d’accès aux documents administratifs (CADA):\n\n« Sont considérés comme documents administratifs, au sens des titres Ier, III et IV du présent livre, quels que soient leur date, leur lieu de conservation, leur forme et leur support, les documents produits ou reçus, dans le cadre de leur mission de service public, par l’État, les collectivités territoriales ainsi que par les autres personnes de droit public ou les personnes de droit privé chargées d’une telle mission. Constituent de tels documents notamment les dossiers, rapports, études, comptes rendus, procès-verbaux, statistiques, instructions, circulaires, notes et réponses ministérielles, correspondances, avis, prévisions, codes sources et décisions. »\nAvis 20230314 - Séance du 30/03/2023 de la Commission d’accès aux documents administratifs\n\nEn revanche, les poids des modèles utilisés par l’administration, notamment ceux\ndes modèles de machine learning ne sont pas réglementés de la même\nmanière (Avis 20230314 de la CADA).\nEn effet, comme il existe toujours\nun risque de rétro-ingénierie amenant à une révélation partielle\ndes données\nd’entraînement lors d’un partage de modèle, les modèles\nentraînés sur des données\nsensibles (comme les décisions de justice étudiées\npar (l’avis 20230314 de la CADA))\nn’ont pas vocation à être partagés.\n\n\n\nLe numérique constitue une part croissante des\némissions de gaz à effet de serre.\nReprésentant aujourd’hui 4 % des émissions mondiales\nde CO2, cette part devrait encore croître (Arcep 2019).\nLe monde de la data science est également\nconcerné.\nL’utilisation de données de plus en\nplus massives, notamment la constitution\nde corpus monumentaux de textes,\nrécupérés par scraping, est une première source\nde dépense d’énergie. De même, la récupération\nen continu de nouvelles traces numériques\nnécessite d’avoir des serveurs fonctionnels\nen continu. A cette première source de\ndépense d’énergie, s’ajoute l’entraînement\ndes modèles qui peut prendre des jours,\ny compris sur des architectures très\npuissantes. Strubell, Ganesh, and McCallum (2019)\nestime que l’entraînement d’un modèle à\nl’état de l’art dans le domaine du\nNLP nécessite autant d’énergie que ce que\nconsommeraient cinq voitures, en moyenne,\nau cours de l’ensemble de leur\ncycle de vie.\nL’utilisation accrue de l’intégration\ncontinue, qui permet de mettre en oeuvre de manière\nautomatisée l’exécution de certains scripts ou\nla production de livrables en continu,\namène également à une dépense d’énergie importante.\nIl convient donc d’essayer de limiter l’intégration\ncontinue à la production d’output vraiment nouveaux.\n\n\n\nPar exemple, cet ouvrage utilise de manière intensive\ncette approche. Néanmoins, pour essayer de limiter\nles effets pervers de la production en continu d’un\nouvrage extensif, seuls les chapitres modifiés\nsont produits lors des prévisualisations mises en\noeuvre à chaque pull request sur le dépôt\nGithub.\n\n\nLes data scientists doivent être conscients\ndes implications de leur usage intensif de\nressources et essayer de minimiser leur\nimpact. Par exemple, plutôt que ré-estimer\nun modèle de NLP,\nla méthode de l’apprentissage par transfert,\nqui permet de transférer les poids d’apprentissage\nd’un modèle à une nouvelle source, permet\nde réduire les besoins computationnels.\nDe même, il peut être utile, pour prendre\nconscience de l’effet d’un code trop long,\nde convertir le temps de calcul en\némissions de gaz à effet de serre.\nLe package codecarbon\npropose cette solution en adaptant l’estimation\nen fonction du mix énergétique du pays\nen question. Mesurer étant le\nprérequis pour prendre conscience puis comprendre,\nce type d’initiatives peut amener à responsabiliser\nles data scientists et ainsi permettre un\nmeilleur partage des ressources."
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#références",
    "href": "content/getting-started/03_data_analysis.html#références",
    "title": "Comment aborder un jeu de données",
    "section": "",
    "text": "Arcep. 2019. “L’empreinte Carbone Du Numérique.” Rapport de l’Arcep.\n\n\nGabelica, Mirko, Ružica Bojčić, and Livia Puljak. 2022. “Many Researchers Were Not Compliant with Their Published Data Sharing Statement: Mixed-Methods Study.” Journal of Clinical Epidemiology.\n\n\nHurley, Mikella, and Julius Adebayo. 2016. “Credit Scoring in the Era of Big Data.” Yale JL & Tech. 18: 148.\n\n\nSamuel, Sheeba, and Daniel Mietchen. 2023. “Computational Reproducibility of Jupyter Notebooks from Biomedical Publications.” https://arxiv.org/abs/2308.07333.\n\n\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. “Energy and Policy Considerations for Deep Learning in NLP.” https://arxiv.org/abs/1906.02243."
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#footnotes",
    "href": "content/getting-started/03_data_analysis.html#footnotes",
    "title": "Comment aborder un jeu de données",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe livre de Reinhart et Rogoff, This time is different, s’appuyait\nsur un Excel constitué à la main. Un doctorant s’est aperçu d’erreurs\ndans celui-ci et a remarqué que lorsqu’on\nsubstituait les chiffres officiels, les résultats n’étaient plus valides.↩︎\nOn suppose ici que le message erroné est transmis sans volonté de\nmanipulation. La manipulation manifeste est un problème encore plus grave.↩︎\nOn suppose ici que le message erroné est transmis sans volonté de\nmanipulation. La manipulation manifeste est un problème encore plus grave.↩︎"
  },
  {
    "objectID": "content/getting-started/01_installation.html",
    "href": "content/getting-started/01_installation.html",
    "title": "Configuration de Python",
    "section": "",
    "text": "Les exercices sont présentés sous la\nforme de notebook jupyter. Ils peuvent être exécutés\ndans plusieurs environnement, au gré des préférences et des connaissances\nde chacun :\nConcernant la première méthode, qui est celle recommandée,\nchaque\nchapitre présente les badges suivants qui permettent d’ouvrir\nla page web en question dans l’environnement de prédilection.\nPar exemple, pour ouvrir le chapitre relatif à\nnumpy dans l’un des environnements temporaires proposés,\nles badges suivants sont proposés :\nQuel que soit l’environnement d’exécution des scripts, l’un des objectifs\nde ce cours est d’adopter un environnement favorable à la reproductibilité\ndes traitements. Ils devraient donc fonctionner, dès lors que l’environnement\nest bien configuré, d’une manière similaire quel que soit\nla machine qui exécute le code.\nComme la reproductibilité est une notion centrale dans une démarche\nscientifique mais également importante dans le monde\nde l’entreprise ou de l’administration, en supplément des notions relatives\nà Python, ce cours montrera comment utiliser Git avec Python et\névoquera un\ncertain nombre de critères de qualité du code qui sont devenus\ndes standards dans la communauté open-source, dans l’industrie et dans\nl’administration. Ces compétences ne sont pas\npropres à Python et seront\nutiles pour tout projet ultérieur. Un cours dédié à cette question\nest proposé par Romain Avouac et moi en dernière année de l’ENSAE. Son\ncontenu est disponible sur https://ensae-reproductibilite.github.io/website/.\nLe projet final devra impérativement\nêtre associé à un dépôt\nsur Github (nous reviendrons dessus) et répondre à\nces critères de qualité, qui serviront toute la vie.\nCe cours vise à acculturer à la conduite de projets de data-science avec\nPython. L’environnement foisonnant de la data-science nécessite un\ncertain nombre d’éléments supplémentaires à Python. La suite\nde ce chapitre permettra de décrire les configurations à mettre\nen oeuvre pour être en mesure d’exploiter la richesse de l’écosystème Python."
  },
  {
    "objectID": "content/getting-started/01_installation.html#local",
    "href": "content/getting-started/01_installation.html#local",
    "title": "Configuration de Python",
    "section": "Installer un environnement adapté à la data-science sur son ordinateur personnel",
    "text": "Installer un environnement adapté à la data-science sur son ordinateur personnel\nCette partie présente plusieurs éléments de configuration d’un environnement\nen local. Cependant, cette approche est de moins en moins fréquente. En effet,\nplusieurs facteurs conjoints ont amené à privilégier des\nserveurs plutôt que des installations locales (évolutions dans les technologies cloud,\nbesoins accrus de ressources, besoins de plus de contrôle sur la confidentialité\ndes données en limitant leur prolifération…). Au sein des administrations et\ndes entreprises, les approches cloud, où l’utilisateur se voit mis à disposition\nune interface graphique alors que les calculs sont déportés sur un serveur\ndistant, est de plus en plus fréquent.\n\nInstaller Python en local\nPour installer Python, il est recommandé d’utiliser\nla distribution Anaconda\nqui permet d’installer une distribution minimale de Python ainsi qu’éventuellement\nun environnement plus complet :\n\nSous Windows, il suffit de télécharger l’exécutable puis\nl’exécuter (cf. la doc officielle ;\nSous Mac, se reporter à la doc officielle ;\nSous Linux, suivre les instructions de la doc officielle selon sa distribution\n\nPasser par Anaconda permet:\n\nd’installer Python ;\nd’installer par défaut une multitude de packages utiles ;\nde pouvoir utiliser un gestionnaire de package nommé conda.\n\nAnaconda permet de créer des environnements isolés et facilite l’installation\nde certaines librairies qui nécessitent l’usage de langages externes (par exemple\ndu C++).\n\n\nInstaller un environnement de développement\nLes notebooks Jupyter (extension .ipynb)\nsont très utilisés en data science. Ils sont en\nparticulier très adaptés à la réalisation d’analyses exploratoires.\nLes notebooks permettent de mêler du code, du texte et des sorties\ngraphiques ou des tableaux. L’intérêt principal des notebooks est qu’ils\npermettent d’exécuter du code très facilement dans un environnement\nPython donné (le kernel Jupyter). Ils sont particulièrement pratiques\npour ajouter du code ou du texte à un document déjà existant, d’où le\nterme de notebook.\nNéanmoins, passée l’étape d’exploration, il est recommandé de plutôt recourir à des\nscripts au format .py. L’utilisation du format .py est l’un des premiers\ngestes pour favoriser la reproductibilité des analyses.\nCes scripts peuvent être édités à l’aide d’éditeurs de texte adaptés au code, comme\nVisual Studio\n(mon préféré),\nSublime Text,\nou PyCharm (privilégier Pycharm Community Edition)\nentre autres.\nCes éditeurs\noffrent des fonctionalités supplémentaires pratiques :\n\nnombreux plugins pour une pleine utilisation de l’écosystème Python: éditeur de Markdown,\ninterface Git, etc.\nfonctionalités classiques d’un IDE dont manque Jupyter: autocomplétion, diagnostic du code, etc.\nintégration avec les environnements Conda\n\n\n\nInstallation de Git\nLe principe de Git ainsi que son usage avec Python sont présentés dans\nune partie dédiée. Cette partie se concentre ainsi sur la question\nde la configuration de Git.\nGit est un langage dont la fonction est de tracer l’historique de modification\nd’un fichier. Pour disposer de ce langage, il est nécessaire d’installer\nle logiciel Git Bash. Grâce à lui, Git sera disponible et des outils\nexternes, notamment les interfaces de développement comme\nVisual Studio, pourront l’utiliser."
  },
  {
    "objectID": "content/getting-started/01_installation.html#exécution-dans-un-environnement-temporaire-sur-un-serveur-distant",
    "href": "content/getting-started/01_installation.html#exécution-dans-un-environnement-temporaire-sur-un-serveur-distant",
    "title": "Configuration de Python",
    "section": "Exécution dans un environnement temporaire sur un serveur distant",
    "text": "Exécution dans un environnement temporaire sur un serveur distant\nComme évoqué précédemment, les technologies dominantes dans\nle domaine du traitement des données ont amené à une évolution des pratiques\ndepuis quelques années.\nLa multiplication de données volumineuses qui dépassent les capacités en RAM\nvoire en stockage des machines personnelles,\nles progrès dans les technologies de stockage type cloud,\nl’adhésion de la communauté aux outils de versioning\n(le plus connu étant Git) sont autant de facteurs\nayant amené à repenser la manière de traiter des données.\nLes infrastructures à l’état de l’art permettent ainsi de découpler stockage\ndes données, stockage du code et exécution des traitements sur les données.\nL’exécution des traitements s’effectue ainsi sur des machines à la durée de vie\ncourte qui stockent temporairement données et code ensembles pour tester\nles traitements.\nAvec les dépôts sur Github ou Gitlab,\non dissocie environnement de stockage des codes et\nd’exécution de ceux-ci. Un système de stockage S3, présenté dans un\nchapitre ultérieur, permet en supplément de dissocier l’environnement\nde stockage des données de ces deux premiers environnements.\nSur le\ndépôt Github de ce cours , on peut\nnaviguer dans les fichiers\n(et voir tout l’historique de modification de ceux-ci). Mais,\ncomment exécuter les scripts sans passer par un poste local ?\nDepuis quelques années, des services en ligne permettant de\nlancer une instance Jupyter à distance (analogue à celle que vous pouvez\nlancer en local en utilisant Anaconda) ont émergé. Parmi celles-ci :\n\nLe SSP Cloud , plateforme développée par l’Insee qui fournit des environnements bac à sable basés sur des technologie de conteneurisation\nGoogle colaboratory\n\n;\nGithub Visual Studio Editor  ;\nBinder  ;\n\nIl est également possible d’exécuter des codes sur les services d’intégration continue de\nGitlab (service Gitlab CI)\nou de Github (via Github Actions). Il s’agit d’une approche\nbash, c’est-à-dire que les scripts sont exécutés par une console à chaque interaction avec le dépôt\ndistant Gitlab/Github, sans session ouverte pour les éditer.\nCette approche est très appropriée\npour assurer la reproductibilité d’une chaîne de traitement (on peut aller\njusqu’au\ndéploiement de visualisations automatiques1) mais n’est pas très pratique pour\nle griffonnage.\nKaggle \npropose des compétitions de code mais\ndonne également la possibilité d’exécuter des notebooks,\ncomme les solutions précédentes.\nIl existe une API Kaggle pour\naccéder à des données Kaggle hors du système Kaggle\n\n\n Warning\nLes performances de ces solutions peuvent être variables.\nLes serveurs publics mis à disposition\nne sont pas forcément des foudres de guerre. Avec ceux-ci,\non vérifie plutôt la reproductibilité des scripts avec des jeux d’exemples.\nIl est bien sûr interdit de mettre des données confidentielles dessus: ces\ndernières doivent rester dans des infrastructures où elles sont autorisées.\nQuand on est dans une entreprise ou administration,\nqui dispose de serveurs propres,\non peut aller plus loin en utilisant ces outils\npour automatiser l’ensemble de la chaîne de traitement.\nAttention: il n’y a pas de garantie de perennité de service\n(notamment avec Binder où\n10 minutes d’inactivité mènent à l’extinction du service). Il s’agit plus d’un service pour griffoner\ndans le même environnement que celui du dépôt Git que de solutions durables.\nLes sessions sur l’environnement SSPCloud sont plus durables mais il convient\nde garder à l’esprit qu’elles sont également temporaires.\n\n\n\nSSP Cloud \nOnyxia, l’autre petit nom du SSP Cloud,\nest une plateforme libre service mutualisée de traitement\nde données statistiques et de datascience.\nCe cloud met à disposition aux statisticiens et aux data scientists\nde l’État un catalogue de services et un environnement de travail simple, rapide et collaboratif, permettant de lancer facilement ces outils et d’y connecter ses données et son code.\nAu-delà des ressources techniques, cette plateforme\nreprésente une opportunité pour les statisticiens publics et les\nétudiants de découvrir\net d’adopter de nouvelles méthodes de travail.\nElle est aussi utilisé à des fins de formations et d’auto-formations.\nDans cet environnement, Jupyter et Visual Studio sont tous deux\ndisponibles.\n\n\nGoogle colaboratory \nGoogle met à disposition une plateforme de calculs basée sur le format Jupyter Notebook.\nUn grand avantage de cette solution est la mise à disposition gratuite de\nGPUs de qualité raisonnable,\noutil quasi-indispensable dans les projets basés sur des méthodes de deep learning.\nIl est possible de connecter les notebooks ouverts à Google Drive ou à\nGithub. L’icone\n\nfournit un raccourci pour lancer le notebook dans un environnement dédié.\n\n\nGithub Visual Studio Editor \nMicrosoft qui possède à la fois Github et Visual Studio a récemment\nlancé une offre Github dev qui permet d’ouvrir et lancer un notebook\nJupyter depuis un navigateur web.\nEn plus des fonctionalités attendues du logiciel Visual Studio\nCette interface permet également de gérer les issues et pull request\nd’un dépôt Github.\n\n\nLa technologie en arrière-plan : Docker \nDocker est l’outil open-source de référence\nen matière de création d’environnements isolés et auto-suffisants (les conteneurs).\nEn pratique, une application codée en Python ne repose que rarement seulement sur\ndu code produit par son développeur, elle fait généralement intervenir des dépendances :\nd’autres librairies Python, ainsi que des librairies liées au système d’exploitation\nsur laquelle elle est développée. Docker va permettre d’empaqueter l’application ainsi\nque toutes ses dépendances et rendre son exécution portable, c’est à dire indépendante\ndu système sur laquelle elle est éxécutée.\nDocker  est utilisé dans\nle cadre de cours afin d’assurer la reproductibilité des exemples.\nPlus de détails sont disponibles dans le cours de dernière année d’ENSAE\ndédié à la mise en production de projets data science\n(https://ensae-reproductibilite.github.io/website/).\nIl est possible d’utiliser les images Docker sur lesquelles reposent\nl’environnement de reproductibilité du cours. Celles-ci sont mises à\ndisposition sur DockerHub, le principal réseau de mise à disposition\nd’images Docker. Il existe une image minimale\nqui intègre Python et Quarto.\nPour utiliser l’image Visual Studio:\ndocker pull linogaliana/python-datascientist-vstudio\ndocker run --rm -p 8787:8787 -e PASSWORD=test linogaliana/python-datascientist-vstudio\nEn se rendant depuis un navigateur sur localhost:8887/, et en rentrant\nle mot de passe test (défini plus haut), on peut ainsi accéder\nà l’interface désirée (attention il s’agit d’un environnement temporaire, pas\npérenne)."
  },
  {
    "objectID": "content/getting-started/01_installation.html#installer-des-packages-supplémentaires",
    "href": "content/getting-started/01_installation.html#installer-des-packages-supplémentaires",
    "title": "Configuration de Python",
    "section": "Installer des packages supplémentaires",
    "text": "Installer des packages supplémentaires\nUn module est un script qui a vocation à définir des objets utilisés\npostérieurement par un interpréteur. C’est un script .py autosuffisant,\ndéfinissant des objets et des relations entre eux et le monde extérieur\n(d’autres modules). Un package est un ensemble cohérent de modules. Par exemple\nscikit-learn propose de nombreux modules utiles pour le machine learning.\nPython, sans ajout de briques supplémentaires,\ntrouvera rapidement ses limites.\nMême dans les scripts les plus simples, on a généralement besoin de packages qui\névitent de réinventer la roue.\nLes packages sont les éléments qui font la richesse des\nlangages open-source.\nIls sont l’équivalent des packages R ou Stata.\nLe monde de développeurs Python est très prolifique :\ndes mises à jour sont très souvent disponibles,\nles bibliothèques de packages sont très nombreuses. Un data scientist\nprendra l’habitude de jongler avec des dizaines de packages dont il connaîtra\nquelques fonctions et où, surtout, il saura aller chercher de l’information.\nLe rythme des mises à jour et des ajouts de fonctionalités\ns’est accéléré ces dernières années. Les grandes compagnies du\nnumérique ont elles-mêmes opensourcées des librairies\ndevenues centrales dans l’écosystème de la data-science\n(TensorFlow par Google, PyTorch par Facebook…)\nLes forums, notamment StackOverflow\nregorgent de bons conseils.\nLes deux meilleurs conseils qu’on puisse donner :\n\nregarder la documentation officielle d’un package. Les bons packages sont\ngénéralement très bien documentés et beaucoup d’erreurs peuvent être évitées\nen apprenant à chercher dans la documentation ;\nen cas d’erreur : copiez-collez l’erreur sur votre moteur de recherche préféré. Quelqu’un aura déjà posé la question, sans doute sur stackoverflow. Néanmoins, ne copiez-collez\npas la réponse sans comprendre la solution.\n\n\nLes gestionnaires de packages\nLes packages d’un langage open-source sont mis à disposition sur\ndes dépôts. Le CTAN est ainsi le dépôt LaTeX le plus connu, le\nCRAN celui du langage R.\nEn Python, il existe deux gestionnaires de packages qu’on utilise\nassociés à deux dépôts différents :\n\npip associé au dépôt PyPi\nconda associé au dépôt Anaconda\n\nAnaconda a permis, il y a quelques années, de faciliter grandement\nl’installation de librairies dépendants d’autres langages\nque Python (notamment des librairies C pour améliorer\nla performance des calculs). Ces dernières sont\ncompliquées à installer, notamment sur Windows.\nLe fait de proposer des librairies pré-compilées sur une grande\nvariété de systèmes d’exploitation a été une avancée\nd’anaconda. PyPi a adopté ce même principe avec les\nwheels ce qui finalement, rend les installations\navec pip à nouveau intéressantes (sauf pour certaines\nlibrairies en Windows).\nAnaconda a deux défauts par rapport à pip :\n\nl’installation de packages via pip est plus rapide que via\nconda. conda est en effet plus précautionneux sur l’interaction\nentre les différentes versions des packages installés.\nmamba a récemment\nété développé pour accélérer l’installation de packages dans un\nenvironnement conda2\nles versions disponibles sur PyPi sont plus récentes\nque celles sur le canal par défaut d’Anaconda. En effet,\npour un développeur de packages, il est possible de publier\nun package de manière automatique sur PyPi\nL’utilisation\ndu canal alternatif qu’est la conda forge permet de disposer de versions plus récentes des packages et limite l’écart avec les versions\ndisponibles sur PyPi.\n\n\n\n Warning\nLes conditions d’utilisation du canal par défaut d’Anaconda sont\nassez restrictives. L’utilisation d’Anaconda dans un cadre commercial est ainsi, depuis 2020,\nsoumis à l’achat de licences commerciales d’Anaconda pour réduire le problème de\npassager clandestin.\nIl est ainsi recommandé, notamment lorsqu’on travaille dans le\nsecteur privé où du code Python peut être utilisé,\nde ne pas ignorer ces conditions pour ne pas se mettre en faute juridiquement.\nLa conda forge n’est pas soumise à ces conditions et est ainsi préférable\ndans les entreprises.\n\n\n\n\nComment installer des packages\nAvec Anaconda, il faut passer par la ligne de commande et taper\nconda install &lt;nom_module&gt;\nPar exemple conda install geopandas. Depuis une cellule de notebook\nJupyter, on ajoute un point d’exclamation pour indiquer à Jupyter\nque la commande doit être interprétée comme une commande shell\net non une commande Python\n!conda install &lt;nom_module&gt; -y\nL’option -y permet d’éviter que conda nous demande confirmation\nsur l’installation du package. Pour mettre à jour un package, on fera\nconda upgrade plutôt que conda install\nAvec pip, on va cette fois taper\npip install &lt;nom_module&gt;\npip permet également d’installer des librairies directement depuis\nGithub à condition que Anaconda et Git sachent\ncommuniquer (ce qui implique en général que Git soit dans le PATH\ndu système d’exploitation). Par exemple, pour installer le package\npynsee\npip install git+https://github.com/InseeFrLab/Py-Insee-Data.git#egg=pynsee\nLa partie dédiée aux environnement virtuels du cours de dernière année de\nl’ENSAE présente plus d’éléments sur les différences moins évidentes\nentre pip et conda."
  },
  {
    "objectID": "content/getting-started/01_installation.html#footnotes",
    "href": "content/getting-started/01_installation.html#footnotes",
    "title": "Configuration de Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLes gains de performance peuvent être assez impressionnants.\nLa création de l’environnement nécessaire à la construction automatisée\nde ce site web a ainsi été divisée par 12 en utilisant mamba plutôt\nque conda pour installer des packages dans un environnement.↩︎\nLes gains de performance peuvent être assez impressionnants.\nLa création de l’environnement nécessaire à la construction automatisée\nde ce site web a ainsi été divisée par 12 en utilisant mamba plutôt\nque conda pour installer des packages dans un environnement.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thèmes en vrac",
    "section": "",
    "text": "Python pour la data science \n\n\nLino Galiana\n\nStar this website on Github\n\nCe site web rend public le contenu du cours de deuxième année (Master 1) de l’ENSAE :\nPython pour la data science\n\nTout est présent sur ce site web ! Des Notebooks Jupyter peuvent être récupérés pour s’exercer. L’ensemble des codes sources est stocké sur Github\n\n\n\n\n\n\n\n\n\n\n\n\n\nPour découvrir Python  de manière thématique\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrections\n\n\nNotebooks corrigés des différents chapitres du cours\n\n\n\nLino Galiana\n\n\nSep 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation\n\n\nRésumé des attentes pour les projets de fin d’année\n\n\n\nLino Galiana\n\n\nSep 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nL’environnement que propose Python pour la data science\nest très riche. Afin de bénéficier du meilleur environnement\npour tirer parti du langage, ce chapitre…\n\n\n\nLino Galiana\n\n\nJul 16, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL’environnement Python pour la data science\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nPython propose un écosystème très riche pour la\ndata science. Ce chapitre fait un tour\nd’horizon de celui-ci en présentant les principaux\npackages qui seront présentés…\n\n\n\nLino Galiana\n\n\nJul 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComment aborder un jeu de données\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nQuelques éléments pour adopter une démarche\nscientifique et éthique face à un\njeu de données.\n\n\n\nLino Galiana\n\n\nJul 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonne pratique de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLes normes communautaires du monde de\nl’open-source ont permis une\nharmonisation de la structure des projets\nPython et des scripts. Ce chapitre\névoque quelques-unes de…\n\n\n\nLino Galiana\n\n\nJul 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuelques rappels sur les principes de base de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nRappels d’éléments essentiels en Python: les règles de syntaxes, les classes,\nles méthodes, etc.\n\n\n\nLino Galiana\n\n\nJul 9, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModules, tests, boucles, fonctions\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLes fonctions permettent de généraliser des\ninstructions. Il s’agit ainsi d’un outil privilégié\npour automatiser des tâches répétitives ou réduire\nla complexité d’une chaîne…\n\n\n\nLino Galiana\n\n\nJul 9, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes classes en Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLa programmation orientée objet (POO) est\nl’un des atouts de Python. Elle permet\nd’adapter des…\n\n\n\nLino Galiana\n\n\nJul 9, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\n\nCette introduction propose quelques éléments de\nrévision des concepts de base en Python et\nprésente l’écosystème Python que nous allons\ndécouvrir tout au long de ce…\n\n\n\nLino Galiana\n\n\nJun 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\n\n\n\n Back to topCitationBibTeX citation:@book{galiana2023,\n  author = {Galiana, Lino},\n  title = {Python Pour La Data Science},\n  date = {2023},\n  url = {https://pythonds.linogaliana.fr/},\n  doi = {10.5281/zenodo.8229676},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGaliana, Lino. 2023. Python Pour La Data Science. https://doi.org/10.5281/zenodo.8229676."
  },
  {
    "objectID": "content/getting-started/index.html",
    "href": "content/getting-started/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours rassemble l’ensemble du contenu du cours\nPython  pour la data science que je donne\nà l’ENSAE\ndepuis 2018.\nCe cours était auparavant donné par Xavier Dupré.\nQuelques éléments supplémentaires sont disponibles dans\nles slides d’introduction.\nDes éléments plus avancés sont présents dans un autre cours consacré\nà la mise en production de projets data science\nque je donne avec Romain Avouac\nà l’ENSAE (ensae-reproductibilite.github.io/website)\nPython est un langage qui a déjà plus de trente ans\nmais qui a connu, au cours de la décennie 2010, une\nnouvelle jeunesse du fait de l’engouement pour\nla data science.\nPython, plus que tout autre\nlangage informatique, réunit des communautés aussi\ndiverses que des statisticiens, des développeurs,\ndes gestionnaires\nd’applications ou d’infrastructures informatiques,\ndes lycées - Python est au programme du bac français\ndepuis quelques années - ou des chercheurs\ndans des champs à la fois théoriques et appliqués. Contrairement\nà beaucoup de langages informatiques qui fédèrent\nune communauté assez homogène, Python est parvenu à réunir\nlargement grâce à quelques principes centraux : la lisibilité\ndu langage, la simplicité à utiliser des modules,\nla simplicité à l’associer à des langages plus performants\npour certaines tâches données, l’énorme volume de documentation\ndisponible en ligne…\nÊtre le deuxième meilleur langage pour réaliser telle ou telle\ntâche\npeut ainsi être une source de succès lorsque la concurrence ne dispose\npas d’un éventail aussi large d’avantages.\nLe succès de Python, de par sa nature de\nlangage couteau-suisse, est indissociable\nde l’émergence du profil du data scientist, individu\ncapable de s’intégrer à différents niveaux dans la valorisation\nde données.\nDavenport and Patil (2012a), dans la Harvard Business Review,\nont ainsi pu parler du “boulot le plus sexy du 21e siècle”\net ont pu, dix ans plus tard, faire un panorama complet de l’évolution\ndes compétences attendues d’un data scientist dans\nla même revue (Davenport and Patil 2012b).\nLa richesse de Python permet de l’utiliser dans toutes les phases\ndu traitement de la donnée, de sa récupération et structuration à partir de\nsources diverses à sa valorisation.\nPar le prisme de la data science, nous verrons que Python est\nun très bon candidat pour assister les data scientists dans tous\nles aspects du travail de données.\nCe cours introduit différents outils qui permettent de mettre en relation\ndes données et des théories grâce à Python. Néanmoins, ce cours\nva au-delà d’une simple introduction au langage et propose\ndes éléments plus approfondis, notamment sur les dernières\ninnovations permises par la data science dans les méthodes de travail.\n\n\nLe succès de scikit-learn et\nde Tensorflow dans la communauté\nde la Data-Science ont beaucoup contribué à l’adoption de Python. Cependant,\nrésumer Python à ces quelques librairies serait réducteur tant il s’agit\nd’un véritable couteau-suisse pour les data scientists,\nles social scientists ou les économistes.\nL’intérêt de Python pour un data scientist ou data economist\nva au-delà du champ du Machine Learning.\nComme pour R, l’intérêt de Python est son rôle central dans un\nécosystème plus large autour d’outils puissants, flexibles et open-source.\nPython concurrence très bien R dans son domaine de prédilection, à\nsavoir l’analyse statistique sur des bases de données structurées.\nComme dans R, les dataframes sont un concept central de Python.\nPython est néanmoins bien plus complet dans certains domaines.\nOutre le Machine Learning,\nPython est mieux adapté aux données volumineuses que\nR. Python est également meilleur que R pour faire\ndu webscraping ou accéder à des données par le biais d’API.\nDans le domaine de l’économétrie, Python offre\nl’avantage de la simplicité avec un nombre restreint de packages (scikit et\nstatsmodels) permettant d’avoir des modèles très généraux\n(les generalized estimating equations)\nalors qu’il faut\nchoisir parmi une grande variété de packages en R pour obtenir les\nmodèles équivalents. Dans le domaine du Deep Learning, Python écrase\nla concurrence.\nAu contraire, dans certains domaines, R reste meilleur, même si les\névolutions très récentes de certains outils peuvent amener à réviser\nce constat. Historiquement,\nR était très bien intégré au langage de publication Markdown ce qui,\npermet la construction de documents reproductibles très raffinés.\nL’émergence récente de Quarto, héritier de R Markdown développé par\nla société Posit permet aux utilisateur de Python de bénéficier\négalement de la richesse de cette approche pour leur langage de prédilection.\nCe site web, à l’arborescence relativement complexe, est ainsi\nconstruit grâce à cet outil qui permet à la fois de tester les blocs\nde code présentés mais aussi de produire de manière automatisée les\ntableaux et graphiques présentés. S’il fallait trouver un point faible\nà Python par rapport à R dans le domaine de la data science\nc’est sur la production de graphiques. matplotlib et seaborn, qui sont\nprésentés dans la partie visualisation, sont d’excellents outils. Néanmoins,\nggplot2, l’équivalent en R est plus facile de prise en main et\npropose une syntaxe extrêmement flexible, qu’il est difficile de ne pas\napprécier. Cependant, l’écosystème de la\nvisualisation de données est en pleine révolution avec le succès\nd’Observable qui\nrapproche l’écosystème JavaScript des développeurs web\nde la communauté des analystes de données.\nUn des avantages comparatifs de Python par rapport à d’autres\nlangages (notamment R et Julia) est sa dynamique,\nce que montre l’explosion du nombre de questions\nsur Stack Overflow.\nCependant, il ne s’agit pas bêtement d’enterrer R.\nAu contraire, outre leur logique très proche,\nles deux langages sont dans une phase de convergence avec des initiatives comme\nreticulate,\nquarto ou\nsnakemake qui\npermettent, de manière différente, de créer des chaînes de traitement\nmélangeant R et Python.\nUne autre raison pour laquelle cette guéguerre R/Python n’a pas\nde sens est que les bonnes\npratiques peuvent être transposées de manière presque transparente d’un\nlangage à l’autre. Il s’agit d’un point qui est développé plus amplement\ndans le cours plus avancé que je donne avec Romain Avouac en dernière année\nd’ENSAE : ensae-reproductibilite.github.io/website.\nA terme, les data scientists et chercheurs en sciences sociales ou\néconomie utiliseront\nde manière presque indifférente, et en alternance, Python et R. Ce cours\nprésentera ainsi régulièrement des analogies avec R pour aider les\npersonnes découvrant Python, mais connaissant déjà bien R, à\nmieux comprendre certains messages.\n\n\n\nLe but de ce cours est de rendre autonome sur\nl’utilisation de Python\ndans un contexte de travail de data scientist ou de\nsocial scientist (économie, sociologie, géographie…).\nAutrement dit,\nil présuppose qu’on désire faire un usage intense\nde données dans un cadre statistique rigoureux.\nLa data science est un ensemble de techniques\nvisant à donner du sens à des sources de données\ndiverses. Selon les organisations,\nles data scientists peuvent ainsi être à\nl’interface de projets nécessitant un\nlarge spectre de compétences\n(analyse\nde données textuelles, représentation\ngraphique interactive…),\navoir des interactions avec des profils\ntrès différents (experts métiers,\ndéveloppeurs, data architect,\ndata engineer…) voire adopter\nun peu tous ces rôles.\nLes innovations\nrécentes de la data science ne se réduisent\nnéanmoins\npas qu’à des découvertes méthodologiques.\nLa data science propose un ensemble de\ntechniques et de méthodes de travail\npour réduire les coûts de passage\nd’un protype à une chaine\nde production pérenne.\nCe cours introduit à quelques notions\nsur le sujet, notamment les\npipelines scikit, pour adopter\ndès l’apprentissage du langage\nquelques bons réflexes (ensae-reproductibilite.github.io/website).\n\n\n\nCe cours ne revient que de manière secondaire\nsur les fondements statistiques ou algorithmiques\nderrière certaines des techniques évoquées.\nNe pas connaître ces notions n’empêche néanmoins pas de comprendre\nle contenu de ce site web. En effet, la facilité d’usage de Python\névite de devoir programmer soi-même un modèle, ce qui rend\npossible l’application\nde modèles dont on n’est pas expert. La connaissance des modèles sera\nplutôt nécessaire dans l’interprétation des résultats.\nCependant, la facilité avec laquelle il est possible de construire des modèles complexes\navec Python peut laisser apparaître que connaître les spécifités de chaque\nmodèle est inutile. Il\ns’agirait d’une grave erreur : même si l’implémentation de modèles est aisée, il\nest nécessaire de bien comprendre la structure des données et leur adéquation\navec les hypothèses d’un modèle.\n\n\n\nCe cours donne une place centrale à\nla notion de reproductibilité. Cette exigence se traduit de diverses\nmanières dans cet enseignement, en particulier en insistant sur un\noutil indispensable pour favoriser le partage de codes informatiques,\nà savoir Git.\nL’ensemble du contenu du site web est reproductible dans des environnements\ninformatiques divers. Il est bien sûr possible de copier-coller les morceaux\nde code présents dans ce site. Cette méthode montrant rapidement ses limites,\nle site présente un certain nombre de boutons disponibles pour\nouvrir la page sous un format Jupyter Notebook sur divers\npages web :\n\nSur l’ensemble du site web,\nil est possible de cliquer\nsur la petite icone \npour être redirigé vers le dépôt Github associé à ce cours.\nUn certain nombre de boutons permettent de transformer chaque\npage web en Jupyter Notebooks s’il est nécessaire de\nvisualiser ou exécuter du code Python.\n\nVoici, par exemple, ces boutons pour le tutoriel numpy :\n\n\n\n\n\n\n\n\n\n\nPour les agents de la fonction publique, ou\nles élèves des écoles partenaires, il est recommandé\nde privilégier le bouton SSPCloud qui est\nune infrastructure cloud moderne, puissante et flexible\ndéveloppée par l’Insee et accessible à l’url\nhttps://datalab.sspcloud.fr1.\nL’ensemble du contenu de ce site s’appuie sur des données\nouvertes, qu’il s’agisse de données françaises (principalement\nissues de la plateforme\ncentralisatrice data.gouv ou du site\nweb de l’Insee) ou de données\naméricaines. Les résultats sont donc reproductibles pour quelqu’un\ndisposant d’un environnement identique.\n\n\n\nCe cours présente\ndes tutoriels et des exercices complets.\nChaque page est structurée sous la forme\nd’un problème concret et présente la\ndémarche générique pour résoudre ce problème général.\nVous pouvez naviguer dans l’architecture du site via la table des matières\nou par les liens vers le contenu antérieur ou postérieur à la fin de chaque\npage. Certaines parties, notamment celle consacrée à la modélisation,\nproposent des exemples fil-rouge pour illustrer la démarche de manière\nplus extensive.\n\n\n\nLes élèves de l’ENSAE valident le cours grâce à\nun projet approfondi.\nLes éléments relatifs à l’évaluation du cours, ainsi qu’une\nliste des projets déjà effectués, sont disponibles dans la\nSection Evaluation.\n\n\n\n\n\nDavenport, Thomas H, and DJ Patil. 2012a. “Data Scientist, the Sexiest Job of the 21st Century.” Harvard Business Review 90 (5): 70–76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n———. 2012b. “Is Data Scientist Still the Sexiest Job of the 21st Century?” Harvard Business Review 90 (5): 70–76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century."
  },
  {
    "objectID": "content/getting-started/index.html#pourquoi-faire-du-python-pour-lanalyse-de-données",
    "href": "content/getting-started/index.html#pourquoi-faire-du-python-pour-lanalyse-de-données",
    "title": "Introduction",
    "section": "",
    "text": "Le succès de scikit-learn et\nde Tensorflow dans la communauté\nde la Data-Science ont beaucoup contribué à l’adoption de Python. Cependant,\nrésumer Python à ces quelques librairies serait réducteur tant il s’agit\nd’un véritable couteau-suisse pour les data scientists,\nles social scientists ou les économistes.\nL’intérêt de Python pour un data scientist ou data economist\nva au-delà du champ du Machine Learning.\nComme pour R, l’intérêt de Python est son rôle central dans un\nécosystème plus large autour d’outils puissants, flexibles et open-source.\nPython concurrence très bien R dans son domaine de prédilection, à\nsavoir l’analyse statistique sur des bases de données structurées.\nComme dans R, les dataframes sont un concept central de Python.\nPython est néanmoins bien plus complet dans certains domaines.\nOutre le Machine Learning,\nPython est mieux adapté aux données volumineuses que\nR. Python est également meilleur que R pour faire\ndu webscraping ou accéder à des données par le biais d’API.\nDans le domaine de l’économétrie, Python offre\nl’avantage de la simplicité avec un nombre restreint de packages (scikit et\nstatsmodels) permettant d’avoir des modèles très généraux\n(les generalized estimating equations)\nalors qu’il faut\nchoisir parmi une grande variété de packages en R pour obtenir les\nmodèles équivalents. Dans le domaine du Deep Learning, Python écrase\nla concurrence.\nAu contraire, dans certains domaines, R reste meilleur, même si les\névolutions très récentes de certains outils peuvent amener à réviser\nce constat. Historiquement,\nR était très bien intégré au langage de publication Markdown ce qui,\npermet la construction de documents reproductibles très raffinés.\nL’émergence récente de Quarto, héritier de R Markdown développé par\nla société Posit permet aux utilisateur de Python de bénéficier\négalement de la richesse de cette approche pour leur langage de prédilection.\nCe site web, à l’arborescence relativement complexe, est ainsi\nconstruit grâce à cet outil qui permet à la fois de tester les blocs\nde code présentés mais aussi de produire de manière automatisée les\ntableaux et graphiques présentés. S’il fallait trouver un point faible\nà Python par rapport à R dans le domaine de la data science\nc’est sur la production de graphiques. matplotlib et seaborn, qui sont\nprésentés dans la partie visualisation, sont d’excellents outils. Néanmoins,\nggplot2, l’équivalent en R est plus facile de prise en main et\npropose une syntaxe extrêmement flexible, qu’il est difficile de ne pas\napprécier. Cependant, l’écosystème de la\nvisualisation de données est en pleine révolution avec le succès\nd’Observable qui\nrapproche l’écosystème JavaScript des développeurs web\nde la communauté des analystes de données.\nUn des avantages comparatifs de Python par rapport à d’autres\nlangages (notamment R et Julia) est sa dynamique,\nce que montre l’explosion du nombre de questions\nsur Stack Overflow.\nCependant, il ne s’agit pas bêtement d’enterrer R.\nAu contraire, outre leur logique très proche,\nles deux langages sont dans une phase de convergence avec des initiatives comme\nreticulate,\nquarto ou\nsnakemake qui\npermettent, de manière différente, de créer des chaînes de traitement\nmélangeant R et Python.\nUne autre raison pour laquelle cette guéguerre R/Python n’a pas\nde sens est que les bonnes\npratiques peuvent être transposées de manière presque transparente d’un\nlangage à l’autre. Il s’agit d’un point qui est développé plus amplement\ndans le cours plus avancé que je donne avec Romain Avouac en dernière année\nd’ENSAE : ensae-reproductibilite.github.io/website.\nA terme, les data scientists et chercheurs en sciences sociales ou\néconomie utiliseront\nde manière presque indifférente, et en alternance, Python et R. Ce cours\nprésentera ainsi régulièrement des analogies avec R pour aider les\npersonnes découvrant Python, mais connaissant déjà bien R, à\nmieux comprendre certains messages."
  },
  {
    "objectID": "content/getting-started/index.html#objectif-du-cours",
    "href": "content/getting-started/index.html#objectif-du-cours",
    "title": "Introduction",
    "section": "",
    "text": "Le but de ce cours est de rendre autonome sur\nl’utilisation de Python\ndans un contexte de travail de data scientist ou de\nsocial scientist (économie, sociologie, géographie…).\nAutrement dit,\nil présuppose qu’on désire faire un usage intense\nde données dans un cadre statistique rigoureux.\nLa data science est un ensemble de techniques\nvisant à donner du sens à des sources de données\ndiverses. Selon les organisations,\nles data scientists peuvent ainsi être à\nl’interface de projets nécessitant un\nlarge spectre de compétences\n(analyse\nde données textuelles, représentation\ngraphique interactive…),\navoir des interactions avec des profils\ntrès différents (experts métiers,\ndéveloppeurs, data architect,\ndata engineer…) voire adopter\nun peu tous ces rôles.\nLes innovations\nrécentes de la data science ne se réduisent\nnéanmoins\npas qu’à des découvertes méthodologiques.\nLa data science propose un ensemble de\ntechniques et de méthodes de travail\npour réduire les coûts de passage\nd’un protype à une chaine\nde production pérenne.\nCe cours introduit à quelques notions\nsur le sujet, notamment les\npipelines scikit, pour adopter\ndès l’apprentissage du langage\nquelques bons réflexes (ensae-reproductibilite.github.io/website)."
  },
  {
    "objectID": "content/getting-started/index.html#public-cible",
    "href": "content/getting-started/index.html#public-cible",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours ne revient que de manière secondaire\nsur les fondements statistiques ou algorithmiques\nderrière certaines des techniques évoquées.\nNe pas connaître ces notions n’empêche néanmoins pas de comprendre\nle contenu de ce site web. En effet, la facilité d’usage de Python\névite de devoir programmer soi-même un modèle, ce qui rend\npossible l’application\nde modèles dont on n’est pas expert. La connaissance des modèles sera\nplutôt nécessaire dans l’interprétation des résultats.\nCependant, la facilité avec laquelle il est possible de construire des modèles complexes\navec Python peut laisser apparaître que connaître les spécifités de chaque\nmodèle est inutile. Il\ns’agirait d’une grave erreur : même si l’implémentation de modèles est aisée, il\nest nécessaire de bien comprendre la structure des données et leur adéquation\navec les hypothèses d’un modèle."
  },
  {
    "objectID": "content/getting-started/index.html#reproductibilité",
    "href": "content/getting-started/index.html#reproductibilité",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours donne une place centrale à\nla notion de reproductibilité. Cette exigence se traduit de diverses\nmanières dans cet enseignement, en particulier en insistant sur un\noutil indispensable pour favoriser le partage de codes informatiques,\nà savoir Git.\nL’ensemble du contenu du site web est reproductible dans des environnements\ninformatiques divers. Il est bien sûr possible de copier-coller les morceaux\nde code présents dans ce site. Cette méthode montrant rapidement ses limites,\nle site présente un certain nombre de boutons disponibles pour\nouvrir la page sous un format Jupyter Notebook sur divers\npages web :\n\nSur l’ensemble du site web,\nil est possible de cliquer\nsur la petite icone \npour être redirigé vers le dépôt Github associé à ce cours.\nUn certain nombre de boutons permettent de transformer chaque\npage web en Jupyter Notebooks s’il est nécessaire de\nvisualiser ou exécuter du code Python.\n\nVoici, par exemple, ces boutons pour le tutoriel numpy :\n\n\n\n\n\n\n\n\n\n\nPour les agents de la fonction publique, ou\nles élèves des écoles partenaires, il est recommandé\nde privilégier le bouton SSPCloud qui est\nune infrastructure cloud moderne, puissante et flexible\ndéveloppée par l’Insee et accessible à l’url\nhttps://datalab.sspcloud.fr1.\nL’ensemble du contenu de ce site s’appuie sur des données\nouvertes, qu’il s’agisse de données françaises (principalement\nissues de la plateforme\ncentralisatrice data.gouv ou du site\nweb de l’Insee) ou de données\naméricaines. Les résultats sont donc reproductibles pour quelqu’un\ndisposant d’un environnement identique."
  },
  {
    "objectID": "content/getting-started/index.html#architecture-du-site-web",
    "href": "content/getting-started/index.html#architecture-du-site-web",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours présente\ndes tutoriels et des exercices complets.\nChaque page est structurée sous la forme\nd’un problème concret et présente la\ndémarche générique pour résoudre ce problème général.\nVous pouvez naviguer dans l’architecture du site via la table des matières\nou par les liens vers le contenu antérieur ou postérieur à la fin de chaque\npage. Certaines parties, notamment celle consacrée à la modélisation,\nproposent des exemples fil-rouge pour illustrer la démarche de manière\nplus extensive."
  },
  {
    "objectID": "content/getting-started/index.html#evaluation",
    "href": "content/getting-started/index.html#evaluation",
    "title": "Introduction",
    "section": "",
    "text": "Les élèves de l’ENSAE valident le cours grâce à\nun projet approfondi.\nLes éléments relatifs à l’évaluation du cours, ainsi qu’une\nliste des projets déjà effectués, sont disponibles dans la\nSection Evaluation."
  },
  {
    "objectID": "content/getting-started/index.html#références",
    "href": "content/getting-started/index.html#références",
    "title": "Introduction",
    "section": "",
    "text": "Davenport, Thomas H, and DJ Patil. 2012a. “Data Scientist, the Sexiest Job of the 21st Century.” Harvard Business Review 90 (5): 70–76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n———. 2012b. “Is Data Scientist Still the Sexiest Job of the 21st Century?” Harvard Business Review 90 (5): 70–76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century."
  },
  {
    "objectID": "content/getting-started/index.html#footnotes",
    "href": "content/getting-started/index.html#footnotes",
    "title": "Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour les utilisateurs de cette infrastructure, les notebooks\nsont également listés, parmi de nombreuses autres\nressources de qualité, sur la\npage Formation↩︎"
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html",
    "href": "content/getting-started/02_DS_environment.html",
    "title": "L’environnement Python pour la data science",
    "section": "",
    "text": "La richesse des langages open-source est la possibilité\nd’utiliser des packages\ndéveloppés par des spécialistes. Python est particulièrement\nbien doté dans le domaine. Pour caricaturer, on lit parfois\nque Python est le deuxième meilleur langage pour toutes les\ntâches, ce qui en fait le meilleur langage.\nEn effet, la malléabilité de Python fait qu’on peut\nl’aborder de manière très différentes\nselon que l’on est plutôt SysAdmin, développeur web ou\ndata scientist. C’est ce dernier profil qui va ici nous\nintéresser.\nLe data scientist devant disposer de nombreuses cordes\nà son arc. Cela se reflète sur l’écosystème de la data science\nqui est assez éclaté. Cependant, ce foisonnement\nn’est pas propre à Python puisque R propose encore plus de\npackages que Python où un certain nombre de framework\nnormalisés limitent l’éclatement de l’écosystème. De plus,\nle foisonnement de l’environnement du data scientist\nest une véritable opportunité puisqu’elle permet\naux packages de se spécialiser dans un\ndomaine, où ils sont plus efficaces, et aux concepteurs\nde package d’oser mettre en oeuvre de nouvelles méthodes,\nindispensables pour que le langage suive les évolutions\nrapides de la recherche ou de la technologie."
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#les-packages-python-essentiels-pour-le-cours-et-la-vie-des-data-scientists",
    "href": "content/getting-started/02_DS_environment.html#les-packages-python-essentiels-pour-le-cours-et-la-vie-des-data-scientists",
    "title": "L’environnement Python pour la data science",
    "section": "Les packages Python essentiels pour le cours et la vie des data scientists",
    "text": "Les packages Python essentiels pour le cours et la vie des data scientists\n\n\n\n\n\nCe\npost,\ndont l’image ci-dessus est tirée, résume la plupart des packages utiles\npour un data scientist ou un économiste/sociologue. Nous nous bornerons\nici à évoquer ceux utilisés quotidiennement.\n\nnumpy\nnumpy gère tout ce qui est calcul matriciel.\nLe langage Python est un des langages les plus lents qui soient1.\nTous les calculs rapides ne sont pas écrits en Python mais en C++, voire Fortran.\nC’est le cas du package numpy. Celui-ci est incontournable\ndès qu’on veut être rapide. Le package\nscipy est une extension où l’on peut trouver\ndes fonctions statistiques, d’optimisation.\nLa Cheat Sheet de numpy est pratique:\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\nComme numpy est la brique de base de l’analyse de données, un chapitre\nde ce cours lui est consacré.\n\n\npandas\nAvant tout, un bon data scientist doit être capable de\ns’approprier et manipuler des données rapidement. Pour cette raison,\npandas est incontournable.\nIl gère la plupart des formats de données. Pour être efficace,\nil est lui aussi implémenté en C++.\nLe package est rapide si on utilise les méthodes pré-implémentées sur\ndes données d’une taille raisonnable (par rapport à la RAM disponible). Il faut\nnéanmoins s’en méfier avec des données volumineuses.\nEn règle générale, un jeu de données nécessite\ntrois fois plus d’espace en mémoire que les\ndonnées n’en prennent sur le disque.\nLa Cheat Sheet de pandas :\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Pandas_Cheat_Sheet_2.pdf\npandas étant un élément incontournable, deux chapitres y sont consacrés.\n\n\nmatplotlib et seaborn\nmatplotlib existe depuis une vingtaine d’années pour doter Python de\nfonctionalités graphiques. Il s’agit d’un package très flexible, offrant\nde nombreuses fonctionalités. Néanmoins, ces dernières années,\nseaborn a émergé pour simplifier la création de certains graphiques\nstandards de l’analyse de données (histogrammes, diagramme en barre, etc. ).\nLe succès de seaborn n’éclipse néanmoins pas matplotlib puisque ce\ndernier est souvent nécessaire pour finaliser la customisation d’un\ngraphique produit par seaborn2\n\n\nscikit-learn\nscikit-learn est le module de machine learning le plus populaire pour\ntrois raisons:\n\nil s’appuie sur une API extrêmement consistante (méthodes fit, transform\net predict, respectivement pour apprendre des données, appliquer des transformations et prédire sur de nouvelles données) ;\nil permet de construire\ndes analyses reproductibles en construisant des pipelines de données ;\nsa documentation est un modèle à suivre.\n\nL’INRIA, institution française, est l’un des éléments moteurs dans\nla création et la maintenance de scikit-learn\n\n\nTensorFlow, PyTorch et Keras\nLes librairies essentielles pour implémenter et utiliser des modèles\nde deep learning en Python ont été développées par des acteurs du\nnumérique.\nTensorFlow est la librairie la plus mature, mais pas nécessairement la plus facile à prendre en main. D’ailleurs, Google semble l’abandonner en usage interne pour lui\npréférer JAX.\nKeras propose une interface high-level,\ndonc plus facile d’utilisation,\nmais qui n’en reste pas moins suffisante pour une grande variété d’usages.\nLa documentation de Keras est très bien faite.\nPyTorch est un framework plus récent mais très complet,\ndont la syntaxe plaira aux amateurs de programmation orienté-objet.\nDéveloppé par Facebook,\nil est très utilisé dans certains domaines de recherche, comme le NLP.\nIl s’agit du framework dont la dynamique récente a été la plus\nascensionnelle.\n\n\nstatsmodels\nstatsmodels plaira plus aux statisticiens, il implémente des modèles\néconométriques similaires à scikit-learn.\nPar rapport à scikit-learn,\nstatsmodels est plus orienté économétrie. La présentation des\nrésultats est très proche de ce qu’on trouve en R.\n\n\nrequests et beautifulsoup\nrequests est l’une des librairies de base de Python, dédiée\nà gérer la connexion avec internet. Les amateurs d’API\nseront des utilisateurs fréquents de celle-ci. Les\npersonnes plus spécialistes de web scraping l’utiliseront avec\nbeautifulsoup qui offre une syntaxe extrêmement puissante\npour récupérer automatiquement du contenu de pages web.\n\n\nnltk et spaCy\nDans le domaine du traitement automisé du langage, plus connu\nsous son acronyme anglais NLP, les deux packages phares sont\nnltk et spaCy.\nnltk est le package historique. Il existe depuis les années\n1990 et propose de nombreuses ressources utiles pour l’analyse\ntextuelle. Néanmoins, ces dernières années, spaCy est venu\nmoderniser l’approche en proposant une approche permettant\nde mieux intégrer les différentes phases du traitement de données\ntextuelles, une excellente documentation et un meilleur support\ndes langues non anglo-saxonnes, comme le Français.\nMais Python est également un outil privilégié pour communiquer:\n\nUne bonne intégration de Python à Markdown (grâce notamment à … R Markdown) qui facilite la construction de documents HTML ou PDF (via Latex)\nSphynx et JupyterBook proposent des modèles de documentation\ntrès complets\nbokeh ou streamlit comme alternative à shiny (R)\nDjango et Flask permettent de construire des applications web en Python\nLes librairies dynamiques, notamment\nfolium ou\nplotly, sont très appréciées pour construire des\nvisualisations dynamiques qui sont pratiques dans une analyse exploratoire\nmais également lorsqu’il faut valoriser ses travaux auprès de\npublics non experts de la donnée.\n\nL’un des nouveaux arrivants dans cet écosystème déjà riche\nest FastAPI). Avec ce package,\nil est très facile de transformer un code Python en API ce qui facilite\nla mise à disposition de données mais aussi de productions par Python (comme\nla mise à disposition d’une API pour permettre à des personnes de tester\nles résultats d’un modèle de machine learning).\nCe n’est qu’une petite partie de l’écosystème Python, d’une richesse rare."
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#environnement-autour-de-python",
    "href": "content/getting-started/02_DS_environment.html#environnement-autour-de-python",
    "title": "L’environnement Python pour la data science",
    "section": "Environnement autour de Python",
    "text": "Environnement autour de Python\nPython est un langage très riche, grâce à sa logique open-source. Mais l’un\ndes principaux intérêts réside dans le riche écosystème avec lequel Python\ns’intègre. On peut donner quelques éléments, dans un inventaire à la Prévert non exaustif.\nEn premier lieu, des éléments reliés au traitement des données :\n\nSpark,\nle framework dominant dans le domaine du traitement des big-data, très bien\ninterfacé avec Python (grâce à l’API pyspark), qui facilite le traitement des données volumineuses. Son utilisation nécessite cependant d’avoir accès à une\ninfrastructure de calculs distribuée.\nCython permet d’intégrer facilement du code C, très\nefficace avec Python (équivalent de Rcpp pour R).\nJulia est un langage récent, qui propose une syntaxe familière aux utilisateurs de languages scientifiques (Python, R, MATLAB), tout en permettant des performances proches du C grâce à une compilation à la volée.\n\nEnfin, des éléments permettant un déploiement de résultats ou d’applications\nen continu :\n* Les images Docker de Jupyterhub facilitent l’usage de l’intégration continue\npour construire des modules, les tester et déployer des site web.\n* Les services type Binder, Google Colab et Kaggle proposent des kernels\nPython"
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#rester-au-courant-des-évolutions",
    "href": "content/getting-started/02_DS_environment.html#rester-au-courant-des-évolutions",
    "title": "L’environnement Python pour la data science",
    "section": "Rester au courant des évolutions",
    "text": "Rester au courant des évolutions\nL’écosystème riche et foisonnant de Python a comme contrepartie\nqu’il faut rester attentif à ses évolutions pour ne pas\nvoir son capital humain vieillir et ainsi devenir has-been.\nAlors qu’avec des langages\nmonolithiques comme\nSAS ou Stata on pouvait se permettre de ne faire de vieille technique\nmais seulement consulter la documentation officielle, avec Python\nou R c’est impossible. Ce cours lui-même est en évolution continue, ce\nqui est assez exigeant :sweating:, pour épouser les évolutions\nde l’écosystème.\nTwitter est une excellente source d’information pour être rapidement\nau courant des évolutions du monde de la data science. Les agrégateurs\nde contenu comme medium ou towardsdatascience proposent des posts\nde qualité hétérogène mais il peut être utile de recevoir par mail\nle feed des nouveaux posts : au bout d’un certain temps, cela peut\npermettre de dégager les nouvelles tendances. Le site\nrealpython propose généralement de très bon posts, complets et\npédagogiques.\nEn ce qui concerne les ouvrages papiers, certains sont de très bonne qualité.\nCependant, il convient de faire attention à la date de mise à jour de ceux-ci :\nla vitesse d’évolution de certains éléments de l’écosystème peut les\npérimer très rapidement."
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#footnotes",
    "href": "content/getting-started/02_DS_environment.html#footnotes",
    "title": "L’environnement Python pour la data science",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPython est un langage interprété, comme R. Cela le rend très\nintelligible, y compris par un non-expert. C’est une des raisons de son\nsuccès. Le créateur de Python, Guido Van Rossum,\nen a fait un des principes philosophiques\nà l’origine de Python: un code est plus souvent lu qu’écrit.\nLa contrepartie est qu’il s’agit d’une surcouche à des langages\nplus bas-niveau, notamment C. Ces derniers proposent beaucoup moins de\nsurcouches. En réalité, les fonctions Python font appel, plus ou moins\ndirectement, à du C. Une manière d’optimiser le code est ainsi d’arriver,\navec le moins de surcouches possible, à la fonction C sous-jacente,\nbeaucoup plus rapide.↩︎\nLa situation est différente en R où ggplot2 a quasiment éclipsé\nl’outil de graphique de base de R.↩︎"
  },
  {
    "objectID": "content/getting-started/04_python_practice.html",
    "href": "content/getting-started/04_python_practice.html",
    "title": "Bonne pratique de Python",
    "section": "",
    "text": "Une référence utile à lire est le\nHitchhiker’s Guide to Python"
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#structure-dun-projet-en-python",
    "href": "content/getting-started/04_python_practice.html#structure-dun-projet-en-python",
    "title": "Bonne pratique de Python",
    "section": "Structure d’un projet en python",
    "text": "Structure d’un projet en python\nLa structure basique d’un projet développé en Python est la suivante, qu’on peut retrouver dans\nce dépôt:\nREADME.md\nLICENSE\nsetup.py\nrequirements.txt\nmonmodule/__init__.py\nmonmodule/core.py\nmonmodule/helpers.py\ndocs/conf.py\ndocs/index.rst\ntests/context.py\ntests/test_basic.py\ntests/test_advanced.py\nQuelques explications et parallèles avec les packages R1 :\n\nLe code Python est stocké dans un module nommé monmodule. C’est le coeur du code dans le projet. Contrairement\nà R, il est possible d’avoir une arborescence avec plusieurs modules dans un seul package. Un bon exemple\nde package dont le fonctionnement adopte une arborescence à plusieurs niveaux est scikit\nLe fichier setup.py sert à construire le package monmodule pour en faire un code utilisable. Il n’est pas\nobligatoire quand le projet n’a pas vocation à être sur PyPi mais il est assez facile à créer en suivant ce\ntemplate. C’est l’équivalent\ndu fichier Description dans un package R\n(exemple)\nLe fichier requirements.txt permet de contrôler les dépendances du projet. Il s’agit des\ndépendances nécessaires pour faire tourner les fonctions (par exemple numpy), les tester et\nconstruire automatiquement la documentation (par exemple sphinx). Dans un package R, le fichier qui contrôle\nl’environnement est le NAMESPACE.\nLe dossier docs stocke la documentation du package. Le mieux est de le générer à partir de\nsphinx et non de l’éditer\nmanuellement. (cf. plus tard).\nLes éléments qui s’en rapprochent dans un package R sont les vignettes.\nLes tests génériques des fonctions. Ce n’est pas obligatoire mais c’est recommandé : ça évite de découvrir deux jours\navant un rendu de projet que la fonction ne produit pas le résultat espéré.\nLe README.md permet de créer une présentation du package qui s’affiche automatiquement sur\ngithub/gitlab et le fichier LICENSE vise à protéger la propriété intellectuelle. Un certain nombre de licences\nstandards existent et peuvent être utilisées comme template grâce au site https://choosealicense.com/\n\n2 La structure nécessaire des projets nécessaire pour pouvoir construire un package R est plus contrainte.\nLes packages devtools, usethis et testthat ont grandement facilité l’élaboration d’un package R. A cet égard,\nil est recommandé de lire l’incontournable livre d’Hadley Wickham"
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#style-de-programmation-et-de-documentation",
    "href": "content/getting-started/04_python_practice.html#style-de-programmation-et-de-documentation",
    "title": "Bonne pratique de Python",
    "section": "Style de programmation et de documentation",
    "text": "Style de programmation et de documentation\n\nThe code is read much more often than it is written.\nGuido Van Rossum [créateur de Python]\n\nPython est un langage très lisible. Avec un peu d’effort sur le nom des objets, sur la gestion\ndes dépendances et sur la structure du programme, on peut\ntrès bien comprendre un script sans avoir besoin de l’exécuter. La communauté Python a abouti à un certain\nnombre de normes, dites PEP (Python Enhancement Proposal), qui constituent un standard\ndans l’écosystème Python. Les deux normes les plus connues sont\nla norme PEP8 (code) et la norme PEP257 (documentation).\nLa plupart de ces recommandations ne sont pas propres à Python, on les retrouve aussi dans R\n(cf. ici).\nOn retrouve de nombreux conseils dans cet ouvrage qu’il est\nrecommandé de suivre. La suite se concentrera sur des éléments complémentaires.\n\nImport des modules\nLes éléments suivants concernent plutôt les scripts finaux, qui appellent de multiples fonctions, que des\nscripts qui définissent des fonctions.\nUn module est un ensemble de fonctions stockées dans un fichier .py. Lorsqu’on écrit dans un script\nimport modu\nPython commence par chercher le fichier modu.py dans le dossier de travail. Il n’est donc pas une bonne\nidée d’appeler un fichier du nom d’un module standard de python, par exemple math.py ou os.py. Si le fichier\nmodu.py n’est pas trouvé dans le dossier de travail, Python va chercher dans le chemin et s’il ne le trouve pas\nretournera une erreur.\nUne fois que modu.py est trouvé, il sera exécuté dans un environnement isolé (relié de manière cohérente\naux dépendances renseignées) et le résultat rendu disponible à l’interpréteur Python pour un usage\ndans la session via le namespace (espace où Python associe les noms donnés aux objets).\nEn premier lieu, ne jamais utiliser la syntaxe suivante :\n# A NE PAS UTILISER\nfrom modu import *\nx = sqrt(4)  # Is sqrt part of modu? A builtin? Defined above?\nL’utilisation de la syntaxe import * créé une ambiguité sur les fonctions disponibles dans l’environnement. Le code\nest ainsi moins clair, moins compartimenté et ainsi moins robuste. La syntaxe à privilégier est la suivante :\nimport modu\nx = modu.sqrt(4)  # Is sqrt part of modu? A builtin? Defined above?"
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#structuration-du-code",
    "href": "content/getting-started/04_python_practice.html#structuration-du-code",
    "title": "Bonne pratique de Python",
    "section": "Structuration du code",
    "text": "Structuration du code\nIl est commun de trouver sur internet des codes très longs, généralement dans un fichier __init__.py\n(méthode pour passer d’un module à un package, qui est un ensemble plus structuré de fonctions).\nContrairement à la légende, avoir des scripts longs est peu désirable et est même mauvais ;\ncela rend le code difficilement à s’approprier et à faire évoluer. Mieux vaut avoir des scripts relativement courts\n(sans l’être à l’excès…) qui font éventuellement appels à des fonctions définies dans d’autres scripts.\nPour la même raison, la multiplication de conditions logiques if…else if…else est généralement très mauvais\nsigne (on parle de code spaghetti) ; mieux vaut\nutiliser des méthodes génériques dans ce type de circonstances."
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#écrire-des-fonctions",
    "href": "content/getting-started/04_python_practice.html#écrire-des-fonctions",
    "title": "Bonne pratique de Python",
    "section": "Écrire des fonctions",
    "text": "Écrire des fonctions\nLes fonctions sont un objet central en Python.\nLa fonction idéale est une fonction qui agit de manière compartimentée :\nelle prend un certain nombre d’inputs et est reliée au monde extérieur uniquement par les dépendances,\nelle effectue des opérations sans interaction avec le monde extérieur et retourne un résultat.\nCette définition assez consensuelle masque un certain nombre d’enjeux :\n\nUne bonne gestion des dépendances nécessite d’avoir appliqué les recommandations évoquées précédemment\nIsoler du monde extérieur nécessite de ne pas faire appel à un objet extérieur à l’environnement de la fonction.\nAutrement dit, aucun objet hors de la portée (scope) de la fonction ne doit être altéré ou utilisé.\n\nPar exemple, le script suivant est mauvais au sens où il utilise un objet y hors du scope de la fonction add\ndef add(x):\n    return x + y\nIl faudrait revoir la fonction pour y ajouter un élément y:\ndef add(x, y):\n    return x + y\nPycharm offre des outils de diagnostics très pratiques pour détecter et corriger ce type d’erreur.\n\n⚠️ aux arguments optionnels\nLa fonction la plus lisible (mais la plus contraignante) est celle\nqui utilise exclusivement des arguments positionnels avec des noms explicites.\nDans le cadre d’une utilisation avancée des fonctions (par exemple un gros modèle de microsimulation), il est\ndifficile d’anticiper tous les objets qui seront nécessaires à l’utilisateur. Dans ce cas, on retrouve généralement\ndans la définition d’une fonction le mot-clé **kwargs (équivalent du ... en R) qui capture les\narguments supplémentaires et les stocke sous forme de dictionnaire. Il s’agit d’une technique avancée de\nprogrammation qui est à utiliser avec parcimonie."
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#documenter-les-fonctions",
    "href": "content/getting-started/04_python_practice.html#documenter-les-fonctions",
    "title": "Bonne pratique de Python",
    "section": "Documenter les fonctions",
    "text": "Documenter les fonctions\nLa documentation d’une fonction s’appelle le docstring. Elle prend la forme suivante :\ndef square_and_rooter(x):\n    \"\"\"Return the square root of self times self.\"\"\"\n    ...\nAvec PyCharm, lorsqu’on utilise trois guillemets sous la définition d’une fonction, un template minimal à\ncompleter est automatiquement généré. Les normes à suivre pour que la docstrings soit reconnue par le package\nsphinx sont présentées dans la PEP257. Néanmoins,\nelles ont été enrichies par le style de docstrings NumPy qui est plus riche et permet ainsi des documentations\nplus explicites\n(voir ici et\nici).\nSuivre ces canons formels permet une lecture simplifiée du code source de la documentation. Mais cela a surtout\nl’avantage, lors de la génération d’un package, de permettre une mise en forme automatique des fichiers\nhelp d’une fonction à partir de la docstrings. L’outil canonique pour ce type de construction automatique est\nsphinx (dont l’équivalent R est Roxygen)"
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#les-tests",
    "href": "content/getting-started/04_python_practice.html#les-tests",
    "title": "Bonne pratique de Python",
    "section": "Les tests",
    "text": "Les tests\nTester ses fonctions peut apparaître formaliste mais c’est, en fait, souvent d’un grand secours car cela permet de\ndétecter et corriger des bugs précoces (ou au moins d’être conscient de leur existence).\nAu-delà de la correction de bug, cela permet de vérifier que\nla fonction produit bien un résultat espéré dans une expérience contrôlée.\nEn fait, il existe deux types de tests:\n\ntests unitaires : on teste seulement une fonctionalité ou propriété\ntests d’intégration : on teste l’intégration de la fonction dans un ensemble plus large de fonctionalités\n\nIci, on va plutôt se focaliser sur la notion de test unitaire, la notion de\ntest d’intégration nécessitant d’avoir une chaîne plus complète de fonctions (mais il ne faut\npas la négliger).\nOn peut partir du principe suivant :\n\ntoute fonctionnalité non testée comporte un bug\n\nLe fichier tests/context.py sert à définir le contexte dans lequel le test de la fonction s’exécute, de manière\nisolée. On peut adopter le modèle suivant, en changeant import monmodule par le nom de module adéquat\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n\nimport monmodule\nChaque fichier du dossier de test\n(par exemple test_basic.py et test_advanced.py) incorpore ensuite la ligne suivante,\nen début de script\nfrom .context import sample\nPour automatiser les tests, on peut utiliser le package unittest\n(doc ici). L’idée est que dans un cadre contrôlé\n(on connaît l’input et en tant que concepteur de la fonction on connaît l’output ou, a minima\nles propriétés de l’output) on peut tester la sortie d’une fonction.\nLa structure canonique de test est la suivante3\nimport unittest\n\ndef fun(x):\n    return x + 1\n\nclass MyTest(unittest.TestCase):\n    def test(self):\n        self.assertEqual(fun(3), 4)\n4 Le code équivalent avec R serait testthat::expect_equal(fun(3),4)\nParler de codecov"
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#partager",
    "href": "content/getting-started/04_python_practice.html#partager",
    "title": "Bonne pratique de Python",
    "section": "Partager",
    "text": "Partager\nCe point est ici évoqué en dernier mais, en fait, il est essentiel et mérite d’être une réflexion prioritaire.\nTout travail n’a pas vocation à être public\nou à dépasser le cadre d’une équipe. Cependant, les mêmes exigences qui s’appliquent lorsqu’un code est public méritent\nde s’appliquer avec un projet personnel. Avant de partager un code avec d’autres, on le partage avec le “futur moi”.\nReprendre un code écrit il y a plusieurs semaines est coûteux et mérite d’anticiper en adoptant des bonnes pratiques qui\nrendront quasi-indolore la ré-appropriation du code.\nL’intégration d’un projet avec git fiabilise grandement le processus d’écriture du code mais aussi, grâce aux\noutils d’intégration continue, la production de contenu (par exemple des visualisations html ou des rapports\nfinaux écrits avec markdown). Il est recommandé d’immédiatement connecter un projet à git, même avec un\ndépôt qui aura vocation à être personnel. Les instructions d’utilisation de git sont détaillées ici."
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#footnotes",
    "href": "content/getting-started/04_python_practice.html#footnotes",
    "title": "Bonne pratique de Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n1↩︎\n1:↩︎\n2↩︎\n2:↩︎"
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html",
    "href": "content/getting-started/06_rappels_fonctions.html",
    "title": "Modules, tests, boucles, fonctions",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink, nbviewerLink;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/tree/main`;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n        nbviewerLink = `https://nbviewer.jupyter.org/${githubRepoNotebooksSimplified}/blob/main/${notebook}`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n    let downloadLink;\n    if (type === \"md\") {\n        downloadLink = `[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath})`;\n    } else {\n        downloadLink = `&lt;a href=\"https://downgit.github.io/#/home?url=${githubLink}${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter\" alt=\"Download\"&gt;&lt;/a&gt;`;\n    }\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    let visualizeLink;\n    if (type === \"md\") {\n        visualizeLink = `[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](${nbviewerLink})`;\n    } else {\n        visualizeLink = `&lt;a href=\"${nbviewerLink}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter\" alt=\"nbviewer\"&gt;&lt;/a&gt;`;\n    }\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink, downloadLink,\n        visualizeLink, sspcloudJupyterLink,\n        sspcloudVscodeLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink, vscodeLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}"
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#utilisation-dun-module-installé",
    "href": "content/getting-started/06_rappels_fonctions.html#utilisation-dun-module-installé",
    "title": "Modules, tests, boucles, fonctions",
    "section": "Utilisation d’un module installé",
    "text": "Utilisation d’un module installé\nPython, comme R, sont des langages\nconstruits sur le principe de briques.\nCes briques sont ce qu’on appelle des packages.\nAu contraire de Stata mais comme pour R,\nil\nfaut toujours préciser les packages que vous utilisez au début du code,\nsinon Python ne reconnait pas les fonctions appelées.\n\nImport module\nOn charge un module grâce à la commande import.\nPour chaque code que vous exécutez,\nil faut charger les modules en introduction.\nUne fois qu’on a chargé le module,\non peut faire appel aux commandes qui en dépendent en les appelant\naprès avoir tapé le nom du module.\nSi vous ne précisez pas le nom du module avant celui de la fonction,\nil ne la trouvera pas forcément.\nVoici un exemple avec le module numpy\nqui est très courant et permet de faire des\ncalculs matriciels sous Python.\n\nimport numpy\nprint(numpy.arange(5))\n\n[0 1 2 3 4]\n\n\n\n\nImport module as md - donner un nom au module\nOn peut aussi donner un pseudonyme au module pour\néviter de taper un nom trop long à chaque fois\nqu’on utilise une fonction.\nClassiquement le nom raccourci de numpy est np,\ncelui de pandas est pd.\n\nimport pandas as pd\nimport numpy as np\nsmall_array = np.array([[1, 2], [3, 4]])\ndata = pd.DataFrame(small_array)\ndata.head()\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n1\n2\n\n\n1\n3\n4\n\n\n\n\n\n\n\n\n\nfrom Module Import fonction - seulement une partie du module\nSi on ne veut pas être obligé de donner\nle nom du module avant d’appeler\nla fonction,\nil y a toujours la possibilité de n’importer qu’une fonction du module.\nDans le cas de l’exemple, Python sait que la fonction arrange est celle de numpy.\nMais attention : si deux fonctions de modules différents\nont le même nom,\nc’est toujours la dernière importée qui gagne.\nOn voit souvent from _module_ import *.\nC’est-à-dire qu’on importe toutes\nles fonctions du module\nmais on n’a pas besoin de spécifier le nom du module avant les méthodes.\n\n\n Warning\nLa méthode from _module_ import * n’est pas recommandée car elle rend le code moins intelligible.\nEn effet, d’où vient la fonction floor ? De maths ou de numpy ?\nElle risque\naussi de créer des conflits de fonction, qui malgré un nom commun peuvent ne\npas attendre les mêmes arguments ou objets.\n\n\n\nfrom numpy import array\nprint(array(5))\n\n5"
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#les-tests",
    "href": "content/getting-started/06_rappels_fonctions.html#les-tests",
    "title": "Modules, tests, boucles, fonctions",
    "section": "Les tests",
    "text": "Les tests\nLes tests permettent d’exécuter telle ou telle instruction\nselon la valeur d’une condition.\nPour faire un test avec un bloc d’instructions, il faut toujours :\n\nque l’expression à vérifier soit suivie de :\nque le bloc d’instruction soit forcément indenté\n\n\nTest avec contrepartie : if et else\nComme dans les autres langages,\non teste une condition. Si elle est vérifiée,\nalors une instruction suit et sinon, une autre instruction est exécutée.\nIl est conseillé de toujours indiquer une contrepartie afin d’éviter les surprises.\n\nTest d’une égalité ou inégalité\n\nx = 6\n\nif x &gt; 5 :\n    print(\"x est plus grand que 5\")\nelse : # la contrepartie si la condition if n'est pas réalisée\n    print(\"x est plus petit que 5\")\n\nx est plus grand que 5\n\n\n\n\nTest dans un intervalle\n\n# on peut avoir des intervalles directement\nx = 6\nif 5 &lt; x &lt; 10 : \n    print(\"x est entre 5 et 10\")\nelse : \n    print(\"x est plus grand que 10\")\n\nx est entre 5 et 10\n\n\n\n# tester plusieurs valeurs avec l'opérateur logique \"or\"\nx = 5\nif x == 5 or x == 10 : \n    print(\"x vaut 5 ou 10\")    \nelse : \n    print(\"x est différent de 5 et 10\")\n\nx vaut 5 ou 10\n\n\n\n\n\nTests successifs : if, elif et else\nAvec if et elif,\ndès qu’on rencontre une condition qui est réalisée,\non n’en cherche pas d’autres potentiellement vérifiées.\nPlusieurs if à la suite peuvent quant à eux être vérifiés.\nSuivant ce que vous souhaitez faire, les opérateurs ne sont pas substituables.\nNotez la différence entre ces deux bouts de code :\n\n#code 1\nx = 5\n\nif x != 10 : \n    print(\"x ne vaut pas 10\")   \nelif x &gt;= 5 : \n    print(\"x est égal ou supérieur à 5\")\n\nx ne vaut pas 10\n\n\nDans le cas de elif, on s’arrête à la première condition vérifiée et dans le cas suivant, on continue à chaque condition vérifiée\n\n#code 2\nx = 5\n\nif x != 10 : \n    print(\"x ne vaut pas 10\")   \nif x &gt;= 5 : \n    print(\"x est égal ou supérieur à 5\")\n\nx ne vaut pas 10\nx est égal ou supérieur à 5"
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#boucles",
    "href": "content/getting-started/06_rappels_fonctions.html#boucles",
    "title": "Modules, tests, boucles, fonctions",
    "section": "Boucles",
    "text": "Boucles\nIl existe deux types de boucles : les boucles for et les boucles while\nLa boucle for parcourt un ensemble, tandis que la boucle while\ncontinue tant qu’une condition est vraie.\n\nBoucle for\n\nParcourir une liste croissantes d’entiers\n\n# parcourt les entiers de 0 à n-1 inclus\nfor i in range(0,3) : \n    print(i)\n\n0\n1\n2\n\n\n\n\nParcourir une liste décroissante d’entiers\n\n# parcourt les entiers de 3 à n+1 inclus\nfor i in range(3,0,-1) : \n    print(i)\n\n3\n2\n1\n\n\n\n\nParcourir une liste de chaines de caractères\nOn va faire une boucle sur les éléments d’une liste\n\n\nBoucle sur les éléments d’une liste\n\nliste_elements = ['Nicolas','Romain','Florimond']\n\n# pour avoir l'ensemble des éléments de la liste\nfor item in liste_elements : \n    print(item)\n\nNicolas\nRomain\nFlorimond\n\n\n\n\nBoucle sur les éléments d’une liste dans une autre liste\n\n# pour avoir la place des éléments de la première liste dans la seconde liste  \n\nliste_globale = ['Violette','Nicolas','Mathilde','Romain','Florimond','Helene'] \n\nfor item in liste_elements : \n    print(item,liste_globale.index(item))\n\nNicolas 1\nRomain 3\nFlorimond 4\n\n\n\n\n\nBonus : les list comprehension\nAvec les listes, il existe aussi un moyen très élégant de condenser son code pour éviter de faire apparaitre des boucles sans arrêt. Comme les boucles doivent etre indentées, le code peut rapidement devenir illisible.\nGrace aux list comprehension, vous pouvez en une ligne faire ce qu’une boucle vous permettait de faire en 3 lignes.\nPar exemple, imaginez que vous vouliez faire la liste de toutes les lettres contenues dans un mot, avec un boucle vous devrez d’abord créer une liste vide, puis ajouter à cette liste toutes les lettres en question avec un .append()\n\nliste_lettres = []\n\nfor lettre in 'ENSAE':\n    liste_lettres.append(lettre)\n\nprint(liste_lettres)\n\n['E', 'N', 'S', 'A', 'E']\n\n\navec une list comprehension, on condense la syntaxe de la manière suivante :\n\nh_letters = [ letter for letter in 'ENSAE' ]\nprint(h_letters)\n\n['E', 'N', 'S', 'A', 'E']\n\n\nAvec une list comprehension\n[ expression for item in list if conditional ]\nest équivalent à\nfor item in list:\n    if conditional:\n        expression  \n\nMise en application\nMettez sous forme de list comprehension le bout de code suivant\n\nsquares = []\n\nfor x in range(10):\n    squares.append(x**2)\nprint(squares)\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\n\n\n\n\nBoucle while\nLe bloc d’instruction d’une boucle while est exécuté tant que la condition est vérifiée.\nLe piège de ces boucles : la boucle while infinie ! Il faut toujours vérifier que votre boucle s’arrêtera un jour, il faut qu’à un moment ou à un autre, il y ait un élément qui s’incrémente ou qui soit modifié.\n\nx = 10\ny = 8\n# tant que y est plus petit que 10, je continue de lui ajouter 1\nwhile y &lt;= x : \n    print(\"y n'est pas encore plus grand que x\")\n    y += 1 # l'incrément\nelse : \n    print(\"y est plus grand que x et vaut\",y)\n\ny n'est pas encore plus grand que x\ny n'est pas encore plus grand que x\ny n'est pas encore plus grand que x\ny est plus grand que x et vaut 11\n\n\n\n\nBreak et continue\nDans les boucles for ou while on peut avoir besoin d’ignorer ou de ne pas effectuer certaines itérations. 2 instructions utiles :\n\nl’instruction break : permet de sortir de la boucle\nl’instruction continue : permet de passer à l’itération suivante sans exécuter les instructions qui suivent\n\n\n# utilisation de break\nfor x in range(5) : \n    if x == 2 : \n        break\n    else :\n        print(x)\n\n0\n1\n\n\n\n# utilisation de continue\nfor x in range(5) : \n    if x == 2 : \n        continue\n    else :\n        print(x)\n\n0\n1\n3\n4"
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#créer-ses-fonctions",
    "href": "content/getting-started/06_rappels_fonctions.html#créer-ses-fonctions",
    "title": "Modules, tests, boucles, fonctions",
    "section": "Créer ses fonctions",
    "text": "Créer ses fonctions\nLes fonctions permettent de faire la même chose sans avoir à recopier le code plusieurs fois dans le même programme. Dès que vous le pouvez, faites des fonctions : le copier-coller est trop dangereux.\n\nElles peuvent prendre plusieurs paramètres (ou aucun) elles peuvent retourner plusieurs résultats (ou aucun)\nPour mettre une aide à la fonction, on écrit au début entre ““” ““” (en rouge dans l’exemple)\n\n\n# 1er exemple de fonction\n\ndef ma_fonction_increment(parametre) : \n    \"\"\"Cette fonction ajoute 1 au paramètre qu'on lui donne\"\"\"\n    x = parametre + 1 \n    return x\n\n# pour documenter la fonction, on écrit son aide\nhelp(ma_fonction_increment)\n\nHelp on function ma_fonction_increment in module __main__:\n\nma_fonction_increment(parametre)\n    Cette fonction ajoute 1 au paramètre qu'on lui donne\n\n\n\nOn peut également :\n\navoir des paramètres facultatifs, mais ils doivent toujours être placés à la fin des paramètres\nen cas de paramètre facultatif, il faut lui donner une valeur par défaut\nretourner plus d’un élément à la fin d’une fonction\navoir des paramètres de tailles différentes\n\n\ndef ma_fonction(p,q = 2) :\n    y1 = p + q\n    y2 = y1%3 #reste de la division euclidienne\n    return y1,y2\n\nx = ma_fonction(11) \n# ici, on n'a pas de 2nd paramètre\n#, par défaut, x = ma_fonction(10,2)\nprint(\"x=\", x)\n\nz = ma_fonction(10,-1)\nprint(\"z =\",z)\n\nx= (13, 1)\nz = (9, 0)\n\n\nUne fonction peut également s’appeler elle même : c’est ce qu’on appelle une fonction récursive.\nDans cet exemple, somme_recursion() est une fonction que nous avons définie de sorte à ce qu’elle s’appelle elle-même (récursif).\nOn utilise l’argument k, qui décroit (-1) chaque fois qu’on fait appel à la fonction.\nLa récursion s’arrête quand k est nul.\nDans cet exemple, on va donc appeler 6 fois la fonction récursive.\n\ndef somme_recursion(k):\n    if(k &gt; 0):\n        result = k + somme_recursion(k - 1)\n        print(k,result)\n    else:\n        result = 0\n    return result\nsomme_recursion(6)\n\n1 1\n2 3\n3 6\n4 10\n5 15\n6 21\n\n\n21\n\n\nLes fonctions sont très utiles et nous vous invitons à les utiliser dès que vous le pouvez car elles permettent d’avoir un code clair et structuré, plutôt que des bouts de code éparpillés."
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#lever-des-exceptions",
    "href": "content/getting-started/06_rappels_fonctions.html#lever-des-exceptions",
    "title": "Modules, tests, boucles, fonctions",
    "section": "Lever des exceptions",
    "text": "Lever des exceptions\nPython peut rencontrer des erreurs en exécutant votre programme.\nCes erreurs peuvent être interceptées très facilement et c’est même, dans certains cas, indispensable. Par exemple, si vous voulez faire une boucle mais que vous savez que l’instruction ne marchera pas toujours : au lieu de lister les cas où une opération n’est pas possible, on peut indiquer directement quelle erreur doit être ignorée.\nCependant, il ne faut pas tout intercepter non plus : si Python envoie une erreur, c’est qu’il y a une raison. Si vous ignorez une erreur, vous risquez d’avoir des résultats très étranges dans votre programme.\n\n# éviter une division par 0, c'est une bonne idée : \n\ndef inverse(x) :\n    '''Cette fonction renvoie l inverse de l argument'''\n    y = 1/x\n    return y\n\ndiv = inverse(0)\n\nZeroDivisionError: division by zero\n\n\nL’erreur est écrite noir sur blanc : ZeroDivisionError\nDans l’idéal on aimerait éviter que notre code bloque sur ce problème. On pourrait passer par un test if et vérifier que x est différent de 0. Mais on se rend vite compte que dans certains cas, on ne peut lister tous les tests en fonction de valeurs.\nAlors on va lui précisier ce qu’il doit faire en fonction de l’erreur retournée.\nSyntaxe\nTry :\ninstruction\nexcept TypeErreur :\nautre instruction\n\n\ndef inverse(x) : \n    try :\n        y = 1/x\n    except ZeroDivisionError :\n        y = None\n    return y\n    \nprint(inverse(10))\nprint(inverse(0))\n\n0.1\nNone\n\n\nIl est recommandé de toujours préciser le type d’erreur qu’on rencontre. Si on met uniquement “except” sans préciser le type, on peut passer à côté d’erreurs pour lesquelles la solution n’est pas universelle."
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#a-retenir-et-questions",
    "href": "content/getting-started/06_rappels_fonctions.html#a-retenir-et-questions",
    "title": "Modules, tests, boucles, fonctions",
    "section": "A retenir et questions",
    "text": "A retenir et questions\n\nA retenir\n\nToujours mettre “:” avant un bloc d’instructions\nIndenter avant un bloc d’instructions (avec 4 espaces et non une tabulation !)\nIndiquer les modules nécessaires à l’exécution en début de code\nDocumenter les fonctions créées\nPréciser le type d’erreur pour les exceptions et potentiellement différencier les blocs d’instructions en fonction de l’erreur\n\n\n\nQuestions\n\nQue fait ce programme ?\n\n\ndef inverse(x) : \n    try :\n        y = 1/x\n    except ZeroDivisionError :\n        y = None\n        return y\n\n\nEcrivez un programme qui peut trouver tous les nombres divisibles par 7 et non multiples de 5 entre 6523 et 8463 (inclus)\nEcrivez un programme qui prend une phrase en entrée et qui calcule le nombre de voyelles en Majuscules et de consonnes en minuscules :\n\nphrase = “Vous savez, moi je ne crois pas qu’il y ait de bonne ou de mauvaise situation. Moi, si je devais résumer ma vie aujourd’hui avec vous, je dirais que c’est d’abord des rencontres. Des gens qui m’ont tendu la main, peut-être à un moment où je ne pouvais pas, où j’étais seul chez moi. Et c’est assez curieux de se dire que les hasards, les rencontres forgent une destinée… Parce que quand on a le goût de la chose, quand on a le goût de la chose bien faite, le beau geste, parfois on ne trouve pas l’interlocuteur en face je dirais, le miroir qui vous aide à avancer. Alors ça n’est pas mon cas, comme je disais là, puisque moi au contraire, j’ai pu : et je dis merci à la vie, je lui dis merci, je chante la vie, je danse la vie… je ne suis qu’amour ! Et finalement, quand beaucoup de gens aujourd’hui me disent ‘Mais comment fais-tu pour avoir cette humanité ?’, et bien je leur réponds très simplement, je leur dis que c’est ce goût de l’amour ce goût donc qui m’a poussé aujourd’hui à entreprendre une construction mécanique, mais demain qui sait ? Peut-être simplement à me mettre au service de la communauté, à faire le don, le don de soi…”"
  },
  {
    "objectID": "content/annexes/evaluation.html",
    "href": "content/annexes/evaluation.html",
    "title": "Evaluation",
    "section": "",
    "text": "Résumé :"
  },
  {
    "objectID": "content/annexes/evaluation.html#attentes-du-projet",
    "href": "content/annexes/evaluation.html#attentes-du-projet",
    "title": "Evaluation",
    "section": "Attentes du projet",
    "text": "Attentes du projet\nLe projet est une problématique à laquelle vous souhaitez répondre à\nl’aide d’un ou de plusieurs jeu(s) de données.\nIl faut donc dans un premier temps se pencher sur la recherche de problématisation et de contextualisation. Nous vous recommandons de prendre un sujet qui vous intéresse pour intéresser également le lecteur.\nTrois dimensions doivent être présentes dans le projet.\nPour chacune de ces parties, il est possible d’aller plus ou moins loin. Il est recommandé d’aller loin sur au moins une des 3 dimensions.\n\nLa récupération et le traitement des données\nCes données peuvent être directement disponibles sous la forme de fichiers txt, csv … ou provenir de sites internet (scraping, API). Plus le travail sur la récupération de données est important (par exemple scraping sur plusieurs sites), plus la partie obtiendra de points. Si le jeu de données utilisé est un téléchargement d’un jeu propre existant, il faudra chercher à le compléter d’une manière ou d’une autre pour obtenir des points sur cette partie.\nVous obtiendrez vraisemblablement des données qui ne sont pas « propres » du premier coup : mettez en place des protocoles de nettoyage pour obtenir à la fin de cette étape un ou des jeux de données fiable et robuste pour mener ensuite votre analyse. C’est également le moment de créer des variables plus appréhendables, mieux identifiées etc.\n\n\nL’analyse descriptive et la représentation graphique\nLa présence de statistiques descriptives est indispensable dans le projet. De la description de la base aux premières grandes tendances des données, cette partie permet d’avoir une vision globale des données : le lien avec la problématique, comment elle permet d’y répondre, quels sont les premiers éléments de réponse… Chaque résultat doit être interprété : pas la peine de faire un describe et de ne pas le commenter.\nEn termes de représentation graphique, plusieurs niveaux sont envisageables. Vous pouvez simplement représenter vos données en utilisant matplotlib, aller plus loin avec seaborn ou scikit-plot, (voire D3.js pour les plus motivés). La base d’une bonne visualisation est de trouver le type de graphique adéquat pour ce que vous voulez montrer (faut-il un scatter ou un line pour représenter une évolution ?) et de le rendre visible : une légende qui a du sens, des axes avec des noms etc. Encore une fois, il faudra commenter votre graphique, qu’est ce qu’il montre, en quoi cela valide / contredit votre argumentaire ?\n\n\nLa modélisation\nVient ensuite la phase de modélisation : un modèle peut être le bienvenu quand des statistiques descriptives ne suffisent pas à apporter une solution complète à votre problématique ou pour compléter / renforcer l’analyse descriptive. Le modèle importe peu (régression linéaire, random forest ou autre) : il doit être approprié (répondre à votre problématique) et justifié.\nVous pouvez aussi confronter plusieurs modèles qui n’ont pas la même vocation : par exemple une CAH pour catégoriser et créer des nouvelles variables / faire des groupes puis une régression.\nMême si le projet n’est pas celui du cours de stats, il faut que la démarche soit scientifique et que les résultats soient interprétés."
  },
  {
    "objectID": "content/annexes/evaluation.html#format-du-rendu",
    "href": "content/annexes/evaluation.html#format-du-rendu",
    "title": "Evaluation",
    "section": "Format du rendu",
    "text": "Format du rendu\nSur le format du rendu, vous devrez :\n\nÉcrire un rapport sous forme de Notebook (quelques exceptions à cette règle peuvent exister, par exemple si vous développer une appli Dash)\nAvoir un répertoire Github avec le rapport. Les données utilisées doivent être accessibles également, dans le dépôt ou sur internet.\nLes dépôts Github où seul un upload du projet a été réalisé seront pénalisés. A l’inverse, les dépôts dans lequels le contrôle de version et le travail collaboratif ont été activement pratiqués (commits fréquents, pull requests, ..) seront valorisés.\nLe code contenu dans le rapport devra être un maximum propre (pas de copier coller de cellule, préférez des fonctions)\n\nCe post donne\nquelques conseils pour avoir des notebooks agréables à lire. N’oubliez pas cette règle :\n\ncode is read much more often than written\n\nLors de l’évaluation, une attention particulière sera donnée à la reproductibilité de votre projet.\nChaque étape (récupération et traitement des données, analyses descriptives, modélisation) doit pouvoir être reproduite à partir du notebook final. Pour les opérations qui prennent du temps (ex : web scraping massif, requêtage d’API avec des limites de nombre de requêtes, entraînement de modèle, etc.), vous devez inclure l’output (base de données, modèle entraîné..) dans le dépôt, afin que les étapes suivantes puissent s’éxecuter sans problème.\nLe test à réaliser : faire tourner toutes les cellules de votre notebook et ne pas avoir d’erreur est une condition sine qua non pour avoir la moyenne."
  },
  {
    "objectID": "content/annexes/evaluation.html#barème-approximatif",
    "href": "content/annexes/evaluation.html#barème-approximatif",
    "title": "Evaluation",
    "section": "Barème approximatif",
    "text": "Barème approximatif\n\nDonnées (collecte et nettoyage) : 4 points\nAnalyse descriptive : 4 points\nModélisation : 2 points\nDémarche scientifique et reproductibilité du projet : 4 points\nFormat du code (code propre et github) : 2 points\nSoutenance : 4 points\n\nLe projet doit être réalisé en groupe de trois, voire deux."
  },
  {
    "objectID": "content/annexes/evaluation.html#projets-menés-par-les-étudiants",
    "href": "content/annexes/evaluation.html#projets-menés-par-les-étudiants",
    "title": "Evaluation",
    "section": "Projets menés par les étudiants",
    "text": "Projets menés par les étudiants\n\n\n\n\n\n\n\n\n\nProjet\nAuteurs\nURL projet \nTags\n\n\n\n\nGPS vélo intégrant les bornes Vélib, les accidents, la congestion et la météo\nVinciane Desbois ; Imane Fares ; Romane Gajdos\nhttps://github.com/ImaneFa/Projet_Python\nVélib ; Pistes cyclables ; Accidents ; Folium\n\n\nQuiz Generator\nAdrien Servière ; Mélissa Tamine\nhttps://github.com/taminemelissa/quiz-generator\nMachine Learning ; Natural Language Processing ; Question Generation ; Word2Vec\n\n\nAnalyse de sentiments sur les vaccins COVID administrés en France\nKOAGNE FONGUIENG Florette ; KONKOBO Idrissa\nhttps://github.com/kidrissa/projetpy\nAPI ; NLP ; Wordcloud ; Modélisation prédictive\n\n\nEstimation de l’empreinte carbone d’une recette de cuisine\nJean-Baptiste Laval ; Hadrien Lolivier ; Sirine Louati\nhttps://github.com/sirinelouati/Plat_CO2\nscraping ; Dashboard ; Empreinte carbone ; Alimentation\n\n\nLe “bon sens du boucher-charcutier de Tourcoing vaut-il mieux que les enquêtes de victimation ?”\nConrad Thiounn ; Gaston Vermersch\nhttps://github.com/cthiounn/python-datascience-ENSAE-2A\nAPI ; Open-data ; ACP ; CAH ; LASSO\n\n\nPrédiction du revenu généré par un film en fonction de ses caractéristiques\nDmitri Lebrun ; Corentin Pernot ; Nina Stizi\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nScrapping ; Cinéma ; Machine Learning\n\n\nAnalyse du réseau ferré de la SNCF: Comment expliquer les retards permanents de la compagnie française ?\nDiego Renaud ; Victor Parent ; Marion Chabrol\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nAPI ; SNCF ; LASSO\n\n\nLe “bon sens du boucher-charcutier de Tourcoing vaut-il mieux que les enquêtes de victimation ?”\nConrad Thiounn ; Gaston Vermersch\nhttps://github.com/cthiounn/python-datascience-ENSAE-2A\nAPI ; Open-data ; ACP ; CAH ; LASSO\n\n\nPrédiction du revenu généré par un film en fonction de ses caractéristiques\nDmitri Lebrun ; Corentin Pernot ; Nina Stizi\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nScrapping ; Cinéma ; Machine Learning\n\n\nAnalyse du réseau ferré de la SNCF: Comment expliquer les retards permanents de la compagnie française ?\nDiego Renaud ; Victor Parent ; Marion Chabrol\nhttps://github.com/NinaStizi/Python_ENSAE_2A\nAPI ; SNCF ; LASSO"
  }
]