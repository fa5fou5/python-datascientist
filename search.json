[
  {
    "objectID": "content/annexes/corrections.html",
    "href": "content/annexes/corrections.html",
    "title": "Corrections",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nSeules les chapitres dont les corrections ne sont pas apparentes sont list√©s sur cette page.",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-1-manipuler-des-donn√©es",
    "href": "content/annexes/corrections.html#partie-1-manipuler-des-donn√©es",
    "title": "Corrections",
    "section": "0.1 Partie 1: manipuler des donn√©es",
    "text": "0.1 Partie 1: manipuler des donn√©es\n\nRetour sur Numpy\n\n\nhtml`${printBadges({fpath: \"content/manipulation/01_numpy.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices Pandas\n\n\nhtml`${printBadges({fpath: \"content/manipulation/02b_pandas_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices Geopandas :\n\n\nhtml`${printBadges({fpath: \"content/manipulation/03_geopandas_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices webscraping\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04a_webscraping_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices expressions r√©guli√®res\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04b_regex_TP.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices API\n\n\nhtml`${printBadges({fpath: \"content/manipulation/04c_API_TP.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-2-visualiser-les-donn√©es",
    "href": "content/annexes/corrections.html#partie-2-visualiser-les-donn√©es",
    "title": "Corrections",
    "section": "0.2 Partie 2: visualiser les donn√©es",
    "text": "0.2 Partie 2: visualiser les donn√©es\n\nExercices graphiques classiques\n\n\nhtml`${printBadges({fpath: \"content/visualisation/matplotlib.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la cartographie\n\n\nhtml`${printBadges({fpath: \"content/visualisation/maps.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-3-mod√©liser",
    "href": "content/annexes/corrections.html#partie-3-mod√©liser",
    "title": "Corrections",
    "section": "0.3 Partie 3: mod√©liser",
    "text": "0.3 Partie 3: mod√©liser\n\nExercices sur le preprocessing\n\n\nhtml`${printBadges({fpath: \"content/modelisation/0_preprocessing.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur l‚Äô√©valuation des mod√®les\n\n\nhtml`${printBadges({fpath: \"content/modelisation/1_modelevaluation.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la classification\n\n\nhtml`${printBadges({fpath: \"content/modelisation/2_SVM.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la r√©gression\n\n\nhtml`${printBadges({fpath: \"content/modelisation/3_regression.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la s√©lection de variables\n\n\nhtml`${printBadges({fpath: \"content/modelisation/4_featureselection.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur le clustering\n\n\nhtml`${printBadges({fpath: \"content/manipulation/5_clustering.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur les pipelines\n\n\nhtml`${printBadges({fpath: \"content/manipulation/6_pipeline.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#partie-4-natural-language-processing-nlp",
    "href": "content/annexes/corrections.html#partie-4-natural-language-processing-nlp",
    "title": "Corrections",
    "section": "0.4 Partie 4: Natural Language Processing (NLP)",
    "text": "0.4 Partie 4: Natural Language Processing (NLP)\n\nD√©couverte des enjeux du NLP\n\n\nhtml`${printBadges({fpath: \"content/NLP/01_intro.qmd\", correction: true})}`\n\n\n\n\n\n\n\nMise en pratique de l‚Äôapproche bag of words\n\n\nhtml`${printBadges({fpath: \"content/NLP/02_exoclean.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices sur la latent dirichlet allocation\n\n\nhtml`${printBadges({fpath: \"content/NLP/03_lda.qmd\", correction: true})}`\n\n\n\n\n\n\n\nD√©couverte de Word2Vec\n\n\nhtml`${printBadges({fpath: \"content/NLP/04_word2vec.qmd\", correction: true})}`\n\n\n\n\n\n\n\nExercices suppl√©mentaires\n\n\nhtml`${printBadges({fpath: \"content/NLP/05_exo_supp.qmd\", correction: true})}`",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#informations-additionnelles",
    "href": "content/annexes/corrections.html#informations-additionnelles",
    "title": "Corrections",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n6362a07\n\n\n2023-10-10 15:08:33\n\n\nlinogaliana\n\n\nAjoute corrections\n\n\n\n\n241cab3\n\n\n2023-10-04 17:53:29\n\n\nLino Galiana\n\n\nErgonomie du site web (#421)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nab7ac8a\n\n\n2023-08-17 17:47:59\n\n\nLino Galiana\n\n\nPath error\n\n\n\n\n68f960b\n\n\n2023-08-11 16:27:52\n\n\nlinogaliana\n\n\ncorrige probleme execution\n\n\n\n\n0800d90\n\n\n2023-08-11 13:32:19\n\n\nlinogaliana\n\n\nRetour des corrections\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/annexes/corrections.html#informations-additionnelles-1",
    "href": "content/annexes/corrections.html#informations-additionnelles-1",
    "title": "Corrections",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n6362a07\n\n\n2023-10-10 15:08:33\n\n\nlinogaliana\n\n\nAjoute corrections\n\n\n\n\n241cab3\n\n\n2023-10-04 17:53:29\n\n\nLino Galiana\n\n\nErgonomie du site web (#421)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nab7ac8a\n\n\n2023-08-17 17:47:59\n\n\nLino Galiana\n\n\nPath error\n\n\n\n\n68f960b\n\n\n2023-08-11 16:27:52\n\n\nlinogaliana\n\n\ncorrige probleme execution\n\n\n\n\n0800d90\n\n\n2023-08-11 13:32:19\n\n\nlinogaliana\n\n\nRetour des corrections\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Corrections"
    ]
  },
  {
    "objectID": "content/git/exogit.html",
    "href": "content/git/exogit.html",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLes exercices suivants sont inspir√©s d‚Äôun cours de Git que j‚Äôai\nparticip√© √† construire\n√† l‚ÄôInsee et dont les ressources sont disponibles\nici. L‚Äôid√©e\ndu cadavre exquis est inspir√©e de\ncette ressource et de celle-ci.\nCette partie part du principe que les concepts g√©n√©raux de Git sont\nma√Ætris√©s et qu‚Äôun environnement de travail fonctionnel avec Git est\ndisponible. Un exemple de tel environnement est le JupyterLab ou l‚Äôenvironnement VSCode du\nSSPCloud o√π une extension\nGit est pr√©-install√©e :\nOutre le chapitre pr√©c√©dent, il existe de\nnombreuses ressources sur internet sur le sujet,\nnotamment une s√©rie de ressources construites\npour l‚ÄôInsee sur ce site\net des ressources de la documentation collaborative sur R qu‚Äôest utilitR\n(des √©l√©ments sur la configuration\net pratique sur RStudio). Toutes\nles ressources ne sont donc pas du Python car Git est un outil transversal\nqui doit servir quel que soit le langage de pr√©dilection.\nGit fait parti des pratiques collaboratives\ndevenues standards dans le domaine de l‚Äôopen-source\nmais √©galement de plus en plus communes dans les administrations et entreprises\nde la data science.\nCe chapitre propose, pour simplifier l‚Äôapprentissage,\nd‚Äôutiliser l‚Äô extension Git de JupyterLab ou de VSCode.\nUn tutoriel pr√©sentant l‚Äôextension JupyterLab est disponible\nici.\nVSCode propose\nprobablement, √† l‚Äôheure actuelle, l‚Äôensemble le plus complet.\nCertains passages de ce TD n√©cessitent d‚Äôutiliser la ligne de commande.\nIl est tout √† fait possible de r√©aliser ce TD enti√®rement avec celle-ci.\nCependant, pour une personne d√©butante en Git, l‚Äôutilisation d‚Äôune\ninterface graphique peut constituer un √©l√©ment important pour\nla compr√©hension et l‚Äôadoption de Git. Une fois √† l‚Äôaise avec\nGit, on peut tout √† fait se passer des interfaces graphiques\npour les routines quotidiennes et ne les utiliser que\npour certaines op√©rations o√π elles s‚Äôav√®rent fort pratiques\n(notamment la comparaison de deux fichiers avant de devoir fusionner).",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#rappels-sur-la-notion-de-d√©p√¥t-distant",
    "href": "content/git/exogit.html#rappels-sur-la-notion-de-d√©p√¥t-distant",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.1 Rappels sur la notion de d√©p√¥t distant",
    "text": "1.1 Rappels sur la notion de d√©p√¥t distant\nComme expliqu√© dans le chapitre pr√©c√©dent,\nil convient de distinguer\nle d√©p√¥t distant (remote) et la copie ou les copies locales (les clones)\nd‚Äôun d√©p√¥t. Le d√©p√¥t distant est g√©n√©ralement stock√© sur une forge\nlogicielle (Github ou Gitlab) et sert √† centraliser la version\ncollective d‚Äôun projet. Les copies locales sont des copies de travail.\nGit est un syst√®me de contr√¥le de version asynchrone, c‚Äôest-√†-dire\nqu‚Äôon n‚Äôinteragit pas en continu avec le d√©p√¥t distant (comme c‚Äôest le\ncas dans le syst√®me SVN) mais qu‚Äôil est possible d‚Äôavoir une version\nlocale qui se diff√©rencie du d√©p√¥t commun et qu‚Äôon rend coh√©rente\nde temps en temps.\nBien qu‚Äôil soit possible d‚Äôavoir une utilisation hors-ligne de Git,\nc‚Äôest-√†-dire un pur contr√¥le de version local sans d√©p√¥t\ndistant, cela est une utilisation\nrare et qui comporte un int√©r√™t limit√©. L‚Äôint√©r√™t de Git est\nd‚Äôoffrir une mani√®re robuste et efficace d‚Äôinteragir avec un\nd√©p√¥t distant facilitant ainsi la collaboration en √©quipe ou en\nsolitaire.\nPour ces exercices, il est propos√©\nd‚Äôutiliser Github, la forge la plus visible.\nL‚Äôavantage de Github par rapport √† son principal concurrent, Gitlab,\nest que le premier est plus visible, car\nmieux index√© par Google et concentre, en partie pour des raisons historiques, plus\nde d√©veloppeurs Python et R (ce qui est important dans des domaines comme\nle code o√π les externalit√©s de r√©seau jouent).",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#premi√®re-√©tape-cr√©er-un-compte-github",
    "href": "content/git/exogit.html#premi√®re-√©tape-cr√©er-un-compte-github",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.2 Premi√®re √©tape: cr√©er un compte Github",
    "text": "1.2 Premi√®re √©tape: cr√©er un compte Github\nLes deux premi√®res √©tapes se font sur Github.\n\n\n Exercice 1 : Cr√©er un compte Github\n\nSi vous n‚Äôen avez pas d√©j√† un, cr√©er un compte sur https://github.com\nCr√©er un d√©p√¥t en suivant les consignes ci-dessous.\n\n\nCr√©ez ce d√©p√¥t priv√©, cela permettra\ndans l‚Äôexercice 2 d‚Äôactiver notre jeton. Vous pourrez le rendre public\napr√®s l‚Äôexercice 2, c‚Äôest comme vous le souhaitez.\nCr√©er ce d√©p√¥t avec un README.md en cliquant sur la case Add a README file\nAjouter un .gitignore en s√©lectionnant le mod√®le Python\n\nConnexion sur https://github.com &gt; + (en haut de la page) &gt; New repository &gt; Renseigner le ‚ÄúRepository name‚Äù &gt; Cocher ‚Äúprivate‚Äù &gt; ‚ÄúCreate repository‚Äù",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#deuxi√®me-√©tape-cr√©er-un-token-jeton-https",
    "href": "content/git/exogit.html#deuxi√®me-√©tape-cr√©er-un-token-jeton-https",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.3 Deuxi√®me √©tape: cr√©er un token (jeton) HTTPS",
    "text": "1.3 Deuxi√®me √©tape: cr√©er un token (jeton) HTTPS",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#principe",
    "href": "content/git/exogit.html#principe",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.4 Principe",
    "text": "1.4 Principe\nGit est un syst√®me d√©centralis√© de contr√¥le de version :\nles codes sont modifi√©s par chaque personne sur son poste de travail,\npuis sont mis en conformit√© avec la version collective disponible\nsur le d√©p√¥t distant au moment o√π le contributeur le d√©cide.\nIl est donc n√©cessaire que la forge connaisse l‚Äôidentit√© de chacun des\ncontributeurs, afin de d√©terminer qui est l‚Äôauteur d‚Äôune modification apport√©e\naux codes stock√©s dans le d√©p√¥t distant.\nPour que Github reconnaisse un utilisateur proposant des modifications,\nil est n√©cessaire de s‚Äôauthentifier (un d√©p√¥t distant, m√™me public, ne peut pas √™tre modifi√© par n‚Äôimporte qui). L‚Äôauthentification consiste ainsi √† fournir un √©l√©ment que seul vous et la forge √™tes cens√©s conna√Ætre : un mot de passe, une cl√© compliqu√©e, un jeton d‚Äôacc√®s‚Ä¶\nPlus pr√©cis√©ment, il existe deux modalit√©s pour faire conna√Ætre son identit√© √† Github :\n\nune authentification HTTPS (d√©crite ici) : l‚Äôauthentification se fait avec un login et un mot de passe ou avec un token (un mot de passe compliqu√© g√©n√©r√© automatiquement par Github et connu exclusivement du d√©tenteur du compte Github) ;\nune authentification SSH : l‚Äôauthentification se fait par une cl√© crypt√©e disponible sur le poste de travail et que GitHub ou GitLab conna√Æt. Une fois configur√©e, cette m√©thode ne n√©cessite plus de faire conna√Ætre son identit√© : l‚Äôempreinte digitale que constitue la cl√© suffit √† reconna√Ætre un utilisateur.\n\nLa documentation collaborative utilitR pr√©sente les raisons pour lesquelles il convient de favoriser\nla m√©thode HTTPS sur la m√©thode SSH.\n\n\n Note\nDepuis Ao√ªt 2021, Github n‚Äôautorise plus l‚Äôauthentification par mot de passe\nlorsqu‚Äôon interagit (pull/push) avec un d√©p√¥t distant\n(raisons ici).\nIl est n√©cessaire d‚Äôutiliser un token (jeton d‚Äôacc√®s) qui pr√©sente l‚Äôavantage\nd‚Äô√™tre r√©voquable (on peut √† tout moment supprimer un jeton si, par exemple,\non suspecte qu‚Äôil a √©t√© diffus√© par erreur) et √† droits limit√©s\n(le jeton permet certaines op√©rations standards mais\nn‚Äôautorise pas certaines op√©rations d√©terminantes comme la suppression\nd‚Äôun d√©p√¥t).\n√Ä partir de mars 2023 et jusqu‚Äô√† la fin de 2023, GitHub commencera progressivement √† exiger que tous les utilisateurs de GitHub activent une ou plusieurs formes d‚Äôauthentification √† deux facteurs (2FA). Pour plus d‚Äôinformations sur le d√©ploiement de l‚Äôinscription 2FA, consultez cet article de blog. Concr√®tement, cela signifie que vous devrez au choix :\n\nRenseigner votre num√©ro de portable pour valider certaines connexions gr√¢ce √† un code que vous recevrez par sms ;\nInstaller une application d‚Äôauthentification (Ex : Microsoft Authenticator) install√©e sur votre t√©l√©phone qui g√©n√®rera un QR code que vous pourrez scanner depuis github, ce qui ne n√©cessite pas que vous ayez √† fournir votre num√©ro de t√©l√©phone\nUtiliser une clef USB de s√©curit√©\n\nPour choisir entre ces diff√©rentes options, vous pouvez vous rendre sur Settings &gt; Password and authentication &gt; Enable two-factor authentication.\n\n\n\n\n Note\nIl est important de ne jamais stocker un token, et encore moins son mot de passe, dans un projet.\nIl est possible de stocker un mot de passe ou token de mani√®re s√©curis√©e et durable\navec le credential helper de Git. Celui-ci est pr√©sent√© par la suite.\nS‚Äôil n‚Äôest pas possible d‚Äôutiliser le credential helper de Git, un mot de passe\nou token peut √™tre stock√© de mani√®re s√©curis√© dans\nun syst√®me de gestion de mot de passe comme Keepass.\nNe jamais stocker un jeton Github, ou pire un mot de passe, dans un fichier\ntexte non crypt√©. Les logiciels de gestion de mot de passe\n(comme Keepass, recommand√© par l‚ÄôAnssi)\nsont simples\nd‚Äôusage et permettent de ne conserver sur l‚Äôordinateur qu‚Äôune version\nhash√©e du mot de passe qui ne peut √™tre d√©crypt√©e qu‚Äôavec un mot de passe\nconnu de vous seuls.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#cr√©er-un-jeton",
    "href": "content/git/exogit.html#cr√©er-un-jeton",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "1.5 Cr√©er un jeton",
    "text": "1.5 Cr√©er un jeton\nLa documentation officielle comporte un certain nombre de captures d‚Äô√©cran expliquant\ncomment proc√©der.\nNous allons utiliser le credential helper associ√© √† Git pour stocker\nce jeton. Ce credential helper permet de conserver de mani√®re p√©renne\nun jeton (on peut aussi faire en sorte que le mot de passe soit automatiquement\nsupprim√© de la m√©moire de l‚Äôordinateur au bout, par\nexemple, d‚Äôune heure).\nL‚Äôinconv√©nient de cette m√©thode est que Git √©crit en clair le jeton dans\nun fichier de configuration. C‚Äôest pour cette raison qu‚Äôon utilise des jetons\npuisque, si ces derniers sont r√©v√©l√©s, on peut toujours les r√©voquer et √©viter\nles probl√®mes (pour ne pas stocker en clair un jeton il faudrait utiliser\nune librairie suppl√©mentaire comme libsecrets qui est au-del√† du programme\nde ce cours).\nSi vous d√©sirez conserver de mani√®re plus durable ou plus s√©curis√©e votre jeton\n(en ne conservant pas le jeton en clair mais de mani√®re hash√©e),\nest d‚Äôutiliser un gestionnaire de mot de passe comme\nKeepass (recommand√© par l‚ÄôAnssi). N√©anmoins,\nil est recommand√© de tout de m√™me fixer une date d‚Äôexp√©ritation\naux jetons pour limiter les risques de s√©curit√© d‚Äôun token qui fuite\nsans s‚Äôen rendre compte.\n\n\n Exercice 2.0 : Cr√©er un service sur le SSPCloud\nEn amont de l‚Äôexercice 2, pour les utilisateurs\ndu SSPCloud,\nil est recommand√© d‚Äôouvrir un service Jupyter\nen suivant les consignes suivantes :\n\nDans la page Mes services, cliquer sur le bouton Nouveau service ;\nChoisir Jupyter-Python ;\nCliquer sur Configuration Jupyter-Python. ‚ö†Ô∏è ne pas lancer le service\ntout de suite !\nFaire d√©filer les onglets pour arriver sur l‚Äôonglet Git ;\nRemplacer la valeur sous Cache par un nombre important,\npar exemple 36000 pour que le jeton que vous utiliserez soit\nvalable 10 heures ;\nLancer le service.\n\n\n\n\n\n Exercice 2 : Cr√©er et stocker un token\n1Ô∏è‚É£ Suivre la\ndocumentation officielle en ne donnant que les droits repo au jeton (ajouter les droits\nworkflow si vous d√©sirez que votre jeton soit utilisable pour des projets\no√π l‚Äôint√©gration continue est n√©cessaire).\nPour r√©sumer les √©tapes devraient √™tre les suivantes :\nSettings &gt; Developers Settings &gt; Personal Access Token &gt; Generate a new token &gt; ‚ÄúMy bash script‚Äù &gt; Expiration ‚Äú30 days‚Äù &gt; cocher juste ‚Äúrepo‚Äù &gt; Generate token &gt; Le copier\n2Ô∏è‚É£ Ouvrir un terminal depuis Jupyter (par exemple File &gt; New &gt; Terminal) ou VSCode (Terminal &gt; New Terminal).\n3Ô∏è‚É£ [Optionnel] Taper dans le terminal la commande\nqui convient selon votre syst√®me d‚Äôexploitation pour activer le\ncredential helper:\n# Sous mac et linux et le datalab\ngit config --global credential.helper store\n\n# Sous windows\ngit config --global credential.helper manager-core\n4Ô∏è‚É£ R√©cup√©rer, sur la page d‚Äôaccueil de votre d√©p√¥t, l‚Äôurl du d√©p√¥t distant.\nIl prend la forme suivante\nhttps://github.com/&lt;username&gt;/&lt;reponame&gt;.git\nVous pouvez utiliser l‚Äôicone √† droite pour copier l‚Äôurl.\n5Ô∏è‚É£ Retournez dans le Terminal. Taper\ngit clone repo_url\no√π repo_url est l‚Äôurl du d√©p√¥t en question (vous pouvez utiliser\nMAJ+Inser pour coller l‚Äôurl pr√©c√©demment copi√©)\nTapez Entr√©e. Dans le cas d‚Äôun r√©pertoire priv√© et sans credential helper, renseignez ensuite votre identifiant, faites Entr√©e, puis votre personal access token, Entr√©e. Si vous n‚Äôavez pas d‚Äôerreur, cela signifie\nque l‚Äôauthentification a bien fonctionn√© et donc que tout va\nbien. Sinon, il vous suffit de r√©√©crire l‚Äôinstruction git clone et de retenter de taper votre personal access token. Normalement, si vous avez cr√©√© un d√©p√¥t vide dans l‚Äôexercice 1,\nvous avez un message de Git:\n\nwarning: You appear to have cloned an empty repository.\n\nCe n‚Äôest pas une erreur mais il est pr√©f√©rable de suivre la\nconsigne de l‚Äôexercice 1 et de cr√©er un projet non vide.\nLe dossier de votre projet a bien\n√©t√© cr√©√©.\nSi vous avez une erreur, suivez la consigne pr√©sent√©e ci-apr√®s\npour r√©initialiser\nvotre credential helper\n6Ô∏è‚É£ Si vous le d√©sirez, vous pouvez changer la visibilit√© de votre d√©p√¥t\nen le rendant public.\n7Ô∏è‚É£ Stocker le token sur le SSP Cloud (ou un gestionnaire de mot de passe) :\n\nMon Compte -&gt; Services externes -&gt; Jeton d‚Äôacc√®s personnel GitHub\n\n\n\n\n\n Note\nSi vous avez fait une faute de frappe dans le mot de passe ou dans le jeton, il est possible de vider la m√©moire\nde la mani√®re suivante, sous Mac ou Linux :\ngit config --global --unset credential.helper\nSous Windows, si vous avez utilis√© l‚Äôoption manager-core √©voqu√©e ci-dessus, vous pouvez utiliser une interface graphique pour effacer le mot de passe ou jeton erron√©. Pour cela, dans le menu d√©marrer, taper Gestionnaire d'identification (ou Credential Manager si Windows ne trouve pas). Dans l‚Äôinterface graphique qui s‚Äôouvre, il est possible de supprimer le mot de passe ou jeton en question. Apr√®s cela, vous devriez √† nouveau avoir l‚Äôopportunit√© de taper un mot de passe ou jeton lors d‚Äôune authentification HTTPS.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#envoyer-des-modifications-sur-le-d√©p√¥t-distant-push",
    "href": "content/git/exogit.html#envoyer-des-modifications-sur-le-d√©p√¥t-distant-push",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "4.1 Envoyer des modifications sur le d√©p√¥t distant: push",
    "text": "4.1 Envoyer des modifications sur le d√©p√¥t distant: push\n\n\n Exercice 6 : Interagir avec Github\nIl convient maintenant d‚Äôenvoyer les fichiers sur le d√©p√¥t distant.\n\n1Ô∏è‚É£\nL‚Äôobjectif est d‚Äôenvoyer vos modifications vers origin.\nOn va passer par la ligne de commande car les boutons push/pull\nde l‚Äôextension Jupyter ne fonctionnent pas de mani√®re syst√©matique.\nTaper\ngit push origin main\nCela signifie: ‚Äúgit envoie (push) mes modifications sur la\nbranche main (la branche sur laquelle on a travaill√©, on reviendra\ndessus) vers mon d√©p√¥t (alias\norigin)‚Äù\nRemarque : Si vous obtenez l‚Äôerreur suivante error: src refspec hello does not match any, c‚Äôest probablement que vous avez indiqu√© le mauvais nom de branche. La confusion se fait souvent entre le nom main ou master (ancienne norme de branche par d√©faut).\nNormalement, si vous avez utilis√© le credential helper, Git ne\nvous demande pas vos identifiants de connexion. Sinon,\nil faut taper\nvotre identifiant Github et votre mot de passe correspond au personal access token nouvellement cr√©√© !\n2Ô∏è‚É£ Retournez voir le d√©p√¥t sur Github, vous devriez maintenant voir le fichier\n.gitignore s‚Äôafficher en page d‚Äôaccueil.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#la-fonctionnalit√©-pull",
    "href": "content/git/exogit.html#la-fonctionnalit√©-pull",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "4.2 La fonctionnalit√© pull",
    "text": "4.2 La fonctionnalit√© pull\nLa deuxi√®me mani√®re d‚Äôinteragir avec le d√©p√¥t est de r√©cup√©rer des\nr√©sultats disponibles en ligne sur sa copie de travail. On appelle\ncela pull.\nPour le moment, vous √™tes tout seul sur le d√©p√¥t. Il n‚Äôy a donc pas de\npartenaire pour modifier un fichier dans le d√©p√¥t distant. On va simuler ce\ncas en utilisant l‚Äôinterface graphique de Github pour modifier\ndes fichiers. On rapatriera les r√©sultats en local dans un deuxi√®me temps.\n\n\n Exercice 7 : Rapatrier des modifs en local\n1Ô∏è‚É£ Se rendre sur votre d√©p√¥t depuis l‚Äôinterface https://github.com\n\nSe placer sur le fichier README.md et cliquer sur le bouton Edit this file, qui prend la forme d‚Äôun ic√¥ne de crayon.\n\n2Ô∏è‚É£ L‚Äôobjectif est de\ndonner au README.md un titre en ajoutant, au d√©but du document, la ligne suivante :\n# Mon oeuvre d'art surr√©aliste \nSautez une ligne et entrez le texte que vous d√©sirez, sans ponctuation. Par exemple,\nle ch√™ne un jour dit au roseau\n3Ô∏è‚É£ Cliquez sur l‚Äôonglet Preview pour voir le texte mis en forme au format Markdown\n4Ô∏è‚É£ R√©diger un titre et un message compl√©mentaire pour faire le commit. Conserver\nl‚Äôoption par d√©faut Commit directly to the main branch\n5Ô∏è‚É£ Editer √† nouveau le README en cliquant sur le crayon juste au dessus\nde l‚Äôaffichage du contenu du README.\nAjouter une deuxi√®me phrase et corrigez la\nponctuation de la premi√®re. Ecrire un message de commit et valider.\nLe Ch√™ne un jour dit au roseau :\nVous avez bien sujet d'accuser la Nature\n6Ô∏è‚É£ Au dessus de l‚Äôaborescence des fichiers, vous devriez voir s‚Äôafficher le\ntitre du dernier commit. Vous pouvez cliquer dessus pour voir la modification\nque vous avez faite.\n7Ô∏è‚É£ Les r√©sultats sont sur le d√©p√¥t distant mais ne sont pas sur votre\ndossier de travail dans Jupyter ou VSCode. Il faut re-synchroniser votre copie locale\navec le d√©p√¥t distant :\n\nSur VSCode, cliquez simplement sur ... &gt; Pull √† c√¥t√© du bouton qui permet\nde visualiser le graphe Git.\nAvec l‚Äôinterface Jupyter, si cela est possible, appuyez tout simplement sur la petite\nfl√®che vers le bas, qui est celle qui a d√©sormais la pastille orange.\nSi cette fl√®che n‚Äôest pas disponible ou si vous travaillez dans un autre\nenvironnement, vous pouvez utiliser la ligne de\ncommande et taper\n\ngit pull origin main\nCela signifie : ‚Äúgit r√©cup√®re (pull) les modifications sur la\nbranche main vers mon d√©p√¥t (alias\norigin)‚Äù\n8Ô∏è‚É£ Regarder √† nouveau l‚Äôhistorique des commits. Cliquez sur le\ndernier commit et affichez les changements sur le fichier. Vous pouvez\nremarquer la finesse du contr√¥le de version : Git d√©tecte au sein de\nla premi√®re ligne de votre texte que vous avez mis des majuscules\nou de la ponctuation.\n\n\nL‚Äôop√©ration pull permet :\n\nA votre syst√®me local de v√©rifier les modifications sur le d√©p√¥t distant\nque vous n‚Äôauriez pas faites (cette op√©ration s‚Äôappelle fetch)\nDe les fusionner s‚Äôil n‚Äôy a pas de conflit de version ou si les conflits de\nversion sont automatiquement fusionnables (deux modifications d‚Äôun fichier mais\nqui ne portent pas sur le m√™me emplacement).",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#le-workflow-adopt√©",
    "href": "content/git/exogit.html#le-workflow-adopt√©",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "6.1 Le workflow adopt√©",
    "text": "6.1 Le workflow adopt√©\nNous allons adopter le mode de travail le plus simple, le Github Flow.\nIl correspond √† cette forme caract√©ristique d‚Äôarbre:\n\nLa branche main constitue le tronc\nLes branches partent de main et divergent\nLorsque les modifications aboutissent, elles sont int√©gr√©es √† main ;\nla branche en question dispara√Æt :\n\n\nIl existe des workflows plus complexes, notamment le Git Flow que j‚Äôutilise\npour d√©velopper ce cours. Ce tutoriel, tr√®s bien fait,\nillustre avec un graphique la complexit√© accrue de ce flow :\n\nCette fois, une branche interm√©diaire, par exemple une branche development\nint√®gre des modifications √† tester avant de les int√©grer dans la version\nofficielle (main).\n\n\n Hint\nVous pourrez trouvez des dizaines d‚Äôarticles et d‚Äôouvrages sur ce sujet dont chacun pr√©tend avoir trouv√© la meilleure organisation du travail (Git flow, GitHub flow, GitLab flow‚Ä¶). Ne lisez pas trop ces livres et articles sinon vous serez perdus (un peu comme avec les magazines destin√©s aux jeunes parents‚Ä¶).\nLa m√©thode de travail la plus simple est le Github flow qu‚Äôon vous a propos√© d‚Äôadopter. L‚Äôarborescence est reconnaissable : des branches divergent et reviennent syst√©matiquement vers main.\nPour des projets plus complexes dans des √©quipes d√©veloppant des applications, on pourra utiliser d‚Äôautres m√©thodes de travail, notamment le Git flow. Il n‚Äôexiste pas de r√®gles universelles pour d√©terminer la m√©thode de travail ; l‚Äôimportant c‚Äôest, avant tout, de se mettre d‚Äôaccord sur des r√®gles communes de travail avec votre √©quipe.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#m√©thode-pour-les-merges",
    "href": "content/git/exogit.html#m√©thode-pour-les-merges",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "6.2 M√©thode pour les merges",
    "text": "6.2 M√©thode pour les merges\nLes merges vers main doivent imp√©rativement passer par Github (ou Gitlab). Cela permet de garder une trace explicite de ceux-ci (par exemple ici), sans avoir √† chercher dans l‚Äôarborescence, parfois complexe, d‚Äôun projet.\nLa bonne pratique veut qu‚Äôon fasse un squash commit pour √©viter une inflation du nombre de commits dans main: les branches ont vocation √† proposer une multitude de petits commits, les modifications dans main doivent √™tre simples √† tracer d‚Äôo√π le fait de modifier des petits bouts de code.\nComme on l‚Äôa fait dans un exercice pr√©c√©dent, il est tr√®s pratique d‚Äôajouter dans le corps du message close #xx o√π xx est le num√©ro d‚Äôune issue associ√©e √† la pull request. Lorsque la pull request sera fusionn√©e, l‚Äôissue sera automatiquement ferm√©e et un lien sera cr√©√© entre l‚Äôissue et la pull request. Cela vous permettra de comprendre, plusieurs mois ou ann√©es plus tard comment et pourquoi telle ou telle fonctionnalit√© a √©t√© impl√©ment√©e.\nEn revanche, l‚Äôint√©gration des derni√®res modifications de main vers une branche se fait en local. Si votre branche est en conflit, le conflit doit √™tre r√©solu dans la branche et pas dans main.\nmain doit toujours rester propre.",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#mise-en-pratique",
    "href": "content/git/exogit.html#mise-en-pratique",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "6.3 Mise en pratique",
    "text": "6.3 Mise en pratique\n\n\n Exercice 9 : Interactions avec le d√©p√¥t distant\nCet exercice se fait par groupe de trois ou quatre. Il y aura deux r√¥les dans ce sc√©nario :\n\nUne personne aura la responsabilit√© d‚Äô√™tre mainteneur\nDeux √† trois personnes seront d√©veloppeurs.\n\n1Ô∏è‚É£ Le mainteneur cr√©e un d√©p√¥t sur Github. Il/Elle donne des droits au(x) d√©veloppeur(s) du projet (Settings &gt; Manage Access &gt; Invite a collaborator).\n2Ô∏è‚É£ Chaque membre du projet, cr√©e une copie locale du projet gr√¢ce √† la commande git clone ou\navec le bouton Clone a repository de JupyterLab.\nPour cela, r√©cup√©rer l‚Äôurl HTTPS du d√©p√¥t en copiant l‚Äôurl du d√©p√¥t que vous pouvez trouver, par exemple, dans la page d‚Äôaccueil du d√©p√¥t, en dessous de Quick setup ‚Äî if you‚Äôve done this kind of thing before\nEn ligne de commande, cela donnera :\ngit clone https://github.com/&lt;username&gt;/&lt;reponame&gt;.git\n3Ô∏è‚É£ Chaque membre du projet cr√©e un fichier avec son nom et son pr√©nom, selon cette structure nom-prenom.md en √©vitant les caract√®res sp√©ciaux. Il √©crit dedans trois phrases de son choix sans ponctuation ni majuscules (pour pouvoir effectuer une correction ult√©rieurement). Enfin, il commit sur le projet.\nPour rappel, en ligne de commande cela donnera les commandes suivantes √† modifier\ngit add nom-prenom.md\ngit commit -m \"C'est l'histoire de XXXXX\"\n4Ô∏è‚É£ Chacun essaie d‚Äôenvoyer (push) ses modifications locales sur le d√©p√¥t:\ngit push origin main\n5Ô∏è‚É£ A ce stade, une seule personne (la plus rapide) devrait ne pas avoir rencontr√© de rejet du push. C‚Äôest normal, avant d‚Äôaccepter une modification Git v√©rifie en premier lieu la coh√©rence de la branche avec le d√©p√¥t distant. Le premier ayant fait un push a modifi√© le d√©p√¥t commun ; les autres doivent int√©grer ces modifications dans leur version locale (pull) avant d‚Äôavoir le droit de proposer un changement.\nPour celui/celle/ceux dont le push a √©t√© refus√©, faire\ngit pull origin main\npour ramener les modifications distantes en local.\n6Ô∏è‚É£ Taper git log et regarder la mani√®re dont a √©t√© int√©gr√© la modification de votre camarade ayant pu faire son push\nVous remarquerez que les commits de vos camarades sont int√©gr√©s tels quels √†\nl‚Äôhistoire du d√©p√¥t.\n7Ô∏è‚É£ Faire √† nouveau\ngit pull origin main\nLe dernier doit refaire, √† nouveau, les √©tapes 5 √† 7 (dans une √©quipe de quatre\nil faudra encore le refaire une fois).\n\n\n\n\n Warning √† nouveau: ne JAMAIS FAIRE git push force\nQuand on fait face √† un rejet du push, on est tent√© de faire passer en force le push malgr√© la mise en garde pr√©c√©dente.\nIl faut imm√©diatement oublier cette solution, elle cr√©e de nombreux probl√®mes et, en fait, ne r√©sout rien. L‚Äôun des risques est de r√©√©crire enti√®rement l‚Äôhistorique rendant les copies locales, et donc les modifications de vos collaborateurs, caduques. Cela vous vaudra, √† raison, des remontrances de vos partenaires qui perdent le b√©n√©fice de leur historique Git qui, s‚Äôils ont des versions sans push depuis longtemps peuvent avoir diverger fortement du d√©p√¥t ma√Ætre.\n\n\n\n\n Exercice 10 : G√©rer les conflits quand on travaille sur le m√™me fichier\nDans la continuit√© de l‚Äôexercice pr√©c√©dent, chaque personne va travailler sur les fichiers des autres membres de l‚Äô√©quipe.\n1Ô∏è‚É£ Les deux ou trois d√©veloppeurs ajoutent la ponctuation et les majuscules du fichier du premier d√©veloppeur.\n2Ô∏è‚É£ Ils sautent une ligne et ajoutent une phrase (pas tous la m√™me).\n3Ô∏è‚É£ Valider les r√©sultats (git add . et commit) et faire un push\n4Ô∏è‚É£ La personne la plus rapide n‚Äôa, normalement, rencontr√© aucune difficult√© (elle peut s‚Äôarr√™ter temporairement pour regarder ce qui va se passer chez les voisins). Les autres voient leur push refus√© et doivent faire un pull.\nüí• Il y a conflit, ce qui doit √™tre signal√© par un message du type :\nAuto-merging XXXXXX\nCONFLICT (content): Merge conflict in XXXXXX.md\nAutomatic merge failed; fix conflicts and then commit the result.\n5Ô∏è‚É£ Etudier le r√©sultat de git status\n6Ô∏è‚É£ Si vous ouvrez les fichiers incrimin√©s, vous devriez voir des balises du type\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nthis is some content to mess with\ncontent to append\n=======\ntotally different content to merge later\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; new_branch_to_merge_later\n7Ô∏è‚É£ Corriger √† la main les fichiers en choisissant, pour chaque ligne, la version qui vous convient et en retirant les balises. Valider en faisant:\ngit add . && git commit -m \"R√©solution du conflit par XXXX\"\nRemplacer XXXX par votre nom. La balise && permet d‚Äôencha√Æner, en une seule ligne de code, les deux commandes.\n8Ô∏è‚É£ Faire un push. Pour la derni√®re personne, refaire les op√©rations 4 √† 8\n\n\nGit permet donc de travailler, en m√™me temps, sur le m√™me fichier et de limiter le nombre de gestes manuels n√©cessaires pour faire la fusion. Lorsqu‚Äôon travaille sur des bouts diff√©rents du m√™me fichier, on n‚Äôa m√™me pas besoin de faire de modification manuelle, la fusion peut √™tre automatique.\nGit est un outil tr√®s puissant. Mais, il ne remplace pas une bonne organisation du travail. Vous l‚Äôavez vu, ce mode de travail uniquement sur main peut √™tre p√©nible. Les branches prennent tout leur sens dans ce cas.\n\n\n Exercice 11 : Gestion des branches\n1Ô∏è‚É£ Le mainteneur va contribuer directement dans main et ne cr√©e pas de branche. Chaque d√©veloppeur cr√©e une branche, en local nomm√©e contrib-XXXXX o√π XXXXX est le pr√©nom:\ngit checkout -b contrib-XXXXX\n2Ô∏è‚É£ Chaque membre du groupe cr√©e un fichier README.md o√π il √©crit une phrase sujet-verbe-compl√©ment. Le mainteneur est le seul √† ajouter un titre dans le README (qu‚Äôil commit dans main).\n3Ô∏è‚É£ Chacun push le produit de son subconscient sur le d√©p√¥t.\n4Ô∏è‚É£ Les d√©veloppeurs ouvrent, chacun, une pull request sur Github de leur branche vers main. Ils lui donnent un titre explicite.\n5Ô∏è‚É£ Dans la discussion de chaque pull request, le mainteneur demande au d√©veloppeur d‚Äôint√©grer le titre qu‚Äôil a √©crit.\n6Ô∏è‚É£ Chaque d√©veloppeur, en local, int√®gre cette modification en faisant\n# Pour √™tre s√ªr d'√™tre sur sa propre branche\ngit checkout branche-XXXX\ngit merge main\nR√©gler le conflit et valider (add et commit). Pousser le r√©sultat. Le mainteneur choisit une des pull request et la valide avec l‚Äôoption squash commits. V√©rifier sur la page d‚Äôaccueil le r√©sultat.\n7Ô∏è‚É£ L‚Äôauteur (si 2 d√©veloppeurs) ou les deux auteurs (si 3 d√©veloppeurs) de la pull request non valid√©e doivent √† nouveau r√©p√©ter l‚Äôop√©ration 6.\n8Ô∏è‚É£ Une fois le conflit de version r√©gl√© et pouss√©, le mainteneur valide la pull request selon la m√™me proc√©dure que pr√©c√©demment.\n9Ô∏è‚É£ V√©rifier l‚Äôarborescence du d√©p√¥t dans Insights &gt; Network. Votre arbre doit avoir une forme caract√©ristique de ce qu‚Äôon appelle le Github flow:",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#informations-additionnelles",
    "href": "content/git/exogit.html#informations-additionnelles",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n56d092b\n\n\n2023-11-14 15:43:00\n\n\nAntoine Palazzolo\n\n\nupdate readme (#451)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\nb6ae3e3\n\n\n2023-11-14 05:49:42\n\n\nlinogaliana\n\n\nCorrige balise md\n\n\n\n\nae5205f\n\n\n2023-11-13 20:35:43\n\n\nlinogaliana\n\n\npr√©cision\n\n\n\n\n428d669\n\n\n2023-11-13 20:31:11\n\n\nlinogaliana\n\n\nExo gitignore\n\n\n\n\n66c6a29\n\n\n2023-11-13 19:53:49\n\n\nlinogaliana\n\n\njupyter sspcloud credential helper\n\n\n\n\n69d5bc7\n\n\n2023-11-13 19:44:01\n\n\nlinogaliana\n\n\nmise √† jour de quelques consignes\n\n\n\n\ne3f1ef1\n\n\n2023-11-13 11:53:50\n\n\nThomas Faria\n\n\nRelecture git (#448)\n\n\n\n\nea9400a\n\n\n2023-11-05 10:54:04\n\n\ntomseimandi\n\n\nInclude VSCode instructions in exogit (#447)\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nf8831e7\n\n\n2023-10-09 10:53:34\n\n\nLino Galiana\n\n\nRelecture antuki geopandas (#429)\n\n\n\n\n5ab34aa\n\n\n2023-10-04 14:54:20\n\n\nKim A\n\n\nRelecture Kim pandas & git (#416)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\nb649205\n\n\n2023-08-28 15:47:09\n\n\nlinogaliana\n\n\nNice image\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\n34cc32c\n\n\n2022-10-14 22:05:47\n\n\nLino Galiana\n\n\nRelecture Git (#300)\n\n\n\n\nfd439f0\n\n\n2022-09-19 09:37:50\n\n\navouacr\n\n\nfix ssp cloud links\n\n\n\n\n3056d41\n\n\n2022-09-02 12:19:55\n\n\navouacr\n\n\nfix all SSP Cloud launcher links\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n36ed7b1\n\n\n2020-10-07 12:36:03\n\n\nLino Galiana\n\n\nCadavre exquis (#66)\n\n\n\n\nd1ad64c\n\n\n2020-10-04 14:43:55\n\n\nLino Galiana\n\n\nFinalisation de la premi√®re partie de l‚Äôexo git (#62)\n\n\n\n\n283e8e9\n\n\n2020-10-02 18:54:30\n\n\nLino Galiana\n\n\nPremi√®re partie des exos git (#61)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†2.1: Interface graphique Git sous Jupyter (√† gauche) et VSCode (√† droite)\nFigure¬†2.1: Interface graphique Git sous Jupyter (√† gauche) et VSCode (√† droite)",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/exogit.html#footnotes",
    "href": "content/git/exogit.html#footnotes",
    "title": "Un cadavre exquis pour d√©couvrir Git",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCe cas de figure arrive lorsqu‚Äôon contribue √† des projets\nsur lesquels on n‚Äôa pas de droit d‚Äô√©criture. Il est alors\nn√©cessaire d‚Äôeffectuer un fork, une copie de ce d√©p√¥t sur laquelle\non dispose de droits.\nDans ce cas de figure, on rencontre g√©n√©ralement un nouvel alias √† c√¥t√© d‚Äôorigin.\nnomm√© upstream (cf.\nle tutoriel Github pour mettre √† jour un fork\net qui pointe vers le d√©p√¥t source √† l‚Äôorigine du fork.\nLa cr√©ation du bouton Fetch upstream par Github facilite grandement\nla mise en coh√©rence d‚Äôupstream et origin et constitue la m√©thode\nrecommand√©e.‚Ü©Ô∏é\nLa commande checkout est un couteau-suisse de la gestion de branche en Git. Elle permet en effet de basculer d‚Äôune branche √† l‚Äôautre, mais aussi d‚Äôen cr√©er, etc.‚Ü©Ô∏é",
    "crumbs": [
      "Un cadavre exquis pour d√©couvrir Git"
    ]
  },
  {
    "objectID": "content/git/index.html",
    "href": "content/git/index.html",
    "title": "Git: un outil n√©cessaire pour les data scientists",
    "section": "",
    "text": "Cette partie du site pr√©sente un √©l√©ment qui n‚Äôest pas propre √†\nPython mais qui est n√©anmoins indispensable : la pratique de Git.\nUne grande partie du contenu de la partie provient\nd‚Äôun cours d√©di√© fait avec Romain Avouac.\nLe chapitre de pr√©sentation de Git propose\nune introduction visant √† pr√©senter l‚Äôint√©r√™t d‚Äôutiliser\ncet outil. Une mise en pratique est propos√©e\navec un cadavre exquis.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/git/index.html#utilisation-de-git-avec-python",
    "href": "content/git/index.html#utilisation-de-git-avec-python",
    "title": "Git: un outil n√©cessaire pour les data scientists",
    "section": "0.1 Utilisation de Git avec Python",
    "text": "0.1 Utilisation de Git avec Python\nGit est √† la fois un outil et un langage. Il\nest donc n√©cessaire d‚Äôinstaller, dans un premier\ntemps Git Bash, puis de connecter\nson outil pr√©f√©r√© pour faire du Python (qu‚Äôil\ns‚Äôagisse de Jupyter, VSCode ou PyCharm).\nCette partie est structur√©e en 2 temps :\n\nPr√©sentation de Git\nExercice pour d√©couvrir Git",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/git/index.html#informations-additionnelles",
    "href": "content/git/index.html#informations-additionnelles",
    "title": "Git: un outil n√©cessaire pour les data scientists",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n57f108f\n\n\n2023-11-10 10:59:36\n\n\nlinogaliana\n\n\nIntro git\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n34cc32c\n\n\n2022-10-14 22:05:47\n\n\nLino Galiana\n\n\nRelecture Git (#300)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html",
    "href": "content/modern-ds/elastic_approfondissement.html",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre est issu du travail produit\ndans le cadre d‚Äôun hackathon de l‚ÄôInsee avec\nRapha√´le Adjerad\net pr√©sente quelques √©l√©ments qui peuvent √™tre utiles\npour l‚Äôenrichissement de donn√©es d‚Äôentreprises\n√† partir d‚Äôun r√©pertoire officiel.\n:warning: Il n√©cessite une version particuli√®re du package elasticsearch pour tenir compte de l‚Äôh√©ritage de la version 7 du moteur Elastic. Pour cela, faire",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#objectif",
    "href": "content/modern-ds/elastic_approfondissement.html#objectif",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "1.1 Objectif",
    "text": "1.1 Objectif\nCe chapitre vise √† approfondir les √©l√©ments pr√©sent√©s sur Elastic pr√©c√©demment. L‚Äôid√©e\nest de se placer dans un contexte op√©rationnel o√π on re√ßoit des informations\nsur des entreprises telles que l‚Äôadresse et la localisation et qu‚Äôon\nd√©sire associer √† des donn√©es administratives consid√©r√©es plus fliables.",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#r√©plication-de-ce-chapitre",
    "href": "content/modern-ds/elastic_approfondissement.html#r√©plication-de-ce-chapitre",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "1.2 R√©plication de ce chapitre",
    "text": "1.2 R√©plication de ce chapitre\nComme le pr√©c√©dent, ce chapitre est plus exigeant en termes d‚Äôinfrastructures que les pr√©c√©dents.\nIl n√©cessite un serveur Elastic. Les utilisateurs du\nSSP Cloud pourront r√©pliquer les exemples de ce cours\ncar cette technologie est disponible (que ce soit pour indexer une base ou\npour requ√™ter une base existante).\nLa premi√®re partie de ce tutoriel, qui consiste √† cr√©er une base Sirene g√©olocalis√©e\n√† partir des donn√©es open-data ne n√©cessite pas d‚Äôarchitecture particuli√®re et\npeut ainsi √™tre ex√©cut√©e en utilisant les packages suivants :\n\nimport numpy as np\nimport pandas as pd",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#sources",
    "href": "content/modern-ds/elastic_approfondissement.html#sources",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "1.3 Sources",
    "text": "1.3 Sources\nCe chapitre va utiliser plusieurs sources de diffusion de\nl‚ÄôInsee:\n\nLe stock des √©tablissements pr√©sents dans les donn√©es de diffusion Sirene ;\nLes donn√©es Sirene g√©olocalis√©es\n\nLes donn√©es √† siretiser sont celles du registre Fran√ßais des √©missions polluantes\n√©tabli par le Minist√®re de la Transition Energ√©tique. Le jeu de donn√©es\nest disponible sur data.gouv",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#importer-la-base-d√©j√†-cr√©√©e",
    "href": "content/modern-ds/elastic_approfondissement.html#importer-la-base-d√©j√†-cr√©√©e",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "3.1 Importer la base d√©j√† cr√©√©e",
    "text": "3.1 Importer la base d√©j√† cr√©√©e\nLes donn√©es √† utiliser pour constuire une base Sirene g√©olocalis√©e\nsont trop volumineuses pour les serveurs mis √† disposition\ngratuitement par Github pour la compilation de ce site web.\nNous proposons ainsi une version d√©j√† construite, stock√©e\ndans l‚Äôespace de mise √† disposition du SSP Cloud. Ce fichier est\nau format parquet et est ouvert √†\ntous, m√™me pour les personnes ne disposant pas d‚Äôun compte.\nLe code ayant construit cette base est pr√©sent√© ci-dessous.\nPour importer cette base, on utilise les fonctionalit√©s\nde pyarrow qui permettent d‚Äôimporter un fichier sur\nun syst√®me de stockage cloud comme s‚Äôil √©tait\npr√©sent sur le disque :\n\nfrom pyarrow import fs\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\nbucket = \"lgaliana\"\npath = \"diffusion/sirene_geolocalized.parquet\"\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\ndf_geolocalized = (\n    pq.ParquetDataset(f\"{bucket}/{path}\", filesystem=s3).read_pandas().to_pandas()\n)\ndf_geolocalized.head(3)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#reproduire-la-construction-de-la-base",
    "href": "content/modern-ds/elastic_approfondissement.html#reproduire-la-construction-de-la-base",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "3.2 Reproduire la construction de la base",
    "text": "3.2 Reproduire la construction de la base\nLa premi√®re base d‚Äôentr√©e √† utiliser est disponible sur\ndata.gouv\n\nimport requests\nimport zipfile\n\nurl_download = (\n    \"https://www.data.gouv.fr/fr/datasets/r/0651fb76-bcf3-4f6a-a38d-bc04fa708576\"\n)\nreq = requests.get(url_download)\n\nwith open(\"sirene.zip\", \"wb\") as f:\n    f.write(req.content)\n\nwith zipfile.ZipFile(\"sirene.zip\", \"r\") as zip_ref:\n    zip_ref.extractall(\"sirene\")\n\nOn va importer seulement les colonnes utiles et simplifier la structure\npour √™tre en mesure de ne garder que les informations qui nous\nint√©ressent (nom de l‚Äôentreprise, adresse, commune, code postal‚Ä¶)\n\nimport pandas as pd\nimport numpy as np\n\nlist_cols = [\n    \"siren\",\n    \"siret\",\n    \"activitePrincipaleRegistreMetiersEtablissement\",\n    \"complementAdresseEtablissement\",\n    \"numeroVoieEtablissement\",\n    \"typeVoieEtablissement\",\n    \"libelleVoieEtablissement\",\n    \"codePostalEtablissement\",\n    \"libelleCommuneEtablissement\",\n    \"codeCommuneEtablissement\",\n    \"etatAdministratifEtablissement\",\n    \"denominationUsuelleEtablissement\",\n    \"activitePrincipaleEtablissement\",\n]\n\ndf = pd.read_csv(\"sirene/StockEtablissement_utf8.csv\", usecols=list_cols)\n\ndf[\"numero\"] = (\n    df[\"numeroVoieEtablissement\"]\n    .replace(\"-\", np.NaN)\n    .str.split()\n    .str[0]\n    .str.extract(\"(\\d+)\", expand=False)\n    .fillna(\"0\")\n    .astype(int)\n)\n\ndf[\"numero\"] = df[\"numero\"].astype(str).replace(\"0\", \"\")\n\ndf[\"adresse\"] = (\n    df[\"numero\"]\n    + \" \"\n    + df[\"typeVoieEtablissement\"]\n    + \" \"\n    + df[\"libelleVoieEtablissement\"]\n)\n\ndf[\"adresse\"] = df[\"adresse\"].replace(np.nan, \"\")\n\ndf = df.loc[df[\"etatAdministratifEtablissement\"] == \"A\"]\n\ndf.rename(\n    {\n        \"denominationUsuelleEtablissement\": \"denom\",\n        \"libelleCommuneEtablissement\": \"commune\",\n        \"codeCommuneEtablissement\": \"code_commune\",\n        \"codePostalEtablissement\": \"code_postal\",\n    },\n    axis=\"columns\",\n    inplace=True,\n)\n\ndf[\"ape\"] = df[\"activitePrincipaleEtablissement\"].str.replace(\"\\.\", \"\", regex=True)\ndf[\"denom\"] = df[\"denom\"].replace(np.nan, \"\")\n\ndf_siret = df.loc[\n    :,\n    [\n        \"siren\",\n        \"siret\",\n        \"adresse\",\n        \"ape\",\n        \"denom\",\n        \"commune\",\n        \"code_commune\",\n        \"code_postal\",\n    ],\n]\ndf_siret[\"code_postal\"] = (\n    df_siret[\"code_postal\"]\n    .replace(np.nan, \"0\")\n    .astype(int)\n    .astype(str)\n    .replace(\"0\", \"\")\n)\n\nOn importe ensuite les donn√©es g√©olocalis√©es\n\nimport zipfile\nimport shutil\nimport os\n\n# os.remove(\"sirene.zip\")\n# shutil.rmtree('sirene/')\n\nurl_geoloc = \"https://files.data.gouv.fr/insee-sirene-geo/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.zip\"\nr = requests.get(url_geoloc)\n\nwith open(\"geoloc.zip\", \"wb\") as f:\n    f.write(r.content)\n\nwith zipfile.ZipFile(\"geoloc.zip\", \"r\") as zip_ref:\n    zip_ref.extractall(\"geoloc\")\n\ndf_geoloc = pd.read_csv(\n    \"geoloc/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.csv\",\n    usecols=[\"siret\", \"epsg\", \"x_longitude\", \"y_latitude\"],\n    sep=\";\",\n)\n\nIl ne reste plus qu‚Äô√† associer les deux jeux de donn√©es\n\ndf_geolocalized = df_siret.merge(df_geoloc, on=\"siret\")\ndf_geolocalized[\"code_commune\"] = df_geolocalized[\"code_commune\"].astype(str)\n\nSi vous avez acc√®s √† un espace de stockage cloud de type\nS3, il est possible d‚Äôutiliser pyarrow pour enregister\ncette base. Afin de l‚Äôenregistrer dans un espace de stockage\npublic, nous allons l‚Äôenregistrer dans un dossier diffusion1\n\nfrom pyarrow import fs\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\nbucket = \"lgaliana\"\npath = \"diffusion/sirene_geolocalized.parquet\"\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\ntable = pa.Table.from_pandas(df_geolocalized)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#d√©finition-du-mapping",
    "href": "content/modern-ds/elastic_approfondissement.html#d√©finition-du-mapping",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "5.1 D√©finition du mapping",
    "text": "5.1 D√©finition du mapping\nOn va proc√©der par √©tape en essayant d‚Äôutiliser la structure la plus simple\npossible.\n:one: On s‚Äôoccupe d‚Äôabord de d√©finir le mapping\npour les variables textuelles.\n\nstring_var = [\"adresse\", \"denom\", \"ape\", \"commune\"]\nmap_string = {\n    \"type\": \"text\",\n    \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n}\nmapping_string = {l: map_string for l in string_var}\n\n:two: Les variables cat√©gorielles sont utilis√©es\npar le biais du type keyword:\n\n# keywords\nkeyword_var = [\"siren\", \"siret\", \"code_commune\", \"code_postal\"]\nmap_keywords = {\n    \"type\": \"text\",\n    \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n}\nmapping_keywords = {l: map_keywords for l in keyword_var}\n\n:three: La nouveaut√© par rapport √† la partie\npr√©c√©dente est l‚Äôutilisation de la\ndimension g√©ographique. Elastic propose\nle type geo_point pour cela.\n\n# geoloc\nmapping_geoloc = {\"location\": {\"type\": \"geo_point\"}}\n\nOn collecte tout cela ensemble dans un\ndictionnaire:\n\n# mapping\nmapping_elastic = {\n    \"mappings\": {\"properties\": {**mapping_string, **mapping_geoloc, **mapping_keywords}}\n}\n\nIl est tout √† fait possible de d√©finir un mapping\nplus raffin√©. Ici, on va privil√©gier\nl‚Äôutilisation d‚Äôun mapping simple pour\nillustrer la recherche par distance\ng√©ographique en priorit√©.",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#cr√©ation-de-lindex",
    "href": "content/modern-ds/elastic_approfondissement.html#cr√©ation-de-lindex",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "5.2 Cr√©ation de l‚Äôindex",
    "text": "5.2 Cr√©ation de l‚Äôindex\nPour cr√©er le nouvel index, on s‚Äôassure d‚Äôabord de ne pas\nd√©j√† l‚Äôavoir cr√©√© et on passe le mapping d√©fini\npr√©c√©demment.\n\nif es.indices.exists(\"sirene\"):\n    es.indices.delete(\"sirene\")\n\nes.indices.create(index=\"sirene\", body=mapping_elastic)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#indexation-de-la-base-g√©olocalis√©e",
    "href": "content/modern-ds/elastic_approfondissement.html#indexation-de-la-base-g√©olocalis√©e",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "5.3 Indexation de la base g√©olocalis√©e",
    "text": "5.3 Indexation de la base g√©olocalis√©e\nPour le moment, l‚Äôindex est vide. Il convient de\nle peupler.\nIl est n√©anmoins n√©cessaire de cr√©er le champ location\nau format attendu par elastic: lat, lon √† partir\nde nos colonnes.\n\ndf_geolocalized[\"location\"] = (\n    df_geolocalized[\"y_latitude\"].astype(str)\n    + \", \"\n    + df_geolocalized[\"x_longitude\"].astype(str)\n)\n\nLa fonction suivante permet de structurer chaque\nligne du DataFrame telle qu‚ÄôElastic l‚Äôattend:\n\ndef gen_dict_from_pandas(index_name, df):\n    \"\"\"\n    Lit un dataframe pandas Open Food Facts, renvoi un it√©rable = dictionnaire des donn√©es √† indexer, sous l'index fourni\n    \"\"\"\n    for i, row in df.iterrows():\n        header = {\"_op_type\": \"index\", \"_index\": index_name, \"_id\": i}\n        yield {**header, **row}\n\nEnfin, on peut industrialiser l‚Äôindexation\nde notre DataFrame en faisant tourner de\nmani√®re successive cette fonction :\n\nfrom elasticsearch.helpers import bulk, parallel_bulk\nfrom collections import deque\n\ndeque(\n    parallel_bulk(\n        client=es,\n        actions=gen_dict_from_pandas(\"sirene\", df_geolocalized),\n        chunk_size=1000,\n        thread_count=4,\n    )\n)\n\n\nes.count(index=\"sirene\")\n\nObjectApiResponse({'count': 13059694, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#premier-exemple-de-requ√™te-g√©ographique",
    "href": "content/modern-ds/elastic_approfondissement.html#premier-exemple-de-requ√™te-g√©ographique",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "6.1 Premier exemple de requ√™te g√©ographique",
    "text": "6.1 Premier exemple de requ√™te g√©ographique\n\nex1 = es.search(\n    index=\"sirene\",\n    body=\"\"\"{\n  \"query\": {\n    \"bool\": {\n      \"must\":\n      { \"match\": { \"denom\":   \"institut national de la statistique\"}}\n      }\n  }\n}\n\"\"\",\n)[\"hits\"][\"hits\"]\n\necho_insee = pd.json_normalize(ex1)\necho_insee\n\nOn remarque d√©j√† que les intitul√©s ne sont\npas bons. Quand est-il de leurs localisations ?\n\nplot_folium_sirene(echo_insee, yvar=\"_source.y_latitude\", xvar=\"_source.x_longitude\")\n\nCe premier essai nous sugg√®re qu‚Äôil est\nn√©cessaire d‚Äôam√©liorer notre recherche.\nPlusieurs voies sont possibles:\n\nAm√©liorer le preprocessing de nos champs\ntextuels en excluant, par exemple, les\nstopwords ;\nEffectuer une restriction g√©ographique\npour mieux cibler l‚Äôensemble de recherche\nTrouver une variable cat√©gorielle jouant\nle r√¥le de variable de blocage2 pour\nmieux cibler les paires pertinentes\n\nConcernant la restriction\ng√©ographique, Elastic fournit une approche\ntr√®s efficace de ciblage g√©ographique.\nEn connaissant une position approximative\nde l‚Äôentreprise √† rechercher,\nil est ainsi possible de\nrechercher dans un rayon\nd‚Äôune taille plus ou moins grande.\nEn supposant qu‚Äôon connaisse pr√©cis√©ment\nla localisation de l‚ÄôInsee, on peut\nchercher dans un rayon relativement\nrestreint. Si notre position √©tait plus\napproximative, on pourrait rechercher\ndans un rayon plus large.\n\nex2 = es.search(\n    index=\"sirene\",\n    body=\"\"\"{\n  \"query\": {\n    \"bool\": {\n      \"must\":\n      { \"match\": { \"denom\":   \"institut national de la statistique\"}}\n      ,\n      \"filter\":\n        {\"geo_distance\": {\n          \"distance\": \"1km\",\n          \"location\": {\n            \"lat\": \"48.8168\",\n            \"lon\": \"2.3099\"\n          }\n        }\n      }\n    }\n  }\n}\n\"\"\",\n)[\"hits\"][\"hits\"]\n\necho_insee = pd.json_normalize(ex2)\necho_insee\n\n\n\n Hint\nConna√Ætre la localisation pr√©cise d‚Äôune\nentreprise\nn√©cessite d√©j√† une bonne remont√©e\nd‚Äôinformation sur celle-ci.\nIl est plus plausible de supposer\nqu‚Äôon dispose, dans une phase amont\nde la chaine de production,\nde l‚Äôadresse de celle-ci.\nDans ce cas, il est utile\nd‚Äôutiliser un service de g√©ocodage,\ncomme l‚ÄôAPI Adresse\nd√©velopp√©e par Etalab.\n\n\nLes r√©sultats sont par construction mieux\ncibl√©s. N√©anmoins ils sont toujours d√©cevants\npuisqu‚Äôon ne parvient pas √† identifier l‚ÄôInsee\ndans les dix meilleurs √©chos.\n\nspecificsearch = es.search(\n    index=\"sirus_2020\",\n    body=\"\"\"{\n  \"query\": {\n    \"bool\": {\n      \"should\":\n          { \"match\": { \"rs_denom\":   \"CPCU - CENTRALE DE BERCY\"}},\n      \"filter\": [\n          {\"geo_distance\": {\n                  \"distance\": \"0.5km\",\n                  \"location\": {\n                        \"lat\": \"48.84329\", \n                        \"lon\": \"2.37396\"\n                              }\n                            }\n            }, \n            { \"prefix\":  { \"apet\": \"3530\" }}\n                ]\n            }\n          }\n}\"\"\",\n)",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#informations-additionnelles",
    "href": "content/modern-ds/elastic_approfondissement.html#informations-additionnelles",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_approfondissement.html#footnotes",
    "href": "content/modern-ds/elastic_approfondissement.html#footnotes",
    "title": "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nConcernant la premi√®re piste, il aurait\nfallu mieux d√©finir notre mapping pour\nautoriser des analyzers. A d√©faut,\nnous pourrons\nutiliser nltk ou spacy pour transformer\nles champs textuels avant d‚Äôenvoyer la requ√™te.\nCette solution pr√©sente l‚Äôinconv√©nient\nde ne pas formatter de la m√™me mani√®re l‚Äôensemble\nindex√© mais pourrait malgr√© tout am√©liorer la pertinence\ndes recherches.‚Ü©Ô∏é\nConcernant la premi√®re piste, il aurait\nfallu mieux d√©finir notre mapping pour\nautoriser des analyzers. A d√©faut,\nnous pourrons\nutiliser nltk ou spacy pour transformer\nles champs textuels avant d‚Äôenvoyer la requ√™te.\nCette solution pr√©sente l‚Äôinconv√©nient\nde ne pas formatter de la m√™me mani√®re l‚Äôensemble\nindex√© mais pourrait malgr√© tout am√©liorer la pertinence\ndes recherches.‚Ü©Ô∏é",
    "crumbs": [
      "Approfondissement ElasticSearch pour des recherches de proximit√© g√©ographique"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html",
    "href": "content/modern-ds/continuous_integration.html",
    "title": "Int√©gration continue avec Python",
    "section": "",
    "text": "Cette page sera actualis√©e prochainement, une version plus √† jour et plus compl√®te peut √™tre trouv√©e sur https://ensae-reproductibilite.github.io/website/\nL‚Äôun des apports principaux des innovations\nr√©centes de la data science est la\nmani√®re dont des projets, malgr√©\nleur complexit√©, peuvent facilement\n√™tre converti en projets p√©rennes\n√† partir\nd‚Äôun prototype bien construit.\nEn s‚Äôinspirant de l‚Äôapproche devops ,\nm√©thode de travail qui consiste √† adopter un certain\nnombre de gestes pour\nautomatiser la production de livrables ou de tests\nd√®s la\nconception du produit, les data scientists\nont adopt√© une m√©thode de travail tr√®s efficace\npour favoriser la r√©utilisation de leur travail\npar d‚Äôautres √©quipes que celles √† l‚Äôorigine de\nla conception du protype initial.\nCette approche devops a √©t√© reprise et √©tendue\npour donner un autre buzz-word, le MLops.\nIl s‚Äôagit d‚Äôune approche qui vise √† cr√©er\net mettre √† disposition des mod√®les de machine\nlearning de mani√®re fiable et automatis√©e\n√† chaque nouvelle √©tape du projet, en parall√®le\nde la mise √† jour du code ayant produit ces\noutput.\nCes nouvelles m√©thodes de travail permettent\ndes gains substantiels de productivit√©\npour les √©quipes d√©veloppant des mod√®les\net r√©duit fortement le co√ªt de reprise d‚Äôun\ncode par une √©quipe en charge de sa\np√©renisation. Ce co√ªt est en effet le principal\nfrein √† la mise en production de nouveaux\nprojets ce qui peut repr√©senter un g√¢chis\nnon n√©gligeable de temps et de ressources.\nComme nous l‚Äôexpliquons avec Romain Avouac\ndans un cours de derni√®re ann√©e de l‚ÄôENSAE\n(https://ensae-reproductibilite.github.io/website/),\nl‚Äôadoption de certaines bonnes pratiques\nde d√©veloppement de code et d‚Äôune d√©marche\nexploitant les derni√®res innovations de\nla data science peut substantiellement\naugmenter les chances d‚Äôun succ√®s\nd‚Äôun projet. Le nouveau paradigme, qui\nconsiste √† int√©grer en amont du projet\ncertaines contraintes de la production\net tester continuellement la mani√®re dont les\nlivrables √©voluent, √©vite que la mise\nen production d‚Äôun projet, qui est co√ªteuse\nen temps et en ressources, n‚Äôaboutisse qu‚Äôau\nmoment o√π le projet est d√©j√† caduc\n(car les donn√©es ou les besoins ont √©volu√©s‚Ä¶).",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#fonctionnement-des-actions-github",
    "href": "content/modern-ds/continuous_integration.html#fonctionnement-des-actions-github",
    "title": "Int√©gration continue avec Python",
    "section": "3.1 Fonctionnement des actions Github",
    "text": "3.1 Fonctionnement des actions Github\nLes actions Github fonctionnent par couches successives au sein desquelles\non effectue un certain nombre d‚Äôinstructions.\nLa meilleure mani√®re d‚Äôapprendre les actions Github est, certes, de lire la\ndocumentation officielle mais surtout,\n√† mon avis, de regarder quelques pipelines pour comprendre la d√©marche.\nL‚Äôun des int√©r√™ts des Github Actions est la possibilit√© d‚Äôavoir un pipeline\nproposant une intrication de langages diff√©rents pour avoir une chaine de\nproduction qui propose les outils les plus efficaces pour r√©pondre √† un\nobjectif en limitant les verrous techniques.\nPar exemple, le pipeline de ce cours, disponible\nsur Github {{&lt; githubrepo  &gt;}} propose une intrication des langages\nPython et R avec des technologies Anaconda (pour contr√¥ler\nl‚Äôenvironnement Python comme expliqu√© dans les chapitres pr√©c√©dents)\net Javascript (pour le d√©ploiement d‚Äôun site web avec le service tiers\nNetlify)2. Cette cha√Æne de production multi-langage permet que\nles m√™mes fichiers sources g√©n√®rent un site web et des notebooks disponibles\nsur plusieurs environnements.\n\n\nname: Production deployment\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  docker:\n    if: \"!contains(github.event.commits[0].message, '[skip ci]')\"\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Set up QEMU\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        uses: docker/setup-qemu-action@v1\n      -\n        name: Set up Docker Buildx\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        uses: docker/setup-buildx-action@v1\n      -\n        name: Login to DockerHub\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        uses: docker/login-action@v1 \n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        if: ${{ github.repository == 'linogaliana/python-datascientist' }}\n        id: docker_build\n        uses: docker/build-push-action@v2\n        env:\n          GITHUB_PAT: ${{ secrets.PAT }}\n        with:\n          file: \"docker/Dockerfile\"\n          push: true\n          tags: linogaliana/python-datascientist:latest\n      -\n        name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}  \n  pages:\n    name: Render-Blog\n    runs-on: ubuntu-latest\n    container: linogaliana/python-datascientist:latest\n    needs: docker\n    if: ${{ !github.event.pull_request.head.repo.fork }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n          ref: ${{ github.event.pull_request.head.ref }}\n          repository: ${{github.event.pull_request.head.repo.full_name}}\n      - name: Configure safe.directory  # Workaround for actions/checkout#760\n        run: git config --global --add safe.directory /__w/python-datascientist/python-datascientist\n      - name: Render website\n        run: |\n          rm -f _quarto.yml\n          cp _quarto-prod.yml _quarto.yml\n          python build/append_environment.py\n          quarto render --to html\n      - name: Publish to Pages\n        if: github.ref == 'refs/heads/master'\n        run: |\n          git config --global user.email quarto-github-actions-publish@example.com\n          git config --global user.name \"Quarto GHA Workflow Runner\"\n          quarto publish gh-pages . --no-render --no-browser\n  enonces:\n    name: Render notebooks\n    runs-on: ubuntu-latest\n    container: linogaliana/python-datascientist:latest\n    needs: docker\n    if: ${{ !github.event.pull_request.head.repo.fork }}    \n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n          ref: ${{ github.event.pull_request.head.ref }}\n      - name: Configure safe.directory  # Workaround for actions/checkout#760\n        run: |\n          git config --global --add safe.directory /__w/python-datascientist/python-datascientist\n          git config --global --add safe.directory /__w/python-datascientist/python-datascientist-notebooks\n      - shell: bash\n        run: |\n          ls\n          conda info\n          conda list\n      - name: Convert in ipynb with Quarto\n        run: |\n         rm -f _quarto.yml\n         cp _quarto-prod.yml _quarto.yml\n         find content -type f -name \"*.qmd\" &gt;&gt; diff\n         cat diff\n         python build/tweak_render.py\n         python build/pimp_notebook.py\n         quarto render content --to ipynb\n         mkdir -p temp_notebooks\n         mkdir -p temp_notebooks/notebooks\n         python build/move_files.py temp_notebooks/notebooks\n         quarto render content --to ipynb --execute -M echo:true\n         mkdir -p temp_notebooks/corrections\n         python build/move_files.py temp_notebooks/corrections\n      - uses: actions/upload-artifact@v2\n        with:\n          name: Source enonce\n          path: content/\n      - uses: actions/upload-artifact@v2\n        with:\n          name: Enonces\n          path: temp_notebooks/notebooks/\n      - uses: actions/upload-artifact@v2\n        with:\n          name: Enonces\n          path: temp_notebooks/corrections/\n      - name: Pushes to another repository\n        uses: linogaliana/github-action-push-to-another-repository@main\n        env:\n          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}\n        with:\n          source-directory: 'temp_notebooks/'\n          destination-repository-username: 'linogaliana'\n          destination-repository-name: 'python-datascientist-notebooks'\n          user-email: lino.galiana@insee.fr\n          destination-github-username: linogaliana\n          #target-branch: test\n          create-target-branch-if-needed: true\n          reset-repo: true\n      - name: Test notebooks run from scratch\n        run: |\n          find temp_notebooks/corrections -name \"*.ipynb\" -exec quarto render {} --execute \\;\n\n\n\n\nLes couches qui constituent les √©tapes du pipeline\nportent ainsi le nom de steps. Un step peut comporter un certain\nnombre d‚Äôinstructions ou ex√©cuter des instructions pr√©-d√©finies.\nL‚Äôune de ces instructions pr√©d√©finies est, par exemple,\nl‚Äôinstallation de Python\nou l‚Äôinitialisation d‚Äôun environnement conda.\nLa documentation officielle de Github propose un\nfichier qui peut servir de mod√®le\npour tester un script Python voire l‚Äôuploader de mani√®re automatique\nsur Pypi.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#int√©gration-continue-avec-python-tester-un-notebook",
    "href": "content/modern-ds/continuous_integration.html#int√©gration-continue-avec-python-tester-un-notebook",
    "title": "Int√©gration continue avec Python",
    "section": "3.2 Int√©gration continue avec Python: tester un notebook",
    "text": "3.2 Int√©gration continue avec Python: tester un notebook\nCette section n‚Äôest absolument pas exhaustive. Au contraire, elle ne fournit\nqu‚Äôun exemple minimal pour expliquer la logique de l‚Äôint√©gration continue. Il\nne s‚Äôagit ainsi pas d‚Äôune garantie absolue de reproductibilit√© d‚Äôun notebook.\nGithub propose une action officielle pour utiliser Python dans un\npipeline d‚Äôint√©gration continue. Elle est disponible sur le\nMarketPlace Github.\nIl s‚Äôagit d‚Äôun bon point de d√©part, √† enrichir.\nLe fichier qui contr√¥le les instructions ex√©cut√©es dans l‚Äôenvironnement Actions\ndoit se trouver dans le dossier .github/workflows/\n(:warning: ne pas oublier le point au d√©but du\nnom du dossier). Il doit √™tre au format YAML avec une extension .yml\nou .yaml.\nIl peut avoir n‚Äôimporte quel nom n√©anmoins il\nvaut mieux lui donner un nom signifiant,\npar exemple prod.yml pour un fichier contr√¥lant une cha√Æne de production.\n\n3.2.1 Lister les d√©pendances\nAvant d‚Äô√©crire les instructions √† ex√©cuter par Github, il faut d√©finir un\nenvironnement d‚Äôex√©cution car Github ne conna√Æt pas la configuration Python\ndont vous avez besoin.\nIl convient ainsi de lister les d√©pendances n√©cessaires dans un fichier\nrequirements.txt (si on utilise un environnement virtuel)\nou un fichier environment.yml (si on pr√©f√®re\nutiliser un environnement conda).\nBien que le principe sous-jacent soit l√©g√®rement diff√©rent,\nces fichiers ont la m√™me fonction :\npermettre la cr√©ation d‚Äôun environnement ex-nihilo\navec un certain nombre de d√©pendances pr√©-install√©es3.\nSi on fait le choix de l‚Äôoption environment.yml,\nle fichier prendra ainsi la forme\nsuivante, √† enrichir en fonction de la\nrichesse de l‚Äôenvironnement souhait√©. :\nchannels:\n  - conda-forge\n\ndependencies:\n  - python&gt;=3.10\n  - jupyter\n  - jupytext\n  - matplotlib\n  - nbconvert\n  - numpy\n  - pandas\n  - scipy\n  - seaborn\nLe m√™me fichier sous le format requirements.txt aura\nla forme suivante :\njupyter\njupytext\nmatplotlib\nnbconvert\nnumpy\npandas\nscipy\nseaborn\nSous leur apparente √©quivalence, au-del√† de\nla question du formatage, ces fichiers ont\ndeux diff√©rences principales :\n\nla version minimale de Python est d√©finie dans\nle fichier environment.yml alors qu‚Äôelle ne l‚Äôest\npas dans un fichier requirements.txt. C‚Äôest\nparce que le second installe les d√©pendances dans\nun environnement d√©j√† existant par ailleurs alors\nque le premier peut servir √† cr√©er l‚Äôenvironnement\navec une certaine configuration de Python ;\nle mode d‚Äôinstallation des packages n‚Äôest pas le\nm√™me. Avec un environment.yml on installera des\npackages via conda alors qu‚Äôavec un requirements.txt\non privil√©giera plut√¥t pip4.\n\nDans le cas de l‚Äôenvironnement conda,\nle choix du channel conda-forge vise √† contr√¥ler le d√©p√¥t utilis√© par\nAnaconda.\n\n\n Hint\nLa conda forge est un d√©p√¥t de package alternatif\nau canal par d√©faut d‚ÄôAnaconda qui est maintenu par\nl‚Äô√©quipe de d√©veloppeurs officiels d‚ÄôAnaconda.\nComme cette derni√®re cherche en priorit√© √†\nassurer la stabilit√© de l‚Äô√©cosyst√®me Anaconda,\nles versions de package √©voluent moins vite\nque le rythme voulu par les d√©veloppeurs de\npackages. Pour cette raison, un d√©p√¥t\nalternatif, o√π les mont√©es de version sont\nplus simples parce qu‚Äôelles d√©pendent des\nd√©veloppeurs de chaque package, a √©merg√©.\nIl s‚Äôagit de la conda forge. Lorsqu‚Äôon\nd√©sire utiliser des fonctionalit√©s r√©centes\nde l‚Äô√©cosyst√®me de la data science,\nil est conseill√© de l‚Äôutiliser.\n\n\nNe pas oublier de mettre ce fichier sous contr√¥le de version et de l‚Äôenvoyer\nsur le d√©p√¥t par un push.\n\n\n3.2.2 Cr√©er un environnement reproductible dans Github Actions\nDeux approches sont possibles √† ce niveau, selon le degr√©\nde reproductibilit√© d√©sir√©5:\n\nCr√©er l‚Äôenvironnement via une action existante. L‚Äôaction\nconda-incubator/setup-miniconda@v2\nest un bon point de d√©part.\nCr√©er l‚Äôenvironnement dans une image Docker.\n\nLa deuxi√®me solution permet de contr√¥ler de mani√®re\nbeaucoup plus fine l‚Äôenvironnement dans lequel\nPython s‚Äô√©x√©cutera ainsi que la mani√®re dont\nl‚Äôenvironnement sera cr√©√©6. N√©anmoins, elle n√©cessite\ndes connaissances plus pouss√©es dans la principe\nde la conteneurisation qui peuvent √™tre co√ªteuses\n√† acqu√©rir. Selon l‚Äôambition du projet, notamment\nles r√©utilisation qu‚Äôil d√©sire,\nun data scientist pourra privil√©gier\ntelle ou telle option. Les deux solutions sont pr√©sent√©es\ndans l‚Äôexemple fil-rouge du cours que nous\ndonnons avec Romain Avouac\n(https://ensae-reproductibilite.github.io/website/application/).\n\n\n3.2.3 Tester un notebook myfile.ipynb\nDans cette partie, on va supposer que le notebook √† tester s‚Äôappelle myfile.ipynb\net se trouve √† la racine du d√©p√¥t. Les\nd√©pendances pour l‚Äôex√©cuter sont\nlist√©es dans un fichier requirements.txt.\nLe mod√®le suivant, expliqu√© en dessous, fournit un mod√®le de recette pour\ntester un notebook. Supposons que ce fichier soit pr√©sent\ndans un chemin .github/workflows/test-notebook.yml\n\n\nEnvironnement virtuel\n\nname: Test notebook execution using Github Actions\n\non: [push]\n\njobs:\n  build-linux:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Python 3.10\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.10'\n      - shell: bash\n      run: |\n        python --version\n    - name: Install dependencies\n      run:\n        pip install -r requirements.txt\n        pip install jupyter nbconvert\n    - name: Test jupyter from command line\n      run:\n        jupyter nbconvert --execute --to notebook --inplace myfile.ipynb\n    - uses: actions/upload-artifact@v3\n      with:\n        name: Notebook\n        path: myfile.ipynb\n        retention-days: 5\n\n\n\nEnvironnement conda\n\nname: Test notebook execution using Github Actions\n\non: [push]\n\njobs:\n  build-linux:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Python 3.10\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.10'\n    - name: Add conda to system path\n      run: |\n        # $CONDA is an environment variable pointing to the root of the miniconda directory\n        echo $CONDA/bin &gt;&gt; $GITHUB_PATH\n    - name: Install dependencies\n      run: |\n        conda env update --file environment.yml --name base\n        conda install jupyter nbconvert\n    - name: Test jupyter from command line\n      run:\n        jupyter nbconvert --execute --to notebook --inplace myfile.ipynb\n    - uses: actions/upload-artifact@v3\n      with:\n        name: Notebook\n        path: myfile.ipynb\n        retention-days: 5\n\nDans les deux cas, la d√©marche est la m√™me:\n\non r√©cup√®re les fichiers pr√©sents dans le d√©p√¥t\n(action checkout) ;\non installe Python ;\non installe les d√©pendances pour ex√©cuter le code.\nDans l‚Äôapproche conda, il est √©galement n√©cessaire\nde faire quelques configurations suppl√©mentaires (notamment\najouter conda aux logiciels reconnus par la ligne\nde commande) ;\non teste le notebook en ligne de commande et remplace\ncelui existant, sur la machine temporaire, par la version\nproduite sur cet environnement neutre.\non rend possible le t√©l√©chargement du\nnotebook produit automatiquement pendant 5 jours7. Ceci\nrepose sur les artefacts qui sont un √©l√©ment r√©cup√©r√©\ndes machines temporaires qui n‚Äôexistent plus d√®s que le\ncode a fini d‚Äô√™tre ex√©cut√©.\n\nCes actions sont ex√©cut√©es √† chaque interaction avec\nle d√©p√¥t distant (push), quelle que soit la\nbranche. A partir de ce mod√®le, il est possible de\nraffiner pour, par exemple, automatiquement\nfaire un commit du notebook valid√© et le pusher\nvia le robot Github8",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#les-services-de-mise-√†-disposition-de-github-et-gitlab",
    "href": "content/modern-ds/continuous_integration.html#les-services-de-mise-√†-disposition-de-github-et-gitlab",
    "title": "Int√©gration continue avec Python",
    "section": "4.1 Les services de mise √† disposition de Github et Gitlab",
    "text": "4.1 Les services de mise √† disposition de Github et Gitlab\nGithub et Gitlab, les deux plateformes de partage\nde code, proposent non seulement des services\ngratuits d‚Äôint√©gration continue mais aussi des services\nde mise √† disposition de sites web pleinement int√©gr√©s\naux services de stockage de code.\nCes services, Gitlab Pages et Github Pages, auxquels\non peut associer le service externe Netlify qui r√©pond\nau m√™me principe9 permettent, √† chaque modification\ndu code source d‚Äôun projet, de reconstruire le site web (le livrable)\nqui peut √™tre directement produit √† partir de certains fichiers\n(des slides revealJS par exemple) ou qui\nsert d‚Äôoutput √† l‚Äôint√©gration continue apr√®s compilation\nde fichiers plus complexes (des fichiers quarto par exemple).\nChaque d√©p√¥t sur Github ou Gitlab peut ainsi √™tre associ√©\n√† un URL de d√©ploiement disponible sur internet. A chaque\ncommit sur le d√©p√¥t, le site web qui sert de livrable\nest ainsi mis √† jour. La version d√©ploy√©e √† partir de la\nbranche principale peut ainsi √™tre consid√©r√©e\ncomme la version de production alors que les branches\nsecondaires peuvent servir d‚Äôespace bac √† sable pour\nv√©rifier que des changements dans le code source\nne mettent pas en p√©ril le livrable. Cette m√©thode,\nqui s√©curise la production d‚Äôun livrable sous forme\nde site web, est ainsi particuli√®rement appr√©ciable.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#les-services-externes-disponibles-sans-infrastructure-sp√©ciale",
    "href": "content/modern-ds/continuous_integration.html#les-services-externes-disponibles-sans-infrastructure-sp√©ciale",
    "title": "Int√©gration continue avec Python",
    "section": "4.2 Les services externes disponibles sans infrastructure sp√©ciale",
    "text": "4.2 Les services externes disponibles sans infrastructure sp√©ciale\nPour fonctionner, l‚Äôint√©gration continue\nn√©cessite de mettre en oeuvre des environnements normalis√©s.\nComme √©voqu√© pr√©c√©demment,\nla technologie sous-jacente est celle de la conteneurisation.\nLes images qui servent de point de d√©part au lancement\nd‚Äôun conteneur sont elles-m√™mes mises √† disposition\ndans des espaces communautaires (des registres d‚Äôimages).\nIl en existe plusieurs, les plus connus √©tant\nle dockerhub ou le registry de Gitlab.\nCes registres servent d‚Äôespaces de stockage pour des images,\nqui sont des objets volumineux (potentiellement plusieurs\nGigas) mais aussi d‚Äôespace de mutualisation en permettant\n√† d‚Äôautres de r√©utiliser une image pr√™te √† l‚Äôemploi ou,\nau contraire, √† partir de\nlaquelle on peut ajouter un certain nombre de couches\npour obtenir l‚Äôenvironnement minimal\nde reproductibilit√©.\nIl est possible d‚Äôutiliser certaines actions Github\npr√™te √† l‚Äôemploi pour constuire une image Docker\n√† partir d‚Äôun fichier Dockerfile. Apr√®s avoir\ncr√©e une connexion entre un compte sur la\nplateforme Github et l‚Äôautre sur DockerHub,\nune mise √† disposition automatis√©e d‚Äôun livrable\nsous forme d‚Äôimage Docker est ainsi possible.\nUne image Docker peut offrir une grande vari√©t√©\nd‚Äôoutput. Elle peut servir uniquement √†\nmettre √† disposition un environnement de\nreproductibilit√© mais elle peut servir √† mettre\n√† disposition, pour les personnes ma√Ætrisant\nDocker, des output plus raffin√©s. Par exemple,\ndans le cours que nous donnons √† l‚ÄôENSAE, nous\nmontrons comment docker peut servir √†\nmettre √† disposition √† un utilisateur tiers\nune application minimaliste (construite avec flask)\nqu‚Äôil fera tourner\nsur son ordinateur.\nSi une image Docker peut √™tre tr√®s utile pour la mise\n√† disposition, elle n√©cessite pour sa r√©utilisation\nun niveau avanc√© d‚Äôexpertise en programmation.\nCela ne conviendra pas √† tous les publics. Certains\nne d√©sireront que b√©n√©ficier d‚Äôune application interactive\no√π ils pourrons visualiser certains r√©sultats en fonction\nd‚Äôactions comme des filtres sur des sous-champs ou le choix\nde certaines plages de donn√©es. D‚Äôautres publics seront\nplut√¥t int√©ress√© par la r√©utilisation d‚Äôun programme\nou des r√©sultats d‚Äôun mod√®le sous forme d‚ÄôAPI mais n‚Äôauront\npas l‚Äôinfrastructure interne pour faire tourner le code\nd‚Äôorigine ou une image Docker. C‚Äôest pour r√©pondre √† ces\nlimites qu‚Äôil peut devenir int√©ressant, pour une √©quipe\nde data science de d√©velopper une architecture\nkubernetes interne, si l‚Äôorganisation en a les moyens, ou\nde payer un fournisseur de service, comme AWS, qui permet\ncela.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#kubernetes-le-sommet-de-la-pente-du-d√©ploiement",
    "href": "content/modern-ds/continuous_integration.html#kubernetes-le-sommet-de-la-pente-du-d√©ploiement",
    "title": "Int√©gration continue avec Python",
    "section": "4.3 Kubernetes: le sommet de la pente du d√©ploiement",
    "text": "4.3 Kubernetes: le sommet de la pente du d√©ploiement\nKubernetes est une technologie qui pousse la logique\nde la conteneurisation √† son paroxysme.\nIl s‚Äôagit d‚Äôun syst√®me open-source, d√©velopp√©\npar Google, permettant\nd‚Äôautomatiser le d√©ploiement, la mise √† l‚Äô√©chelle\net la gestion d‚Äôapplications conteneuris√©es.\nGr√¢ce √† Kubernetes, une application, par exemple\nun site web proposant de la r√©activit√©,\npeut √™tre mise √† disposition et reporter les calculs,\nlorsqu‚Äôils sont n√©cessaires, sur\nun serveur. L‚Äôutilisation de Kubernetes dans\nun projet de data science permet ainsi\nd‚Äôanticiper √† la fois l‚Äôinterface d‚Äôune application\nvalorisant un projet mais aussi le fonctionnement\ndu back-office, par exemple en testant la capacit√©\nde charge de cette application. Une introduction\n√† Kubernetes orient√© donn√©e peut √™tre trouv√©e dans\nle cours d√©di√© √† la mise en production\nque nous donnons avec Romain Avouac et dans ce\npost de blog tr√®s bien fait.\nDans les grandes organisations, o√π les r√¥les sont\nplus sp√©cialis√©s que dans les petites structures,\nce ne sont pas n√©cessairement les data scientists\nqui devront ma√Ætriser Kubernetes mais plut√¥t\nles data-architect ou les data-engineer. N√©anmoins,\nles data scientists devront √™tre capable de\ndialoguer avec eux et mettre en oeuvre une m√©thode\nde travail adapt√©e (celle-ci reposera en principe sur\nl‚Äôapproche CI/CD). Dans les petites structures, les\ndata scientist peuvent √™tre en mesure\nde mettre en oeuvre le d√©ploiement en continu. En\nrevanche, il est plus rare, dans ces structures,\no√π les moyens humains de maintenance sont limit√©s,\nque les serveurs sur lesquels fonctionnent Kubernetes\nsoient d√©tenus en propres. En g√©n√©ral, ils sont lou√©s\ndans des services de paiement √† la demande de type\nAWS.",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#informations-additionnelles",
    "href": "content/modern-ds/continuous_integration.html#informations-additionnelles",
    "title": "Int√©gration continue avec Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n7adbea4\n\n\n2023-06-12 11:25:40\n\n\nLino Galiana\n\n\nUpdate CI elements\n\n\n\n\n23cd4a1\n\n\n2022-07-05 10:31:03\n\n\nLino Galiana\n\n\nPr√©cisions suppl√©mentaires dans la partie CI/CD (#246)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/modern-ds/continuous_integration.html#footnotes",
    "href": "content/modern-ds/continuous_integration.html#footnotes",
    "title": "Int√©gration continue avec Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCes services d‚Äôint√©gration continue √©taient utilis√©s lorsque Github\nne proposait pas encore de service int√©gr√©, comme le faisait Gitlab.\nIls sont de moins en moins fr√©quemment utilis√©s.‚Ü©Ô∏é\nPour r√©duire le temps n√©cessaire pour construire le site web, ce\npipeline s‚Äôappuie sur un environnement Docker construit sur un autre d√©p√¥t\ndisponible √©galement sur Github\n.\nCelui-ci part d‚Äôune configuration syst√®me Linux et construit un environnement\nAnaconda √† partir d‚Äôun fichier environment.yml qui liste toutes les d√©pendances\nn√©cessaires pour ex√©cuter les morceaux de code du site web.\nCet environnement Anaconda est construit gr√¢ce √† l‚Äôoutil mamba qui permet\nd‚Äôaller beaucoup plus vite dans la constitution d‚Äôenvironnements que ne le\npermet conda.‚Ü©Ô∏é\nSur la diff√©rence entre les environnements virtuels\net les environnements conda, voir\ncette partie de cours\nplus avanc√© que nous donnons\navec Romain Avouac sur la mise en production\nde projets data science.‚Ü©Ô∏é\nIl est possible d‚Äôinstaller une partie des packages\navec pip en d√©finissant un champ pip dans le\nfichier environment.yml. N√©anmoins, les concepteurs\nd‚ÄôAnaconda recommandent d‚Äô√™tre prudent avec cette m√©thode\nqui pr√©sente certes l‚Äôavantage d‚Äôacc√©l√©rer le temps de\ncr√©ation de l‚Äôenvironnement mais peut cr√©er des\ndifficult√©s avec des librairies n√©cessitant d‚Äôautres\nlangages syst√®me comme le C.‚Ü©Ô∏é\nLe point de vue que nous d√©fendons avec\nRomain Avouac dans notre cours sur la reproductibilit√©\nest qu‚Äôil s‚Äôagit d‚Äôun continuum dans lequel on investit\nplus ou moins en fonction de ses contraintes, de ses\nbesoins, de ses comp√©tences, du temps humain qu‚Äôon\npeut d√©dier √† d√©velopper des output reproductibles\net le temps gagn√© en d√©veloppant une telle approche.\nSelon o√π on se trouve sur ce cursus, en fonction\ndes solutions d√©j√† existantes qu‚Äôon peut trouver\nsur internet, on va plus ou moins raffiner\nnotre int√©gration et nos d√©ploiements\ncontinus.‚Ü©Ô∏é\nIl est recommand√© de ne pas garder la p√©riode de r√©tention\ndes artefacts par d√©faut car celle-ci est assez longue (90 jours).\nLes output pouvant √™tre assez volumineux et expirant rapidement\n(en g√©n√©ral ce qui nous int√©resse est la derni√®re ou l‚Äôavant\nderni√®re version de l‚Äô_output), pour des raisons √©cologiques,\nil est recommand√© de fixer des p√©riodes courtes. Cela peut √™tre\nfait directement dans le fichier configurant l‚Äôint√©gration\ncontinue comme ici ou dans les param√®tres par d√©faut\ndu d√©p√¥t pour que cette r√®gle s‚Äôapplique √† toutes les\nproductions faites par int√©gration continue.‚Ü©Ô∏é\nIl est recommand√© de ne pas garder la p√©riode de r√©tention\ndes artefacts par d√©faut car celle-ci est assez longue (90 jours).\nLes output pouvant √™tre assez volumineux et expirant rapidement\n(en g√©n√©ral ce qui nous int√©resse est la derni√®re ou l‚Äôavant\nderni√®re version de l‚Äô_output), pour des raisons √©cologiques,\nil est recommand√© de fixer des p√©riodes courtes. Cela peut √™tre\nfait directement dans le fichier configurant l‚Äôint√©gration\ncontinue comme ici ou dans les param√®tres par d√©faut\ndu d√©p√¥t pour que cette r√®gle s‚Äôapplique √† toutes les\nproductions faites par int√©gration continue.‚Ü©Ô∏é\nIl s‚Äôagit du service utilis√©, par exemple,\npour ce cours. Netlify est un service de mise √† disposition\nqui offre des fonctionalit√©s plus compl√®tes que celles\npermises par Gitlab Pages et Github Pages. Outre cet\navantage, il est plus facile √† configurer que Github Pages\nqui n√©cessite l‚Äôusage d‚Äôune branche d√©di√©e nomm√©e gh-pages,\nce qui peut\nrebutant.‚Ü©Ô∏é\nIl s‚Äôagit du service utilis√©, par exemple,\npour ce cours. Netlify est un service de mise √† disposition\nqui offre des fonctionalit√©s plus compl√®tes que celles\npermises par Gitlab Pages et Github Pages. Outre cet\navantage, il est plus facile √† configurer que Github Pages\nqui n√©cessite l‚Äôusage d‚Äôune branche d√©di√©e nomm√©e gh-pages,\nce qui peut\nrebutant.‚Ü©Ô∏é",
    "crumbs": [
      "Int√©gration continue avec Python"
    ]
  },
  {
    "objectID": "content/NLP/05_exo_supp.html",
    "href": "content/NLP/05_exo_supp.html",
    "title": "Exercices suppl√©mentaires",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page approfondit certains aspects pr√©sent√©s dans les autres tutoriels.\nIl s‚Äôagit d‚Äôune suite d‚Äôexercice, avec corrections, pour pr√©senter d‚Äôautres aspects du NLP ou pratiquer sur des donn√©es diff√©rentes.",
    "crumbs": [
      "Exercices suppl√©mentaires"
    ]
  },
  {
    "objectID": "content/NLP/05_exo_supp.html#informations-additionnelles",
    "href": "content/NLP/05_exo_supp.html#informations-additionnelles",
    "title": "Exercices suppl√©mentaires",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Exercices suppl√©mentaires"
    ]
  },
  {
    "objectID": "content/NLP/03_lda.html",
    "href": "content/NLP/03_lda.html",
    "title": "Latent Dirichlet Allocation (LDA)",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page approfondit les exercices pr√©sent√©s dans la\nsection pr√©c√©dente.\nOn va ainsi continuer notre exploration de la litt√©rature anglophones :\nLes donn√©es sont disponibles dans la base de\ndonn√©es spooky.csv et peuvent √™tre\nimport√©es par Python en utilisant directement l‚Äôurl\nhttps://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv.\nLe but va √™tre dans un premier temps de regarder dans le d√©tail les termes les plus fr√©quents utilis√©s par les auteurs, et les repr√©senter graphiquement.\nCe notebook est librement inspir√© de :\nLa LDA est une technique d‚Äôestimation bay√©sienne.\nLe cours d‚ÄôAlberto Brietti\nsur le sujet constitue une tr√®s bonne ressource pour comprendre\nles fondements de cette technique.",
    "crumbs": [
      "Latent Dirichlet Allocation (LDA)"
    ]
  },
  {
    "objectID": "content/NLP/03_lda.html#informations-additionnelles",
    "href": "content/NLP/03_lda.html#informations-additionnelles",
    "title": "Latent Dirichlet Allocation (LDA)",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\nd2a2773\n\n\n2023-07-07 15:59:36\n\n\nLino Galiana\n\n\nRetour du wordcloud (#372)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n934149d\n\n\n2023-02-13 11:45:23\n\n\nLino Galiana\n\n\nget_feature_names is deprecated in scikit 1.0.X versions (#351)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\nbb38643\n\n\n2022-06-08 16:59:40\n\n\nLino Galiana\n\n\nR√©pare bug leaflet (#234)\n\n\n\n\n299cff3\n\n\n2022-06-08 13:19:03\n\n\nLino Galiana\n\n\nProbl√®me code JS suite (#233)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\ne94c1c5\n\n\n2021-12-23 21:34:46\n\n\nLino Galiana\n\n\nUn tutoriel sur les pipelines :tada: (#203)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nf4e61ed\n\n\n2020-12-10 15:00:12\n\n\nLino Galiana\n\n\nAjout partie LDA (#88)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Latent Dirichlet Allocation (LDA)"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html",
    "href": "content/NLP/01_intro.html",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette partie est une introduction\n√† la question du nettoyage de donn√©es textuelles.\nIl s‚Äôagit de montrer la logique, quelques exemples\navec Python \net s‚Äôamuser avec comme base d‚Äôexemple un livre formidable üìñ :\nLe Comte de Monte Cristo.\nL‚Äôobjectif est de d√©couvrir les principaux enjeux du nettoyage de donn√©es en NLP\net les enjeux de l‚Äôanalyse de fr√©quence.",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#objectif",
    "href": "content/NLP/01_intro.html#objectif",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "2.1 Objectif",
    "text": "2.1 Objectif\nLe natural language processing (NLP) ou\ntraitement automatis√© du langage (TAL) en Fran√ßais,\nvise √† extraire de l‚Äôinformation de textes √† partir d‚Äôune analyse statistique du contenu.\nCette d√©finition permet d‚Äôinclure de nombreux champs d‚Äôapplications au sein\ndu NLP (traduction, analyse de sentiment, recommandation, surveillance, etc. ).\nCette approche implique de transformer un texte, qui est une information compr√©hensible par un humain, en un nombre, information appropri√©e pour un ordinateur dans le cadre d‚Äôune approche statistique ou algorithmique.\nTransformer une information textuelle en valeurs num√©riques propres √† une analyse statistique n‚Äôest pas une t√¢che √©vidente. Les donn√©es textuelles sont non structur√©es puisque l‚Äôinformation cherch√©e, qui est propre √† chaque analyse, est perdue au milieu d‚Äôune grande masse d‚Äôinformations qui doit, de plus, √™tre interpr√©t√©e dans un certain contexte (un m√™me mot ou une phrase n‚Äôayant pas la m√™me signification selon le contexte).\nSi cette t√¢che n‚Äô√©tait pas assez difficile comme √ßa, on peut ajouter d‚Äôautres difficult√©s propres √† l‚Äôanalyse textuelle car ces donn√©es sont :\n\nbruit√©es : ortographe, fautes de frappe‚Ä¶\nchangeantes : la langue √©volue avec de nouveaux mots, sens‚Ä¶\ncomplexes : structures variables, accords‚Ä¶\nambigu√´s : synonymie, polys√©mie, sens cach√©‚Ä¶\npropres √† chaque langue : il n‚Äôexiste pas de r√®gle de passage unique entre deux langues\nde grande dimension : des combinaisons infinies de s√©quences de mots",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#m√©thode",
    "href": "content/NLP/01_intro.html#m√©thode",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "2.2 M√©thode",
    "text": "2.2 M√©thode\nL‚Äôanalyse textuelle vise √† transformer le texte en donn√©es\nnum√©riques manipulables. Pour cela il est n√©cessaire de se fixer\nune unit√© s√©mantique minimale.\nCette unit√© textuelle peut √™tre le mot ou encore une s√©quence de n\nmots (un n-gramme) ou encore une cha√Æne de caract√®res (e.g.¬†la\nponctuation peut √™tre signifiante). On parle de token.\nOn peut ensuite utiliser diverses techniques (clustering,\nclassification supervis√©e) suivant l‚Äôobjectif poursuivi pour exploiter\nl‚Äôinformation transform√©e. Mais les √©tapes de nettoyage de texte sont indispensables.\nSinon un algorithme sera incapable de d√©tecter une information pertinente dans l‚Äôinfini des possibles.",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#tokenisation",
    "href": "content/NLP/01_intro.html#tokenisation",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "3.1 Tokenisation",
    "text": "3.1 Tokenisation\n\n\n Hint\nLors de la premi√®re utilisation de NLTK, il est n√©cessaire de t√©l√©charger\nquelques √©l√©ments n√©cessaires √† la tokenisation, notamment la ponctuation.\nPour cela, il est recommand√© d‚Äôutiliser la commande suivante :\nimport nltk\n\nnltk.download(\"punkt\")\n\n\n\nimport nltk\n\nnltk.download(\"punkt\")\n\n[nltk_data] Downloading package punkt to /github/home/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n\n\nTrue\n\n\nLa tokenisation consiste √† d√©couper un texte en morceaux. Ces morceaux\npourraient √™tre des phrases, des chapitres, des n-grammes ou des mots. C‚Äôest\ncette derni√®re option que l‚Äôon va choisir, plus simple pour retirer les\nstop words :\n\nimport nltk\n\nwords = nltk.word_tokenize(dumas, language=\"french\")\nwords[1030:1050]\n\n['que',\n 'voulez-vous',\n ',',\n 'monsieur',\n 'edmond',\n ',',\n 'reprit',\n \"l'armateur\",\n 'qui',\n 'paraissait',\n 'se',\n 'consoler',\n 'de',\n 'plus',\n 'en',\n 'plus',\n ',',\n 'nous',\n 'sommes',\n 'tous']\n\n\nOn remarque que les mots avec apostrophes sont li√©s en un seul, ce qui est\npeut-√™tre faux sur le plan de la grammaire mais peu avoir un sens pour une\nanalyse statistique. Il reste des signes de ponctuation qu‚Äôon peut √©liminer\navec la m√©thode isalpha:\n\nwords = [word for word in words if word.isalpha()]\nwords[1030:1050]\n\n['assez',\n 'sombre',\n 'obs√©quieux',\n 'envers',\n 'ses',\n 'sup√©rieurs',\n 'insolent',\n 'envers',\n 'ses',\n 'subordonn√©s',\n 'aussi',\n 'outre',\n 'son',\n 'titre',\n 'comptable',\n 'qui',\n 'est',\n 'toujours',\n 'un',\n 'motif']",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#retirer-les-stop-words",
    "href": "content/NLP/01_intro.html#retirer-les-stop-words",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "3.2 Retirer les stop words",
    "text": "3.2 Retirer les stop words\nLe jeu de donn√©es est maintenant propre. On peut d√©sormais retirer les\nmots qui n‚Äôapportent pas de sens et servent seulement √† faire le\nlien entre deux pr√©positions. On appelle ces mots des\nstop words dans le domaine du NLP.\n\n\n Hint\nLors de la premi√®re utilisation de NLTK, il est n√©cessaire de t√©l√©charger\nles stop words.\nimport nltk\n\nnltk.download(\"stopwords\")\n\n\nComme indiqu√© ci-dessus, pour t√©l√©charger\nle corpus de stop words1, il est\nn√©cessaire d‚Äôex√©cuter la ligne de\ncommande suivante :\n\nimport nltk\n\nnltk.download(\"stopwords\")\n\n[nltk_data] Downloading package stopwords to /github/home/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n\n\nTrue\n\n\n\nfrom nltk.corpus import stopwords\n\nprint(stopwords.words(\"french\"))\n\nstop_words = set(stopwords.words(\"french\"))\n\n\nwords = [w for w in words if not w in stop_words]\nprint(words[1030:1050])\n\n['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'm√™me', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', '√†', 'm', 'n', 's', 't', 'y', '√©t√©', '√©t√©e', '√©t√©es', '√©t√©s', '√©tant', '√©tante', '√©tants', '√©tantes', 'suis', 'es', 'est', 'sommes', '√™tes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', '√©tais', '√©tait', '√©tions', '√©tiez', '√©taient', 'fus', 'fut', 'f√ªmes', 'f√ªtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'f√ªt', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'e√ªmes', 'e√ªtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'e√ªt', 'eussions', 'eussiez', 'eussent']\n['celui', 'dant√®s', 'a', 'd√©pos√©', 'passant', 'comment', 'paquet', 'd√©poser', 'danglars', 'rougit', 'passais', 'devant', 'porte', 'capitaine', 'entrouverte', 'vu', 'remettre', 'paquet', 'cette', 'lettre']\n\n\nCes retraitements commencent √† porter leurs fruits puisque des mots ayant plus\nde sens commencent √† se d√©gager, notamment les noms des personnages\n(Fernand, Merc√©d√®s, Villefort, etc.)\n\nwc = make_wordcloud(\" \".join(words))\n\nfig = plt.figure()\n\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis(\"off\")",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#stemming",
    "href": "content/NLP/01_intro.html#stemming",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "3.3 Stemming",
    "text": "3.3 Stemming\nPour r√©duire la complexit√© d‚Äôun texte, on peut tirer partie de\n‚Äúclasses d‚Äô√©quivalence‚Äù : on peut\nconsid√©rer que diff√©rentes formes d‚Äôun m√™me mot (pluriel,\nsingulier, conjugaison) sont √©quivalentes et les remplacer par une\nm√™me forme dite canonique. Il existe deux approches dans le domaine :\n\nla lemmatisation qui requiert la connaissance des statuts\ngrammaticaux (exemple : chevaux devient cheval)\nla racinisation (stemming) plus fruste mais plus rapide, notamment\nen pr√©sence de fautes d‚Äôorthographes. Dans ce cas, chevaux peut devenir chev\nmais √™tre ainsi confondu avec chevet ou cheveux\n\nLa racinisation est plus simple √† mettre en oeuvre car elle peut s‚Äôappuyer sur\ndes r√®gles simples pour extraire la racine d‚Äôun mot.\nPour r√©duire un mot dans sa forme ‚Äúracine‚Äù, c‚Äôest-√†-dire en s‚Äôabstrayant des\nconjugaisons ou variations comme les pluriels, on applique une m√©thode de\nstemming. Le but du stemming est de regrouper de\nnombreuses variantes d‚Äôun mot comme un seul et m√™me mot.\nPar exemple, une fois que l‚Äôon applique un stemming, ‚Äúchats‚Äù et ‚Äúchat‚Äù\ndeviennent un m√™me mot.\nCette approche a l‚Äôavantage de r√©duire la taille du vocabulaire √† ma√Ætriser\npour l‚Äôordinateur et le mod√©lisateur. Il existe plusieurs algorithmes de\nstemming, notamment le Porter Stemming Algorithm ou le\nSnowball Stemming Algorithm. Nous pouvons utiliser ce dernier en Fran√ßais :\n\nfrom nltk.stem.snowball import SnowballStemmer\n\nstemmer = SnowballStemmer(language=\"french\")\n\nstemmed = [stemmer.stem(word) for word in words]\nprint(stemmed[1030:1050])\n\n['celui', 'dantes', 'a', 'd√©pos', 'pass', 'comment', 'paquet', 'd√©pos', 'danglar', 'roug', 'pass', 'dev', 'port', 'capitain', 'entrouvert', 'vu', 'remettr', 'paquet', 'cet', 'lettr']\n\n\nA ce niveau, les mots commencent √† √™tre moins intelligibles par un humain.\nLa machine prendra le relais, on lui a pr√©par√© le travail.\n\n\n Note\nIl existe aussi le stemmer suivant :\nfrom nltk.stem.snowball import FrenchStemmer\n\nstemmer = FrenchStemmer()",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#informations-additionnelles",
    "href": "content/NLP/01_intro.html#informations-additionnelles",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n4c060a1\n\n\n2023-12-01 17:44:17\n\n\nLino Galiana\n\n\nUpdate book image location\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na1ab3d9\n\n\n2023-11-24 10:57:02\n\n\nLino Galiana\n\n\nReprise des chapitres NLP (#459)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\na9b384e\n\n\n2023-07-18 18:07:16\n\n\nLino Galiana\n\n\nS√©pare les notebooks (#373)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n164fa68\n\n\n2022-11-30 09:13:45\n\n\nLino Galiana\n\n\nTravail partie NLP (#328)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n3299f1d\n\n\n2022-01-08 16:50:11\n\n\nLino Galiana\n\n\nClean NLP notebooks (#215)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n04f8b8f\n\n\n2021-09-08 11:55:35\n\n\nLino Galiana\n\n\necho = FALSE sur la page tuto NLP\n\n\n\n\n048e3dd\n\n\n2021-09-02 18:36:23\n\n\nLino Galiana\n\n\nFix problem with Dumas corpus (#134)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n49e2826\n\n\n2021-05-13 18:11:20\n\n\nLino Galiana\n\n\nCorrige quelques images n‚Äôapparaissant pas (#108)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n48ed9d2\n\n\n2021-05-01 08:58:58\n\n\nLino Galiana\n\n\nlien mort corrig√©\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†3.1: Nuage de mot produit √† partir du Comte de Monte Cristo\nOpenFoodFacts avant nettoyage\nScanner-data avant nettoyage\nOpenFoodFacts apr√®s nettoyage\nScanner-data apr√®s nettoyage",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/NLP/01_intro.html#footnotes",
    "href": "content/NLP/01_intro.html#footnotes",
    "title": "Quelques √©l√©ments pour comprendre les enjeux du NLP",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe corpus de stop words de NLTK\nest relativement limit√©. Il est recommand√©\nde privil√©gier celui de SpaCy, plus\ncomplet, pour √©liminer plus de mots\nvalises.‚Ü©Ô∏é",
    "crumbs": [
      "Quelques √©l√©ments pour comprendre les enjeux du NLP"
    ]
  },
  {
    "objectID": "content/modelisation/7_mlapi.html",
    "href": "content/modelisation/7_mlapi.html",
    "title": "Mettre √† disposition un mod√®le par le biais d‚Äôune API",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre pr√©sente la deuxi√®me application\nd‚Äôune journ√©e de cours que j‚Äôai\ndonn√© √† l‚ÄôUniversit√© Dauphine dans le cadre\ndes PSL Data Week.\nL‚Äôobjectif de ce chapitre est d‚Äôamener √† d√©velopper\nune API du type de celle-ci.\nLe chapitre pr√©c√©dent constituait une introduction √† la cr√©ation\nde pipelines de machine learning.\nCe chapitre va aller plus loin en montrant la d√©marche pour le rendre\ndisponible √† plus grande √©chelle par le biais d‚Äôune API pouvant\n√™tre consomm√©e avec de nouvelles donn√©es. L‚Äôobjectif de celle-ci est\nde ne pas contraindre les r√©utilisateurs d‚Äôun mod√®le\n√† disposer d‚Äôun environnement technique complexe\npour pouvoir utiliser le m√™me mod√®le que celui entra√Æn√© pr√©c√©demment.",
    "crumbs": [
      "Mettre √† disposition un mod√®le par le biais d'une API"
    ]
  },
  {
    "objectID": "content/modelisation/7_mlapi.html#informations-additionnelles",
    "href": "content/modelisation/7_mlapi.html#informations-additionnelles",
    "title": "Mettre √† disposition un mod√®le par le biais d‚Äôune API",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\ne4642ee\n\n\n2023-11-27 17:02:05\n\n\nLino Galiana\n\n\nDeploy ML model as API (#460)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Mettre √† disposition un mod√®le par le biais d'une API"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html",
    "href": "content/modelisation/5_clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nIl peut √©galement √™tre utile d‚Äôinstaller plotnine\npour r√©aliser des graphiques simplement:\n!pip install plotnine",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#principe",
    "href": "content/modelisation/5_clustering.html#principe",
    "title": "Clustering",
    "section": "2.1 Principe",
    "text": "2.1 Principe\nL‚Äôobjectif des k-means est de partitionner l‚Äôespace des observations en trouvant des points (centroids) jouant le r√¥le de centres de gravit√© pour lesquels les observations proches peuvent √™tre regroup√©es dans une classe homog√®ne.\nL‚Äôalgorithme k-means fonctionne par it√©ration, en initialisant les centro√Ødes puis en les mettant √† jour √† chaque\nit√©ration, jusqu‚Äô√† ce que les centro√Ødes se stabilisent. Quelques exemples de clusters issus de la m√©thode k-means :\n\n\n\n Hint\nL‚Äôobjectif des k-means est de trouver une partition des donn√©es \\(S=\\{S_1,...,S_K\\}\\) telle que\n\\[\n\\arg\\min_{S} \\sum_{i=1}^K \\sum_{x \\in S_i} ||x - \\mu_i||^2\n\\]\navec \\(\\mu_i\\) la moyenne des \\(x_i\\) dans l‚Äôensemble de points \\(S_i\\)\n\n\nDans ce chapitre nous allons principalement\nutiliser Scikit. Voici n√©anmoins une proposition\nd‚Äôimports de packages, pour gagner du temps.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nfrom sklearn.cluster import KMeans  # pour kmeans\nimport seaborn as sns  # pour scatterplots\n\n\n\n Exercice 1 : Principe des k-means\n\nImporter les donn√©es et se restreindre aux variables 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Percent of adults with less than a high school diploma, 2015-19', \"Percent of adults with a bachelor's degree or higher, 2015-19\" et bien s√ªr 'per_gop'. Appelez cette base restreinte df2 et enlevez les valeurs manquantes.\nFaire un k-means avec \\(k=4\\).\nCr√©er une variable label dans votes stockant le r√©sultat de la typologie\nAfficher cette typologie sur une carte.\nChoisir les variables Median_Household_Incomme_2019 et Unemployment_rate_2019 et repr√©senter le nuage de points en colorant diff√©remment\nen fonction du label obtenu. Quel est le probl√®me ?\nRefaire les questions 2 √† 5 en standardisant les variables en amont\nRepr√©senter la distribution du vote pour chaque cluster\n\n\n\nLa carte obtenue √† la question 4, qui permet de\nrepr√©senter spatialement nos groupes, est\nla suivante :\n\n\n\n\n\n\n\n\n\nLe nuage de point de la question 5, permettant de repr√©senter\nla relation entre Median_Household_Income_2019\net Unemployment_rate_2019, aura l‚Äôaspect suivant :\n\n\n\n\n\n\n\n\n\nLa classification appara√Æt un peu trop nettement dans cette figure.\nCela sugg√®re que la variable de revenu (Median_Household_Income_2019)\nexplique un peu trop bien le partitionnement produit par notre\nmod√®le pour que ce soit normal. C‚Äôest probablement le fait\nde la variance forte du revenu par rapport aux autres variables.\nDans ce type de sitution, comme cela a √©t√© √©voqu√©, il est\nrecommand√© de standardiser les variables.\n\n\n\n\n\n\n\n\n\nOn obtient ainsi la carte suivante √† la question 5:\n\n\n\n\n\n\n\n\n\nEt le nuage de point de la question 5 pr√©sente un aspect moins\nd√©terministe, ce qui est pr√©f√©rable :\n\n\n\n\n\n\n\n\n\nEnfin, en ce qui concerne la question 6, on obtient cet\nhistogramme des votes pour chaque cluster :\n\n\n/opt/mamba/lib/python3.11/site-packages/plotnine/stats/stat_bin.py:109: PlotnineWarning: 'stat_bin()' using 'bins = 31'. Pick better value with 'binwidth'.\n\n\n\n\n\n\n\n\n\n\n\n Hint\nIl faut noter plusieurs points sur l‚Äôalgorithme impl√©ment√© par d√©faut par scikit-learn, que l‚Äôon peut lire dans\nla documentation :\n\nl‚Äôalgorithme impl√©ment√© par d√©faut est kmeans ++ (cf.¬†param√®tre init). Cela signifie que\nl‚Äôinitialisation des centro√Ødes est faite de mani√®re intelligente pour que les centro√Ødes initiaux soient choisis\nafin de ne pas √™tre trop proches.\nl‚Äôalgorithme va √™tre d√©marr√© avec n_init centro√Ødes diff√©rents et le mod√®le va choisir la meilleure initialisation\nen fonction de l‚Äôinertie du mod√®le, par d√©faut √©gale √† 10.\n\nLe mod√®le renvoie les cluster_centers_, les labels labels_, l‚Äôinertie inertia_ et le nombre d‚Äôit√©rations\nn_iter_.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#choisir-le-nombre-de-clusters",
    "href": "content/modelisation/5_clustering.html#choisir-le-nombre-de-clusters",
    "title": "Clustering",
    "section": "2.2 Choisir le nombre de clusters",
    "text": "2.2 Choisir le nombre de clusters\nLe nombre de clusters est fix√© par le mod√©lisateur.\nIl existe plusieurs fa√ßons de fixer ce nombre :\n\nconnaissance a priori du probl√®me ;\nanalyse d‚Äôune m√©trique sp√©cifique pour d√©finir le nombre de clusters √† choisir ;\netc.\n\nIl y a un arbitrage √† faire\nentre biais et variance :\nun trop grand nombre de clusters implique une variance\nintra-cluster tr√®s faible (sur-apprentissage, m√™me s‚Äôil n‚Äôest jamais possible de d√©terminer\nle vrai type d‚Äôune observation puisqu‚Äôon est en apprentissage non supervis√©).\nSans connaissance a priori du nombre de clusters, on peut recourir √† deux familles de m√©thodes :\n\nLa m√©thode du coude (elbow method) : On prend le point d‚Äôinflexion de la courbe\nde performance du mod√®le. Cela repr√©sente le moment o√π ajouter un cluster\n(complexit√© croissante du mod√®le) n‚Äôapporte que des gains mod√©r√©s dans la\nmod√©lisation des donn√©es.\nLe score de silhouette : On mesure la similarit√© entre un point et les autres points\ndu cluster par rapport aux autres clusters. Plus sp√©cifiquement :\n\n\nSilhouette value is a measure of how similar an object is to its own cluster\n(cohesion) compared to other clusters (separation). The silhouette ranges\nfrom ‚àí1 to +1, where a high value indicates that the object is\nwell matched to its own cluster and poorly matched to neighboring\nclusters. If most objects have a high value, then the clustering\nconfiguration is appropriate. If many points have a low or negative\nvalue, then the clustering configuration may have too many or too few clusters\nSource: Wikipedia\n\nLe score de silhouette d‚Äôune observation est donc √©gal √†\n(m_nearest_cluster - m_intra_cluster)/max( m_nearest_cluster,m_intra_cluster)\no√π m_intra_cluster est la moyenne des distances de l‚Äôobservation aux observations du m√™me cluster\net m_nearest_cluster est la moyenne des distances de l‚Äôobservation aux observations du cluster le plus proche.\nLe package yellowbrick fournit une extension utile √† scikit pour repr√©senter\nfacilement la performance en clustering.\n\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\n\nvisualizer = KElbowVisualizer(model, k=(2, 12))\nvisualizer.fit(df2[xvars])  # Fit the data to the visualizer\n\n\n\n&lt;Axes: title={'center': 'Distortion Score Elbow for KMeans Clustering'}, xlabel='k', ylabel='distortion score'&gt;\n\n\n&lt;Figure size 768x528 with 0 Axes&gt;\n\n\n\nPour la m√©thode du coude, la courbe\nde performance du mod√®le marque un coude l√©ger √† \\(k=4\\). Le mod√®le initial\nsemblait donc appropri√©.\nyellowbrick permet √©galement de repr√©senter des silhouettes mais\nl‚Äôinterpr√©tation est moins ais√©e et le co√ªt computationnel plus √©lev√© :\n\nfrom yellowbrick.cluster import SilhouetteVisualizer\n\nfig, ax = plt.subplots(2, 2, figsize=(15, 8))\nj = 0\nfor i in [3, 4, 6, 10]:\n    j += 1\n    \"\"\"\n    Create KMeans instance for different number of clusters\n    \"\"\"\n    km = KMeans(\n        n_clusters=i, init=\"k-means++\", n_init=10, max_iter=100, random_state=42\n    )\n    q, mod = divmod(j, 2)\n    \"\"\"\n    Create SilhouetteVisualizer instance with KMeans instance\n    Fit the visualizer\n    \"\"\"\n    visualizer = SilhouetteVisualizer(km, colors=\"yellowbrick\", ax=ax[q - 1][mod])\n    ax[q - 1][mod].set_title(\"k = \" + str(i))\n    visualizer.fit(df2[xvars])\n\n\nLe score de silhouette offre une repr√©sentation plus riche que la courbe coud√©e.\nSur ce graphique, les barres verticales en rouge et en pointill√© repr√©sentent le score de silhouette\nglobal pour chaque k choisi. On voit par exemple que pour tous les k repr√©sent√©s ici, le\nscore de silhouette se situe entre 0.5 et 0.6 et varie peu.\nEnsuite, pour un k donn√©, on va avoir la repr√©sentation des scores de silhouette de chaque\nobservation, regroup√©es par cluster.\nPar exemple, pour k = 4, ici, on voit bien quatre couleurs diff√©rentes qui sont les 4 clusters mod√©lis√©s.\nLes ordonn√©es sont toutes les observations clusteris√©es et en abscisses on a le score de silhouette de\nchaque observation. Si au sein d‚Äôun cluster, les observations ont un score de silhouette plus faible que le\nscore de silhouette global (ligne verticale en rouge), cela signifie que les observations du clusters sont\ntrop proches des autres clusters.\nGr√¢ce √† cette repr√©sentation, on peut aussi se rendre compte de la taille relative des clusters. Par exemple,\navec k = 3, on voit qu‚Äôon a deux clusters cons√©quents et un plus ‚Äúpetit‚Äù cluster relativement aux deux autres.\nCela peut nous permettre de choisir des clusters de tailles homog√®nes ou non.\nEnfin, quand le score de silhouette est n√©gatif, cela signifie que la moyenne des distances de l‚Äôobservation\naux observations du cluster le plus proche est inf√©rieure √† la moyenne des distances de l‚Äôobservation aux\nobservations de son cluster. Cela signifie que l‚Äôobservation est mal class√©e.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#autres-m√©thodes-de-clustering",
    "href": "content/modelisation/5_clustering.html#autres-m√©thodes-de-clustering",
    "title": "Clustering",
    "section": "2.3 Autres m√©thodes de clustering",
    "text": "2.3 Autres m√©thodes de clustering\nIl existe de nombreuses autres m√©thodes de clustering. Parmi les plus connues, on peut citer trois exemples en particulier :\n\nLe clustering ascendant hi√©rarchique\nDBSCAN\nles m√©langes de Gaussiennes\n\n\n2.3.1 Clustering Ascendant Hi√©rarchique (CAH)\nQuel est le principe ?\n\nOn commence par calculer la dissimilarit√© entre nos N individus, i.e. leur distance deux √† deux dans l‚Äôespace de nos variables\nPuis on regroupe les deux individus dont le regroupement minimise un crit√®re d‚Äôagr√©gation donn√©, cr√©ant ainsi une classe comprenant ces deux individus.\nOn calcule ensuite la dissimilarit√© entre cette classe et les N-2 autres individus en utilisant le crit√®re d‚Äôagr√©gation.\nPuis on regroupe les deux individus ou classes d‚Äôindividus dont le regroupement minimise le crit√®re d‚Äôagr√©gation.\nOn continue ainsi jusqu‚Äô√† ce que tous les individus soient regroup√©s.\n\nCes regroupements successifs produisent un arbre binaire de classification (dendrogramme), dont la racine correspond √† la classe regroupant l‚Äôensemble des individus. Ce dendrogramme repr√©sente une hi√©rarchie de partitions. On peut alors choisir une partition en tronquant l‚Äôarbre √† un niveau donn√©, le niveau d√©pendant soit des contraintes de l‚Äôutilisateur, soit de crit√®res plus objectifs.\nPlus d‚Äôinformations ici.\n\n\n2.3.2 DBSCAN\nL‚Äôalgorithme DBSCAN est impl√©ment√© dans sklearn.cluster.\nIl peut √™tre utilis√© pour faire de la d√©tection d‚Äôanomalies\nnotamment.\nEn effet, cette m√©thode repose sur le clustering en r√©gions o√π la densit√©\ndes observations est continue, gr√¢ce √† la notion de voisinage selon une certaine distance epsilon.\nPour chaque observation, on va regarder si dans son voisinage selon une distance epsilon, il y a des voisins. S‚Äôil y a au\nmoins min_samples voisins, alors l‚Äôobservation sera une core instance.\nLes observations qui ne sont pas des core instances et qui n‚Äôen ont pas dans leur voisinage selon une distance espilon\nvont √™tre d√©tect√©es comme des anomalies.\n\n\n2.3.3 Les m√©langes de gaussiennes\nEn ce qui concerne la th√©orie, voir le cours Probabilit√©s num√©riques et statistiques computationnelles, M1 Jussieu, V.Lemaire et T.Rebafka\nSe r√©f√©rer notamment aux notebooks pour l‚Äôalgorithme EM pour m√©lange gaussien.\nDans sklearn, les m√©langes gaussiens sont impl√©ment√©s dans sklearn.mixture comme GaussianMixture.\nLes param√®tres importants sont alors le nombre de gaussiennes n_components et le nombre d‚Äôinitiatisations n_init.\nIl est possible de faire de la d√©tection d‚Äôanomalie savec les m√©langes de gaussiennes.\n\n\n Pour aller plus loin\nIl existe de nombreuses autres m√©thodes de clustering :\n\nLocal outlier factor ;\nBayesian gaussian mixture models ;\nD‚Äôautres m√©thodes de clustering hi√©rarchique ;\netc.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#pour-la-visualisation-de-clusters",
    "href": "content/modelisation/5_clustering.html#pour-la-visualisation-de-clusters",
    "title": "Clustering",
    "section": "3.1 Pour la visualisation de clusters",
    "text": "3.1 Pour la visualisation de clusters\nLa m√©thode la plus simple pour visualiser les clusters, peu importe la m√©thode avec laquelles ils ont √©t√© obtenus, serait de repr√©senter chaque individu dans l‚Äôespace √† N dimensions des variables de la table, et colorier chaque individu en fonction de son cluster.\nOn pourrait alors bien diff√©rencier les variables les plus discrimantes et les diff√©rents groupes.\nUn seul probl√®me ici : d√®s que N &gt; 3, nous avons du mal √† repr√©senter le r√©sultat de fa√ßon intelligible‚Ä¶\nC‚Äôest l√† qu‚Äôintervient l‚ÄôAnalyse en Composantes Principales (ACP), qui permet de projeter notre espace √† haute dimension dans un espace de dimension plus petite.\nLa contrainte majeure de la projection est de pouvoir conserver le maximum d‚Äôinformation (mesur√©e par la variance totale de l‚Äôensemble de donn√©es) dans notre nombre r√©duit de dimensions, appel√©es composantes principales.\nEn se limitant √† 2 ou 3 dimensions, on peut ainsi se repr√©senter visuellement les relations entre les observations avec une perte de fiabilit√© minimale.\nOn peut g√©n√©ralement esp√©rer que les clusters d√©termin√©s dans notre espace √† N dimensions se diff√©rencient bien sur notre projection par ACP, et que la composition des composantes principales en fonction des variables initiales permette d‚Äôinterpr√©ter les clusters obtenus.\nEn effet, la combinaison lin√©aire des colonnes donnant naissance √† nos nouveaux axes a souvent un ‚Äúsens‚Äù dans le monde r√©el :\n\nSoit parce qu‚Äôune petite poign√©e de variables repr√©sente la majorit√© de la composante\nSoit parce que la plupart des colonnes intervenant dans la composante somm√©e se combinent bien pour former une interpr√©tation naturelle.\n\nPour mettre en pratique les m√©thodes de cr√©ation de clusters, de la base brute jusqu‚Äô√† la visualisation par ACP, vous pouvez consulter la partie 2 du sujet 3 du funathon 2023, Explorer les habitudes alimentaires de nos compatriotes, sur le SSP Cloud ou sur Github.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#pour-la-r√©duction-de-dimension",
    "href": "content/modelisation/5_clustering.html#pour-la-r√©duction-de-dimension",
    "title": "Clustering",
    "section": "3.2 Pour la r√©duction de dimension",
    "text": "3.2 Pour la r√©duction de dimension\nL‚ÄôACP est √©galement tr√®s utile dans le champ de la r√©duction du nombre de variables pour de nombreux types de mod√©lisations, comme par exemple les r√©gressions lin√©aires.\nIl est ainsi possible de projeter l‚Äôespace des variables explicatives dans un espace de dimension donn√©e plus faible, pour notamment limiter les risques d‚Äôoverfitting.",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/5_clustering.html#informations-additionnelles",
    "href": "content/modelisation/5_clustering.html#informations-additionnelles",
    "title": "Clustering",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n98112c0\n\n\n2023-12-11 09:35:53\n\n\nLino Galiana\n\n\nAjoute une standardisation de variables dans la partie clustering (#471)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf5ad021\n\n\n2022-11-15 17:40:16\n\n\nLino Galiana\n\n\nRelec clustering et lasso (#322)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n7058752\n\n\n2022-03-04 15:35:17\n\n\nLino Galiana\n\n\nRelecture Word2Vec (#216)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\nc6fa115\n\n\n2021-05-12 18:54:53\n\n\nRaphaele Adjerad\n\n\nEl√©ments compl√©mentaires clustering (#107)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n59eadf5\n\n\n2020-11-12 16:41:46\n\n\nLino Galiana\n\n\nCorrection des typos partie ML (#81)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Clustering"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html",
    "href": "content/modelisation/3_regression.html",
    "title": "R√©gression : une introduction",
    "section": "",
    "text": "Le pr√©c√©dent chapitre visait √† proposer un premier mod√®le pour comprendre\nles comt√©s o√π le parti R√©publicain l‚Äôemporte. La variable d‚Äôint√©r√™t √©tant\nbimodale (victoire ou d√©faite), on √©tait dans le cadre d‚Äôun mod√®le de\nclassification.\nMaintenant, sur les m√™mes donn√©es, on va proposer un mod√®le de r√©gression\npour expliquer le score du parti R√©publicain. La variable est donc continue.\nNous ignorerons le fait que ses bornes se trouvent entre 0 et 100 et donc\nqu‚Äôil faudrait, pour √™tre rigoureux, transformer l‚Äô√©chelle afin d‚Äôavoir\ndes donn√©es dans cet intervalle.\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nCe chapitre va utiliser plusieurs packages\nde mod√©lisation, les principaux √©tant Scikit et Statsmodels.\nVoici une suggestion d‚Äôimport pour tous ces packages.\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html#la-r√©gression-lin√©aire",
    "href": "content/modelisation/3_regression.html#la-r√©gression-lin√©aire",
    "title": "R√©gression : une introduction",
    "section": "1.1 La r√©gression lin√©aire",
    "text": "1.1 La r√©gression lin√©aire\nC‚Äôest la mani√®re la plus simple de repr√©senter la loi \\(h_\\theta(X)\\) comme\ncombinaison lin√©aire de variables \\(X\\) et de param√®tres \\(\\theta\\). Dans ce\ncas,\n\\[\n\\mathbb{E}_\\theta(Y|X) = X\\beta\n\\]\nCette relation est encore, sous cette formulation, th√©orique. Il convient\nde l‚Äôestimer √† partir des donn√©es observ√©es \\(y\\). La m√©thode des moindres\ncarr√©s consiste √† minimiser l‚Äôerreur quadratique entre la pr√©diction et\nles donn√©es observ√©es (ce qui explique qu‚Äôon puisse voir la r√©gression comme\nun probl√®me de Machine Learning). En toute g√©n√©ralit√©, la m√©thode des\nmoindres carr√©s consiste √† trouver l‚Äôensemble de param√®tres \\(\\theta\\)\ntel que\n\\[\n\\theta = \\arg \\min_{\\theta \\in \\Theta} \\mathbb{E}\\bigg[ \\left( y - h_\\theta(X) \\right)^2 \\bigg]\n\\]\nCe qui, dans le cadre de la r√©gression lin√©aire, s‚Äôexprime de la mani√®re suivante :\n\\[\n\\beta = \\arg\\min \\mathbb{E}\\bigg[ \\left( y - X\\beta \\right)^2 \\bigg]\n\\]\nLorsqu‚Äôon am√®ne le mod√®le th√©orique (\\(\\mathbb{E}_\\theta(Y|X) = X\\beta\\)) aux donn√©es,\non formalise le mod√®le de la mani√®re suivante :\n\\[\nY = X\\beta + \\epsilon\n\\]\nAvec une certaine distribution du bruit \\(\\epsilon\\) qui d√©pend\ndes hypoth√®ses faites. Par exemple, avec des\n\\(\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)\\) i.i.d., l‚Äôestimateur \\(\\beta\\) obtenu\nest √©quivalent √† celui du Maximum de Vraisemblance dont la th√©orie asymptotique\nnous assure l‚Äôabsence de biais, la variance minimale (borne de Cramer-Rao).\n\n\n Exercice 1a : R√©gression lin√©aire avec scikit\nCet exercice vise √† illustrer la mani√®re d‚Äôeffectuer une r√©gression lin√©aire avec scikit.\nDans ce domaine,\nstatsmodels est nettement plus complet, ce que montrera l‚Äôexercice suivant.\nL‚Äôint√©r√™t principal de faire\ndes r√©gressions avec scikit est de pouvoir comparer les r√©sultats d‚Äôune r√©gression lin√©aire\navec d‚Äôautres mod√®les de r√©gression. Cependant, le chapitre sur les\npipelines montrera qu‚Äôon peut tr√®s bien ins√©rer, avec quelques efforts\nde programmation orient√©e objet, une r√©gression statsmodels dans\nun pipeline scikit.\nL‚Äôobjectif est d‚Äôexpliquer le score des R√©publicains en fonction de quelques\nvariables. Contrairement au chapitre pr√©c√©dent, o√π on se focalisait sur\nun r√©sultat binaire (victoire/d√©faite des R√©publicains), cette\nfois on va chercher √† mod√©liser directement le score des R√©publicains.\n\nA partir de quelques variables, par exemple, ‚ÄòUnemployment_rate_2019‚Äô, ‚ÄòMedian_Household_Income_2019‚Äô, ‚ÄòPercent of adults with less than a high school diploma, 2015-19‚Äô, ‚ÄúPercent of adults with a bachelor‚Äôs degree or higher, 2015-19‚Äù, expliquer la variable per_gop √† l‚Äôaide d‚Äôun √©chantillon d‚Äôentra√Ænement X_train constitu√© au pr√©alable.\n\n‚ö†Ô∏è Utiliser la variable Median_Household_Income_2019\nen log sinon son √©chelle risque d‚Äô√©craser tout effet.\n\nAfficher les valeurs des coefficients, constante comprise\nEvaluer la pertinence du mod√®le avec le \\(R^2\\) et la qualit√© du fit avec le MSE.\nRepr√©senter un nuage de points des valeurs observ√©es\net des erreurs de pr√©diction. Observez-vous\nun probl√®me de sp√©cification ?\n\n\n\nVoici le nuage de points de nos erreurs:\n\n\n\n\n\n\n\n\n\nClairement, le mod√®le pr√©sente un probl√®me de sp√©cification.\n\n\n Exercice 1b : R√©gression lin√©aire avec statsmodels\nCet exercice vise √† illustrer la mani√®re d‚Äôeffectuer une r√©gression lin√©aire avec statsmodels qui offre des fonctionnalit√©s plus proches de celles de R, et moins orient√©es Machine Learning.\nL‚Äôobjectif est toujours d‚Äôexpliquer le score des R√©publicains en fonction de quelques\nvariables.\n\nA partir de quelques variables, par exemple, ‚ÄòUnemployment_rate_2019‚Äô, ‚ÄòMedian_Household_Income_2019‚Äô, ‚ÄòPercent of adults with less than a high school diploma, 2015-19‚Äô, ‚ÄúPercent of adults with a bachelor‚Äôs degree or higher, 2015-19‚Äù, expliquer la variable per_gop.\n‚ö†Ô∏è utiliser la variable Median_Household_Income_2019\nen log sinon son √©chelle risque d‚Äô√©craser tout effet.\nAfficher un tableau de r√©gression.\nEvaluer la pertinence du mod√®le avec le R^2.\nUtiliser l‚ÄôAPI formula pour r√©gresser le score des r√©publicains en fonction de la variable Unemployment_rate_2019, de Unemployment_rate_2019 au carr√© et du log de\nMedian_Household_Income_2019.\n\n\n\n\n\n Hint\nPour sortir une belle table pour un rapport sous \\(\\LaTeX\\), il est possible d‚Äôutiliser\nla m√©thode Summary.as_latex. Pour un rapport HTML, on utilisera Summary.as_html\n\n\n\n\n Note\nLes utilisateurs de R retrouveront des √©l√©ments tr√®s familiers avec statsmodels,\nnotamment la possibilit√© d‚Äôutiliser une formule pour d√©finir une r√©gression.\nLa philosophie de statsmodels est similaire √† celle qui a influ√© sur la construction\ndes packages stats et MASS de R: offrir une librairie g√©n√©raliste, proposant\nune large gamme de mod√®les. N√©anmoins, statsmodels b√©n√©ficie de sa jeunesse\npar rapport aux packages R. Depuis les ann√©es 1990, les packages R visant\n√† proposer des fonctionalit√©s manquantes dans stats et MASS se sont\nmultipli√©s alors que statsmodels, enfant des ann√©es 2010, n‚Äôa eu qu‚Äô√†\nproposer un cadre g√©n√©ral (les generalized estimating equations) pour\nenglober ces mod√®les.",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html#la-r√©gression-logistique",
    "href": "content/modelisation/3_regression.html#la-r√©gression-logistique",
    "title": "R√©gression : une introduction",
    "section": "1.2 La r√©gression logistique",
    "text": "1.2 La r√©gression logistique\nCe mod√®le s‚Äôapplique √† une distribution binaire.\nDans ce cas, \\(\\mathbb{E}_{\\theta} (Y|X) = \\mathbb{P}_{\\theta} (Y = 1|X)\\).\nLa r√©gression logistique peut √™tre vue comme un mod√®le lin√©aire en probabilit√© :\n\\[\n\\text{logit}\\bigg(\\mathbb{E}_{\\theta}(Y|X)\\bigg) = \\text{logit}\\bigg(\\mathbb{P}_{\\theta}(Y = 1|X)\\bigg) = X\\beta\n\\]\nLa fonction \\(\\text{logit}\\) est \\(]0,1[ \\to \\mathbb{R}: p \\mapsto \\log(\\frac{p}{1-p})\\).\nElle permet ainsi de transformer une probabilit√© dans \\(\\mathbb{R}\\).\nSa fonction r√©ciproque est la sigmo√Øde (\\(\\frac{1}{1 + e^{-x}}\\)),\nobjet central du Deep Learning.\nIl convient de noter que les probabilit√©s ne sont pas observ√©es, c‚Äôest l‚Äôoutcome\nbinaire (0/1) qui l‚Äôest. Cela am√®ne √† voir la r√©gression logistique de deux\nmani√®res diff√©rentes :\n\nEn √©conom√©trie, on s‚Äôint√©resse au mod√®le latent qui d√©termine le choix de\nl‚Äôoutcome. Par exemple, si on observe les choix de participer ou non au march√©\ndu travail, on va mod√©liser les facteurs d√©terminant ce choix ;\nEn Machine Learning, le mod√®le latent n‚Äôest n√©cessaire que pour classifier\ndans la bonne cat√©gorie les observations\n\nL‚Äôestimation des param√®tres \\(\\beta\\) peut se faire par maximum de vraisemblance\nou par r√©gression, les deux solutions sont √©quivalentes sous certaines\nhypoth√®ses.\n\n\n Note\nPar d√©faut, scikit applique une r√©gularisation pour p√©naliser les mod√®les\npeu parcimonieux (comportement diff√©rent\nde celui de statsmodels). Ce comportement par d√©faut est √† garder √† l‚Äôesprit\nsi l‚Äôobjectif n‚Äôest pas de faire de la pr√©diction.\n\n\n\n\n Exercice 2a : R√©gression logistique avec scikit\nAvec scikit, en utilisant √©chantillons d‚Äôapprentissage et d‚Äôestimation :\n\nEvaluer l‚Äôeffet des variables d√©j√† utilis√©es sur la probabilit√© des R√©publicains\nde gagner. Affichez la valeur des coefficients.\nD√©duire une matrice de confusion et\nune mesure de qualit√© du mod√®le.\nSupprimer la r√©gularisation gr√¢ce au param√®tre penalty. Quel effet sur les param√®tres estim√©s ?\n\n\n\n\n\n Exercice 2b : R√©gression logistique avec statmodels\nEn utilisant √©chantillons d‚Äôapprentissage et d‚Äôestimation :\n\nEvaluer l‚Äôeffet des variables d√©j√† utilis√©es sur la probabilit√© des R√©publicains\nde gagner.\nFaire un test de ratio de vraisemblance concernant l‚Äôinclusion de la variable de (log)-revenu.\n\n\n\n\n\n Hint\nLa statistique du test est :\n\\[\nLR = -2\\log\\bigg(\\frac{\\mathcal{L}_{\\theta}}{\\mathcal{L}_{\\theta_0}}\\bigg) = -2(\\mathcal{l}_{\\theta} - \\mathcal{l}_{\\theta_0})\n\\]",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/3_regression.html#informations-additionnelles",
    "href": "content/modelisation/3_regression.html#informations-additionnelles",
    "title": "R√©gression : une introduction",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n58c7128\n\n\n2023-06-11 21:32:03\n\n\nLino Galiana\n\n\nchange na subset (#362)\n\n\n\n\n2ed4aa7\n\n\n2022-11-07 15:57:31\n\n\nLino Galiana\n\n\nReprise 2e partie ML + R√®gle probl√®me mathjax (#319)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n59eadf5\n\n\n2020-11-12 16:41:46\n\n\nLino Galiana\n\n\nCorrection des typos partie ML (#81)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "R√©gression : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html",
    "href": "content/modelisation/1_modelevaluation.html",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nNous allons ici voir des m√©thodes g√©n√©rales permettant de s‚Äôassurer que le mod√®le\nde Machine Learning mobilis√© est de qualit√©. Ce chapitre ne pr√©sente pas\nd‚Äôexercice ou de code, il est l√† pour pr√©senter certains concepts\nque nous appliquerons dans les prochains chapitres.",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#classification",
    "href": "content/modelisation/1_modelevaluation.html#classification",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "4.1 Classification",
    "text": "4.1 Classification\nLa plupart des crit√®res de performance sont construits √† partir de la matrice de confusion :\n\n\n\nImage emprunt√©e √† https://www.lebigdata.fr/confusion-matrix-definition\n\n\nA partir des 4 coins de cette matrice, il existe plusieurs mesure de performance\n\n\n\n\n\n\n\n\nCrit√®re\nMesure\nCalcul\n\n\n\n\nAccuracy\nTaux de classification correcte\nDiagonale du tableau : \\(\\frac{TP+TN}{TP+FP+FN+FP}\\)\n\n\nPrecision\nTaux de vrais positifs\nLigne des pr√©dictions positives : \\(\\frac{TP}{TP+FP}\\)\n\n\nRecall (rappel)\nCapacit√© √† identifier les labels positifs\nColonne des pr√©dictions positives : \\(\\frac{TP}{TP+FN}\\)\n\n\nF1 Score\nMesure synth√©tique (moyenne harmonique) de la pr√©cision et du rappel\n\\(2 \\frac{precision \\times recall}{precision + recall}\\)\n\n\n\nEn pr√©sence de classes d√©sequilibr√©es, la\nF-mesure est plus pertinente pour √©valuer les\nperformances mais l‚Äôapprentissage restera\nmauvais si l‚Äôalgorithme est sensible √† ce\nprobl√®me. Notamment, si on d√©sire avoir une performance √©quivalente sur les classes minoritaires, il faut g√©n√©ralement les sur-pond√©rer (ou faire un √©chantillonnage stratifi√©) lors de la constitution de l‚Äô√©chantillon d‚Äôobservation.\nIl est possible de construire des mod√®les √† partir des probabilit√©s pr√©dites d‚Äôappartenir √† la classe d‚Äôint√©r√™t. Pour cela, on fixe un seuil \\(c\\) tel que\n\\[\n\\mathbb{P}(y_i=1|X_i) &gt; c \\Rightarrow \\widehat{y}_i = 1\n\\]\nPlus on augmente \\(c\\), plus on est s√©lectif sur le crit√®re d‚Äôappartenance √† la classe.\nLa pr√©cision, i.e.¬†le taux de vrais positifs parmi les pr√©dictions positives, augmente. Mais on augmente le nombre de positifs manqu√©s (autrement dit on diminue le rappel). Pour chaque valeur de \\(c\\) correspond une matrice de confusion et donc des mesures de performances.\nLa courbe ROC est un outil classique pour repr√©senter en un graphique l‚Äôensemble de ces\ninformations en faisant varier \\(c\\) de 0 √† 1:\n\nL‚Äôaire sous la courbe (AUC) permet d‚Äô√©valuer quantitativement le meilleur mod√®le au\nsens de ce crit√®re. L‚ÄôAUC repr√©sente la probabilit√© que le mod√®le soit capable de distinguer entre la classe positive et n√©gative.",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#r√©gression",
    "href": "content/modelisation/1_modelevaluation.html#r√©gression",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "4.2 R√©gression",
    "text": "4.2 R√©gression\nEn Machine Learning, les indicateurs de performance en r√©gression sont les suivants :\n\n\n\n\n\n\n\nNom\nFormule\n\n\n\n\nMean squared error\n\\(MSE = \\mathbb{E}\\left[(y - h_\\theta(X))^2\\right]\\)\n\n\nRoot Mean squared error\n\\(RMSE = \\sqrt{\\mathbb{E}\\left[(y - h_\\theta(X))^2\\right]}\\)\n\n\nMean Absolute Error\n\\(MAE = \\mathbb{E} \\bigg[ \\lvert y - h_\\theta(X) \\rvert \\bigg]\\)\n\n\nMean Absolute Percentage Error\n\\(MAE = \\mathbb{E}\\left[ \\left\\lvert \\frac{y - h_\\theta(X)}{y} \\right\\rvert \\right]\\)\n\n\n\nL‚Äô√©conom√®tre se focalise moins sur la qualit√© de la pr√©diction et utilisera\nd‚Äôautres crit√®res pour √©valuer la qualit√© d‚Äôun mod√®le (certains, comme le BIC, sont\n√† regarder aussi dans une optique Machine Learning) : \\(R^2\\), \\(BIC\\),\n\\(AIC\\), log-likelihood, etc.",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#informations-additionnelles",
    "href": "content/modelisation/1_modelevaluation.html#informations-additionnelles",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\nfd3c955\n\n\n2023-11-18 14:22:38\n\n\nLino Galiana\n\n\nFormattage des chapitres scikit (#453)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n6264438\n\n\n2022-06-29 14:53:05\n\n\nLino Galiana\n\n\nRetire typo math (#243)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nImage emprunt√©e √† https://www.lebigdata.fr/confusion-matrix-definition",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/1_modelevaluation.html#footnotes",
    "href": "content/modelisation/1_modelevaluation.html#footnotes",
    "title": "Evaluer la qualit√© d‚Äôun mod√®le",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCette formule permet de bien comprendre la th√©orie statistique asymptotique, notamment le th√©or√®me de Cramer-Rao. Dans la classe des estimateurs sans biais, c‚Äôest-√†-dire dont le premier terme est nul, trouver l‚Äôestimateur √† variance minimale revient √† trouver l‚Äôestimateur qui minimise \\(\\mathbb{E}\\bigg[(y - h_\\theta(X))^2 \\bigg]\\). C‚Äôest la d√©finition m√™me de la r√©gression, ce qui, quand on fait des hypoth√®ses suppl√©mentaires sur le mod√®le statistique, explique le th√©or√®me de Cramer-Rao.‚Ü©Ô∏é",
    "crumbs": [
      "Evaluer la qualit√© d'un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/index.html",
    "href": "content/modelisation/index.html",
    "title": "Partie 3: mod√©liser",
    "section": "",
    "text": "Les data scientists sont souvent associ√©s √† la mise en oeuvre\nde mod√®les complexes d‚Äôintelligence artificielle.\nLe succ√®s m√©diatique de ce type d‚Äôoutils, notamment ChatGPT,\nn‚Äôy est pas pour rien. Cependant, la mod√©lisation n‚Äôest souvent\nqu‚Äôune\nphase du travail du data scientist, un peu comme la visualisation.\nD‚Äôailleurs, dans certaines organisations o√π la division des t√¢ches\nest plus pouss√©e, les data engineers sont au moins aussi\nimpliqu√©s dans la phase de mod√©lisation que les data scientists.\nC‚Äôest souvent un p√©ch√© de jeunesse de penser qu‚Äôon peut r√©sumer\nle travail du data scientist exclusivement √† la phase de mod√©lisation.\nCette derni√®re d√©pend tr√®s fortement de la qualit√© du travail de\nnettoyage et structuration des donn√©es mis en oeuvre en amont. La\nmise en oeuvre de mod√®les complexes, qui s‚Äôaccomodent de donn√©es\npeu structur√©es, est gourmande en ressources et co√ªteuse. Ce ne sont\ndonc qu‚Äôun nombre limit√© d‚Äôacteurs qui peuvent entra√Æner, ex nihilo,\ndes grands mod√®les de langage1, capables de d√©penser au moins 300 000 dollars\ndans l‚Äôentra√Ænement d‚Äôun mod√®le, avant m√™me toute phase d‚Äôinf√©rence (Izsak, Berchansky, and Levy 2021).\nCes besoins computationnels pour entra√Æner de grands mod√®les de langage sont\nd‚Äôailleurs assez gourmands en √©nergie, ce qui peut amener √†\ndes empreintes carbones non n√©gligeables (Strubell, Ganesh, and McCallum 2019; Arcep 2019).\nHeureusement, il est possible de mettre en oeuvre des mod√©lisations plus\nl√©g√®res (celles que nous pr√©senterons dans les prochains chapitres)\nou de r√©utiliser des mod√®les pr√©-entra√Æn√©s pour les sp√©cialiser\nsur un nouveau jeu de donn√©es (principe du fine tuning2).\nEn fait, pour √™tre plus pertinent que des approches plus parcimonieuses,\nles techniques de deep learning, notamment\nles r√©seaux de neurones, n√©cessitent soit des volumes de donn√©es tr√®s\nimportants (des millions voire dizaine de millions d‚Äôobservations) soit\ndes donn√©es √† la structure complexe comme le langage naturel ou les images.\nDans de nombreux cas, des mod√®les plus simples comme les techniques d‚Äôapprentissage\nautomatique (machine learning) suffisent largement.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#la-mod√©lisation-une-approche-au-coeur-de-la-statistique",
    "href": "content/modelisation/index.html#la-mod√©lisation-une-approche-au-coeur-de-la-statistique",
    "title": "Partie 3: mod√©liser",
    "section": "La mod√©lisation, une approche au coeur de la statistique",
    "text": "La mod√©lisation, une approche au coeur de la statistique\nUn mod√®le statistique\nest une repr√©sentation simplifi√©e et structur√©e d‚Äôun ph√©nom√®ne r√©el,\nconstruite √† partir d‚Äôobservations regroup√©es dans un ensemble partiel de donn√©es.\nUn mod√®le vise √† capturer les relations et les sch√©mas sous-jacents au sein de ces donn√©es, permettant ainsi de formuler des hypoth√®ses, d‚Äôeffectuer des pr√©dictions et d‚Äôextrapoler des conclusions au-del√†\nde l‚Äôensemble de donn√©es mesur√©es.\nLes mod√®les statistiques fournissent ainsi un cadre analytique pour explorer, comprendre et interpr√©ter les informations contenues dans les donn√©es.\nDans le domaine de la recherche √©conomique, ils peuvent servir √†\nassocier certains param√®tres structurants des mod√®les de comportement\n√©conomique √† des valeurs quantitatives.\nLes mod√®les statistiques, comme les mod√®les √©conomiques\npr√©sentent n√©anmoins toujours une part d‚Äôirr√©alisme (Friedman 1953; Salmon 2010)\net accepter de mani√®re trop litt√©rale les implications d‚Äôun mod√®le, m√™me s‚Äôil\na de bonnes performances pr√©dictives, peut √™tre dangereux et relever d‚Äôun biais\nscientiste. On s√©lectionne plut√¥t le moins mauvais mod√®le\nque le vrai processus g√©n√©rateur des donn√©es.\nRepr√©senter la r√©alit√© sous la forme d‚Äôun mod√®le est un principe √† la\nbase de la statistique comme discipline scientifique et ayant des\napplications dans de nombreux champs disciplinaires : √©conomie,\nsociologie, g√©ographique, biologie, physique, etc.\nSelon les disciplines, le nom donn√© peut varier mais on retrouve\nr√©guli√®rement la m√™me approche scientifique : le mod√©lisateur\nconstruit des relations entre plusieurs variables th√©oriques\nayant des contreparties empiriques afin d‚Äôexpliquer tel ou tel\nprocessus.\nDans l‚Äôenseignement de l‚ÄôENSAE ce type d‚Äôapproche empirique se retrouve\nprincipalement dans deux types d‚Äôapproches : le machine learning et\nl‚Äô√©conom√©trie. La diff√©rence est certes\ns√©mantique - la r√©gression lin√©aire peut √™tre consid√©r√©e comme une\ntechnique de machine learning ou d‚Äô√©conom√©trie - mais elle est\n√©galement conceptuelle :\n\nDans le domaine du machine learning,\nla structure impos√©e par le mod√©lisateur est minimale et ce sont plut√¥t\nles algorithmes qui, sur des crit√®res de performance statistique, vont\namener √† choisir une loi math√©matique qui correspond au mieux aux donn√©es ;\nEn √©conom√©trie,\nles hypoth√®ses de structure des lois sont plus fortes (m√™me dans un cadre semi ou non-param√©trique) et sont plus souvent impos√©es\npar le mod√©lisateur.\n\nDans cette partie du cours, nous allons principalement\nparler de machine learning car il s‚Äôagit d‚Äôune perspective\nplus op√©rationnelle que l‚Äô√©conom√©trie qui est plus directement associ√©e\n√† des concepts statistiques complexes comme la th√©orie asymptotique.\nL‚Äôadoption du machine learning dans la litt√©rature √©conomique a √©t√© longue\ncar la structuration des donn√©es est souvent le\npendant empirique d‚Äôhypoth√®ses th√©oriques sur le comportement des acteurs ou des march√©s (Athey and Imbens 2019; Charpentier, Flachaire, and Ly 2018).\nPour caricaturer, l‚Äô√©conom√©trie s‚Äôattacherait √† comprendre la causalit√© de certaines variables sur une autre.\nCela implique que ce qui int√©resse l‚Äô√©conom√®tre\nest principalement de l‚Äôestimation des param√®tres (et l‚Äôincertitude\nsur l‚Äôestimation de ceux-ci) qui permettent de quantifier l‚Äôeffet d‚Äôune\nvariation d‚Äôune variable sur une autre.\nToujours pour caricaturer,\nle machine learning se focaliserait\nsur un simple objectif pr√©dictif en exploitant les relations de corr√©lations entre les variables.\nDans cette perspective, l‚Äôimportant n‚Äôest pas la causalit√© mais le fait qu‚Äôune variation\nde \\(x\\)% d‚Äôune variable permette d‚Äôanticiper un changement de \\(\\beta x\\) de la variable\nd‚Äôint√©r√™t ; peu importe la raison.\nMullainathan and Spiess (2017) ont ainsi, pour simplifier, propos√© la diff√©rence fondamentale qui\nsuit : l‚Äô√©conom√©trie se pr√©occupe de \\(\\widehat{\\beta}\\) l√† o√π le machine learning\nse focalise sur \\(\\widehat{y}\\). Les deux sont bien s√ªr reli√©s dans un cadre\nlin√©aire mais cette diff√©rence d‚Äôapproche a des implications importantes\nsur la structure des mod√®les √©tudi√©s, notamment leur parcimonie3.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#quelques-d√©finitions",
    "href": "content/modelisation/index.html#quelques-d√©finitions",
    "title": "Partie 3: mod√©liser",
    "section": "Quelques d√©finitions",
    "text": "Quelques d√©finitions\nDans cette partie du cours nous allons employer un certain nombre\nde termes devenus familiers aux praticiens du machine learning\nmais qui m√©ritent d‚Äô√™tre explicit√©s.\n\nMachine learning et deep learning\nJusqu‚Äô√† pr√©sent nous avons beaucoup utilis√©, sans le d√©finir, le\nconcept de machine learning, dont la traduction fran√ßaise est\napprentissage automatique mais le terme anglo-saxon est suffisamment\nutilis√© pour √™tre consid√©r√© comme standard.\nLe machine learning est un ensemble de techniques algorithmiques\nqui permettent aux ordinateurs d‚Äôapprendre, √† partir d‚Äôexemples, √† ajuster un mod√®le\nsans avoir explicitement d√©fini celui-ci. A partir d‚Äôalgorithmes it√©ratifs et d‚Äôune\nm√©trique de performance, des r√®gles de classification ou de pr√©diction vont permettre\nde mettre en relation des caract√©ristiques (features) avec une variable d‚Äôint√©r√™t (label)4.\nDe nombreux algorithmes existent et se distinguent sur la mani√®re d‚Äôintroduire une structure plus ou\nmoins formelle dans la relation entre les variables observ√©es. Nous n‚Äôallons voir que quelques-uns\nde ces algorithmes : support vector machine (SVM), r√©gression logistique, arbres de d√©cision, for√™ts\nal√©atoires, etc. Simples √† mettre en oeuvre gr√¢ce √† la librairie Scikit-Learn, ils permettront\nd√©j√† de comprendre la d√©marche originale du machine learning que vous pourrez approfondir\nult√©rieurement.\nAu sein de la grande famille des algorithmes de machine learning, tendent de plus √† plus √† devenir\nautonomes les techniques de r√©seaux de neurone. Les techniques qui s‚Äôappuient sur les r√©seaux de neurones sont regroup√©s\ndans une famille qu‚Äôon\nappelle deep learning (apprentissage profond en Fran√ßais).\nCes r√©seaux sont inspir√©s du fonctionnement du cerveau humain et sont compos√©s de nombreuses couches de neurones interconnect√©s.\nLa structure canonique bien connue est illustr√©e dans la Figure¬†1.\nLe deep learning est int√©ressant pour cr√©er des mod√®les capables d‚Äôapprendre de repr√©sentations\nde donn√©es complexes et abstraites √† partir de donn√©es brutes,\nce qui √©vite parfois la complexe t√¢che de d√©finir manuellement des caract√©ristiques sp√©cifiques √† cibler.\nLes champs de l‚Äôanalyse d‚Äôimage (computer vision) ou du traitement du langage naturel sont les principaux\ncas d‚Äôapplication de ces m√©thodes.\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Exemple de structure d‚Äôun r√©seau de neurones (source: lebigdata.fr)\n\n\n\nNous n‚Äôallons pas vraiment parler dans ce cours de deep learning car ces mod√®les, pour √™tre pertinents, n√©cessitent\nsoit des donn√©es structur√©es d‚Äôun volume important (ce qui est rarement disponible\nen open data) soit des cas d‚Äôusage sp√©cifiques, plus avanc√©s que ne le permet\nun cours d‚Äôintroduction. L‚Äôorganisation HuggingFace, cr√©atrice de la\nplateforme du m√™me nom facilitant la r√©utilisation de mod√®les de deep learning\npropose d‚Äôexcellents cours sur le sujet, notamment sur\nle traitement du langage naturel (NLP).\nNous ferons du traitement du langage naturel dans la prochaine partie de ce cours mais\nde mani√®re plus modeste en revenant sur les concepts n√©cessaires avant de mettre en oeuvre\nune mod√©lisation sophistiqu√©e du langage.\n\n\nApprentissage supervis√© ou non supervis√©\nUne ligne de clivage importante entre les m√©thodes √† mettre en oeuvre est le fait d‚Äôobserver ou non\nle label (la variable \\(y\\)) qu‚Äôon d√©sire mod√©liser.\nPrenons par exemple un site de commerce qui dispose\nd‚Äôinformations sur ses clients comme l‚Äô√¢ge, le sexe, le lieu de r√©sidence.\nCe site peut d√©sirer\nexploiter cette information de diff√©rentes mani√®res pour mod√©liser le comportement d‚Äôachat.\nEn premier lieu, ce site peut d√©sirer\nanticiper le volume d‚Äôachat d‚Äôun nouveau client ayant certaines caract√©ristiques.\nDans ce cas, il est possible d‚Äôutiliser les montants d√©pens√©s par d‚Äôautres clients en fonction de leurs\ncaract√©ristiques. L‚Äôinformation pour notre nouveau client n‚Äôest pas mesur√©e mais elle peut s‚Äôappuyer\nsur un ensemble d‚Äôobservations de la m√™me variable.\nMais il est tout √† fait possible d‚Äôentra√Æner un mod√®le sur un label qu‚Äôon ne mesure pas, en supposant\nqu‚Äôil fasse sens. Par exemple notre site de commerce peut d√©sirer d√©terminer, en fonction des\ncaract√©ristiques de notre nouveau client et de sa client√®le existante, s‚Äôil appartient √† tel ou\ntel groupe de consommateurs : les d√©pensiers, les √©conomes‚Ä¶ Bien s√ªr on ne sait jamais a priori\n√† quel groupe appartient un consommateur mais le rapprochement entre consommateurs ayant un comportement\nsimilaire permettra de donner du sens √† cette cat√©gorie. Dans ce cas, l‚Äôalgorithme apprendra √† reconna√Ætre\nquelles caract√©ristiques sont structurantes dans la constitution de groupes au comportement similaire et\npermettra d‚Äôassocier tout nouveau consommateur √† un groupe.\nCes deux exemples illustrent l‚Äôapproche diff√©rente selon qu‚Äôon essaie de construire des mod√®les\nsur un label observ√© ou non. Cela constitue m√™me l‚Äôune des dualit√©s fondamentale dans les\ntechniques de machine learning :\n\nApprentissage supervis√© : la valeur cible est connue et peut √™tre utilis√©e pour √©valuer la qualit√© d‚Äôun mod√®le ;\nApprentissage non supervis√© : la valeur cible est inconnue et ce sont des crit√®res statistiques qui vont amener\n√† s√©lectionner la structure de donn√©es la plus plausible.\n\nCette partie du cours illustrera ces deux approches de mani√®re diff√©rente √† partir du m√™me\njeu de donn√©es, les r√©sultats des √©lections am√©ricaines.\nDans le cas de l‚Äôapprentissage supervis√©, nous chercherons √† mod√©liser directement\nle r√©sultat des candidats aux √©lections (soit le score soit le gagnant). Dans\nle cas de l‚Äôapprentissage non supervis√©, nous essaierons de regrouper les\nterritoires au comportement de vote similaire en fonction de facteurs\nsocio-d√©mographiques.\n\n\n0.0.1 Classification et r√©gression\nUne deuxi√®me dualit√© fondamentale qui est d√©terminante dans le choix de la m√©thode de machine learning\n√† mettre en oeuvre est la nature du label. S‚Äôagit-il d‚Äôune variable continue ou d‚Äôune variable\ndiscr√®te, c‚Äôest-√†-dire prenant un nombre limit√© de modalit√©s ?\nCette diff√©rence de nature entre les donn√©es am√®ne √† distinguer deux types d‚Äôapproche :\n\nDans les probl√©matiques de classification, o√π notre label \\(y\\) a un nombre fini de valeurs5,\non cherche √† pr√©dire dans quelle classe ou √† quel groupe il est possible de rattacher nos donn√©es.\nPar exemple, si vous prenez du caf√© le matin, faites-vous partie du groupe des personnes ronchons au lever ?\nLes m√©triques de performance utilisent g√©n√©ralement la proportion de bonnes ou mauvaises classifications\npour estimer la qualit√© d‚Äôun mod√®le.\nDans les probl√©matiques de r√©gression, o√π notre label est une grandeur num√©rique, on\ncherche √† pr√©dire directement la valeur de notre variable dans le mod√®le. Par exemple, si vous\navez tel ou tel √¢ge, quel est votre d√©pense quotidienne en fast food. Les m√©triques\nde performance sont g√©n√©ralement des moyennes plus ou moins sophistiqu√©es d‚Äô√©carts entre\nla pr√©diction et la valeur observ√©e.\n\nEn r√©sum√©, l‚Äôaide-m√©moire suivante, issue de l‚Äôaide de Scikit-Learn, peut d√©j√† donner de premiers enseignements sur les diff√©rentes familles de mod√®les :\n\n\n\n\n\n\n\n\n\n\nFigure¬†2: Une cheatsheet des algorithmes disponibles dans Scikit-Learn",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#donn√©es",
    "href": "content/modelisation/index.html#donn√©es",
    "title": "Partie 3: mod√©liser",
    "section": "Donn√©es",
    "text": "Donn√©es\nLa plupart des exemples de cette partie s‚Äôappuient sur les r√©sultats des\n√©lections US 2020 au niveau comt√©s. Plusieurs bases sont utilis√©es pour\ncela :\n\nLes donn√©es √©lectorales sont une reconstruction √† partir des donn√©es du MIT election lab\npropos√©es sur Github par tonmcg\nou directement disponibles sur le site du MIT Election Lab\nLes donn√©es socio√©conomiques (population, donn√©es de revenu et de pauvret√©,\ntaux de ch√¥mage, variables d‚Äô√©ducation) proviennent de l‚ÄôUSDA (source)\nLe shapefile vient des donn√©es du Census Bureau. Le fichier peut\n√™tre t√©l√©charg√© directement depuis cet url:\nhttps://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_county_20m.zip\n\nLe code pour construire une base unique √† partir de ces sources diverses\nest disponible ci-dessous :\n\n\n\nimport urllib\nimport urllib.request\nimport os\nimport zipfile\nfrom urllib.request import Request, urlopen\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\n\ndef download_url(url, save_path):\n    with urllib.request.urlopen(url) as dl_file:\n        with open(save_path, 'wb') as out_file:\n            out_file.write(dl_file.read())\n\n\ndef create_votes_dataframes():\n    \n  Path(\"data\").mkdir(parents=True, exist_ok=True)\n  \n  \n  download_url(\"https://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_county_20m.zip\", \"data/shapefile\")\n  with zipfile.ZipFile(\"data/shapefile\", 'r') as zip_ref:\n      zip_ref.extractall(\"data/counties\")\n  \n  shp = gpd.read_file(\"data/counties/cb_2019_us_county_20m.shp\")\n  shp = shp[~shp[\"STATEFP\"].isin([\"02\", \"69\", \"66\", \"78\", \"60\", \"72\", \"15\"])]\n  shp\n  \n  df_election = pd.read_csv(\"https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2020_US_County_Level_Presidential_Results.csv\")\n  df_election.head(2)\n  population = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/PopulationEstimates.xls?v=290.4\", header = 2).rename(columns = {\"FIPStxt\": \"FIPS\"})\n  education = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/Education.xls?v=290.4\", header = 4).rename(columns = {\"FIPS Code\": \"FIPS\", \"Area name\": \"Area_Name\"})\n  unemployment = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/Unemployment.xls?v=290.4\", header = 4).rename(columns = {\"fips_txt\": \"FIPS\", \"area_name\": \"Area_Name\", \"Stabr\": \"State\"})\n  income = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/PovertyEstimates.xls?v=290.4\", header = 4).rename(columns = {\"FIPStxt\": \"FIPS\", \"Stabr\": \"State\", \"Area_name\": \"Area_Name\"})\n  \n  \n  dfs = [df.set_index(['FIPS', 'State']) for df in [population, education, unemployment, income]]\n  data_county = pd.concat(dfs, axis=1)\n  df_election = df_election.merge(data_county.reset_index(), left_on = \"county_fips\", right_on = \"FIPS\")\n  df_election['county_fips'] = df_election['county_fips'].astype(str).str.lstrip('0')\n  shp['FIPS'] = shp['GEOID'].astype(str).str.lstrip('0')\n  votes = shp.merge(df_election, left_on = \"FIPS\", right_on = \"county_fips\")\n  \n  req = Request('https://dataverse.harvard.edu/api/access/datafile/3641280?gbrecs=false')\n  req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n  content = urlopen(req)\n  df_historical = pd.read_csv(content, sep = \"\\t\")\n  #df_historical = pd.read_csv('https://dataverse.harvard.edu/api/access/datafile/3641280?gbrecs=false', sep = \"\\t\")\n  \n  df_historical = df_historical.dropna(subset = [\"FIPS\"])\n  df_historical[\"FIPS\"] = df_historical[\"FIPS\"].astype(int)\n  df_historical['share'] = df_historical['candidatevotes']/df_historical['totalvotes']\n  df_historical = df_historical[[\"year\", \"FIPS\", \"party\", \"candidatevotes\", \"share\"]]\n  df_historical['party'] = df_historical['party'].fillna(\"other\")\n  \n  df_historical_wide = df_historical.pivot_table(index = \"FIPS\", values=['candidatevotes',\"share\"], columns = [\"year\",\"party\"])\n  df_historical_wide.columns = [\"_\".join(map(str, s)) for s in df_historical_wide.columns.values]\n  df_historical_wide = df_historical_wide.reset_index()\n  df_historical_wide['FIPS'] = df_historical_wide['FIPS'].astype(str).str.lstrip('0')\n  votes['FIPS'] = votes['GEOID'].astype(str).str.lstrip('0')\n  votes = votes.merge(df_historical_wide, on = \"FIPS\")\n  votes[\"winner\"] =  np.where(votes['votes_gop'] &gt; votes['votes_dem'], 'republican', 'democrats') \n\n  return votes\n\n\n\nCette partie n‚Äôest absolument pas exhaustive. Elle constitue un point\nd‚Äôentr√©e dans le sujet √† partir d‚Äôune s√©rie d‚Äôexemples sur un fil rouge.\nDe nombreux mod√®les plus approfondis, que ce soit en √©conom√©trie ou en machine learning\nm√©riteraient d‚Äô√™tre √©voqu√©s. Pour les personnes d√©sirant en savoir plus sur les\nmod√®les √©conom√©triques, qui seront moins √©voqu√©s que ceux de machine learning,\nje recommande la lecture de Turrell and contributors (2021).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#r√©f√©rences",
    "href": "content/modelisation/index.html#r√©f√©rences",
    "title": "Partie 3: mod√©liser",
    "section": "0.1 R√©f√©rences",
    "text": "0.1 R√©f√©rences\n\n\nArcep. 2019. ‚ÄúL‚Äôempreinte Carbone Du Num√©rique.‚Äù Rapport de l‚ÄôArcep.\n\n\nAthey, Susan, and Guido W Imbens. 2019. ‚ÄúMachine Learning Methods That Economists Should Know About.‚Äù Annual Review of Economics 11: 685‚Äì725.\n\n\nCharpentier, Arthur, Emmanuel Flachaire, and Antoine Ly. 2018. ‚ÄúEconometrics and Machine Learning.‚Äù Economie Et Statistique 505 (1): 147‚Äì69.\n\n\nFriedman, Milton. 1953. ‚ÄúThe Methodology of Positive Economics.‚Äù In Essays in Positive Economics. Chicago: The University of Chicago Press.\n\n\nIzsak, Peter, Moshe Berchansky, and Omer Levy. 2021. ‚ÄúHow to Train BERT with an Academic Budget.‚Äù https://arxiv.org/abs/2104.07705.\n\n\nMullainathan, Sendhil, and Jann Spiess. 2017. ‚ÄúMachine Learning: An Applied Econometric Approach.‚Äù Journal of Economic Perspectives 31 (2): 87‚Äì106. https://doi.org/10.1257/jep.31.2.87.\n\n\nSalmon, Pierre. 2010. ‚ÄúLe Probl√®me Du r√©alisme Des Hypoth√®ses En √©conomie Politique.‚Äù\n\n\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum. 2019. ‚ÄúEnergy and Policy Considerations for Deep Learning in NLP.‚Äù https://arxiv.org/abs/1906.02243.\n\n\nTurrell, Arthur, and contributors. 2021. Coding for Economists. Online. https://aeturrell.github.io/coding-for-economists.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#informations-additionnelles",
    "href": "content/modelisation/index.html#informations-additionnelles",
    "title": "Partie 3: mod√©liser",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\ne52cc8a\n\n\n2023-12-19 21:40:01\n\n\nLino Galiana\n\n\nAutomatic black formatting for python examples (#477)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec (antuki?) partie modelisation (#183)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†1: Exemple de structure d‚Äôun r√©seau de neurones (source: lebigdata.fr)\nFigure¬†2: Une cheatsheet des algorithmes disponibles dans Scikit-Learn",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modelisation/index.html#footnotes",
    "href": "content/modelisation/index.html#footnotes",
    "title": "Partie 3: mod√©liser",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNous reviendrons de mani√®re √©pisodique\nsur ce principe des grands mod√®les de langage\nqui sont devenus, en quelques ann√©es,\ncentraux dans l‚Äô√©cosyst√®me de la data science mais sont √©galement\namen√©s √† devenir des outils grands publics, √† la mani√®re de ChatGPT.‚Ü©Ô∏é\nHistoriquement, cette approche n√©cessitait de disposer de donn√©es labellis√©es donc d‚Äô√™tre\ndans un cadre d‚Äôapprentissage supervis√©.\nCependant, avec l‚Äôutilisation de plus en plus\nfr√©quente de donn√©es non structur√©es, sans labels, a √©merg√© une approche int√©ressante\nqui ne n√©cessite plus forc√©ment de labelliser des volumes importants de donn√©es en amont :\nle reinforcement learning with human feedback.\nCet article d‚ÄôAndrew Ng revient sur la mani√®re dont cette approche\nchange la donne dans l‚Äôentra√Ænement ou le r√©-entra√Ænement de mod√®les.‚Ü©Ô∏é\nComme nous l‚Äôavons dit, cette diff√©renciation est un peu\ncaricaturale, notamment maintenant que les √©conomistes sont\nplus familiaris√©s aux concepts d‚Äô√©valuation de performance\npr√©dictive sur des sous-ensembles d‚Äôapprentissage et de test (mais\nl‚Äô√©volution est lente).\nLa recherche en machine learning est quant √† elle tr√®s dynamique\nsur la question de l‚Äôexplicabilit√© et de l‚Äôinterpr√©tabilit√©\ndes mod√®les de machine learning, notamment autour du concept\nde valeurs de Shapley.‚Ü©Ô∏é\nPour faire l‚Äôanalogie avec le cadre √©conom√©trique, les features sont les variables explicatives\nou covariates (la matrice \\(X\\)) et le label est la variable expliqu√©e (\\(y\\)).‚Ü©Ô∏é\nNous allons nous focaliser sur le cas binaire, le plus simple. Dans ce type de probl√®mes,\nla variable \\(y\\) a deux modalit√©s : gagnant-perdant, 0-1, oui-non‚Ä¶ N√©anmoins il existe de\nnombreux cas d‚Äôusage o√π la variable dispose de plus de modalit√©s, par exemples des\nscores de satisfaction entre 0 et 5 ou A et D. La mise en oeuvre de mod√®les est plus\ncomplexe mais l‚Äôid√©e g√©n√©rale est souvent de se ramener √† un ensemble de mod√®les dichotomiques\npour pouvoir appliquer des m√©triques simples et stables.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html",
    "href": "content/visualisation/matplotlib.html",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLa pratique de la visualisation se fera, dans ce cours, en r√©pliquant des graphiques qu‚Äôon peut trouver sur\nla page de l‚Äôopen data de la ville de Paris\nici.\nCe TP vise √† initier :\nNous verrons par la suite la mani√®re de construire des cartes facilement avec\ndes formats √©quivalents.\nSi vous √™tes int√©ress√©s par R ,\nune version tr√®s proche de ce TP est\ndisponible dans ce cours d‚Äôintroduction √† R pour l‚ÄôENS.\nNote\n√ätre capable de construire des visualisations de donn√©es\nint√©ressantes est une comp√©tence n√©cessaire √† tout\ndata scientist ou chercheur. Pour am√©liorer\nla qualit√© de ces visualisations, il est recommand√©\nde suivre certains conseils donn√©s par des sp√©cialistes\nde la dataviz sur la s√©miologie graphique.\nLes bonnes visualisations de donn√©es, comme celles du New York Times,\nreposent certes sur des outils adapt√©s (des librairies JavaScript)\nmais aussi sur certaines r√®gles de repr√©sentation qui permettent\nde comprendre en quelques secondes le message d‚Äôune visualisation.\nCe post de blog\nest une ressource qu‚Äôil est utile de consulter r√©guli√®rement.\nCe post de blog d‚ÄôAlbert Rapp montre bien comment construire graduellement une bonne visualisation\nde donn√©es.",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#contexte",
    "href": "content/visualisation/matplotlib.html#contexte",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "6.1 Contexte",
    "text": "6.1 Contexte\nL‚Äôinconv√©nient des figures avec ggplot est que celles-ci ne permettent\npas d‚Äôinteraction avec le lecteur. Toute l‚Äôinformation doit donc √™tre\ncontenue dans la figure ce qui peut la rendre difficile √† lire.\nSi la figure est bien faite, avec diff√©rents niveaux d‚Äôinformation, cela\npeut bien fonctionner.\nIl est n√©anmoins plus simple, gr√¢ce aux technologies web, de proposer des\nvisualisations √† plusieurs niveaux. Un premier niveau d‚Äôinformation, celui du\ncoup d‚Äôoeil, peut suffire √† assimiler les principaux messages de la\nvisualisation. Ensuite, un comportement plus volontaire de recherche\nd‚Äôinformation secondaire peut permettre d‚Äôen savoir plus. Les visualisations\nr√©actives, qui sont maintenant la norme dans le monde de la dataviz,\npermettent ce type d‚Äôapproche : le lecteur d‚Äôune visualisation peut passer\nsa souris √† la recherche d‚Äôinformation compl√©mentaire (par exemple les\nvaleurs exactes) ou cliquer pour faire appara√Ætre des informations compl√©mentaires\nsur la visualisation ou autour.\nCes visualisations reposent sur le m√™me triptyque que l‚Äôensemble de l‚Äô√©cosyst√®me\nweb : HTML, CSS et JavaScript. Les utilisateurs de Python\nne vont jamais manipuler directement ces langages, qui demandent une\ncertaine expertise, mais vont utiliser des librairies au niveau de R qui g√©n√®reront automatiquement tout le code HTML, CSS et JavaScript\npermettant de cr√©er la figure.",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#la-librairie-plotly",
    "href": "content/visualisation/matplotlib.html#la-librairie-plotly",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "6.2 La librairie Plotly",
    "text": "6.2 La librairie Plotly\nLe package Plotly est une surcouche √† la librairie Javascript\nPlotly.js qui permet de cr√©er et manipuler des objets graphiques de mani√®re\ntr√®s flexible afin de produire des objets r√©actifs sans avoir √† recourir\n√† Javascript.\nLe point d‚Äôentr√©e recommand√© est le module plotly.express\n(documentation ici) qui offre une arborescence\nriche mais n√©anmoins intuitive pour construire des graphiques\n(objets plotly.graph_objects.Figure) pouvant √™tre modifi√©s a posteriori\nsi besoin (par exemple pour customiser les axes).\n\n\n Visualiser les figures produites par Plotly\nDans un notebook Jupyter classique, les lignes suivantes de code permettent\nd‚Äôafficher le r√©sultat d‚Äôune commande Plotly sous un bloc de code :\nfrom plotly.offline import init_notebook_mode\n\ninit_notebook_mode(connected=True)\nPour JupyterLab, l‚Äôextension jupyterlab-plotly s‚Äôav√®re n√©cessaire:\n!jupyter labextension install jupyterlab-plotly",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#r√©plication-de-lexemple-pr√©c√©dent-avec-plotly",
    "href": "content/visualisation/matplotlib.html#r√©plication-de-lexemple-pr√©c√©dent-avec-plotly",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "6.3 R√©plication de l‚Äôexemple pr√©c√©dent avec Plotly",
    "text": "6.3 R√©plication de l‚Äôexemple pr√©c√©dent avec Plotly\nLes repr√©sentations fig√©es comme celles ci-dessus\nsont approri√©es pour des rapports ou articles.\nN√©anmoins\nLes modules suivants seront n√©cessaires pour construire des graphiques\navec plotly:\n\n\n Exercice 7: un barplot avec Plotly\nL‚Äôobjectif est de reconstuire le premier diagramme en barre rouge avec Plotly.\n\nR√©alisez le graphique en utilisant la fonction ad√©quate avec plotly.express et‚Ä¶\n\nNe pas prendre le\nth√®me par d√©faut mais un √† fond blanc, pour avoir un r√©sultat ressemblant\n√† celui propos√© sur le site de l‚Äôopen-data.\nPour la couleur rouge,\nvous pouvez utiliser l‚Äôargument color_discrete_sequence.\nNe pas oublier de nommer les axes\nPensez √† la couleur du texte de l‚Äôaxe inf√©rieur\n\nTester un autre th√®me, √† fond sombre. Pour les couleurs, faire un\ngroupe stockant les trois plus fortes valeurs puis les autres.\n\n\n\nLa premi√®re question permet de construire le graphique suivant :\n\n\n                                                \n\n\nAlors qu‚Äôavec le th√®me sombre (question 2), on obtient :\n\n\n                                                \n\n\nCette repr√©sentation montre bien le caract√®re sp√©cial de l‚Äôann√©e 2020. Pour\nrappeller au lecteur distrait la nature particuli√®re de la p√©riode, marqu√©e\npar un premier confinement qu‚Äôon voit bien dans les donn√©es, on pourrait,\navec l‚Äôaide de la documentation,\najouter deux barres verticales pour marquer les dates de d√©but et\nde fin de cette p√©riode.",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#informations-additionnelles",
    "href": "content/visualisation/matplotlib.html#informations-additionnelles",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\ncf91965\n\n\n2023-12-02 13:15:18\n\n\nlinogaliana\n\n\nhref in dataviz chapter\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\ndf01f01\n\n\n2023-10-10 15:55:04\n\n\nLino Galiana\n\n\nMenus automatis√©s (#432)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n057dae1\n\n\n2023-09-20 16:28:46\n\n\nLino Galiana\n\n\nChapitre visualisation (#406)\n\n\n\n\n1d0780c\n\n\n2023-09-18 14:49:59\n\n\nLino Galiana\n\n\nProbl√®me rendu chapitre matplotlib (#405)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n8df7cb2\n\n\n2023-07-20 17:16:03\n\n\nlinogaliana\n\n\nChange link\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nf2e8922\n\n\n2023-06-12 14:54:20\n\n\nLino Galiana\n\n\nRemove spoiler shortcode (#364)\n\n\n\n\n2dc82e7\n\n\n2022-10-18 22:46:47\n\n\nLino Galiana\n\n\nRelec Kim (visualisation + API) (#302)\n\n\n\n\n03babc6\n\n\n2022-10-03 16:53:47\n\n\nLino Galiana\n\n\nParler des r√®gles de la dataviz (#291)\n\n\n\n\n89c10c3\n\n\n2022-08-25 08:30:22\n\n\nLino Galiana\n\n\nAdaptation du shortcode spoiler en notebook (#257)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n2812ef4\n\n\n2022-07-07 15:58:58\n\n\nLino Galiana\n\n\nPetite viz sympa des prenoms (#242)\n\n\n\n\na4e2426\n\n\n2022-06-16 19:34:18\n\n\nLino Galiana\n\n\nImprove style (#238)\n\n\n\n\n02ed1e2\n\n\n2022-06-09 19:06:05\n\n\nLino Galiana\n\n\nR√®gle probl√®me plotly (#235)\n\n\n\n\n299cff3\n\n\n2022-06-08 13:19:03\n\n\nLino Galiana\n\n\nProbl√®me code JS suite (#233)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\n66a5276\n\n\n2021-11-23 16:13:20\n\n\nLino Galiana\n\n\nRelecture partie visualisation (#181)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\na5b7c99\n\n\n2020-10-05 15:07:09\n\n\nLino Galiana\n\n\nDonne lien vers donn√©es compteurs\n\n\n\n\n18be8f4\n\n\n2020-10-01 17:08:53\n\n\nLino Galiana\n\n\nInt√©gration de box inspir√©es du th√®me pydata sphinx (#58)\n\n\n\n\n5ac3cbe\n\n\n2020-09-28 18:59:24\n\n\nLino Galiana\n\n\nContinue la partie graphiques (#54)\n\n\n\n\n94f39ec\n\n\n2020-09-24 21:25:32\n\n\nLino Galiana\n\n\nquelques mots sur vizu\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/matplotlib.html#footnotes",
    "href": "content/visualisation/matplotlib.html#footnotes",
    "title": "De beaux graphiques avec python : mise en pratique",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJ‚Äôai retir√© la couleur sur l‚Äôaxe des ordonn√©es qui, je trouve,\napporte peu √† la figure voire d√©grade la compr√©hension du message.‚Ü©Ô∏é",
    "crumbs": [
      "De beaux graphiques avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html",
    "href": "content/manipulation/04b_regex_TP.html",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#classes-de-caract√®res",
    "href": "content/manipulation/04b_regex_TP.html#classes-de-caract√®res",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "2.1 Classes de caract√®res",
    "text": "2.1 Classes de caract√®res\nLors d‚Äôune recherche, on s‚Äôint√©resse aux caract√®res et souvent aux classes de caract√®res : on cherche un chiffre, une lettre, un caract√®re dans un ensemble pr√©cis ou un caract√®re qui n‚Äôappartient pas √† un ensemble pr√©cis. Certains ensembles sont pr√©d√©finis, d‚Äôautres doivent √™tre d√©finis √† l‚Äôaide de crochets.\nPour d√©finir un ensemble de caract√®res, il faut √©crire cet ensemble entre crochets. Par exemple, [0123456789] d√©signe un chiffre. Comme c‚Äôest une s√©quence de caract√®res cons√©cutifs, on peut r√©sumer cette √©criture en [0-9].\nPar\nexemple, si on d√©sire trouver tous les pattern qui commencent par un c suivi\nd‚Äôun h puis d‚Äôune voyelle (a, e, i, o, u), on peut essayer\ncette expression r√©guli√®re.\n\nre.findall(\"[c][h][aeiou]\", \"chat, chien, veau, vache, ch√®vre\")\n\n['cha', 'chi', 'che']\n\n\nIl serait plus pratique d‚Äôutiliser Pandas dans ce cas pour isoler les\nlignes qui r√©pondent √† la condition logique (en ajoutant les accents\nqui ne sont pas compris sinon):\n\nimport pandas as pd\n\ntxt = pd.Series(\"chat, chien, veau, vache, ch√®vre\".split(\", \"))\ntxt.str.match(\"ch[ae√©√®iou]\")\n\n0     True\n1     True\n2    False\n3    False\n4     True\ndtype: bool\n\n\nCependant, l‚Äôusage ci-dessus des classes de caract√®res\nn‚Äôest pas le plus fr√©quent.\nOn privil√©gie celles-ci pour identifier des\npattern complexe plut√¥t qu‚Äôune suite de caract√®res litt√©raux.\nLes tableaux d‚Äôaide m√©moire illustrent une partie des\nclasses de caract√®res les plus fr√©quentes\n([:digit:] ou \\d‚Ä¶)",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#quantifieurs",
    "href": "content/manipulation/04b_regex_TP.html#quantifieurs",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "2.2 Quantifieurs",
    "text": "2.2 Quantifieurs\nNous avons rencontr√© les quantifieurs avec notre premi√®re expression\nr√©guli√®re. Ceux-ci contr√¥lent le nombre de fois\nqu‚Äôun pattern est rencontr√©.\nLes plus fr√©quents sont:\n\n? : 0 ou 1 match ;\n+ : 1 ou plus de matches ;\n* : 0 or more matches.\n\nPar exemple, colou?r permettra de matcher √† la fois l‚Äô√©criture am√©ricaine et anglaise\n\nre.findall(\"colou?r\", \"Did you write color or colour?\")\n\n['color', 'colour']\n\n\nCes quantifiers peuvent bien s√ªr √™tre associ√©s √†\nd‚Äôautres types de caract√®res, notamment les classes de caract√®res.\nCela peut √™tre extr√®mement pratique.\nPar exemple, \\d+ permettra de capturer un ou plusieurs chiffres, \\s?\npermettra d‚Äôajouter en option un espace,\n[\\w]{6,8} un mot entre six et huit lettres qu‚Äôon √©crira‚Ä¶\nIl est aussi possible de d√©finir le nombre de r√©p√©titions\navec {}:\n\n{n} matche exactement n fois ;\n{n,} matche au moins n fois ;\n{n,m} matche entre n et m fois.\n\nCependant, la r√©p√©tition des termes\nne s‚Äôapplique par d√©faut qu‚Äôau dernier\ncaract√®re pr√©c√©dent le quantifier.\nOn peut s‚Äôen convaincre avec l‚Äôexemple ci-dessus:\n\nprint(re.match(\"toc{4}\", \"toctoctoctoc\"))\n\nNone\n\n\nPour pallier ce probl√®me, il existe les parenth√®ses.\nLe principe est le m√™me qu‚Äôavec les r√®gles num√©riques:\nles parenth√®ses permettent d‚Äôintroduire une hi√©rarchie.\nPour reprendre l‚Äôexemple pr√©c√©dent, on obtient\nbien le r√©sultat attendu gr√¢ce aux parenth√®ses:\n\nprint(re.match(\"(toc){4}\", \"toctoctoctoc\"))\nprint(re.match(\"(toc){5}\", \"toctoctoctoc\"))\nprint(re.match(\"(toc){2,4}\", \"toctoctoctoc\"))\n\n&lt;re.Match object; span=(0, 12), match='toctoctoctoc'&gt;\nNone\n&lt;re.Match object; span=(0, 12), match='toctoctoctoc'&gt;\n\n\n\n\n Note\nL‚Äôalgorithme des expressions r√©guli√®res essaye toujours de faire correspondre le plus grand morceau √† l‚Äôexpression r√©guli√®re.\nPar exemple, soit une chaine de caract√®re HTML:\n\ns = \"&lt;h1&gt;Super titre HTML&lt;/h1&gt;\"\n\nL‚Äôexpression r√©guli√®re re.findall(\"&lt;.*&gt;\", s) correspond, potentiellement,\n√† trois morceaux :\n\n&lt;h1&gt;\n&lt;/h1&gt;\n&lt;h1&gt;Super titre HTML&lt;/h1&gt;\n\nC‚Äôest ce dernier qui sera choisi, car le plus grand. Pour\ns√©lectionner le plus petit,\nil faudra √©crire les multiplicateurs comme ceci : *?, +?.\nEn voici quelques exemples:\n\ns = \"&lt;h1&gt;Super titre HTML&lt;/h1&gt;\\n&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;\"\nprint(re.findall(\"&lt;.*&gt;\", s))\nprint(re.findall(\"&lt;p&gt;.*&lt;/p&gt;\", s))\nprint(re.findall(\"&lt;p&gt;.*?&lt;/p&gt;\", s))\nprint(re.compile(\"&lt;.*?&gt;\").findall(s))\n\n['&lt;h1&gt;Super titre HTML&lt;/h1&gt;', '&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;']\n['&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;']\n['&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; est un langage tr√®s flexible&lt;/p&gt;']\n['&lt;h1&gt;', '&lt;/h1&gt;', '&lt;p&gt;', '&lt;code&gt;', '&lt;/code&gt;', '&lt;/p&gt;']",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#aide-m√©moire",
    "href": "content/manipulation/04b_regex_TP.html#aide-m√©moire",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "2.3 Aide-m√©moire",
    "text": "2.3 Aide-m√©moire\nLe tableau ci-dessous peut servir d‚Äôaide-m√©moire\nsur les regex:\n\n\n\n\n\n\n\nExpression r√©guli√®re\nSignification\n\n\n\n\n\"^\"\nD√©but de la cha√Æne de caract√®res\n\n\n\"$\"\nFin de la cha√Æne de caract√®res\n\n\n\"\\\\.\"\nUn point\n\n\n\".\"\nN‚Äôimporte quel caract√®re\n\n\n\".+\"\nN‚Äôimporte quelle suite de caract√®res non vide\n\n\n\".*\"\nN‚Äôimporte quelle suite de caract√®res, √©ventuellement vi\n\n\n\"[:alnum:]\"\nUn caract√®re alphanum√©rique\n\n\n\"[:alpha:]\"\nUne lettre\n\n\n\"[:digit:]\"\nUn chiffre\n\n\n\"[:lower:]\"\nUne lettre minuscule\n\n\n\"[:punct:]\"\nUn signe de ponctuation\n\n\n\"[:space:]\"\nun espace\n\n\n\"[:upper:]\"\nUne lettre majuscule\n\n\n\"[[:alnum:]]+\"\nUne suite d‚Äôau moins un caract√®re alphanum√©rique\n\n\n\"[[:alpha:]]+\"\nUne suite d‚Äôau moins une lettre\n\n\n\"[[:digit:]]+\"\nUne suite d‚Äôau moins un chiffre\n\n\n\"[[:lower:]]+\"\nUne suite d‚Äôau moins une lettre minuscule\n\n\n\"[[:punct:]]+\"\nUne suite d‚Äôau moins un signe de ponctuation\n\n\n\"[[:space:]]+\"\nUne suite d‚Äôau moins un espace\n\n\n\"[[:upper:]]+\"\nUne suite d‚Äôau moins une lettre majuscule\n\n\n\"[[:alnum:]]*\"\nUne suite de caract√®res alphanum√©riques, √©ventuellement vide\n\n\n\"[[:alpha:]]*\"\nUne suite de lettres, √©ventuellement vide\n\n\n\"[[:digit:]]*\"\nUne suite de chiffres, √©ventuellement vide\n\n\n\"[[:lower:]]*\"\nUne suite de lettres minuscules, √©ventuellement vide\n\n\n\"[[:upper:]]*\"\nUne suite de lettres majuscules, √©ventuellement vide\n\n\n\"[[:punct:]]*\"\nUne suite de signes de ponctuation, √©ventuellement vide\n\n\n\"[^[:alpha:]]+\"\nUne suite d‚Äôau moins un caract√®re autre qu‚Äôune lettre\n\n\n\"[^[:digit:]]+\"\nUne suite d‚Äôau moins un caract√®re autre qu‚Äôun chiffre\n\n\n\"\\|\"\nL‚Äôune des expressions x ou y est pr√©sente\n\n\n[abyz]\nUn seul des caract√®res sp√©cifi√©s\n\n\n[abyz]+\nUn ou plusieurs des caract√®res sp√©cifi√©s (√©ventuellement r√©p√©t√©s)\n\n\n[^abyz]\nAucun des caract√®res sp√©cifi√©s n‚Äôest pr√©sent\n\n\n\nCertaines classes de caract√®res b√©n√©ficient d‚Äôune syntaxe plus l√©g√®re car\nelles sont tr√®s fr√©quentes. Parmi-celles:\n\n\n\n\n\n\n\nExpression r√©guli√®re\nSignification\n\n\n\n\n\\d\nN‚Äôimporte quel chiffre\n\n\n\\D\nN‚Äôimporte quel caract√®re qui n‚Äôest pas un caract√®re\n\n\n\\s\nN‚Äôimporte quel espace (espace, tabulation, retour √† la ligne)\n\n\n\\S\nN‚Äôimporte quel caract√®re qui n‚Äôest pas un espace\n\n\n\\w\nN‚Äôimporte quel type de mot (lettres et nombres)\n\n\n\\W\nN‚Äôimporte quel ensemble qui n‚Äôest pas un mot (lettres et nombres)\n\n\n\nDans l‚Äôexercice suivant, vous allez pouvoir mettre en pratique\nles exemples pr√©c√©dents sur une regex un peu plus compl√®te.\nCet exercice ne n√©cessite pas la connaissance des subtilit√©s\ndu package re, vous n‚Äôaurez besoin que de re.findall.\nCet exercice utilisera la chaine de caract√®re suivante :\n\ns = \"\"\"date 0 : 14/9/2000\ndate 1 : 20/04/1971     date 2 : 14/09/1913     date 3 : 2/3/1978\ndate 4 : 1/7/1986     date 5 : 7/3/47     date 6 : 15/10/1914\ndate 7 : 08/03/1941     date 8 : 8/1/1980     date 9 : 30/6/1976\"\"\"\ns\n\n'date 0 : 14/9/2000\\ndate 1 : 20/04/1971     date 2 : 14/09/1913     date 3 : 2/3/1978\\ndate 4 : 1/7/1986     date 5 : 7/3/47     date 6 : 15/10/1914\\ndate 7 : 08/03/1941     date 8 : 8/1/1980     date 9 : 30/6/1976'\n\n\n\n\n Exercice 1\n\nOn va d‚Äôabord s‚Äôoccuper d‚Äôextraire le jour de naissance.\n\nLe premier chiffre du jour est 0, 1, 2 ou 3. Traduire cela sous la forme d‚Äôune s√©quence [X-X]\nLe deuxi√®me chiffre du jour est lui entre 0 et 9. Traduire cela sous la s√©quence ad√©quate\nRemarquez que le premier jour est facultatif. Intercaler entre les deux classes de caract√®re ad√©quate\nle quantifieur qui convient\nAjouter le slash √† la suite du motif\nTester avec re.findall. Vous devriez obtenir beaucoup plus d‚Äô√©chos que n√©cessaire.\nC‚Äôest normal, √† ce stade la\nregex n‚Äôest pas encore finalis√©e\n\nSuivre la m√™me logique pour les mois en notant que les mois du calendrier gr√©gorien ne d√©passent\njamais la premi√®re dizaine. Tester avec re.findall\nDe m√™me pour les ann√©es de naissance en notant que jusqu‚Äô√† preuve du contraire, pour des personnes vivantes\naujourd‚Äôhui, les mill√©naires concern√©s sont restreints. Tester avec re.findall\nCette regex n‚Äôest pas naturelle, on pourrait tr√®s bien se satisfaire de classes de\ncaract√®res g√©n√©riques \\d m√™me si elles pourraient, en pratique, nous s√©lectionner des\ndates de naissance non possibles (43/78/4528 par exemple). Cela permettrait\nd‚Äôall√©ger la regex afin de la rendre plus intelligible. Ne pas oublier l‚Äôutilit√© des quantifieurs.\nComment adapter la regex pour qu‚Äôelle soit toujours valide pour nos cas mais permette aussi de\ncapturer les dates de type YYYY/MM/DD ? Tester sur 1998/07/12\n\n\n\nA l‚Äôissue de la question 1, vous devriez avoir ce r√©sultat :\n\n\n['14/',\n '9/',\n '20/',\n '04/',\n '14/',\n '09/',\n '2/',\n '3/',\n '1/',\n '7/',\n '7/',\n '3/',\n '15/',\n '10/',\n '08/',\n '03/',\n '8/',\n '1/',\n '30/',\n '6/']\n\n\nA l‚Äôissue de la question 2, vous devriez avoir ce r√©sultat, qui\ncommence √† prendre forme:\n\n\n['14/9',\n '20/04',\n '14/09',\n '2/3',\n '1/7',\n '7/3',\n '15/10',\n '08/03',\n '8/1',\n '30/6']\n\n\nA l‚Äôissue de la question 3, on parvient bien\n√† extraire les dates :\n\n\n['14/9/2000',\n '20/04/1971',\n '14/09/1913',\n '2/3/1978',\n '1/7/1986',\n '7/3/47',\n '15/10/1914',\n '08/03/1941',\n '8/1/1980',\n '30/6/1976']\n\n\nSi tout va bien, √† la question 5, votre regex devrait\nfonctionner:\n\n\n['14/9/2000',\n '20/04/1971',\n '14/09/1913',\n '2/3/1978',\n '1/7/1986',\n '7/3/47',\n '15/10/1914',\n '08/03/1941',\n '8/1/1980',\n '30/6/1976',\n '1998/07/12']",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#extraction-dadresses-email",
    "href": "content/manipulation/04b_regex_TP.html#extraction-dadresses-email",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "6.1 Extraction d‚Äôadresses email",
    "text": "6.1 Extraction d‚Äôadresses email\nIl s‚Äôagit d‚Äôun usage classique des regex\n\ntext_emails = (\n    \"Hello from toto@gmail.com to titi.grominet@yahoo.com about the meeting @2PM\"\n)\n\n\n\n Exercice : extraction d'adresses email\nUtiliser la structure d‚Äôune adresse mail [XXXX]@[XXXX] pour r√©cup√©rer\nce contenu\n\n\n\n\n['toto@gmail.com', 'titi.grominet@yahoo.com']",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#extraire-des-ann√©es-depuis-un-dataframe-pandas",
    "href": "content/manipulation/04b_regex_TP.html#extraire-des-ann√©es-depuis-un-dataframe-pandas",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "6.2 Extraire des ann√©es depuis un DataFrame Pandas",
    "text": "6.2 Extraire des ann√©es depuis un DataFrame Pandas\nL‚Äôobjectif g√©n√©ral de l‚Äôexercice est de nettoyer des colonnes d‚Äôun DataFrame en utilisant des expressions r√©guli√®res.\n\n\n Exercice\nLa base en question contient des livres de la British Library et quelques informations les concernant. Le jeu de donn√©es est disponible ici : https://raw.githubusercontent.com/realpython/python-data-cleaning/master/Datasets/BL-Flickr-Images-Book.csv\nLa colonne ‚ÄúDate de Publication‚Äù n‚Äôest pas toujours une ann√©e, il y a parfois d‚Äôautres informations. Le but de l‚Äôexercice est d‚Äôavoir une date de publication du livre propre et de regarder la distribution des ann√©es de publications.\nPour ce faire, vous pouvez :\n\nSoit choisir de r√©aliser l‚Äôexercice sans aide. Votre lecture de l‚Äô√©nonc√© s‚Äôarr√™te donc ici. Vous devez alors faire attention √† bien regarder vous-m√™me la base de donn√©es et la transformer avec attention.\nSoit suivre les diff√©rentes √©tapes qui suivent pas √† pas.\n\nVersion guid√©e üëá\n\nLire les donn√©es depuis l‚Äôurl https://raw.githubusercontent.com/realpython/python-data-cleaning/master/Datasets/BL-Flickr-Images-Book.csv. Attention au s√©parateur\nNe garder que les colonnes ['Identifier', 'Place of Publication', 'Date of Publication', 'Publisher', 'Title', 'Author']\nObserver la colonne ‚ÄòDate of Publication‚Äô et remarquer le probl√®me sur certaines lignes (par exemple la ligne 13)\nCommencez par regarder le nombre d‚Äôinformations manquantes. On ne pourra pas avoir mieux apr√®s la regex, et normalement on ne devrait pas avoir moins‚Ä¶\nD√©terminer la forme de la regex pour une date de publication. A priori, il y a 4 chiffres qui forment une ann√©e.\nUtiliser la m√©thode str.extract() avec l‚Äôargument expand = False (pour ne conserver que la premi√®re date concordant avec notre pattern)?\nOn a 2 NaN qui n‚Äô√©taient pas pr√©sents au d√©but de l‚Äôexercice. Quels sont-ils et pourquoi ?\nQuelle est la r√©partition des dates de publications dans le jeu de donn√©es ? Vous pouvez par exemple afficher un histogramme gr√¢ce √† la m√©thode plot avec l‚Äôargument kind =\"hist\".\n\n\n\n\nVoici par exemple le probl√®me qu‚Äôon demande de d√©tecter √† la question 3 :\n\n\n\n\n\n\n\n\n\n\nDate of Publication\nTitle\n\n\n\n\n13\n1839, 38-54\nDe Aardbol. Magazijn van hedendaagsche land- e...\n\n\n14\n1897\nCronache Savonesi dal 1500 al 1570 ... Accresc...\n\n\n15\n1865\nSee-Saw; a novel ... Edited [or rather, writte...\n\n\n16\n1860-63\nGeÃÅodeÃÅsie d'une partie de la Haute EÃÅthiopie,...\n\n\n17\n1873\n[With eleven maps.]\n\n\n18\n1866\n[Historia geograÃÅfica, civil y politica de la ...\n\n\n19\n1899\nThe Crisis of the Revolution, being the story ...\n\n\n\n\n\n\n\n\n\n\n181\n\n\nGr√¢ce √† notre regex (question 5), on obtient ainsi un DataFrame plus conforme √† nos attentes\n\n\n\n\n\n\n\n\n\n\nDate of Publication\nyear\n\n\n\n\n0\n1879 [1878]\n1879\n\n\n7\nNaN\nNaN\n\n\n13\n1839, 38-54\n1839\n\n\n16\n1860-63\n1860\n\n\n23\n1847, 48 [1846-48]\n1847\n\n\n...\n...\n...\n\n\n8278\n1883, [1884]\n1883\n\n\n8279\n1898-1912\n1898\n\n\n8283\n1831, 32\n1831\n\n\n8284\n[1806]-22\n1806\n\n\n8286\n1834-43\n1834\n\n\n\n\n1759 rows √ó 2 columns\n\n\n\n\nQuant aux nouveaux NaN,\nil s‚Äôagit de lignes qui ne contenaient pas de cha√Ænes de caract√®res qui ressemblaient √† des ann√©es :\n\n\n\n\n\n\n\n\n\n\nDate of Publication\nyear\n\n\n\n\n1081\n112. G. & W. B. Whittaker\nNaN\n\n\n7391\n17 vols. University Press\nNaN\n\n\n\n\n\n\n\n\nEnfin, on obtient l‚Äôhistogramme suivant des dates de publications:",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#informations-additionnelles",
    "href": "content/manipulation/04b_regex_TP.html#informations-additionnelles",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n62b2a7c\n\n\n2022-12-28 15:00:50\n\n\nLino Galiana\n\n\nSuite chapitre regex (#340)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb138cf3\n\n\n2021-10-21 18:05:59\n\n\nLino Galiana\n\n\nMise √† jour TP webscraping et API (#164)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\na5f4824\n\n\n2021-07-16 14:20:27\n\n\nLino Galiana\n\n\nExo suppl√©mentaire webscraping marmiton üçù (#121) (#124)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04b_regex_TP.html#footnotes",
    "href": "content/manipulation/04b_regex_TP.html#footnotes",
    "title": "Ma√Ætriser les expressions r√©guli√®res",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nN‚Äôimporte quel caract√®re √† part le retour √† la ligne (\\n). Ceci est √† garder en t√™te, j‚Äôai d√©j√† perdu des heures √† chercher pourquoi mon . ne capturait pas ce que je voulais qui s‚Äô√©talait sur plusieurs lignes‚Ä¶‚Ü©Ô∏é",
    "crumbs": [
      "Ma√Ætriser les expressions r√©guli√®res"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html",
    "href": "content/manipulation/04a_webscraping_TP.html",
    "title": "Web scraping avec Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLe web scraping d√©signe les techniques d‚Äôextraction du contenu des sites internet.\nC‚Äôest une pratique tr√®s utile pour toute personne souhaitant travailler sur des informations disponibles en ligne, mais n‚Äôexistant pas forc√©ment sous la forme d‚Äôun tableau Excel.\nCe TP vous pr√©sente comment cr√©er et ex√©cuter des robots afin de recup√©rer rapidement des informations utiles √† vos projets actuels ou futurs.\nIl part de quelques cas d‚Äôusages concret.\nCe chapitre est tr√®s fortement inspir√© et r√©adapt√© √† partir de celui de Xavier Dupr√©, l‚Äôancien professeur de la mati√®re.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#la-zone-grise-de-la-l√©galit√©-du-web-scraping",
    "href": "content/manipulation/04a_webscraping_TP.html#la-zone-grise-de-la-l√©galit√©-du-web-scraping",
    "title": "Web scraping avec Python",
    "section": "1.1 La zone grise de la l√©galit√© du web scraping",
    "text": "1.1 La zone grise de la l√©galit√© du web scraping\nEn premier lieu, en ce qui concerne la question de la l√©galit√©\nde la r√©cup√©ration d‚Äôinformation par scraping, il existe\nune zone grise. Ce n‚Äôest pas parce qu‚Äôune information est\ndisponible sur internet, directement ou avec un peu de recherche,\nqu‚Äôelle peut √™tre r√©cup√©r√©e et r√©utilis√©e.\nL‚Äôexcellent cours d‚ÄôAntoine Palazzolo √©voque un certain nombre de cas\nm√©diatiques et judiciaires sur cette question.\nDans le champ fran√ßais, la CNIL a publi√© en 2020\nde nouvelles directives sur le web scraping repr√©cisant\nque toute donn√©e ne peut √™tre r√©utilis√©e √† l‚Äôinsu de la personne\n√† laquelle ces donn√©es appartiennent. Autrement dit, en principe,\nles donn√©es collect√©es par web scraping sont soumises au\nRGPD, c‚Äôest-√†-dire n√©cessitent le consentement des personnes\n√† partir desquelles la r√©utilisation des donn√©es est faite.\nIl est donc recommand√© d‚Äô√™tre vigilant avec les donn√©es r√©cup√©r√©es\npar web scraping pour ne pas se mettre en faute l√©galement.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#stabilit√©-et-fiabilit√©-des-informations-re√ßues",
    "href": "content/manipulation/04a_webscraping_TP.html#stabilit√©-et-fiabilit√©-des-informations-re√ßues",
    "title": "Web scraping avec Python",
    "section": "1.2 Stabilit√© et fiabilit√© des informations re√ßues",
    "text": "1.2 Stabilit√© et fiabilit√© des informations re√ßues\nLa r√©cup√©ration de donn√©es par web scraping\nest certes pratique mais elle ne correspond pas n√©cessairement\n√† un usage pens√©, ou d√©sir√©, par un fournisseur de donn√©es.\nLes donn√©es √©tant co√ªteuses √† collecter et √† mettre √† disposition,\ncertains sites ne d√©sirent pas n√©cessairement que celles-ci soient\nextraites gratuitement et facilement. A fortiori lorsque la donn√©e\npeut permettre √† un concurrent de disposer d‚Äôune information\nutile d‚Äôun point de vue commercial (prix d‚Äôun produit concurrent, etc.).\nLes acteurs mettent donc souvent en oeuvre des strat√©gies pour bloquer ou\nlimiter la quantit√© de donn√©es scrap√©es. La m√©thode la plus\nclassique est la d√©tection et le blocage\ndes requ√™tes faites par des robots plut√¥t que par des humains.\nPour des acteurs sp√©cialis√©s, cette d√©tection est tr√®s facile car\nde nombreuses preuves permettent d‚Äôidentifier si une visite du site web\nprovient d‚Äôun utilisateur\nhumain derri√®re un navigateur ou d‚Äôun robot. Pour ne citer que quelques indices :\nvitesse de la navigation entre pages, rapidit√© √† extraire la donn√©e,\nempreinte digitale du navigateur utilis√©, capacit√© √† r√©pondre √† des\nquestions al√©atoires (captcha)‚Ä¶\nLes bonnes pratiques, √©voqu√©es par la suite, ont pour objectif de faire\nen sorte qu‚Äôun robot se comporte de mani√®re civile en adoptant un comportement\nproche de celui de l‚Äôhumain mais sans contrefaire le fait qu‚Äôil ne s‚Äôagit\npas d‚Äôun humain.\nIl convient d‚Äôailleurs\nd‚Äô√™tre prudent quant aux informations re√ßues par web scraping.\nLa donn√©e √©tant au coeur du mod√®le √©conomique de certains acteurs, certains\nn‚Äôh√©sitent pas √† renvoyer des donn√©es fausses aux robots\nplut√¥t que les bloquer. C‚Äôest de bonne guerre !\nUne autre technique pi√®ge s‚Äôappelle le honey pot. Il s‚Äôagit de pages qu‚Äôun humain\nn‚Äôirait jamais visiter - par exemple parce qu‚Äôelles n‚Äôapparaissent pas dans\nl‚Äôinterface graphique - mais sur lesquelles un robot, en recherche automatique\nde contenu, va rester bloquer.\nSans aller jusqu‚Äô√† la strat√©gie de blocage du web scraping, d‚Äôautres raisons\npeuvent expliquer qu‚Äôune r√©cup√©ration de donn√©es ait fonctionn√© par\nle pass√© mais ne fonctionne plus. La plus fr√©quente est un changement dans la structure\nd‚Äôun site web. Le web scraping pr√©sente en effet l‚Äôinconv√©nient d‚Äôaller chercher\nde l‚Äôinformation dans une structure tr√®s hi√©rarchis√©e. Un changement dans cette structure\npeut suffire √† rendre un robot incapable de r√©cup√©rer du contenu. Or, pour rester\nattractifs, les sites web changent fr√©quemment ce qui peut facilement\nrendre inop√©rant un robot.\nDe mani√®re g√©n√©rale, l‚Äôun des principaux messages de ce\nchapitre, √† retenir, est que le\nweb scraping est une solution de dernier ressort, pour des r√©cup√©rations ponctuelles de donn√©es sans garantie de fonctionnement ult√©rieur. Il est pr√©f√©rable de privil√©gier les API lorsque celles-ci sont disponibles.\nCes derni√®res ressemblent √† un contrat (formel ou non) entre un fournisseur de donn√©es\net un utilisateur o√π sont d√©finis des besoins (les donn√©es) mais aussi des\nconditions d‚Äôacc√®s (nombre de requ√™tes, volum√©trie, authentification‚Ä¶) l√†\no√π le web scraping est plus proche du comportement dans le Far West.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#les-bonnes-pratiques",
    "href": "content/manipulation/04a_webscraping_TP.html#les-bonnes-pratiques",
    "title": "Web scraping avec Python",
    "section": "1.3 Les bonnes pratiques",
    "text": "1.3 Les bonnes pratiques\nLa possibilit√© de r√©cup√©rer des donn√©es par l‚Äôinterm√©diaire\nd‚Äôun robot ne signifie pas qu‚Äôon peut se permettre de ne pas √™tre\ncivilis√©. En effet, lorsqu‚Äôil est non-ma√Ætris√©, le\nweb scraping peut ressembler √† une attaque informatique\nclassique pour faire sauter un site web : le d√©ni de service.\nLe cours d‚ÄôAntoine Palazzolo revient\nsur certaines bonnes pratiques qui ont √©merg√© dans la communaut√©\ndes scrapeurs. Il est recommand√© de lire cette ressource\npour en apprendre plus sur ce sujet. Y sont √©voqu√©es\nplusieurs conventions, parmi lesquelles :\n\nSe rendre, depuis la racine du site,\nsur le fichier robots.txt pour v√©rifier les consignes\npropos√©es par les d√©veloppeurs du site web pour\ncadrer le comportement des robots ;\nEspacer chaque requ√™tes de plusieurs secondes, comme le ferait\nun humain, afin d‚Äô√©viter de surcharger le site web et de le\nfaire sauter par d√©ni de service ;\nFaire les requ√™tes dans les heures creuses de fr√©quentation du\nsite web s‚Äôil ne s‚Äôagit pas d‚Äôun site consult√© internationalement.\nPar exemple, pour un site en fran√ßais, lancer le robot\npendant la nuit en France m√©tropolitaine, est une bonne pratique.\nPour lancer un robot depuis Python √† une heure programm√©e\n√† l‚Äôavance, il existe les cronjobs.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#les-balises",
    "href": "content/manipulation/04a_webscraping_TP.html#les-balises",
    "title": "Web scraping avec Python",
    "section": "2.1 Les balises",
    "text": "2.1 Les balises\nSur une page web, vous trouverez toujours √† coup s√ªr des √©l√©ments comme &lt;head&gt;, &lt;title&gt;, etc. Il s‚Äôagit des codes qui vous permettent de structurer le contenu d‚Äôune page HTML et qui s‚Äôappellent des balises.\nCitons, par exemple, les balises &lt;p&gt;, &lt;h1&gt;, &lt;h2&gt;, &lt;h3&gt;, &lt;strong&gt; ou &lt;em&gt;.\nLe symbole &lt; &gt; est une balise : il sert √† indiquer le d√©but d‚Äôune partie. Le symbole &lt;/ &gt; indique la fin de cette partie. La plupart des balises vont par paires, avec une balise ouvrante et une balise fermante (par exemple &lt;p&gt; et &lt;/p&gt;).\nPar exemple, les principales balises\nd√©finissant la structure d‚Äôun tableau sont les suivantes :\n\n\n\nBalise\nDescription\n\n\n\n\n&lt;table&gt;\nTableau\n\n\n&lt;caption&gt;\nTitre du tableau\n\n\n&lt;tr&gt;\nLigne de tableau\n\n\n&lt;th&gt;\nCellule d‚Äôen-t√™te\n\n\n&lt;td&gt;\nCellule\n\n\n&lt;thead&gt;\nSection de l‚Äôen-t√™te du tableau\n\n\n&lt;tbody&gt;\nSection du corps du tableau\n\n\n&lt;tfoot&gt;\nSection du pied du tableau\n\n\n\nApplication : un tableau en HTML\nLe code HTML du tableau suivant :\n&lt;table&gt;\n&lt;caption&gt; Le Titre de mon tableau &lt;/caption&gt;\n\n   &lt;tr&gt;\n      &lt;th&gt;Pr√©nom&lt;/th&gt;\n      &lt;th&gt;Nom&lt;/th&gt;\n      &lt;th&gt;Profession&lt;/th&gt;\n   &lt;/tr&gt;\n   &lt;tr&gt;\n      &lt;td&gt;Mike &lt;/td&gt;\n      &lt;td&gt;Stuntman&lt;/td&gt;\n      &lt;td&gt;Cascadeur&lt;/td&gt;\n   &lt;/tr&gt;\n   &lt;tr&gt;\n      &lt;td&gt;Mister&lt;/td&gt;\n      &lt;td&gt;Pink&lt;/td&gt;\n      &lt;td&gt;Gangster&lt;/td&gt;\n   &lt;/tr&gt;\n&lt;/table&gt;\nDonnera dans le navigateur :\n\n\n\nLe Titre de mon tableau\n\n\nPr√©nom\nNom\nProfession\n\n\nMike\nStuntman\nCascadeur\n\n\nMister\nPink\nGangster\n\n\n\n\n\n\n2.1.1 Parent et enfant\nDans le cadre du langage HTML, les termes de parent (parent) et enfant (child) servent √† d√©signer des √©lements embo√Æt√©s les uns dans les autres. Dans la construction suivante, par exemple :\n&lt;div&gt; \n    &lt;p&gt;\n       bla,bla\n    &lt;/p&gt;\n&lt;/div&gt;\nSur la page web, cela apparaitra de la mani√®re suivante :\n\n \n    \n       bla,bla\n    \n\n\nOn dira que l‚Äô√©l√©ment &lt;div&gt; est le parent de l‚Äô√©l√©ment &lt;p&gt; tandis que l‚Äô√©l√©ment &lt;p&gt; est l‚Äôenfant de l‚Äô√©l√©ment &lt;div&gt;.\n\nMais pourquoi apprendre √ßa pour ‚Äúscraper‚Äù ?\n\nParce que, pour bien r√©cup√©rer les informations d‚Äôun site internet, il faut pouvoir comprendre sa structure et donc son code HTML. Les fonctions Python qui servent au scraping sont principalement construites pour vous permettre de naviguer entre les balises.\nAvec Python, vous allez en fait reproduire votre comportement manuel de recherche de mani√®re\n√† l‚Äôautomatiser.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#les-packages-disponibles",
    "href": "content/manipulation/04a_webscraping_TP.html#les-packages-disponibles",
    "title": "Web scraping avec Python",
    "section": "3.1 Les packages disponibles",
    "text": "3.1 Les packages disponibles\nDans la premi√®re partie de ce chapitre,\nnous allons essentiellement utiliser le package BeautifulSoup4,\nen conjonction avec urllib\nou requests. Ces deux derniers packages permettent de r√©cup√©rer le texte\nbrut d‚Äôune page qui sera ensuite\ninspect√© via BeautifulSoup4.\nBeautifulSoup sera suffisant quand vous voudrez travailler sur des pages HTML statiques. D√®s que les informations que vous recherchez sont g√©n√©r√©es via l‚Äôex√©cution de scripts Javascript, il vous faudra passer par des outils comme Selenium.\nDe m√™me, si vous ne connaissez pas l‚ÄôURL, il faudra passer par un framework comme Scrapy, qui passe facilement d‚Äôune page √† une autre. On appelle\ncette technique le ‚Äúweb crawling‚Äù. Scrapy est plus complexe √† manipuler que BeautifulSoup : si vous voulez plus de d√©tails, rendez-vous sur la page du tutoriel Scrapy.\nLe web scraping est un domaine o√π la reproductibilit√© est compliqu√©e √† mettre en oeuvre.\nUne page web √©volue\npotentiellement r√©guli√®rement et d‚Äôune page web √† l‚Äôautre, la structure peut\n√™tre tr√®s diff√©rente ce qui rend certains codes difficilement exportables.\nPar cons√©quent, la meilleure mani√®re d‚Äôavoir un programme fonctionnel est\nde comprendre la structure d‚Äôune page web et dissocier les √©l√©ments exportables\n√† d‚Äôautres cas d‚Äôusages des requ√™tes ad hoc.\n\n!pip install -q lxml\n\nimport bs4\nimport lxml\nimport pandas\nimport urllib\n\nfrom urllib import request\n\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n\n\n\n Note\nPour √™tre en mesure d‚Äôutiliser Selenium, il est n√©cessaire\nde faire communiquer Python avec un navigateur web (Firefox ou Chromium).\nLe package webdriver-manager permet de faire savoir √† Python o√π\nse trouve ce navigateur s‚Äôil est d√©j√† install√© dans un chemin standard.\nPour l‚Äôinstaller, le code de la cellule ci-dessous peut √™tre utilis√©.\n\n\nPour faire fonctionner Selenium, il faut utiliser un package\nnomm√© webdriver-manager:\n\n!pip install webdriver-manager\n\nRequirement already satisfied: webdriver-manager in /opt/mamba/lib/python3.11/site-packages (4.0.1)\nRequirement already satisfied: requests in /opt/mamba/lib/python3.11/site-packages (from webdriver-manager) (2.31.0)\nRequirement already satisfied: python-dotenv in /opt/mamba/lib/python3.11/site-packages (from webdriver-manager) (1.0.1)\nRequirement already satisfied: packaging in /opt/mamba/lib/python3.11/site-packages (from webdriver-manager) (23.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (1.26.18)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests-&gt;webdriver-manager) (2024.2.2)\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#r√©cup√©rer-le-contenu-dune-page-html",
    "href": "content/manipulation/04a_webscraping_TP.html#r√©cup√©rer-le-contenu-dune-page-html",
    "title": "Web scraping avec Python",
    "section": "3.2 R√©cup√©rer le contenu d‚Äôune page HTML",
    "text": "3.2 R√©cup√©rer le contenu d‚Äôune page HTML\nOn va commencer doucement. Prenons une page wikipedia,\npar exemple celle de la Ligue 1 de football, mill√©sime 2019-2020 : Championnat de France de football 2019-2020. On va souhaiter r√©cup√©rer la liste des √©quipes, ainsi que les url des pages Wikipedia de ces √©quipes.\nEtape 1Ô∏è‚É£ : se connecter √† la page wikipedia et obtenir le code source.\nPour cela, le plus simple est d‚Äôutiliser le package urllib ou, mieux, requests.\nNous allons ici utiliser la fonction request du package urllib:\n\nurl_ligue_1 = (\n    \"https://fr.wikipedia.org/wiki/Championnat_de_France_de_football_2019-2020\"\n)\n\nrequest_text = request.urlopen(url_ligue_1).read()\n# print(request_text[:1000])\n\n\ntype(request_text)\n\nbytes\n\n\nEtape 2Ô∏è‚É£ : utiliser le package BeautifulSoup\nqui permet de rechercher efficacement\nles balises contenues dans la chaine de caract√®res\nrenvoy√©e par la fonction request:\n\npage = bs4.BeautifulSoup(request_text, \"lxml\")\n\nSi on print l‚Äôobjet page cr√©√©e avec BeautifulSoup,\non voit que ce n‚Äôest plus une chaine de caract√®res mais bien une page HTML avec des balises.\nOn peut √† pr√©sent chercher des √©lements √† l‚Äôint√©rieur de ces balises.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-find",
    "href": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-find",
    "title": "Web scraping avec Python",
    "section": "3.3 La m√©thode find",
    "text": "3.3 La m√©thode find\nPar exemple, si on veut conna√Ætre le titre de la page, on utilise la m√©thode .find et on lui demande ‚Äútitle‚Äù\n\nprint(page.find(\"title\"))\n\n&lt;title&gt;Championnat de France de football 2019-2020 ‚Äî Wikip√©dia&lt;/title&gt;\n\n\nLa methode .find ne renvoie que la premi√®re occurence de l‚Äô√©l√©ment.\nPour vous en assurer vous pouvez :\n\ncopier le bout de code source obtenu lorsque vous chercher une table,\nle coller dans une cellule de votre notebook\net passer la cellule en ‚ÄúMarkdown‚Äù\n\nLa cellule avec le copier-coller du code source donne :\n\nprint(page.find(\"table\"))\n\n&lt;table&gt;&lt;caption style=\"background-color:#99cc99;color:#000000;\"&gt;G√©n√©ralit√©s&lt;/caption&gt;&lt;tbody&gt;&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Sport&lt;/th&gt;\n&lt;td&gt;\n&lt;a href=\"/wiki/Football\" title=\"Football\"&gt;Football&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Organisateur(s)&lt;/th&gt;\n&lt;td&gt;\n&lt;a href=\"/wiki/Ligue_de_football_professionnel_(France)\" title=\"Ligue de football professionnel (France)\"&gt;LFP&lt;/a&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;√âdition&lt;/th&gt;\n&lt;td&gt;\n&lt;abbr class=\"abbr\" title=\"Quatre-vingt-deuxi√®me (huitante-deuxi√®me / octante-deuxi√®me)\"&gt;82&lt;sup&gt;e&lt;/sup&gt;&lt;/abbr&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Lieu(x)&lt;/th&gt;\n&lt;td&gt;\n&lt;span class=\"datasortkey\" data-sort-value=\"France\"&gt;&lt;span class=\"flagicon\"&gt;&lt;span class=\"mw-image-border noviewer\" typeof=\"mw:File\"&gt;&lt;a class=\"mw-file-description\" href=\"/wiki/Fichier:Flag_of_France.svg\" title=\"Drapeau de la France\"&gt;&lt;img alt=\"Drapeau de la France\" class=\"mw-file-element\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"13\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/20px-Flag_of_France.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/30px-Flag_of_France.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/40px-Flag_of_France.svg.png 2x\" width=\"20\"/&gt;&lt;/a&gt;&lt;/span&gt; &lt;/span&gt;&lt;a href=\"/wiki/France\" title=\"France\"&gt;France&lt;/a&gt;&lt;/span&gt; et &lt;br/&gt;&lt;span class=\"datasortkey\" data-sort-value=\"Monaco\"&gt;&lt;span class=\"flagicon\"&gt;&lt;span class=\"mw-image-border noviewer\" typeof=\"mw:File\"&gt;&lt;a class=\"mw-file-description\" href=\"/wiki/Fichier:Flag_of_Monaco.svg\" title=\"Drapeau de Monaco\"&gt;&lt;img alt=\"Drapeau de Monaco\" class=\"mw-file-element\" data-file-height=\"800\" data-file-width=\"1000\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/20px-Flag_of_Monaco.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/30px-Flag_of_Monaco.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/40px-Flag_of_Monaco.svg.png 2x\" width=\"20\"/&gt;&lt;/a&gt;&lt;/span&gt; &lt;/span&gt;&lt;a href=\"/wiki/Monaco\" title=\"Monaco\"&gt;Monaco&lt;/a&gt;&lt;/span&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Date&lt;/th&gt;\n&lt;td&gt;\nDu &lt;time class=\"nowrap date-lien\" data-sort-value=\"2019-08-09\" datetime=\"2019-08-09\"&gt;&lt;a href=\"/wiki/9_ao%C3%BBt_en_sport\" title=\"9 ao√ªt en sport\"&gt;9&lt;/a&gt; &lt;a class=\"mw-redirect\" href=\"/wiki/Ao%C3%BBt_2019_en_sport\" title=\"Ao√ªt 2019 en sport\"&gt;ao√ªt&lt;/a&gt; &lt;a href=\"/wiki/2019_en_football\" title=\"2019 en football\"&gt;2019&lt;/a&gt;&lt;/time&gt;&lt;br/&gt;au &lt;time class=\"nowrap date-lien\" data-sort-value=\"2020-03-08\" datetime=\"2020-03-08\"&gt;&lt;a href=\"/wiki/8_mars_en_sport\" title=\"8 mars en sport\"&gt;8 mars&lt;/a&gt; &lt;a href=\"/wiki/2020_en_football\" title=\"2020 en football\"&gt;2020&lt;/a&gt;&lt;/time&gt; &lt;small&gt;(arr√™t d√©finitif)&lt;/small&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Participants&lt;/th&gt;\n&lt;td&gt;\n20 √©quipes&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Matchs jou√©s&lt;/th&gt;\n&lt;td&gt;\n279 (sur 380 pr√©vus)&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;th scope=\"row\" style=\"width:10.5em;\"&gt;Site web officiel&lt;/th&gt;\n&lt;td&gt;\n&lt;cite class=\"ouvrage\" id=\"site_officiel\" style=\"font-style: normal;\"&gt;&lt;a class=\"external text\" href=\"https://www.ligue1.fr/\" rel=\"nofollow\"&gt;Site officiel&lt;/a&gt;&lt;/cite&gt;&lt;/td&gt;\n&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;\n\n\nce qui est le texte source permettant de g√©n√©rer le tableau suivant :\n\n\n\nG√©n√©ralit√©s\n\n\n\n\nSport\n\n\nFootball\n\n\n\n\nOrganisateur(s)\n\n\nLFP\n\n\n\n\n√âdition\n\n\n82e\n\n\n\n\nLieu(x)\n\n\n France et  Monaco\n\n\n\n\nDate\n\n\nDu 9 ao√ªt 2019au 8 mars 2020 (arr√™t d√©finitif)\n\n\n\n\nParticipants\n\n\n20 √©quipes\n\n\n\n\nMatchs jou√©s\n\n\n279 (sur 380 pr√©vus)\n\n\n\n\nSite web officiel\n\n\nSite officiel",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-findall",
    "href": "content/manipulation/04a_webscraping_TP.html#la-m√©thode-findall",
    "title": "Web scraping avec Python",
    "section": "3.4 La m√©thode findAll",
    "text": "3.4 La m√©thode findAll\nPour trouver toutes les occurences, on utilise .findAll().\n\nprint(\n    \"Il y a\", len(page.findAll(\"table\")), \"√©l√©ments dans la page qui sont des &lt;table&gt;\"\n)\n\nIl y a 34 √©l√©ments dans la page qui sont des &lt;table&gt;",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#r√©cup√©ration-des-localisations-des-stades",
    "href": "content/manipulation/04a_webscraping_TP.html#r√©cup√©ration-des-localisations-des-stades",
    "title": "Web scraping avec Python",
    "section": "5.1 R√©cup√©ration des localisations des stades",
    "text": "5.1 R√©cup√©ration des localisations des stades\nEssayez de comprendre pas √† pas ce qui est fait dans les √©tapes qui suivent (la r√©cup√©ration d‚Äôinformations suppl√©mentaires en naviguant dans les pages des diff√©rents clubs).\n\nimport urllib\nimport pandas as pd\nimport bs4\n\ndivision = []\nequipe = []\nstade = []\nlatitude_stade = []\nlongitude_stade = []\n\nurl_list = [\n    \"http://fr.wikipedia.org/wiki/Championnat_de_France_de_football_2019-2020\",\n    \"http://fr.wikipedia.org/wiki/Championnat_de_France_de_football_de_Ligue_2_2019-2020\",\n]\n\nfor url_ligue in url_list:\n\n    print(url_ligue)\n    sock = urllib.request.urlopen(url_ligue).read()\n    page = bs4.BeautifulSoup(sock)\n\n    # Rechercher les liens des √©quipes dans la liste disponible sur wikipedia\n\n    for team in page.findAll(\"span\", {\"class\": \"toponyme\"}):\n\n        # Indiquer si c'est de la ligue 1 ou de la ligue 2\n\n        if url_ligue == url_list[0]:\n            division.append(\"L1\")\n        else:\n            division.append(\"L2\")\n\n        # Trouver le nom et le lien de l'√©quipe\n\n        if team.find(\"a\") != None:\n            team_url = team.find(\"a\").get(\"href\")\n            name_team = team.find(\"a\").get(\"title\")\n            equipe.append(name_team)\n            url_get_info = \"http://fr.wikipedia.org\" + team_url\n            print(url_get_info)\n\n            # aller sur la page de l'√©quipe\n\n            search = urllib.request.urlopen(url_get_info).read()\n            search_team = bs4.BeautifulSoup(search)\n\n            # trouver le stade\n            compteur = 0\n            for stadium in search_team.findAll(\"tr\"):\n                for x in stadium.findAll(\"th\", {\"scope\": \"row\"}):\n                    if x.contents[0].string == \"Stade\" and compteur == 0:\n                        compteur = 1\n                        # trouver le lien du stade et son nom\n                        url_stade = stadium.findAll(\"a\")[1].get(\"href\")\n                        name_stadium = stadium.findAll(\"a\")[1].get(\"title\")\n                        stade.append(name_stadium)\n                        url_get_stade = \"http://fr.wikipedia.org\" + url_stade\n                        print(url_get_stade)\n\n                        # Aller sur la page du stade et trouver ses coodronn√©es g√©ographiques\n\n                        search_stade = urllib.request.urlopen(url_get_stade).read()\n                        soup_stade = bs4.BeautifulSoup(search_stade)\n                        kartographer = soup_stade.find(\n                            \"a\", {\"class\": \"mw-kartographer-maplink\"}\n                        )\n                        if kartographer == None:\n                            latitude_stade.append(None)\n                            longitude_stade.append(None)\n                        else:\n                            for coordinates in kartographer:\n                                print(coordinates)\n                                liste = coordinates.split(\",\")\n                                latitude_stade.append(\n                                    str(liste[0]).replace(\" \", \"\") + \"'\"\n                                )\n                                longitude_stade.append(\n                                    str(liste[1]).replace(\" \", \"\") + \"'\"\n                                )\n\n\ndict = {\n    \"division\": division,\n    \"equipe\": equipe,\n    \"stade\": stade,\n    \"latitude\": latitude_stade,\n    \"longitude\": longitude_stade,\n}\ndata = pd.DataFrame(dict)\ndata = data.dropna()\n\n\ndata.head(5)\n\n\n\n\n\n\n\n\n\ndivision\nequipe\nstade\nlatitude\nlongitude\n\n\n\n\n0\nL1\nParis Saint-Germain Football Club\nParc des Princes\n48¬∞¬†50‚Ä≤¬†29‚Ä≥¬†N'\n2¬∞¬†15‚Ä≤¬†11‚Ä≥¬†E'\n\n\n1\nL1\nLOSC Lille\nStade Pierre-Mauroy\n50¬∞¬†36‚Ä≤¬†43‚Ä≥¬†N'\n3¬∞¬†07‚Ä≤¬†50‚Ä≥¬†E'\n\n\n2\nL1\nOlympique lyonnais\nParc Olympique lyonnais\n45¬∞¬†45‚Ä≤¬†55‚Ä≥¬†N'\n4¬∞¬†58‚Ä≤¬†55‚Ä≥¬†E'\n\n\n3\nL1\nAssociation sportive de Saint-√âtienne\nStade Geoffroy-Guichard\n45¬∞¬†27‚Ä≤¬†39‚Ä≥¬†N'\n4¬∞¬†23‚Ä≤¬†25‚Ä≥¬†E'\n\n\n4\nL1\nOlympique de Marseille\nStade V√©lodrome\n43¬∞¬†16‚Ä≤¬†11‚Ä≥¬†N'\n5¬∞¬†23‚Ä≤¬†45‚Ä≥¬†E'\n\n\n\n\n\n\n\n\nOn va transformer les coordonn√©es en degr√©s en coordonn√©es num√©riques\nafin d‚Äô√™tre en mesure de faire une carte.\n\nimport re\n\n\ndef dms2dd(degrees, minutes, seconds, direction):\n    dd = float(degrees) + float(minutes) / 60 + float(seconds) / (60 * 60)\n    if direction in (\"S\", \"O\"):\n        dd *= -1\n    return dd\n\n\ndef parse_dms(dms):\n    parts = re.split(\"[^\\d\\w]+\", dms)\n    lat = dms2dd(parts[0], parts[1], parts[2], parts[3])\n    # lng = dms2dd(parts[4], parts[5], parts[6], parts[7])\n    return lat\n\n\ndata[\"latitude\"] = data[\"latitude\"].apply(parse_dms)\ndata[\"longitude\"] = data[\"longitude\"].apply(parse_dms)\n\nTous les √©l√©ments sont en place pour faire une belle carte √† ce stade. On\nva utiliser folium pour celle-ci, qui est pr√©sent√© dans la partie\nvisualisation.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#cartes-stades-ligue1",
    "href": "content/manipulation/04a_webscraping_TP.html#cartes-stades-ligue1",
    "title": "Web scraping avec Python",
    "section": "5.2 Carte des stades avec folium",
    "text": "5.2 Carte des stades avec folium\n\nimport geopandas as gpd\nfrom pathlib import Path\nimport folium\n\ngdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data.longitude, data.latitude))\n\nPath(\"leaflet\").mkdir(parents=True, exist_ok=True)\n\ncenter = gdf[[\"latitude\", \"longitude\"]].mean().values.tolist()\nsw = gdf[[\"latitude\", \"longitude\"]].min().values.tolist()\nne = gdf[[\"latitude\", \"longitude\"]].max().values.tolist()\n\nm = folium.Map(location=center, tiles=\"openstreetmap\")\n\n# I can add marker one by one on the map\nfor i in range(0, len(gdf)):\n    folium.Marker(\n        [gdf.iloc[i][\"latitude\"], gdf.iloc[i][\"longitude\"]], popup=gdf.iloc[i][\"stade\"]\n    ).add_to(m)\n\nm.fit_bounds([sw, ne])\n\nLa carte obtenue doit ressembler √† la suivante :\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#version-non-guid√©e",
    "href": "content/manipulation/04a_webscraping_TP.html#version-non-guid√©e",
    "title": "Web scraping avec Python",
    "section": "6.1 Version non guid√©e",
    "text": "6.1 Version non guid√©e\n\n\n Exercice 2 : Les pokemon (version non guid√©e)\nPour cet exercice, nous vous demandons d‚Äôobtenir diff√©rentes informations sur les pok√©mons :\n\nles informations personnelles des 893 pokemons sur le site internet pokemondb.net.\nLes informations que nous aimerions obtenir au final dans un DataFrame sont celles contenues dans 4 tableaux :\n\n\nPok√©dex data\nTraining\nBreeding\nBase stats\n\n\nNous aimerions que vous r√©cup√©riez √©galement les images de chacun des pok√©mons et que vous les enregistriez dans un dossier\n\n\nPetit indice : utilisez les modules request et shutil\nPour cette question, il faut que vous cherchiez de vous m√™me certains √©l√©ments, tout n‚Äôest pas pr√©sent dans le TD.\n\n\n\nPour la question 1, l‚Äôobjectif est d‚Äôobtenir le code source d‚Äôun tableau comme\ncelui qui suit\n(Pokemon Nincada).\n\n\n\nPok√©dex data\n\n\n\n\n\nNational ‚Ññ\n\n\n290\n\n\n\n\nType\n\n\nBug Ground\n\n\n\n\nSpecies\n\n\nTrainee Pok√©mon\n\n\n\n\nHeight\n\n\n0.5¬†m (1‚Ä≤08‚Ä≥)\n\n\n\n\nWeight\n\n\n5.5¬†kg (12.1¬†lbs)\n\n\n\n\nAbilities\n\n\n1. Compound EyesRun Away (hidden ability)\n\n\n\n\nLocal ‚Ññ\n\n\n042 (Ruby/Sapphire/Emerald)111 (X/Y ‚Äî Central Kalos)043 (Omega Ruby/Alpha Sapphire)104 (Sword/Shield)\n\n\n\n\n\n\n\n\n\nTraining\n\n\n\n\n\nEV yield\n\n\n1 Defense\n\n\n\n\nCatch rate\n\n\n255 (33.3% with Pok√©Ball, full HP)\n\n\n\n\nBase Friendship\n\n\n70 (normal)\n\n\n\n\nBase Exp.\n\n\n53\n\n\n\n\nGrowth Rate\n\n\nErratic\n\n\n\n\n\n\n\nBreeding\n\n\n\n\n\nEgg Groups\n\n\nBug\n\n\n\n\nGender\n\n\n50% male, 50% female\n\n\n\n\nEgg cycles\n\n\n15 (3,599‚Äì3,855 steps)\n\n\n\n\n\n\n\n\n\n\n\n\nBase stats\n\n\n\n\n\n\nHP\n\n\n31\n\n\n\n\n\n\n\n172\n\n\n266\n\n\n\n\nAttack\n\n\n45\n\n\n\n\n\n\n\n85\n\n\n207\n\n\n\n\nDefense\n\n\n90\n\n\n\n\n\n\n\n166\n\n\n306\n\n\n\n\nSp. Atk\n\n\n30\n\n\n\n\n\n\n\n58\n\n\n174\n\n\n\n\nSp. Def\n\n\n30\n\n\n\n\n\n\n\n58\n\n\n174\n\n\n\n\nSpeed\n\n\n40\n\n\n\n\n\n\n\n76\n\n\n196\n\n\n\n\n\n\nTotal\n\n\n266\n\n\n\n\nMin\n\n\nMax\n\n\n\n\n\n\n\nPour la question 2, l‚Äôobjectif est d‚Äôobtenir\nles images des pokemon.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#version-guid√©e",
    "href": "content/manipulation/04a_webscraping_TP.html#version-guid√©e",
    "title": "Web scraping avec Python",
    "section": "6.2 Version guid√©e",
    "text": "6.2 Version guid√©e\nLes prochaines parties permettront de faire l‚Äôexercice ci-dessus\n√©tape par √©tape,\nde mani√®re guid√©e.\nNous souhaitons tout d‚Äôabord obtenir les\ninformations personnelles de tous\nles pokemons sur pokemondb.net.\nLes informations que nous aimerions obtenir au final pour les pokemons sont celles contenues dans 4 tableaux :\n\nPok√©dex data\nTraining\nBreeding\nBase stats\n\nNous proposons ensuite de r√©cup√©rer et afficher les images.\n\n6.2.1 Etape 1: constituer un DataFrame de caract√©ristiques\n\n\n Exercice 2b : Les pok√©mons (version guid√©e)\nPour r√©cup√©rer les informations, le code devra √™tre divis√© en plusieurs √©tapes :\n\nTrouvez la page principale du site et la transformer en un objet intelligible pour votre code.\nLes fonctions suivantes vous seront utiles :\n\n\nurllib.request.Request\nurllib.request.urlopen\nbs4.BeautifulSoup\n\n\nCr√©ez une fonction qui permet de r√©cup√©rer la page d‚Äôun pok√©mon √† partir de son nom.\nA partir de la page de bulbasaur, obtenez les 4 tableaux qui nous int√©ressent :\n\n\non va chercher l‚Äô√©l√©ment suivant : ('table', { 'class' : \"vitals-table\"})\npuis stocker ses √©l√©ments dans un dictionnaire\n\n\nR√©cup√©rez par ailleurs la liste de noms des pok√©mons qui nous permettra de faire une boucle par la suite. Combien trouvez-vous de pok√©mons ?\nEcrire une fonction qui r√©cup√®re l‚Äôensemble des informations sur les dix premiers pok√©mons de la liste et les int√®gre dans un DataFrame\n\n\n\nA l‚Äôissue de la question 3,\nvous devriez obtenir une liste de caract√©ristiques proche de celle-ci :\n\n\n{'National ‚Ññ': '0001',\n 'name': 'bulbasaur',\n 'Type': ' Grass Poison ',\n 'Species': 'Seed Pok√©mon',\n 'Height': '0.7\\xa0m (2‚Ä≤04‚Ä≥)',\n 'Weight': '6.9\\xa0kg (15.2\\xa0lbs)',\n 'Abilities': '1. OvergrowChlorophyll (hidden ability)',\n 'Local ‚Ññ': \"0001 (Red/Blue/Yellow)0226 (Gold/Silver/Crystal)0001 (FireRed/LeafGreen)0231 (HeartGold/SoulSilver)0080 (X/Y ‚Äî Central Kalos)0001 (Let's Go Pikachu/Let's Go Eevee)0068 (The Isle of Armor)0164 (The Indigo Disk)\",\n 'EV yield': ' 1 Sp. Atk ',\n 'Catch rate': ' 45 (5.9% with Pok√©Ball, full HP) ',\n 'Base Friendship': ' 50 (normal) ',\n 'Base Exp.': '64',\n 'Growth Rate': 'Medium Slow',\n 'Egg Groups': 'Grass, Monster',\n 'Gender': '87.5% male, 12.5% female',\n 'Egg cycles': '20 (4,884‚Äì5,140 steps) ',\n 'HP': '45',\n 'Attack': '49',\n 'Defense': '49',\n 'Sp. Atk': '65',\n 'Sp. Def': '65',\n 'Speed': '45'}\n\n\nLa structure est ici en dictionnaire, ce qui est pratique.\nEnfin, vous pouvez int√©grer les informations\ndes dix premiers pok√©mons √† un\nDataFrame, qui aura l‚Äôaspect suivant :\n\n\n\n\n\n\n\n\n\n\nNational ‚Ññ\nname\nType\nSpecies\nHeight\nWeight\nAbilities\nLocal ‚Ññ\nEV yield\nCatch rate\n...\nGrowth Rate\nEgg Groups\nGender\nEgg cycles\nHP\nAttack\nDefense\nSp. Atk\nSp. Def\nSpeed\n\n\n\n\n0\n0001\nbulbasaur\nGrass Poison\nSeed Pok√©mon\n0.7¬†m (2‚Ä≤04‚Ä≥)\n6.9¬†kg (15.2¬†lbs)\n1. OvergrowChlorophyll (hidden ability)\n0001 (Red/Blue/Yellow)0226 (Gold/Silver/Crysta...\n1 Sp. Atk\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nGrass, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n45\n49\n49\n65\n65\n45\n\n\n1\n0002\nivysaur\nGrass Poison\nSeed Pok√©mon\n1.0¬†m (3‚Ä≤03‚Ä≥)\n13.0¬†kg (28.7¬†lbs)\n1. OvergrowChlorophyll (hidden ability)\n0002 (Red/Blue/Yellow)0227 (Gold/Silver/Crysta...\n1 Sp. Atk, 1 Sp. Def\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nGrass, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n60\n62\n63\n80\n80\n60\n\n\n2\n0003\nvenusaur\nGrass Poison\nSeed Pok√©mon\n2.0¬†m (6‚Ä≤07‚Ä≥)\n100.0¬†kg (220.5¬†lbs)\n1. OvergrowChlorophyll (hidden ability)\n0003 (Red/Blue/Yellow)0228 (Gold/Silver/Crysta...\n2 Sp. Atk, 1 Sp. Def\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nGrass, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n80\n82\n83\n100\n100\n80\n\n\n3\n0004\ncharmander\nFire\nLizard Pok√©mon\n0.6¬†m (2‚Ä≤00‚Ä≥)\n8.5¬†kg (18.7¬†lbs)\n1. BlazeSolar Power (hidden ability)\n0004 (Red/Blue/Yellow)0229 (Gold/Silver/Crysta...\n1 Speed\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nDragon, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n39\n52\n43\n60\n50\n65\n\n\n4\n0005\ncharmeleon\nFire\nFlame Pok√©mon\n1.1¬†m (3‚Ä≤07‚Ä≥)\n19.0¬†kg (41.9¬†lbs)\n1. BlazeSolar Power (hidden ability)\n0005 (Red/Blue/Yellow)0230 (Gold/Silver/Crysta...\n1 Sp. Atk, 1 Speed\n45 (5.9% with Pok√©Ball, full HP)\n...\nMedium Slow\nDragon, Monster\n87.5% male, 12.5% female\n20 (4,884‚Äì5,140 steps)\n58\n64\n58\n80\n65\n80\n\n\n\n\n5 rows √ó 22 columns\n\n\n\n\n\n\n6.2.2 Etape 2: r√©cup√©rer et afficher des photos de Pokemon\nNous aimerions que vous r√©cup√©riez √©galement les images des 5 premiers pok√©mons\net que vous les enregistriez dans un dossier.\n\n\n Exercice 2b : Les pok√©mons (version guid√©e)\n\nLes URL des images des pokemon prennent la forme ‚Äúhttps://img.pokemondb.net/artwork/{pokemon}.jpg‚Äù.\nUtiliser les modules requests et shutil pour t√©l√©charger\net enregistrer en local les images.\nImporter ces images stock√©es au format JPEG dans Python gr√¢ce √† la fonction imread du package skimage.io\n\n\n\n\n!pip install scikit-image\n\nRequirement already satisfied: scikit-image in /opt/mamba/lib/python3.11/site-packages (0.23.2)\nRequirement already satisfied: numpy&gt;=1.23 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (1.26.4)\nRequirement already satisfied: scipy&gt;=1.9 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (1.13.0)\nRequirement already satisfied: networkx&gt;=2.8 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (3.3)\nRequirement already satisfied: pillow&gt;=9.1 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (10.3.0)\nRequirement already satisfied: imageio&gt;=2.33 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (2.34.1)\nRequirement already satisfied: tifffile&gt;=2022.8.12 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (2024.5.22)\nRequirement already satisfied: packaging&gt;=21 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (23.2)\nRequirement already satisfied: lazy-loader&gt;=0.4 in /opt/mamba/lib/python3.11/site-packages (from scikit-image) (0.4)\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#premier-exemple-en-scrapant-un-moteur-de-recherche",
    "href": "content/manipulation/04a_webscraping_TP.html#premier-exemple-en-scrapant-un-moteur-de-recherche",
    "title": "Web scraping avec Python",
    "section": "7.1 Premier exemple en scrapant un moteur de recherche",
    "text": "7.1 Premier exemple en scrapant un moteur de recherche\nDans cet exemple, nous allons essayer d‚Äôaller sur le\nsite de Bing Actualit√©s\net entrer dans la barre de recherche un sujet donn√©.\nPour tester, nous allons faire une recherche avec le mot-cl√© ‚ÄúTrump‚Äù.\nL‚Äôinstallation de Selenium n√©cessite d‚Äôavoir Chromium qui est un\nnavigateur Google Chrome minimaliste.\nLa version de chromedriver\ndoit √™tre &gt;= 2.36 et d√©pend de la version de Chrome que vous avez sur votre environnement\nde travail. Pour installer cette version minimaliste de Chrome sur un environnement\nLinux, vous pouvez vous r√©f√©rer √† l‚Äôencadr√© d√©di√©.\n\n\n Installation de Selenium\nD‚Äôabord, il convient d‚Äôinstaller les d√©pendances.\nSur Colab, vous pouvez utiliser les commandes suivantes :\n\n!sudo apt-get update\n!sudo apt install -y unzip xvfb libxi6 libgconf-2-4 -y\n!sudo apt install chromium-chromedriver -y\n!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n\n\nSi vous √™tes sur le SSP Cloud, vous pouvez\nex√©cuter les commandes suivantes :\n\n!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -O /tmp/chrome.deb\n!sudo apt-get update\n!sudo -E apt-get install -y /tmp/chrome.deb\n!pip install chromedriver-autoinstaller selenium\n\nimport chromedriver_autoinstaller\nchromedriver_autoinstaller.install()\n\n\nVous pouvez ensuite installer Selenium.\nPar exemple, depuis une\ncellule de Notebook :\n\n\nApr√®s avoir install√© Chromium,\nil est n√©cessaire d‚Äôindiquer √† Python o√π\nle trouver. Si vous √™tes sur Linux et que vous\navez suivi les consignes pr√©c√©dentes, vous pouvez faire :\n\nimport selenium\nfrom webdriver_manager.chrome import ChromeDriverManager\n\npath_to_web_driver = ChromeDriverManager().install()\n\nEn premier lieu, il convient d‚Äôinitialiser le comportement\nde Selenium en r√©pliquant les param√®tres\ndu navigateur. Pour cela, on va d‚Äôabord initialiser\nnotre navigateur avec quelques options :\n\nimport time\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\nchrome_options = webdriver.ChromeOptions()\nchrome_options.add_argument(\"--headless\")\nchrome_options.add_argument(\"--no-sandbox\")\nchrome_options.add_argument(\"--disable-dev-shm-usage\")\n# chrome_options.add_argument('--verbose')\n\nPuis on lance le navigateur :\n\nfrom selenium.webdriver.chrome.service import Service\n\nservice = Service(executable_path=path_to_web_driver)\n\nbrowser = webdriver.Chrome(service=service, options=chrome_options)\n\nOn va sur le site de Bing Actualit√©s,\net on lui indique le mot cl√© que nous souhaitons chercher.\nEn l‚Äôoccurrence, on s‚Äôint√©resse aux actualit√©s de Donald Trump.\nApr√®s avoir inspect√© la page depuis les outils de d√©veloppement du navigateur,\non voit que la barre de recherche est un √©lement du code appel√© q (comme query).\nOn va ainsi demander √† selenium de chercher cet √©l√©ment:\n\nbrowser.get(\"https://www.bing.com/news\")\n\nsearch = browser.find_element(\"name\", \"q\")\nprint(search)\nprint([search.text, search.tag_name, search.id])\n\n# on envoie √† cet endroit le mot qu'on aurait tap√© dans la barre de recherche\nsearch.send_keys(\"Trump\")\n\nsearch_button = browser.find_element(\"xpath\", \"//input[@id='sb_form_go']\")\nsearch_button.click()\n\nSelenium permet de capturer l‚Äôimage qu‚Äôon verrait dans le navigateur\navec get_screenshot_as_png. Cela peut √™tre utile pour v√©rifier qu‚Äôon\na fait la bonne action :\n\n\n\n\n\n\n\n\n\nEnfin, on peut extraire les r√©sultats. Plusieurs\nm√©thodes sont disponibles. La m√©thode la plus\npratique, lorsqu‚Äôelle est disponible,\nest d‚Äôutiliser le XPath qui est un chemin\nnon ambigu pour acc√©der √† un √©lement. En effet,\nplusieurs √©l√©ments peuvent partager la m√™me classe ou\nle m√™me attribut ce qui peut faire qu‚Äôune recherche\nde ce type peut renvoyer plusieurs √©chos.\nPour d√©terminer le XPath d‚Äôun objet, les outils\nde d√©veloppeurs de votre site web sont pratiques.\nPar exemple, sous Firefox, une fois que vous\navez trouv√© un √©l√©ment dans l‚Äôinspecteur, vous\npouvez faire click droit &gt; Copier &gt; XPath.\nEnfin, pour mettre fin √† notre session, on demande\n√† Python de quitter le navigateur:\n\nbrowser.quit()\n\nOn a obtenu les r√©sultats suivants :\n\n\n['https://www.realclearpolitics.com/video/2024/05/27/trump_lawyer_alina_habba_with_a_fair_judge_there_would_be_a_full_acquittal_hung_jury_at_worst.html', 'https://www.msn.com/en-us/news/politics/nikki-haley-voting-for-trump-tells-you-a-lot-about-the-republican-party-today-says-susan-glasser/vi-BB1n8Pxs?ocid=BingNewsSearch', 'https://www.bbc.co.uk/news/articles/crgg4kv0682o', 'https://www.nytimes.com/2024/05/27/climate/trump-electric-vehicles.html', 'https://www.msn.com/en-us/news/politics/trump-heckled-kennedy-rejected-at-libertarian-convention/ar-BB1n8zTA?ocid=BingNewsSearch', 'https://www.msn.com/en-us/news/politics/trump-told-donors-he-will-crush-pro-palestinian-protests-deport-demonstrators/ar-BB1n7F9z?ocid=BingNewsSearch', 'https://news.yahoo.com/news/trump-freaks-york-trial-judge-154210883.html', 'https://www.msn.com/en-us/news/politics/donald-trump-fumes-at-alvin-braggs-court-move/ar-BB1n7Ger?ocid=BingNewsSearch']\n\n\nLes autres m√©thodes utiles de Selenium:\n\n\n\n\n\n\n\nM√©thode\nR√©sultat\n\n\n\n\nfind_element(****).click()\nUne fois qu‚Äôon a trouv√© un √©l√©ment r√©actif, notamment un bouton, on peut cliquer dessus pour activer une nouvelle page\n\n\nfind_element(****).send_keys(\"toto\")\nUne fois qu‚Äôon a trouv√© un √©l√©ment, notamment un champ o√π s‚Äôauthentifier, on peut envoyer une valeur, ici ‚Äútoto‚Äù.",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#utiliser-selenium-pour-jouer-√†-2048",
    "href": "content/manipulation/04a_webscraping_TP.html#utiliser-selenium-pour-jouer-√†-2048",
    "title": "Web scraping avec Python",
    "section": "7.2 Utiliser Selenium pour jouer √† 2048",
    "text": "7.2 Utiliser Selenium pour jouer √† 2048\nDans cet exemple, on utilise le module pour que Python\nappuie lui m√™me sur les touches du clavier afin de jouer √† 2048.\nNote : ce bout de code ne donne pas une solution √† 2048,\nil permet juste de voir ce qu‚Äôon peut faire avec Selenium.\n\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.common.keys import Keys\n\n# on ouvre la page internet du jeu 2048\nservice = Service(executable_path=path_to_web_driver)\n\nbrowser = webdriver.Chrome(service=service, options=chrome_options)\nbrowser.get(\"https://play2048.co//\")\n\n# Ce qu'on va faire : une boucle qui r√©p√®te inlassablement la m√™me chose : haut / droite / bas / gauche\n\n# on commence par cliquer sur la page pour que les touches sachent\nbutton = browser.find_element(\"class name\", \"grid-container\")\nbrowser.execute_script(\"arguments[0].click();\", button)\ntime.sleep(0.5)\n\ngrid = browser.find_element(\"tag name\", \"body\")\n\n# pour savoir quels coups faire √† quel moment, on cr√©e un dictionnaire\ndirection = {0: Keys.UP, 1: Keys.RIGHT, 2: Keys.DOWN, 3: Keys.LEFT}\ncount = 0\n\nwhile True:\n    try:  # on v√©rifie que le bouton \"Try again\" n'est pas l√† - sinon √ßa veut dire que le jeu est fini\n        retryButton = browser.find_element(\"link text\", \"Try again\")\n        scoreElem = browser.find_element(\"class name\", \"score-container\")\n        break\n    except:\n        # Do nothing.  Game is not over yet\n        pass\n    # on continue le jeu - on appuie sur la touche suivante pour le coup d'apr√®s\n    count += 1\n    grid.send_keys(direction[count % 4])\n    time.sleep(0.1)\n\nprint(\"Score final : {} en {} coups\".format(scoreElem.text, count))\nbrowser.quit()",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#exercice-suppl√©mentaire",
    "href": "content/manipulation/04a_webscraping_TP.html#exercice-suppl√©mentaire",
    "title": "Web scraping avec Python",
    "section": "7.3 Exercice suppl√©mentaire",
    "text": "7.3 Exercice suppl√©mentaire\nPour d√©couvrir une autre application possible du web scraping, vous pouvez √©galement vous lancer dans le sujet 5 de l‚Äô√©dition 2023 d‚Äôun hackathon non comp√©titif organis√© par l‚ÄôInsee :\n\nSur Github\nSur le SSPCloud\n\nLe contenu de la section NLP du cours pourra vous √™tre utile pour la seconde partie du sujet !",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/04a_webscraping_TP.html#informations-additionnelles",
    "href": "content/manipulation/04a_webscraping_TP.html#informations-additionnelles",
    "title": "Web scraping avec Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n762f85a\n\n\n2023-10-23 18:12:15\n\n\nLino Galiana\n\n\nMise en forme du TP webscraping (#441)\n\n\n\n\n8071bbb\n\n\n2023-10-23 17:43:37\n\n\ntomseimandi\n\n\nMake minor changes to 02b, 03, 04a (#440)\n\n\n\n\n3eb0aeb\n\n\n2023-10-23 11:59:24\n\n\nThomas Faria\n\n\nRelecture jusqu‚Äôaux API (#439)\n\n\n\n\n102ce9f\n\n\n2023-10-22 11:39:37\n\n\nThomas Faria\n\n\nRelecture Thomas, premi√®re partie (#438)\n\n\n\n\nfbbf066\n\n\n2023-10-16 14:57:03\n\n\nAntoine Palazzolo\n\n\nCorrection TP scraping (#435)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\nb7f4d7e\n\n\n2023-09-17 17:03:14\n\n\nAntoine Palazzolo\n\n\nRenvoi vers sujet funathon pour partie scraping (#404)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8baf507\n\n\n2023-08-28 11:09:30\n\n\nLino Galiana\n\n\nLien mort formation webscraping\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n3560f1f\n\n\n2023-07-21 17:04:56\n\n\nLino Galiana\n\n\nBuild on smaller sized image (#384)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\n938f9bc\n\n\n2022-12-04 15:28:37\n\n\nLino Galiana\n\n\nTest selenium en int√©gration continue (#331)\n\n\n\n\n342b59b\n\n\n2022-12-04 11:55:00\n\n\nRomain Avouac\n\n\nProcedure to install selenium on ssp cloud (#330)\n\n\n\n\n037842a\n\n\n2022-11-22 17:52:25\n\n\nLino Galiana\n\n\nWebscraping exercice nom et age ministres (#326)\n\n\n\n\n738c074\n\n\n2022-11-17 12:23:29\n\n\nLino Galiana\n\n\nNettoie le TP scraping (#323)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\n43a863f\n\n\n2022-09-27 11:14:18\n\n\nLino Galiana\n\n\nChange notebook url (#283)\n\n\n\n\n25046de\n\n\n2022-09-26 18:08:19\n\n\nLino Galiana\n\n\nRectifie bug TP webscraping (#281)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\nbb38643\n\n\n2022-06-08 16:59:40\n\n\nLino Galiana\n\n\nR√©pare bug leaflet (#234)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n66e2837\n\n\n2021-12-24 16:54:45\n\n\nLino Galiana\n\n\nFix a few typos in the new pipeline tutorial (#208)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb138cf3\n\n\n2021-10-21 18:05:59\n\n\nLino Galiana\n\n\nMise √† jour TP webscraping et API (#164)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Web scraping avec Python"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html",
    "href": "content/manipulation/03_geopandas_tutorial.html",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "",
    "text": "La partie GeoPandas a √©volu√© r√©cemment. Vous pouvez retrouver les contenus li√©s √† GeoPandas dans le chapitre suivant (√©l√©ments magistraux et exercices):"
  },
  {
    "objectID": "content/manipulation/03_geopandas_tutorial.html#informations-additionnelles",
    "href": "content/manipulation/03_geopandas_tutorial.html#informations-additionnelles",
    "title": "Donn√©es spatiales : d√©couverte de geopandas",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n91bfa52\n\n\n2024-05-27 15:01:32\n\n\nLino Galiana\n\n\nRestructuration partie geopandas (#500)\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\nce33d5d\n\n\n2024-01-16 15:47:22\n\n\nLino Galiana\n\n\nAdapte les exemples de code de cartiflette (#482)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n102ce9f\n\n\n2023-10-22 11:39:37\n\n\nThomas Faria\n\n\nRelecture Thomas, premi√®re partie (#438)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nf8831e7\n\n\n2023-10-09 10:53:34\n\n\nLino Galiana\n\n\nRelecture antuki geopandas (#429)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\na9198de\n\n\n2023-08-25 18:33:00\n\n\nLino Galiana\n\n\nGeopandas tutorial\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n8d81b5f\n\n\n2023-02-18 18:21:59\n\n\nLino Galiana\n\n\nChange source get_vectorfile (#355)\n\n\n\n\nd2eb6c2\n\n\n2023-02-18 17:15:35\n\n\nLino Galiana\n\n\nUpdate index.qmd\n\n\n\n\n3912a7e\n\n\n2023-02-07 17:18:25\n\n\nLino Galiana\n\n\nBack to IGN provider (#350)\n\n\n\n\n0312041\n\n\n2022-12-11 13:43:49\n\n\nLino Galiana\n\n\nreprend box de geopandas (#332)\n\n\n\n\n6662800\n\n\n2022-10-28 11:14:27\n\n\nLino Galiana\n\n\nChange IGN dataset provider (#308)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\n8df6bbc\n\n\n2022-10-12 11:50:57\n\n\nLino Galiana\n\n\nCorrige les tags du tuto geopandas (#295)\n\n\n\n\naf763cc\n\n\n2022-10-12 10:17:56\n\n\nLino Galiana\n\n\nReprise exercice geopandas (#294)\n\n\n\n\n1ef97df\n\n\n2022-10-11 12:14:03\n\n\nLino Galiana\n\n\nRelecture chapitre geopandas (#289)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n5cac236\n\n\n2021-12-16 19:46:43\n\n\nLino Galiana\n\n\nun petit mot sur mercator (#201)\n\n\n\n\n77120b8\n\n\n2021-11-01 20:28:28\n\n\nLino Galiana\n\n\nAjoute une section sur le geocodage (#173)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n735e677\n\n\n2021-10-19 09:46:12\n\n\nLino Galiana\n\n\nR√®gle probl√®me des cartes qui s‚Äôaffichent pas (#165)\n\n\n\n\n5ad057f\n\n\n2021-10-10 15:13:16\n\n\nLino Galiana\n\n\nRelectures pandas & geopandas (#159)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\nbadc492\n\n\n2020-09-22 18:36:33\n\n\nLino Galiana\n\n\nFinalize geopandas section (#48)\n\n\n\n\nffb05cf\n\n\n2020-09-10 17:18:15\n\n\nLino Galiana\n\n\nPartie sur les donn√©es spatiales (#20) :warning: pas fini\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')"
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html",
    "href": "content/manipulation/02a_pandas_tutorial.html",
    "title": "Introduction √† Pandas",
    "section": "",
    "text": "La partie Pandas a √©volu√© r√©cemment. Vous pouvez retrouver les contenus li√©s √† Pandas dans les chapitres suivants:"
  },
  {
    "objectID": "content/manipulation/02a_pandas_tutorial.html#informations-additionnelles",
    "href": "content/manipulation/02a_pandas_tutorial.html#informations-additionnelles",
    "title": "Introduction √† Pandas",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\ne0d615e\n\n\n2024-05-03 11:15:29\n\n\nLino Galiana\n\n\nRestructure la partie Pandas (#497)\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\nc03aa61\n\n\n2024-01-16 17:33:18\n\n\nLino Galiana\n\n\nExercice sur les chemins relatifs (#483)\n\n\n\n\n056c606\n\n\n2023-12-20 20:08:25\n\n\nlinogaliana\n\n\nChange pandas image\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\ncef6a0d\n\n\n2023-10-18 13:18:46\n\n\nLino Galiana\n\n\nAll√®gement des actions github (#437)\n\n\n\n\n97676f5\n\n\n2023-10-14 17:56:44\n\n\nLino Galiana\n\n\nDu style pour le site (#434)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nac80862\n\n\n2023-10-07 21:05:25\n\n\nLino Galiana\n\n\nRelecture antuki (#427)\n\n\n\n\n7e03cea\n\n\n2023-10-04 14:07:17\n\n\nLino Galiana\n\n\nClean pandas tutorial and exercises (#417)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nc312bdc\n\n\n2023-08-11 18:06:25\n\n\nLino Galiana\n\n\nA few controls for Quarto website (#389)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\ndde3e93\n\n\n2023-07-21 22:22:05\n\n\nLino Galiana\n\n\nFix bug on chapter order (#385)\n\n\n\n\n3560f1f\n\n\n2023-07-21 17:04:56\n\n\nLino Galiana\n\n\nBuild on smaller sized image (#384)\n\n\n\n\nf146354\n\n\n2023-07-21 18:15:10\n\n\nLino Galiana\n\n\nUpdate index.qmd\n\n\n\n\nf6dde33\n\n\n2023-07-18 22:32:00\n\n\nLino Galiana\n\n\nChange badges (#376)\n\n\n\n\n143e706\n\n\n2023-07-18 19:37:28\n\n\nLino Galiana\n\n\nAm√©liore la navigation (#375)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\n64baaf8\n\n\n2023-07-03 17:05:53\n\n\nLino Galiana\n\n\nScript for branch deploy (#367)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n867325e\n\n\n2023-06-11 13:56:43\n\n\nLino Galiana\n\n\nAdd numeric_only argument (#359)\n\n\n\n\n9918817\n\n\n2022-12-30 15:10:59\n\n\nLino Galiana\n\n\nRetour sur le chapitre DallE / StableDiffusion (#344)\n\n\n\n\n94e7c0a\n\n\n2022-12-29 09:42:35\n\n\nLino Galiana\n\n\npip install pynsee (#342)\n\n\n\n\na8dd720\n\n\n2022-12-26 21:35:52\n\n\nLino Galiana\n\n\nImprove aesthetics on Github (#338)\n\n\n\n\ne2b53ac\n\n\n2022-09-28 17:09:31\n\n\nLino Galiana\n\n\nRetouche les chapitres pandas (#287)\n\n\n\n\neb8f922\n\n\n2022-09-22 17:40:43\n\n\nLino Galiana\n\n\nCorrige bug TP pandas (#276)\n\n\n\n\nfd439f0\n\n\n2022-09-19 09:37:50\n\n\navouacr\n\n\nfix ssp cloud links\n\n\n\n\n3056d41\n\n\n2022-09-02 12:19:55\n\n\navouacr\n\n\nfix all SSP Cloud launcher links\n\n\n\n\n8042a16\n\n\n2022-08-24 16:23:36\n\n\nLino Galiana\n\n\nBox pour les notebooks :sparkles: (#256)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n2360ff7\n\n\n2022-08-02 16:29:57\n\n\nLino Galiana\n\n\nTest wowchemy update (#247)\n\n\n\n\nd3a5406\n\n\n2022-06-27 17:44:30\n\n\nLino Galiana\n\n\nUtilisation test du syst√®me de r√©f√©rence de quarto (#240)\n\n\n\n\n1239e3e\n\n\n2022-06-21 14:05:15\n\n\nLino Galiana\n\n\nEnonces (#239)\n\n\n\n\n48606dd\n\n\n2022-05-31 19:05:11\n\n\nLino Galiana\n\n\nAm√©lioration rendu dataframe pandas (#229)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n5cac236\n\n\n2021-12-16 19:46:43\n\n\nLino Galiana\n\n\nun petit mot sur mercator (#201)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n5ad057f\n\n\n2021-10-10 15:13:16\n\n\nLino Galiana\n\n\nRelectures pandas & geopandas (#159)\n\n\n\n\n4870662\n\n\n2021-10-05 08:29:33\n\n\nRomain Avouac\n\n\nfix and simplify pyinsee install (#157)\n\n\n\n\n0677932\n\n\n2021-10-03 15:32:51\n\n\nLino Galiana\n\n\nAjoute un code pour download pynsee (#156)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4a317e3\n\n\n2021-08-31 12:38:17\n\n\nLino Galiana\n\n\npynsee pour importer des donn√©es Insee üöÄ (#127)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n175d377\n\n\n2021-05-04 18:29:26\n\n\nRaphaele Adjerad\n\n\nQuelques manipulations suppl√©mentaires pandas (#106)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n76e206c\n\n\n2020-09-09 18:02:08\n\n\nLino Galiana\n\n\nFinalisation du chapitre pandas (#24)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n85365ca\n\n\n2020-09-05 14:50:10\n\n\nlinogaliana\n\n\najout badges onyxia\n\n\n\n\n611be4d\n\n\n2020-09-05 14:27:47\n\n\nlinogaliana\n\n\nmodifs marginales\n\n\n\n\n0559398\n\n\n2020-09-05 14:22:55\n\n\nlinogaliana\n\n\nmodifs marginales\n\n\n\n\n9c12c2c\n\n\n2020-09-04 17:39:09\n\n\nLino Galiana\n\n\nIntroduction √† pandas (#11)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')"
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html",
    "href": "content/manipulation/02_pandas_suite.html",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#environnement",
    "href": "content/manipulation/02_pandas_suite.html#environnement",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "1.1 Environnement",
    "text": "1.1 Environnement\nLe chapitre pr√©c√©dent utilisait quasi exclusivement la librairie Pandas. Nous allons dans ce chapitre utiliser d‚Äôautres packages en compl√©ment de celui-ci.\nComme expliqu√© ci-dessous, nous allons utiliser une librairie nomm√©e pynsee pour r√©cup√©rer les donn√©es de l‚ÄôInsee utiles √† enrichir notre jeu de donn√©es de l‚ÄôAdeme. Cette librairie n‚Äôest pas install√©e par d√©faut dans Python. Avant de pouvoir l‚Äôutiliser,\nil est n√©cessaire de l‚Äôinstaller, comme la librairie great_tables que nous verrons √† la fin de ce chapitre:\n\n!pip install xlrd\n!pip install pynsee\n!pip install great_tables\n\nL‚Äôinstruction !pip install &lt;pkg&gt; est une mani√®re de faire comprendre √† Jupyter, le moteur d‚Äôex√©cution derri√®re les notebooks que la commande qui suit (pip install ce &lt;pkg&gt;)\nest une commande syst√®me, √† ex√©cuter hors de Python (dans le terminal par exemple pour un syst√®me Linux).\nLes premiers packages indispensables pour d√©marrer ce chapitre sont les suivants:\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pynsee\nimport pynsee.download\n\nPour obtenir des r√©sultats reproductibles, on peut fixer la racine du g√©n√©rateur\npseudo-al√©atoire.\n\nnp.random.seed(123)",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#donn√©es-utilis√©es",
    "href": "content/manipulation/02_pandas_suite.html#donn√©es-utilis√©es",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "1.2 Donn√©es utilis√©es",
    "text": "1.2 Donn√©es utilis√©es\nCe tutoriel continue l‚Äôexploration du jeu de donn√©es du chapitre pr√©c√©dent:\n\nLes √©missions de gaz √† effet de serre estim√©es au niveau communal par l‚ÄôADEME. Le jeu de donn√©es est\ndisponible sur data.gouv\net requ√™table directement dans Python avec\ncet url ;\n\nLes probl√©matiques d‚Äôenrichissement de donn√©es (association d‚Äôune source √† une autre √† partir de caract√©ristiques communes) seront pr√©sent√©es √† partir de deux sources produites par l‚ÄôInsee:\n\nLe\ncode officiel g√©ographique,\nun r√©f√©rentiel\nproduit par l‚ÄôInsee utilis√© pour identifier les communes √† partir d‚Äôun code unique, contrairement au code postal ;\nLes donn√©es Filosofi, une source sur les revenus des Fran√ßais √† une √©chelle spatiale fine construite par l‚ÄôInsee √† partir des d√©clarations fiscales et d‚Äôinformations sur les prestations sociales. En l‚Äôoccurrence, nous allons utiliser les niveaux de revenu et les populations1 au niveau communal afin de les mettre en regard de nos donn√©es d‚Äô√©missions.\n\nPour faciliter l‚Äôimport de donn√©es Insee, il est recommand√© d‚Äôutiliser le package\npynsee qui simplifie l‚Äôacc√®s aux principaux jeux de donn√©es\nde l‚ÄôInsee disponibles sur le site web insee.fr\nou via des API.\n\n\n Note\nLe package pynsee comporte deux principaux points d‚Äôentr√©e :\n\nLes API de l‚ÄôInsee, ce qui sera illustr√© dans le chapitre consacr√©.\nQuelques jeux de donn√©es directement issus du site web de\nl‚ÄôInsee (insee.fr)\n\nDans ce chapitre, nous allons exclusivement utiliser cette deuxi√®me\napproche. Cela se fera par le module pynsee.download.\nLa liste des donn√©es disponibles depuis ce package est ici.\nLa fonction download_file attend un identifiant unique\npour savoir quelle base de donn√©es aller chercher et\nrestructurer depuis le\nsite insee.fr.\n\n\nConna√Ætre la liste des bases disponibles\n\nPour conna√Ætre la liste des bases disponibles, vous\npouvez utiliser la fonction meta = pynsee.get_file_list()\napr√®s avoir fait import pynsee.\nCelle-ci renvoie un DataFrame dans lequel on peut\nrechercher, par exemple gr√¢ce √† une recherche\nde mots-clefs :\n\nimport pynsee\n\nmeta = pynsee.get_file_list()\nmeta.loc[meta[\"label\"].str.contains(r\"Filosofi.*2016\")]\n\n\n\n\n\n\n\n\n\nid\nname\nlabel\ncollection\nlink\ntype\nzip\nbig_zip\ndata_file\ntab\n...\nlabel_col\ndate_ref\nmeta_file\nseparator\ntype_col\nlong_col\nval_col\nencoding\nlast_row\nmissing_value\n\n\n\n\n79\nFILOSOFI_COM_2016\nFILOSOFI_COM\nDonn√©es Filosofi niveau communal ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nCOM\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n80\nFILOSOFI_EPCI_2016\nFILOSOFI_EPCI\nDonn√©es Filosofi niveau EPCI ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nEPCI\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n81\nFILOSOFI_ARR_2016\nFILOSOFI_ARR\nDonn√©es Filosofi niveau arondissement ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nARR\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n82\nFILOSOFI_DEP_2016\nFILOSOFI_DEP\nDonn√©es Filosofi niveau d√©partemental ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nDEP\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n83\nFILOSOFI_REG_2016\nFILOSOFI_REG\nDonn√©es Filosofi niveau r√©gional ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nREG\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n84\nFILOSOFI_METRO_2016\nFILOSOFI_METRO\nDonn√©es Filosofi niveau France m√©tropolitaine ...\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nMETRO\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n85\nFILOSOFI_AU2010_2016\nFILOSOFI_AU2010\nDonn√©es Filosofi niveau aire urbaine ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nAU2010\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n86\nFILOSOFI_UU2010_2016\nFILOSOFI_UU2010\nDonn√©es Filosofi niveau unit√© urbaine ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nUU2010\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n87\nFILOSOFI_ZE2010_2016\nFILOSOFI_ZE2010\nDonn√©es Filosofi niveau zone d‚Äôemploi ‚Äì 2016\nFILOSOFI\nhttps://www.insee.fr/fr/statistiques/fichier/4...\nxls\nTrue\nFalse\nbase-cc-filosofi-2016.xls\nZE2010\n...\nNaN\n2016-01-01\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n9 rows √ó 24 columns\n\n\n\n\nIci, meta['label'].str.contains(r\"Filosofi.*2016\") signifie:\n‚Äúpandas trouve moi tous les labels o√π sont contenus les termes Filosofi et 2016.‚Äù\n(.* signifiant ‚Äúpeu m‚Äôimporte le nombre de mots ou caract√®res entre‚Äù)",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#donn√©es-d√©mission-de-lademe",
    "href": "content/manipulation/02_pandas_suite.html#donn√©es-d√©mission-de-lademe",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "2.1 Donn√©es d‚Äô√©mission de l‚ÄôAdeme",
    "text": "2.1 Donn√©es d‚Äô√©mission de l‚ÄôAdeme\nComme expliqu√© au chapitre pr√©c√©dent, ces donn√©es peuvent √™tre import√©es tr√®s simplement avec Pandas\n\nimport pandas as pd\n\nurl = \"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\"\nemissions = pd.read_csv(url)\nemissions.head(2)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n\n\n\n\n\n\n\n\nNous allons d‚Äôores et d√©j√† conserver le nom des secteurs √©metteurs pr√©sents dans la base de donn√©es pour simplifier des utilisations ult√©rieures:\n\nsecteurs = emissions.select_dtypes(include=\"number\").columns\n\nLes exploitations ult√©rieures de ces donn√©es utiliseront la dimension d√©partementale dont nous avons montr√© la construction au chapitre pr√©c√©dent:\n\nemissions[\"dep\"] = emissions[\"INSEE commune\"].str[:2]",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#donn√©es-filosofi",
    "href": "content/manipulation/02_pandas_suite.html#donn√©es-filosofi",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "2.2 Donn√©es Filosofi",
    "text": "2.2 Donn√©es Filosofi\nOn va utiliser les donn√©es Filosofi (donn√©es de revenus) au niveau communal de 2016.\nCe n‚Äôest pas la m√™me ann√©e que les donn√©es d‚Äô√©mission de CO2, ce n‚Äôest donc pas parfaitement rigoureux,\nmais cela permettra tout de m√™me d‚Äôillustrer\nles principales fonctionnalit√©s de Pandas\nLe point d‚Äôentr√©e principal de la fonction pynsee est la fonction download_file.\nLe code pour t√©l√©charger les donn√©es est le suivant :\n\nfrom pynsee.download import download_file\n\nfilosofi = download_file(\"FILOSOFI_COM_2016\")\n\nLe DataFrame en question a l‚Äôaspect suivant :\n\nfilosofi.sample(3)\n\n\n\n\n\n\n\n\n\nCODGEO\nLIBGEO\nNBMENFISC16\nNBPERSMENFISC16\nMED16\nPIMP16\nTP6016\nTP60AGE116\nTP60AGE216\nTP60AGE316\n...\nPPEN16\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\n\n\n\n\n34640\n93077\nVillemomble\n11968\n30123.5\n21782.222222222223\n61\n19\n22\n23\n19\n...\n23.1\n9\n5.1\n2.1\n1.7\n1.3\n-19.6\n9371.481481481482\n40950.8\n4.36972532901237\n\n\n9988\n28073\nChampseru\n121\n326.5\n24806\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n17537\n48190\nTermes\n92\n210.5\n19108.571428571428\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n3 rows √ó 29 columns\n\n\n\n\nPandas a g√©r√© automatiquement les types de variables. Il le fait relativement bien, mais une v√©rification est toujours utile pour les variables qui ont un statut sp√©cifique.\nPour les variables qui ne sont pas en type float alors qu‚Äôelles devraient l‚Äô√™tre, on modifie leur type.\n\nfilosofi = filosofi.astype({c: \"float\" for c in filosofi.columns[2:]})\n\nUn simple coup d‚Äôoeil sur les donn√©es\ndonne une id√©e assez pr√©cise de la mani√®re dont les donn√©es sont organis√©es.\nOn remarque que certaines variables de filosofi semblent avoir beaucoup de valeurs manquantes (secret statistique)\nalors que d‚Äôautres semblent compl√®tes.\nSi on d√©sire exploiter filosofi, il faut faire attention √† la variable choisie.\nNotre objectif √† terme va √™tre de relier l‚Äôinformation contenue entre ces\ndeux jeux de donn√©es. En effet, sinon, nous risquons d‚Äô√™tre frustr√© : nous allons\nvouloir en savoir plus sur les √©missions de gaz carbonique mais seront tr√®s\nlimit√©s dans les possibilit√©s d‚Äôanalyse sans ajout d‚Äôune information annexe\nissue de filosofi.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#principe",
    "href": "content/manipulation/02_pandas_suite.html#principe",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "3.1 Principe",
    "text": "3.1 Principe\nNous avons vu, lors du chapitre pr√©c√©dent, comment obtenir\nune statistique agr√©g√©e simplement gr√¢ce √† Pandas.\nIl est n√©anmoins commun d‚Äôavoir des donn√©es avec des strates\ninterm√©diaires d‚Äôanalyse pertinentes: des variables g√©ographiques, l‚Äôappartenance √† des groupes socio-d√©mographiques li√©s √† des caract√©ristiques renseign√©es, des indicatrices de p√©riode temporelle, etc.\nPour mieux comprendre la structure de ses donn√©es, les data scientists sont donc souvent amen√©s √† construire des statistiques descriptives sur des sous-groupes pr√©sents dans les donn√©es. Pour reprendre l‚Äôexemple sur les √©missions, nous avions pr√©c√©demment construit des statistiques d‚Äô√©missions au niveau national. Mais qu‚Äôen est-il du profil d‚Äô√©mission des diff√©rents d√©partements ? Pour r√©pondre √† cette question, il sera utile d‚Äôagr√©ger nos donn√©es au niveau d√©partemental. Ceci nous donnera une information diff√©rente du jeu de donn√©es initial (niveau communal) et du niveau le plus agr√©g√© (niveau national).\nEn SQL, il est tr√®s simple de d√©couper des donn√©es pour\neffectuer des op√©rations sur des blocs coh√©rents et recollecter des r√©sultats\ndans la dimension appropri√©e.\nLa logique sous-jacente est celle du split-apply-combine qui est repris\npar les langages de manipulation de donn√©es, auxquels pandas\nne fait pas exception.\nL‚Äôimage suivante, issue de\nce site,\nrepr√©sente bien la mani√®re dont fonctionne l‚Äôapproche\nsplit-apply-combine:\n\n\n\nSplit-apply-combine (Source: unlhcc.github.io)\n\n\nEn Pandas, on utilise groupby pour d√©couper les donn√©es selon un ou\nplusieurs axes (ce tutoriel sur le sujet\nest particuli√®rement utile).\nL‚Äôensemble des op√©rations d‚Äôagr√©gation (comptage, moyennes, etc.) que nous avions vues pr√©c√©demment peut √™tre mise en oeuvre par groupe.\nTechniquement, cette op√©ration consiste √† cr√©er une association\nentre des labels (valeurs des variables de groupe) et des\nobservations. Utiliser la m√©thode groupby ne d√©clenche pas d‚Äôop√©rations avant la mise en oeuvre d‚Äôune statistique, cela cr√©√© seulement une relation formelle entre des observations et des regroupemens qui seront utilis√©s a posteriori:\n\nfilosofi[\"dep\"] = filosofi[\"CODGEO\"].str[:2]\nfilosofi.groupby(\"dep\").__class__\n\npandas.core.groupby.generic.DataFrameGroupBy\n\n\nTant qu‚Äôon n‚Äôappelle pas une action sur un DataFrame par groupe, du type\nhead ou display, pandas n‚Äôeffectue aucune op√©ration. On parle de\nlazy evaluation. Par exemple, le r√©sultat de df.groupby('dep') est\nune transformation qui n‚Äôest pas encore √©valu√©e :\n\nfilosofi.groupby(\"dep\")\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f432c292dd0&gt;",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#illustration-1-d√©nombrement-par-groupe",
    "href": "content/manipulation/02_pandas_suite.html#illustration-1-d√©nombrement-par-groupe",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "3.2 Illustration 1: d√©nombrement par groupe",
    "text": "3.2 Illustration 1: d√©nombrement par groupe\nPour illustrer l‚Äôapplication de ce principe √† un comptage, on peut d√©nombrer le nombre de communes par d√©partement en 2023 (chaque ann√©e cette statistique change du fait des fusions de communes). Pour cela, il suffit de prendre le r√©f√©rentiel des communes fran√ßaises issu du code officiel g√©ographique (COG) et d√©nombrer par d√©partement gr√¢ce √† count:\n\nimport pandas as pd\n\nurl_cog_2023 = \"https://www.insee.fr/fr/statistiques/fichier/6800675/v_commune_2023.csv\"\ncog_2023 = pd.read_csv(url_cog_2023)\n\nGr√¢ce √† ce jeu de donn√©es, sans avoir recours aux statistiques par groupe, on peut d√©j√† savoir combien on a, respectivement, de communes, d√©partements et r√©gions en France:\n\n1communes = cog_2023.loc[cog_2023[\"TYPECOM\"] == \"COM\"]\ncommunes.loc[:, [\"COM\", \"DEP\", \"REG\"]].nunique()\n\n\n1\n\nOn se restreint au statut ‚ÄúCommune‚Äù car ce fichier comporte √©galement les codes Insee pour d‚Äôautres status, comme les ‚ÄúArrondissements municipaux‚Äù de Paris, Lyon et Marseille.\n\n\n\n\nCOM    34945\nDEP      101\nREG       18\ndtype: int64\n\n\nMaintenant, int√©ressons nous aux d√©partements ayant le plus de communes. Il s‚Äôagit de la m√™me fonction de d√©nombrement o√π on joue, cette fois, sur le groupe √† partir duquel est calcul√© la statistique.\nCalculer cette statistique se fait de mani√®re assez transparente lorsqu‚Äôon conna√Æt le principe d‚Äôun calcul de statistiques avec Pandas:\n\ncommunes = cog_2023.loc[cog_2023[\"TYPECOM\"] == \"COM\"]\ncommunes.groupby(\"DEP\").agg({\"COM\": \"nunique\"})\n\n\n\n\n\n\n\n\n\nCOM\n\n\nDEP\n\n\n\n\n\n01\n392\n\n\n02\n798\n\n\n03\n317\n\n\n04\n198\n\n\n05\n162\n\n\n...\n...\n\n\n971\n32\n\n\n972\n34\n\n\n973\n22\n\n\n974\n24\n\n\n976\n17\n\n\n\n\n101 rows √ó 1 columns\n\n\n\n\nEn SQL, on utiliserait la requ√™te suivante:\nSELECT dep, COUNT DISTINCT \"COM\" AS COM \nFROM communes\nGROUP BY dep \nWHERE TYPECOM == 'COM';\nLa sortie est une Serie index√©e. Ce n‚Äôest pas tr√®s pratique comme nous avons pu l‚Äô√©voquer au cours du chapitre pr√©c√©dent. Il est plus pratique de transformer cet objet en DataFrame avec reset_index. Enfin, avec sort_values, on obtient la statistique d√©sir√©e:\n\n(\n    communes.groupby(\"DEP\")\n    .agg({\"COM\": \"nunique\"})\n    .reset_index()\n    .sort_values(\"COM\", ascending=False)\n)\n\n\n\n\n\n\n\n\n\nDEP\nCOM\n\n\n\n\n62\n62\n890\n\n\n1\n02\n798\n\n\n80\n80\n772\n\n\n57\n57\n725\n\n\n76\n76\n708\n\n\n...\n...\n...\n\n\n96\n971\n32\n\n\n99\n974\n24\n\n\n98\n973\n22\n\n\n100\n976\n17\n\n\n75\n75\n1\n\n\n\n\n101 rows √ó 2 columns",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#illustration-2-agr√©gats-par-groupe",
    "href": "content/manipulation/02_pandas_suite.html#illustration-2-agr√©gats-par-groupe",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "3.3 Illustration 2: agr√©gats par groupe",
    "text": "3.3 Illustration 2: agr√©gats par groupe\nPour illustrer les agr√©gats par groupe nous pouvons prendre le jeu de donn√©es de l‚ÄôInsee filosofi et compter la population gr√¢ce √† la variable NBPERSMENFISC16.\nPour calculer le total au niveau France enti√®re nous pouvons faire de deux mani√®res :\n\nfilosofi[\"NBPERSMENFISC16\"].sum() * 1e-6\n\n66.9322415\n\n\n\nfilosofi.agg({\"NBPERSMENFISC16\": \"sum\"}).div(1e6)\n\nNBPERSMENFISC16    66.932242\ndtype: float64\n\n\no√π les r√©sultats sont report√©s en millions de personnes. La logique est identique lorsqu‚Äôon fait des statistiques par groupe, il s‚Äôagit seulement de remplacer filosofi par filosofi.groupby('dep') pour cr√©er une version partitionn√©e par d√©partement de notre jeu de donn√©es:\n\n1filosofi.groupby(\"dep\")[\"NBPERSMENFISC16\"].sum()\n\n\n1\n\nAvec cette approche, il faut faire attention √† l‚Äôordre des op√©rations: d‚Äôabord on effectue le groupby puis on conserve la colonne d‚Äôint√©r√™t\n\n\n\n\ndep\n01     613088.0\n02     514249.0\n03     329435.0\n04     156537.5\n05     133992.5\n        ...    \n92    1583682.0\n93    1586664.5\n94    1345977.0\n95    1226059.0\n97    1191947.0\nName: NBPERSMENFISC16, Length: 97, dtype: float64\n\n\n\nfilosofi.groupby(\"dep\").agg({\"NBPERSMENFISC16\": \"sum\"})\n\n\n\n\n\n\n\n\n\nNBPERSMENFISC16\n\n\ndep\n\n\n\n\n\n01\n613088.0\n\n\n02\n514249.0\n\n\n03\n329435.0\n\n\n04\n156537.5\n\n\n05\n133992.5\n\n\n...\n...\n\n\n92\n1583682.0\n\n\n93\n1586664.5\n\n\n94\n1345977.0\n\n\n95\n1226059.0\n\n\n97\n1191947.0\n\n\n\n\n97 rows √ó 1 columns\n\n\n\n\nLa seconde approche est plus pratique car elle donne directement un DataFrame Pandas et non une s√©rie index√©e sans nom. A partir de celle-ci, quelques manipulations basiques peuvent suffire pour avoir un tableau diffusables sur la d√©mographie d√©partementale. N√©anmoins, celui-ci, serait quelques peu brut de d√©coffrage car nous ne poss√©dons √† l‚Äôheure actuelle que les num√©ros de d√©partement. Pour avoir le nom de d√©partements, il faudrait utiliser une deuxi√®me base de donn√©es et croiser les informations communes entre elles (en l‚Äôoccurrence le num√©ro du d√©partement). C‚Äôest l‚Äôobjet de la prochaine partie.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#exercice-dapplication",
    "href": "content/manipulation/02_pandas_suite.html#exercice-dapplication",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "3.4 Exercice d‚Äôapplication",
    "text": "3.4 Exercice d‚Äôapplication\nCet exercice d‚Äôapplication s‚Äôappuie sur le jeu de donn√©es de l‚ÄôAdeme nomm√© emissions pr√©c√©demment.\n\n\n Exercice 1 : agr√©gations par groupe\n\nCalculer les √©missions totales du secteur ‚ÄúR√©sidentiel‚Äù par d√©partement et rapporter la valeur au d√©partement le plus polluant dans le domaine. En tirer des intutitions sur la r√©alit√© que cette statistique refl√®te.\nCalculer, pour chaque d√©partement, les √©missions totales de chaque secteur. Pour chaque d√©partement, calculer la proportion des √©missions totales venant de chaque secteur.\n\n\n\nIndice pour cette question\n\n\n‚ÄúGrouper par‚Äù = groupby\n‚Äú√©missions totales‚Äù = agg({*** : \"sum\"})\n\n\n\n\nA la question 1, le r√©sultat obtenu devrait √™tre le suivant:\n\n\n\n\n\n\n\n\n\n\ndep\nR√©sidentiel\nR√©sidentiel (% valeur max)\n\n\n\n\n59\n59\n3.498347e+06\n1.000000\n\n\n75\n75\n1.934580e+06\n0.552998\n\n\n69\n69\n1.774653e+06\n0.507283\n\n\n62\n62\n1.738090e+06\n0.496832\n\n\n57\n57\n1.644192e+06\n0.469991\n\n\n\n\n\n\n\n\nCe classement refl√®te peut-√™tre plus la d√©mographie que le processus qu‚Äôon d√©sire mesurer. Sans l‚Äôajout d‚Äôune information annexe sur la population de chaque d√©partement pour contr√¥ler ce facteur, on peut difficilement savoir s‚Äôil y a une diff√©rence structurelle de comportement entre les habitants du Nord (d√©partement 59) et ceux de la Moselle (d√©partement 57).\nA l‚Äôissue de la question 2, prenons la part des √©missions de l‚Äôagriculture et du secteur tertiaire dans les √©missions d√©partementales:\n\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n...\nPart Agriculture\nPart Autres transports\nPart Autres transports international\nPart CO2 biomasse hors-total\nPart D√©chets\nPart Energie\nPart Industrie hors-√©nergie\nPart R√©sidentiel\nPart Routier\nPart Tertiaire\n\n\ndep\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n23\n1.430068e+06\n5060.057601\n0.000000\n210196.604389\n26550.858041\n9752.578164\n28626.245699\n134197.515156\n434767.868975\n70733.245013\n...\n60.855172\n0.215326\n0.000000\n8.944716\n1.129846\n0.415012\n1.218163\n5.710647\n18.501132\n3.009986\n\n\n48\n7.510594e+05\n5697.938112\n0.000000\n70903.948092\n26011.591018\n6065.340741\n17803.285591\n61033.998303\n253618.488432\n43661.121359\n...\n60.772448\n0.461052\n0.000000\n5.737238\n2.104744\n0.490781\n1.440564\n4.938605\n20.521701\n3.532867\n\n\n15\n1.539204e+06\n8261.874450\n18.804572\n228415.892777\n44814.875202\n13138.432196\n85214.659284\n128315.601994\n443832.903418\n84364.615635\n...\n59.761414\n0.320777\n0.000730\n8.868517\n1.739990\n0.510115\n3.308560\n4.982005\n17.232336\n3.275556\n\n\n12\n2.122331e+06\n13796.608978\n3124.844800\n331420.983449\n52412.681268\n35405.484754\n112897.690887\n268862.654280\n795413.985637\n170211.845832\n...\n54.336847\n0.353227\n0.080004\n8.485186\n1.341893\n0.906467\n2.890457\n6.883541\n20.364540\n4.357839\n\n\n32\n1.026604e+06\n4599.824552\n0.000000\n201732.703762\n50950.668326\n16651.432346\n53468.498055\n158218.000190\n446345.993580\n105662.674213\n...\n49.732924\n0.222835\n0.000000\n9.772766\n2.468261\n0.806664\n2.590235\n7.664734\n21.622845\n5.118737\n\n\n\n\n5 rows √ó 21 columns\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\n...\nPart Agriculture\nPart Autres transports\nPart Autres transports international\nPart CO2 biomasse hors-total\nPart D√©chets\nPart Energie\nPart Industrie hors-√©nergie\nPart R√©sidentiel\nPart Routier\nPart Tertiaire\n\n\ndep\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n75\n0.000000\n42216.829025\n1.837660e+02\n1.186577e+06\n27358.781206\n147965.117571\n434314.469384\n1.934580e+06\n1.625583e+06\n1.331630e+06\n...\n0.000000\n0.627255\n0.002730\n17.630092\n0.406495\n2.198457\n6.453018\n28.743870\n24.152808\n19.785275\n\n\n94\n2259.429643\n218992.353559\n3.146283e+05\n6.914050e+05\n213619.661516\n76341.230740\n467189.038927\n1.336894e+06\n1.169432e+06\n7.636502e+05\n...\n0.043001\n4.167781\n5.987888\n13.158562\n4.065530\n1.452898\n8.891367\n25.443275\n22.256193\n14.533505\n\n\n92\n91.408184\n12340.794839\n2.101194e+02\n1.067889e+06\n264497.880711\n242842.018012\n706597.424067\n1.466794e+06\n1.198420e+06\n8.360132e+05\n...\n0.001577\n0.212930\n0.003625\n18.425550\n4.563695\n4.190041\n12.191761\n25.308332\n20.677765\n14.424724\n\n\n93\n2018.470982\n59617.086124\n1.101400e+06\n7.259516e+05\n252166.943778\n102837.663903\n433216.360990\n1.316452e+06\n1.396911e+06\n8.630178e+05\n...\n0.032277\n0.953326\n17.612287\n11.608558\n4.032355\n1.644458\n6.927483\n21.051146\n22.337751\n13.800359\n\n\n83\n151715.557862\n21772.374976\n2.854770e+04\n5.795888e+05\n233522.964403\n47044.063669\n139710.930613\n5.938382e+05\n1.944266e+06\n5.610540e+05\n...\n3.527399\n0.506209\n0.663736\n13.475487\n5.429428\n1.093778\n3.248291\n13.806786\n45.204334\n13.044551\n\n\n\n\n5 rows √ó 21 columns\n\n\n\n\nCes r√©sultats sont assez logiques ; les d√©partements ruraux ont une part plus importante de leur √©mission issue de l‚Äôagriculture, les d√©partements urbains ont plus d‚Äô√©missions issues du secteur tertiaire, ce qui est li√© √† la densit√© plus importante de ces espaces.\nGr√¢ce √† ces statistiques on progresse dans la connaissance de notre jeu de donn√©es et donc de la nature des √©missions de C02 en France.\nLes statistiques descriptives par groupe nous permettent de mieux saisir l‚Äôh√©t√©rog√©n√©it√© spatiale de notre ph√©nom√®ne.\nCependant, on reste limit√© dans notre capacit√© √† interpr√©ter les statistiques obtenues sans recourir √† l‚Äôutilisation d‚Äôinformation annexe. Pour donner du sens et de la valeur √† une statistique, il faut g√©n√©ralement associer celle-ci √† de la connaissance annexe sous peine qu‚Äôelle soit d√©sincarn√©e.\nDans la suite de ce chapitre, nous envisagerons une premi√®re voie qui est le croisement avec des donn√©es compl√©mentaires. On appelle ceci un enrichissement de donn√©es. Ces donn√©es peuvent √™tre des observations √† un niveau identique √† celui de la source d‚Äôorigine. Par exemple, l‚Äôun des croisements les plus communs est d‚Äôassocier une base client √† une base d‚Äôachats afin de mettre en regard un comportement d‚Äôachat avec des caract√©ristiques pouvant expliquer celui-ci. Les associations de donn√©es peuvent aussi se faire √† des niveaux conceptuels diff√©rents, en g√©n√©ral √† un niveau plus agr√©g√© pour contextualiser la donn√©e plus fine et comparer une observation √† des mesures dans un groupe similaire. Par exemple, on peut associer des temps et des modes de transports individuels √† ceux d‚Äôune m√™me classe d‚Äô√¢ge ou de personnes r√©sidant dans la m√™me commune pour pouvoir comparer la diff√©rence entre certains individus et un groupe sociod√©mographique similaire.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#principe-1",
    "href": "content/manipulation/02_pandas_suite.html#principe-1",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "4.1 Principe",
    "text": "4.1 Principe\nQuand on a plusieurs informations pour un m√™me individu ou groupe, on\nretrouve g√©n√©ralement deux types de structure de donn√©es :\n\nformat wide : les donn√©es comportent des observations r√©p√©t√©es, pour un m√™me individu (ou groupe), dans des colonnes diff√©rentes\nformat long : les donn√©es comportent des observations r√©p√©t√©es, pour un m√™me individu, dans des lignes diff√©rentes avec une colonne permettant de distinguer les niveaux d‚Äôobservations\n\nUn exemple de la distinction entre les deux peut √™tre pris √† l‚Äôouvrage de r√©f√©rence d‚ÄôHadley Wickham, R for Data Science:\n\n\n\nDonn√©es long et wide (Source: R for Data Science)\n\n\nL‚Äôaide m√©moire suivante aidera √† se rappeler les fonctions √† appliquer si besoin :\n\nLe fait de passer d‚Äôun format wide au format long (ou vice-versa)\npeut √™tre extr√™mement pratique car certaines fonctions sont plus ad√©quates sur une forme de donn√©es ou sur l‚Äôautre.\nEn r√®gle g√©n√©rale, avec Python comme avec R, les formats long sont souvent pr√©f√©rables.\nLes formats wide sont plut√¥t pens√©s pour des tableurs comme Excel ou on dispose d‚Äôun nombre r√©duit\nde lignes √† partir duquel faire des tableaux crois√©s dynamiques.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#exercice-dapplication-1",
    "href": "content/manipulation/02_pandas_suite.html#exercice-dapplication-1",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "4.2 Exercice d‚Äôapplication",
    "text": "4.2 Exercice d‚Äôapplication\nLes donn√©es de l‚ÄôADEME, et celles de l‚ÄôInsee √©galement, sont au format\nwide.\nLe prochain exercice illustre l‚Äôint√©r√™t de faire la conversion long \\(\\to\\) wide\navant de faire un graphique avec la m√©thode plot vue au chapitre pr√©c√©dent\n\n\n Exercice 2: Restructurer les donn√©es : wide to long\n\nCr√©er une copie des donn√©es de l‚ÄôADEME en faisant df_wide = emissions_wide.copy()\nRestructurer les donn√©es au format long pour avoir des donn√©es d‚Äô√©missions par secteur en gardant comme niveau d‚Äôanalyse la commune (attention aux autres variables identifiantes).\nFaire la somme par secteur et repr√©senter graphiquement\nGarder, pour chaque d√©partement, le secteur le plus polluant",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#principe-2",
    "href": "content/manipulation/02_pandas_suite.html#principe-2",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "5.1 Principe",
    "text": "5.1 Principe\nNous allons ici nous focaliser sur le cas le plus favorable qui est la situation\no√π une information permet d‚Äôapparier de mani√®re exacte deux bases de donn√©es2.\nC‚Äôest un besoin quotidien des data scientists d‚Äôassocier des informations pr√©sentes dans plusieurs fichiers. Par exemple, dans des bases de donn√©es d‚Äôentreprises, les informations clients (adresse, √¢ge, etc.) seront dans un fichier, les ventes dans un autre et les caract√©ristiques des produits dans un troisi√®me fichier. Afin d‚Äôavoir une base compl√®te mettant en regard toutes ces informations, il sera d√®s lors n√©cessaire de joindre ces trois fichiers sur la base d‚Äôinformations communes.\nCette pratique d√©coule du fait que de nombreux syst√®mes d‚Äôinformation prennent la forme d‚Äôun sch√©ma en √©toile:\n\n\n\nIllustration du sch√©ma en √©toile (Source: Databricks)\n\n\nCette structuration de l‚Äôinformation est tr√®s li√©e au mod√®le des tables relationnelles des ann√©es 1980. Aujourd‚Äôhui, il existe des mod√®les de donn√©es plus flexibles o√π l‚Äôinformation est empil√©e dans un data lake sans structure a priori. N√©anmoins ce mod√®le du sch√©ma en √©toile conserve une pertinence parce qu‚Äôil permet de partager l‚Äôinformation qu‚Äô√† ceux qui en ont besoin laissant le soin √† ceux qui ont besoin de lier des donn√©es entre elles de le faire.\nPuisque la logique du sch√©ma en √©toile vient historiquement des bases relationnelles, il est naturel qu‚Äôil s‚Äôagisse d‚Äôune approche intrins√®quement li√©e √† la philosophie du SQL, jusque dans le vocabulaire. On parle souvent de jointure de donn√©es, un h√©ritage du terme JOIN de SQL, et la mani√®re de d√©crire les jointures (left join, right join‚Ä¶) est directement issue des instructions SQL associ√©es.\nOn parle g√©n√©ralement de base de gauche et de droite pour illustrer les jointures:",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#mise-en-oeuvre-avec-pandas",
    "href": "content/manipulation/02_pandas_suite.html#mise-en-oeuvre-avec-pandas",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "5.2 Mise en oeuvre avec Pandas",
    "text": "5.2 Mise en oeuvre avec Pandas\nEn Pandas, la m√©thode la plus pratique pour associer des jeux de donn√©es √† partir de caract√©ristiques communes est merge. Ses principaux arguments permettent de contr√¥ler le comportement de jointure. Nous allons les explorer de mani√®re visuelle.\nEn l‚Äôoccurrence, pour notre probl√©matique de construction de statistiques\nsur les √©missions de gaz carbonique, la base de gauche sera le DataFrame emission et la base de droite le DataFrame filosofi:\n\nemissions.head(2)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n01\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n01\n\n\n\n\n\n\n\n\n\nfilosofi.head(2)\n\n\n\n\n\n\n\n\n\nCODGEO\nLIBGEO\nNBMENFISC16\nNBPERSMENFISC16\nMED16\nPIMP16\nTP6016\nTP60AGE116\nTP60AGE216\nTP60AGE316\n...\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\ndep\n\n\n\n\n0\n01001\nL'Abergement-Cl√©menciat\n313.0\n795.5\n22679.000000\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n01\n\n\n1\n01002\nL'Abergement-de-Varey\n101.0\n248.0\n24382.083333\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n01\n\n\n\n\n2 rows √ó 30 columns\n\n\n\n\nOn parle de cl√©(s) de jointure pour nommer la ou les variable(s) n√©cessaire(s) √† la fusion de donn√©es. Ce sont les variables communes aux deux jeux de donn√©es. Il n‚Äôest pas n√©cessaire qu‚Äôelles aient le m√™me nom en revanche elles doivent partager des valeurs communes autrement l‚Äôintersection entre ces deux bases est l‚Äôensemble vide.\nOn peut jouer sur deux dimensions dans la jointure (ceci sera plus clair ensuite avec les exemples graphiques).\n\nIl existe principalement trois types de fusions: left join et right join ou un combo des deux selon le type de pivot qu‚Äôon d√©sire mettre en oeuvre.\nEnsuite, il existe deux mani√®res de fusionner les valeurs une fois qu‚Äôon a choisi un pivot: inner ou outer join. Dans le premier cas, on ne conserve que les observations o√π les cl√©s de jointures sont pr√©sentes dans les deux bases, dans le second on conserve toutes les observations de la cl√© de jointure des variables pivot quitte √† avoir des valeurs manquantes si la deuxi√®me base de donn√©es n‚Äôa pas de telles observations.\n\nDans les exemples ci-dessous, nous allons utiliser les codes communes et les d√©partements comme variables de jointure. En soi, l‚Äôusage du d√©partement n‚Äôest pas n√©cessaire puisqu‚Äôil se d√©duit directement du code commune mais cela permet d‚Äôillustrer le principe des jointures sur plusieurs variables. A noter que le nom de la commune est volontairement mis de c√¥t√© pour effectuer des jointures alors que c‚Äôest une information commune aux deux bases. Cependant, comme il s‚Äôagit d‚Äôun champ textuel, dont le formattage peut suivre une norme diff√©rente dans les deux bases, ce n‚Äôest pas une information fiable pour faire une jointure exacte.\nPour illustrer le principe du pivot √† gauche ou √† droite, on va cr√©er deux variables identificatrices de la ligne de nos jeux de donn√©es de gauche et de droite. Cela nous permettra de trouver facilement les lignes pr√©sentes dans un jeu de donn√©es mais pas dans l‚Äôautre.\n\nemissions = emissions.reset_index(names=[\"id_left\"])\nfilosofi = filosofi.reset_index(names=[\"id_right\"])\n\n\n5.2.1 Left join\nCommen√ßons avec la jointure √† gauche. Comme son nom l‚Äôindique, on va prendre la variable de gauche en pivot:\n\n\nleft_merged = emissions.merge(\n    filosofi, left_on=[\"INSEE commune\", \"dep\"], right_on=[\"CODGEO\", \"dep\"], how=\"left\"\n)\nleft_merged.head(3)\n\n\n\n\n\n\n\n\n\nid_left\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\n...\nPPEN16\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\n\n\n\n\n0\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n...\n27.0\n8.8\n6.9\n2.8\n2.1\n2.0\n-15.7\n10457.083333\n33880.555556\n3.239962\n\n\n\n\n3 rows √ó 44 columns\n\n\n\n\nIl est recommand√© de toujours expliciter les cl√©s de jointures par le biais des arguments left_on, right_on ou on si les noms de variables sont communs dans les deux bases.\nSi on a des noms de variables communes entre les bases mais qu‚Äôelles ne sont pas d√©finies comme cl√©s de jointures, celles-ci ne seront pas utilis√©es pour joindre mais seront conserv√©es avec un suffixe qui par d√©faut est _x et _y (param√©trable par le biais de l‚Äôargument suffixes).\nLa syntaxe Pandas √©tant directement inspir√©e de SQL, on a une traduction assez transparente de l‚Äôinstruction ci-dessus en SQL:\nSELECT *\nFROM emissions\nLEFT JOIN filosofi\n  ON emissions.`INSEE commune` = filosofi.CODGEO\n  AND emissions.dep = filosofi.dep;\nEn faisant une jointure √† gauche, on doit en principe avoir autant de lignes que la base de donn√©es √† gauche:\n\nleft_merged.shape[0] == emissions.shape[0]\n\nTrue\n\n\nAutrement, cela est signe qu‚Äôil y a une cl√© dupliqu√©e √† droite. Gr√¢ce √† notre variable id_right, on peut savoir les codes communes √† droite qui n‚Äôexistent pas √† gauche:\n\nleft_merged.loc[left_merged[\"id_right\"].isna()].tail(3)\n\n\n\n\n\n\n\n\n\nid_left\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\n...\nPPEN16\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\n\n\n\n\n35348\n35348\n91182\nCOURCOURONNES\n24.548795\n103.360309\nNaN\n9623.065698\n111.241872\n1276.170296\n3745.877636\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n35360\n35360\n91222\nESTOUCHES\n1790.002871\nNaN\nNaN\n113.797978\n30.548162\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n35687\n35687\n95259\nGADANCOURT\n312.298700\nNaN\nNaN\n142.113291\n11.372909\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n3 rows √ó 44 columns\n\n\n\n\nCela vient du fait que nous utilisons des donn√©es qui ne sont pas de la m√™me ann√©e de r√©f√©rence du code officiel g√©ographique (2016 vs 2018). Pendant cet intervalle, il y a eu des changements de g√©ographie, notamment des fusions de communes. Par exemple, la commune de Courcouronnes qu‚Äôon a vu ci-dessus peut √™tre retrouv√©e regroup√©e avec Evry dans le jeu de donn√©es filosofi (base de droite):\n\nfilosofi.loc[filosofi[\"LIBGEO\"].str.lower().str.contains(\"courcouronnes\")]\n\n\n\n\n\n\n\n\n\nid_right\nCODGEO\nLIBGEO\nNBMENFISC16\nNBPERSMENFISC16\nMED16\nPIMP16\nTP6016\nTP60AGE116\nTP60AGE216\n...\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\ndep\n\n\n\n\n34441\n34441\n91228\n√âvry-Courcouronnes\n23761.0\n65184.5\n17107.0\n47.0\n26.0\n30.0\n26.0\n...\n4.0\n10.5\n4.4\n3.1\n2.9\n-15.0\n9139.090909\n30888.0\n3.379767\n91\n\n\n\n\n1 rows √ó 31 columns\n\n\n\n\nDans un exercice de construction de statistiques publiques, on ne pourrait donc se permettre cette disjonction des ann√©es.\n\n\n5.2.2 _Right join__\n\nLe principe est le m√™me mais cette fois c‚Äôest la base de droite qui est prise sous forme de pivot:\n\nright_merged = emissions.merge(\n    filosofi, left_on=[\"INSEE commune\", \"dep\"], right_on=[\"CODGEO\", \"dep\"], how=\"right\"\n)\nright_merged.head(3)\n\n\n\n\n\n\n\n\n\nid_left\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\n...\nPPEN16\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\n\n\n\n\n0\n0.0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1.0\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n2.0\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n...\n27.0\n8.8\n6.9\n2.8\n2.1\n2.0\n-15.7\n10457.083333\n33880.555556\n3.239962\n\n\n\n\n3 rows √ó 44 columns\n\n\n\n\nL‚Äôinstruction √©quivalente en SQL serait\nSELECT *\nFROM filosofi\nRIGHT JOIN emissions\n  ON filosofi.CODGEO = emissions.`INSEE commune`\n  AND filosofi.dep = emissions.dep;\nOn peut, comme pr√©c√©demment, v√©rifier la coh√©rence des dimensions:\n\nright_merged.shape[0] == filosofi.shape[0]\n\nTrue\n\n\nPour v√©rifier le nombre de lignes des donn√©es Filosofi que nous n‚Äôavons pas dans notre jeu d‚Äô√©missions de gaz carbonique, on peut faire\n\nright_merged[\"id_left\"].isna().sum()\n\n61\n\n\nC‚Äôest un nombre faible. Quelles sont ces observations ?\n\nright_merged.loc[\n    right_merged[\"id_left\"].isna(),\n    filosofi.columns.tolist() + emissions.columns.tolist(),\n]\n\n\n\n\n\n\n\n\n\nid_right\nCODGEO\nLIBGEO\nNBMENFISC16\nNBPERSMENFISC16\nMED16\nPIMP16\nTP6016\nTP60AGE116\nTP60AGE216\n...\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\n\n\n\n\n4346\n4346\n13055\nMarseille\n362971.0\n815045.5\n18248.000000\n47.0\n26.0\n34.0\n30.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n13\n\n\n27115\n27115\n69123\nLyon\n225617.0\n459305.5\n22806.000000\n60.0\n15.0\n21.0\n13.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n69\n\n\n29288\n29288\n75056\nParis\n1027657.0\n2074629.5\n26808.000000\n69.0\n16.0\n17.0\n13.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n75\n\n\n34874\n34874\n97201\nL'Ajoupa-Bouillon\n688.0\n1634.0\n14116.833333\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n97\n\n\n34875\n34875\n97202\nLes Anses-d'Arlet\n1390.0\n3274.5\n14645.277778\n25.0\n37.0\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n97\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n34927\n34927\n97420\nSainte-Suzanne\n7827.0\n23118.0\n15110.666667\n26.0\n38.0\n53.0\n39.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n97\n\n\n34928\n34928\n97421\nSalazie\n2358.0\n6967.0\n11280.937500\n12.0\n58.0\nNaN\n63.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n97\n\n\n34929\n34929\n97422\nLe Tampon\n27916.0\n73468.5\n14243.809524\n25.0\n41.0\n56.0\n45.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n97\n\n\n34930\n34930\n97423\nLes Trois-Bassins\n2386.0\n7105.0\n14031.785714\n23.0\n42.0\nNaN\n42.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n97\n\n\n34931\n34931\n97424\nCilaos\n2038.0\n5603.0\n12034.375000\n15.0\n53.0\nNaN\n60.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n97\n\n\n\n\n61 rows √ó 45 columns\n\n\n\n\nIl est suprenant de voir que Paris, Lyon et Marseille sont pr√©sents\ndans la base des statistiques communales mais pas dans celles des √©missions.\nPour comprendre pourquoi, recherchons dans nos donn√©es d‚Äô√©missions les observations li√©es √† Marseille:\n\nemissions.loc[emissions[\"Commune\"].str.lower().str.contains(\"MARSEILLE\")]\n\n\n\n\n\n\n\n\n\nid_left\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\n\n\n\n\n\n\n\n\n\n\nCela vient du fait que le jeu de donn√©es des √©missions de l‚ÄôAdeme propose de l‚Äôinformation sur les arrondissements dans les trois plus grandes villes\nl√† o√π le jeu de donn√©es de l‚ÄôInsee ne fait pas cette d√©composition.\n\n\n5.2.3 Inner join\n\nIl s‚Äôagit du jeu de donn√©es o√π les cl√©s sont retrouv√©es √† l‚Äôintersection des deux tables.\n\ninner_merged = emissions.merge(\n    filosofi, left_on=[\"INSEE commune\", \"dep\"], right_on=[\"CODGEO\", \"dep\"], how=\"inner\"\n)\ninner_merged.head(3)\n\n\n\n\n\n\n\n\n\nid_left\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\n...\nPPEN16\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\n\n\n\n\n0\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n...\n27.0\n8.8\n6.9\n2.8\n2.1\n2.0\n-15.7\n10457.083333\n33880.555556\n3.239962\n\n\n\n\n3 rows √ó 44 columns\n\n\n\n\nEn SQL, cela donne\nSELECT *\nFROM emissions\nINNER JOIN filosofi\n  ON emissions.`INSEE commune` = filosofi.CODGEO\n  AND emissions.dep = filosofi.dep;\nLe nombre de lignes dans notre jeu de donn√©es peut √™tre compar√© au jeu de droite et de gauche:\n\ninner_merged.shape[0] == (left_merged.shape[0] - left_merged[\"id_right\"].isna().sum())\n\nTrue\n\n\n\ninner_merged.shape[0] == (right_merged.shape[0] - right_merged[\"id_left\"].isna().sum())\n\nTrue\n\n\n\n\n5.2.4 Full join\nLe full join est un pivot √† gauche puis √† droite pour les informations qui n‚Äôont pas √©t√© trouv√©es\n\n\nfull_merged = emissions.merge(\n    filosofi, left_on=[\"INSEE commune\", \"dep\"], right_on=[\"CODGEO\", \"dep\"], how=\"outer\"\n)\nfull_merged.head(3)\n\n\n\n\n\n\n\n\n\nid_left\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\n...\nPPEN16\nPPAT16\nPPSOC16\nPPFAM16\nPPMINI16\nPPLOGT16\nPIMPOT16\nD116\nD916\nRD16\n\n\n\n\n0\n0.0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1.0\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n2.0\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n...\n27.0\n8.8\n6.9\n2.8\n2.1\n2.0\n-15.7\n10457.083333\n33880.555556\n3.239962\n\n\n\n\n3 rows √ó 44 columns\n\n\n\n\nComme d‚Äôhabitude, la traduction en SQL est presque imm√©diate:\nSELECT *\nFROM emissions\nFULL OUTER JOIN filosofi\n  ON emissions.`INSEE commune` = filosofi.CODGEO\n  AND emissions.dep = filosofi.dep;\nCette fois, on a une combinaison de nos trois jeux de donn√©es initiaux:\n\nLe inner join ;\nLe left join sur les observations sans cl√© de droite ;\nLe right join sur les observations sans cl√© de gauche ;\n\n\n(full_merged[\"id_left\"].isna().sum() + full_merged[\"id_right\"].isna().sum()) == (\n    left_merged[\"id_right\"].isna().sum() + right_merged[\"id_left\"].isna().sum()\n)\n\nTrue\n\n\n\n\n5.2.5 En r√©sum√©",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#exemples-didentifiants-dans-les-donn√©es-fran√ßaises",
    "href": "content/manipulation/02_pandas_suite.html#exemples-didentifiants-dans-les-donn√©es-fran√ßaises",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "5.3 Exemples d‚Äôidentifiants dans les donn√©es fran√ßaises",
    "text": "5.3 Exemples d‚Äôidentifiants dans les donn√©es fran√ßaises\n\n5.3.1 Le Code officiel g√©ographique (COG): l‚Äôidentifiant des donn√©es g√©ographiques\nPour les donn√©es g√©ographiques, il existe de nombreux identifiants selon la probl√©matique d‚Äô√©tude.\nParmi les besoins principaux, on retrouve le fait d‚Äôapparier des donn√©es g√©ographiques √† partir d‚Äôun identifiant administratif commun. Par exemple, associer deux jeux de donn√©es au niveau communal.\nPour cela, l‚Äôidentifiant de r√©f√©rence est le code Insee, issu du Code officiel g√©ographique (COG) que nous utilisons depuis le dernier chapitre et que nous aurons amplement l‚Äôoccasion d‚Äôexploiter au cours des diff√©rents chapitres de ce cours.\nLa g√©ographie administrative √©tant en √©volution perp√©tuelle, la base des code Insee est une base vivante. Le site et les API de l‚ÄôInsee permettent de r√©cup√©rer l‚Äôhistorique d‚Äôapr√®s-guerre afin de pouvoir faire de l‚Äôanalyse g√©ographique sur longue p√©riode.\nLes codes postaux ne peuvent √™tre consid√©r√©s comme un identifiant : ils peuvent regrouper plusieurs communes ou, au contraire, une m√™me commune peut avoir plusieurs codes postaux. Il s‚Äôagit d‚Äôun syst√®me de gestion de la Poste qui n‚Äôa pas √©t√© construit pour l‚Äôanalyse statistique.\nPour se convaincre du probl√®me, √† partir des donn√©es mises √† disposition par La Poste, on peut voir que le code postal 11420 correspond √† 11 communes:\n\ncodes_postaux = pd.read_csv(\n    \"https://datanova.laposte.fr/data-fair/api/v1/datasets/laposte-hexasmal/raw\",\n    sep=\";\",\n    encoding=\"latin1\",\n    dtype={\"Code_postal\": \"str\", \"#Code_commune_INSEE\": \"str\"},\n)\ncodes_postaux.loc[codes_postaux[\"Code_postal\"] == \"11420\"]\n\n\n\n\n\n\n\n\n\n#Code_commune_INSEE\nNom_de_la_commune\nCode_postal\nLibell√©_d_acheminement\nLigne_5\n\n\n\n\n3921\n11033\nBELPECH\n11420\nBELPECH\nNaN\n\n\n3944\n11057\nCAHUZAC\n11420\nCAHUZAC\nNaN\n\n\n4080\n11184\nLAFAGE\n11420\nLAFAGE\nNaN\n\n\n4124\n11226\nMAYREVILLE\n11420\nMAYREVILLE\nNaN\n\n\n4134\n11236\nMOLANDIER\n11420\nMOLANDIER\nNaN\n\n\n4176\n11277\nPECHARIC ET LE PY\n11420\nPECHARIC ET LE PY\nNaN\n\n\n4177\n11278\nPECH LUNA\n11420\nPECH LUNA\nNaN\n\n\n4182\n11283\nPEYREFITTE SUR L HERS\n11420\nPEYREFITTE SUR L HERS\nNaN\n\n\n4189\n11290\nPLAIGNE\n11420\nPLAIGNE\nNaN\n\n\n4264\n11365\nST SERNIN\n11420\nST SERNIN\nNaN\n\n\n4317\n11419\nVILLAUTOU\n11420\nVILLAUTOU\nNaN\n\n\n\n\n\n\n\n\nEn anticipant sur les comp√©tences d√©velopp√©es lors des prochains chapitres, nous pouvons repr√©senter le probl√®me sous forme cartographique en prenant l‚Äôexemple de l‚ÄôAude. Le code pour produire la carte des codes communes est donn√© tel quel, il n‚Äôest pas d√©velopp√© car il fait appel √† des concepts et librairies qui seront pr√©sent√©s lors du prochain chapitre:\n\nfrom cartiflette import carti_download\n\nshp_communes = carti_download(\n    values=[\"11\"],\n    crs=4326,\n    borders=\"COMMUNE\",\n    simplification=50,\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n1)\n\ncodes_postaux11 = shp_communes.merge(\n    codes_postaux, left_on=\"INSEE_COM\", right_on=\"#Code_commune_INSEE\"\n2)\n3codes_postaux11 = codes_postaux11.dissolve(by=\"Code_postal\")\n\n4# Carte\nax = shp_communes.plot(color=\"white\", edgecolor=\"blue\", linewidth=0.5)\nax = codes_postaux11.plot(ax=ax, color=\"none\", edgecolor=\"black\")\nax.set_axis_off()\n\n\n1\n\nR√©cup√©ration des contours officiels de l‚ÄôAude produits par l‚ÄôIGN par le biais de la librairie cartiflette\n\n2\n\nJointure par le biais du code commune entre les deux sources de donn√©es\n\n3\n\nOn agr√®ge la g√©om√©trie au niveau des codes postaux\n\n4\n\nOn cr√©e une carte √† partir de nos deux couches\n\n\n\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed\n\n\n\n\n\nG√©ographie des codes postaux et des communes dans l‚ÄôAude (11)\n\n\n\n\n\n\n5.3.2 Sirene: l‚Äôidentifiant dans les donn√©es d‚Äôentreprises\nPour relier les microdonn√©es d‚Äôentreprises fran√ßaises, il existe un num√©ro unique d‚Äôidentification : le num√©ro Siren. Il s‚Äôagit d‚Äôun num√©ro d‚Äôidentification dans un r√©pertoire l√©gal d‚Äôentreprise indispensable pour toutes d√©marches juridiques, fiscales‚Ä¶ Pour les entreprises qui poss√®dent plusieurs √©tablissements - par exemple dans plusieurs villes - il existe un identifiant d√©riv√© qui s‚Äôappelle le Siret: aux 9 chiffres du num√©ro Sirene s‚Äôajoutent 5 chiffres d‚Äôidentifications de l‚Äô√©tablissement. D‚Äôailleurs, les administrations publiques sont √©galement concern√©es par le num√©ro Siren: √©tant amen√©es √† effectuer des op√©rations de march√©s (achat de mat√©riel, locations de biens, etc.) elles disposent √©galement d‚Äôun identifiant Siren. Etant inscrits dans des r√©pertoires l√©gaux pour lesquels les citoyens sont publics, les num√©ros Siren et les noms des entreprises associ√©es sont disponibles en open data, par exemple sur annuaire-entreprises.data.gouv.fr/ pour une recherche ponctuelle, sur data.gouv.fr.\nCette base Sirene est une mine d‚Äôinformation, parfois comique, sur les entreprises fran√ßaises. Par exemple, le site tif.hair/ s‚Äôest amus√© √† r√©pertorier la part des salons de coiffures proposant des jeux de mots dans le nom du salon. Lorsqu‚Äôun entrepreneur d√©clare la cr√©ation d‚Äôune entreprise, il re√ßoit un num√©ro Sirene et un code d‚Äôactivit√© (le code APE) reli√© √† la description qu‚Äôil a d√©clar√© de l‚Äôactivit√© de son entreprise. Ce code permet de classer l‚Äôactivit√© d‚Äôune entreprise dans la Nomenclature d‚Äôactivit√©s fran√ßaises (NAF) ce qui servira √† l‚ÄôInsee pour la publication de statistiques sectorielles. En l‚Äôoccurrence, pour les coiffeurs, le code dans la NAF est 96.02A. Il est possible √† partir de la base disponible en open data d‚Äôavoir en quelques lignes de Python la liste de tous les coiffeurs puis de s‚Äôamuser √† explorer ces donn√©es (objet du prochain exercice optionnel.)\nLe jeu de donn√©es de l‚Äôensemble des entreprises √©tant assez volumineux (autour de 4Go en CSV apr√®s d√©compression), il est plus pratique de partir sur un jeu de donn√©es au format Parquet, plus optimis√© (plus de d√©tails sur ce format dans le chapitre d‚Äôapprofondissement qui lui est consacr√©).\nPour lire ce type de fichiers de mani√®re optimale, il est conseill√© d‚Äôutiliser la librairie DuckDB qui permet de ne consommer que les donn√©es n√©cessaires et non de t√©l√©charger l‚Äôensemble du fichier pour n‚Äôen lire qu‚Äôune partie comme ce serait le cas avec Pandas (voir la fin de ce chapitre, section ‚ÄúAller au-del√† de Pandas‚Äù). La requ√™te SQL suivante se traduit en langage naturel par l‚Äôinstruction suivante: ‚ÄúA partir du fichier Parquet, je ne veux que quelques colonnes du fichier pour les coiffeurs (APE: 96.02A) dont le nom de l‚Äôentreprise (denominationUsuelleEtablissement) est renseign√©‚Äù:\n\nimport duckdb\n\ncoiffeurs = duckdb.sql(\n    \"\"\"\n  SELECT\n    siren, siret, dateDebut, enseigne1Etablissement, activitePrincipaleEtablissement, denominationUsuelleEtablissement\n  FROM\n    read_parquet('https://minio.lab.sspcloud.fr/lgaliana/data/sirene2024.parquet')\n  WHERE\n    activitePrincipaleEtablissement == '96.02A'\n    AND\n    denominationUsuelleEtablissement IS NOT NULL\n\"\"\"\n)\n1coiffeurs = coiffeurs.df()\n\n\n1\n\nOn convertit le dataframe DuckDB en DataFrame Pandas.\n\n\n\n\n\ncoiffeurs.head(3)\n\n\n\n\n\n\n\n\n\nsiren\nsiret\ndateDebut\nenseigne1Etablissement\nactivitePrincipaleEtablissement\ndenominationUsuelleEtablissement\n\n\n\n\n0\n024050379\n02405037900023\n2016-01-14\nNone\n96.02A\nSOPHA COIFFURE\n\n\n1\n024076481\n02407648100019\n2017-07-17\nNone\n96.02A\nSAF COIFFURE\n\n\n2\n047142872\n04714287200036\n2011-07-31\nNone\n96.02A\nJENNY\n\n\n\n\n\n\n\n\nL‚Äôexercice suivant, optionnel, propose de s‚Äôamuser √† reproduire de mani√®re simplifi√©e le recensement fait par tif.hair/\ndes jeux de mots dans les salons de coiffure. Il permet de pratiquer quelques m√©thodes de manipulation textuelle, en avance de phase sur le chapitre consacr√© aux expressions r√©guli√®res.\n\n\n Exercice optionnel : les coiffeurs blagueurs \nDans cet exercice, nous allons consid√©rer exclusivement la variable denominationUsuelleEtablissement.\n\nDans cette base, [ND] est un code pour valeur manquante. Comme Python n‚Äôa pas de raison de le savoir a priori et donc d‚Äôavoir interpr√©t√© ces valeurs comme √©tant manquantes, utiliser la m√©thode replace pour remplacer [ND] par un champ textuel vide. Recoder √©galement les valeurs manquantes sous forme de champ textuel vide afin d‚Äô√©viter des erreurs ult√©rieures li√©es √† l‚Äôimpossibilit√© d‚Äôappliquer certaines m√©thodes textuelles aux valeurs manquantes.\nRechercher toutes les observations o√π le terme tif appara√Æt en faisant attention √† la capitalisation de la variable. Regarder quelques observations\nA partir de cet exemple, normaliser les noms des salons en retirant les caract√®res sp√©ciaux et compter les jeux de mots les plus fr√©quents\n\n\n\nAvec la question 2, on retrouve une liste de jeux de mots assez imaginatifs √† partir du terme tif:\n\n\n\n\n\n\n\n\n\n\nsiren\nsiret\ndateDebut\nenseigne1Etablissement\nactivitePrincipaleEtablissement\ndenominationUsuelleEtablissement\n\n\n\n\n58\n305078503\n30507850300029\n2018-09-30\nNone\n96.02A\nBRI'TIF\n\n\n88\n307197160\n30719716000061\n2017-02-28\nSUPER AC TIFF\n96.02A\nSUPER AC TIFF\n\n\n89\n307241158\n30724115800046\n2015-11-30\nSYMPA'TIFS\n96.02A\nSYMPA'TIFS\n\n\n108\n309994028\n30999402800020\n2019-08-31\nDIMINU'TIF\n96.02A\nDIMINU'TIF\n\n\n231\n316081413\n31608141300015\n2011-02-28\nNone\n96.02A\nDIMINU'TIF COIFFURE\n\n\n240\n316584390\n31658439000033\n2017-06-30\nNone\n96.02A\nEXO TIF\n\n\n322\n320783780\n32078378000044\n2019-03-01\nACTIF NEUF COIFFURE\n96.02A\nACTIF NEUF COIFFURE\n\n\n421\n324565431\n32456543100057\n2014-01-01\nNone\n96.02A\nPORTE ATIF\n\n\n430\n325016277\n32501627700049\n2016-12-31\nNone\n96.02A\nBEAUTIFUL KRYSTAL\n\n\n437\n325155653\n32515565300034\n2016-12-26\nCREATIFS\n96.02A\nCREATIFS\n\n\n\n\n\n\n\n\nLes 5 jeux de mots les plus fr√©quents sont les suivants:\n\n\ndenominationUsuelleEtablissement\nCREATIF             37\nIMAGINATIF          29\nCREATIF COIFFURE    26\nDIMINUTIF           19\nEVOLUTIF            19\nName: count, dtype: int64\n\n\nBien s√ªr, pour aller plus loin, il faudrait mieux normaliser les donn√©es, v√©rifier que l‚Äôinformation recherch√©e n‚Äôest pas √† cheval sur plusieurs colonnes et bien s√ªr faire de l‚Äôinspection visuelle pour d√©tecter les jeux de mots cach√©s. Mais d√©j√†, en quelques minutes, on a des statistiques partielles sur le ph√©nom√®ne des coiffeurs blagueurs.\n\n\n5.3.3 Le NIR et la question de la confidentialit√© des identifiants individuels\nEn ce qui concerne les individus, il existe un identifiant unique permettant de relier ceux-ci dans diff√©rentes sources de donn√©es : le NIR, aussi connu sous le nom de num√©ro Insee ou num√©ro de s√©curit√© sociale.\nCe num√©ro est n√©cessaire √† l‚Äôadministration pour la gestion des droits √† prestations sociales (maladie, vieillesse, famille‚Ä¶). Au-del√† de cette fonction qui peut √™tre utile au quotidien, ce num√©ro est un identifiant individuel unique dans le R√©pertoire national d‚Äôidentification des personnes physiques (RNIPP).\nCet identifiant est principalement pr√©sent dans des bases de gestion, li√©es aux fiches de paie, aux prestations sociales, etc. Cependant, a contrario du num√©ro Sirene, celui-ci contient en lui-m√™me plusieurs informations sensibles - en plus d‚Äô√™tre intrins√®quement reli√© √† la probl√©matique sensible des droits √† la s√©curit√© sociale.\n\n\n\nLe num√©ro de s√©curit√© sociale (Source: Am√©li)\n\n\nPour pallier ce probl√®me, a r√©c√©mment √©t√© mis en oeuvre le code statistique non signifiant (CSNS) ou NIR hach√©, un identifiant individuel anonyme non identifiant. L‚Äôobjectif de cet identifiant anonymis√© est de r√©duire la diss√©mination d‚Äôune information personnelle qui permettait certes aux fonctionnaires et chercheurs de relier de mani√®re d√©terministe de nombreuses bases de donn√©es mais donnait une information non indispensable aux analystes sur les personnes en question.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#exercices-dapplication",
    "href": "content/manipulation/02_pandas_suite.html#exercices-dapplication",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "5.4 Exercices d‚Äôapplication",
    "text": "5.4 Exercices d‚Äôapplication\n\n5.4.1 Pourquoi a-t-on besoin d‚Äôun code commune quand on a d√©j√† son nom ?\nCet exercice va revenir un peu en arri√®re afin de saisir pourquoi nous avons pris comme hypoth√®se ci-dessus que le code commune √©tait la cl√© de jointure.\n\n\n Exercice 3: v√©rification des cl√©s de jointure\nOn commence par v√©rifier les dimensions des DataFrames et la structure de certaines variables cl√©s.\nEn l‚Äôoccurrence, les variables fondamentales pour lier nos donn√©es sont les variables communales.\nIci, on a deux variables g√©ographiques: un code commune et un nom de commune.\n\nV√©rifier les dimensions des DataFrames.\nIdentifier dans filosofi les noms de communes qui correspondent √† plusieurs codes communes et s√©lectionner leurs codes. En d‚Äôautres termes, identifier les LIBGEO tels qu‚Äôil existe des doublons de CODGEO et les stocker dans un vecteur x (conseil: faire attention √† l‚Äôindex de x).\n\nOn se focalise temporairement sur les observations o√π le libell√© comporte plus de deux codes communes diff√©rents\n\nQuestion 3. Regarder dans filosofi ces observations.\nQuestion 4. Pour mieux y voir, r√©ordonner la base obtenue par order alphab√©tique.\nQuestion 5. D√©terminer la taille moyenne (variable nombre de personnes: NBPERSMENFISC16) et quelques statistiques descriptives de ces donn√©es.\nComparer aux m√™mes statistiques sur les donn√©es o√π libell√©s et codes communes co√Øncident.\nQuestion 6. V√©rifier les grandes villes (plus de 100 000 personnes),\nla proportion de villes pour lesquelles un m√™me nom est associ√© √† diff√©rents codes commune.\nQuestion 7. V√©rifier dans filosofi les villes dont le libell√© est √©gal √† Montreuil.\nV√©rifier √©galement celles qui contiennent le terme ‚ÄòSaint-Denis‚Äô.\n\n\n\nCe petit exercice permet donc de se rassurer car les libell√©s dupliqu√©s\nsont en fait des noms de commune identiques mais qui ne sont pas dans le m√™me d√©partement.\nIl ne s‚Äôagit donc pas d‚Äôobservations dupliqu√©es.\nOn peut donc se fier aux codes communes, qui eux sont uniques.\n\n\n5.4.2 Calculer une empreinte carbone gr√¢ce √† l‚Äôassociation entre des sources\n\n\n Exercice 4: Calculer l'empreinte carbone par habitant\nEn premier lieu, on va calculer l‚Äôempreinte carbone de chaque commune.\n\nCr√©er une variable emissions qui correspond aux √©missions totales d‚Äôune commune\nFaire une jointure √† gauche entre les donn√©es d‚Äô√©missions et les donn√©es de cadrage3.\nCalculer l‚Äôempreinte carbone (√©missions totales / population).\n\nA ce stade nous pourrions avoir envie d‚Äôaller vers la mod√©lisation pour essayer d‚Äôexpliquer\nles d√©terminants de l‚Äôempreinte carbone √† partir de variables communales.\nUne approche inf√©rentielle n√©cessite n√©anmoins pour √™tre pertinente de\nv√©rifier en amont des statistiques descriptives.\n\nSortir un histogramme en niveau puis en log de l‚Äôempreinte carbone communale.\n\nAvec une meilleure compr√©hension de nos donn√©es, nous nous rapprochons\nde la statistique inf√©rentielle. N√©anmoins, nous avons jusqu‚Äô√† pr√©sent\nconstruit des statistiques univari√©es mais n‚Äôavons pas cherch√© √† comprendre\nles r√©sultats en regardant le lien avec d‚Äôautres variables.\nCela nous am√®ne vers la statistique bivari√©e, notamment l‚Äôanalyse des corr√©lations.\nCe travail est important puisque toute mod√©lisation ult√©rieure consistera √†\nraffiner l‚Äôanalyse des corr√©lations pour tenir compte des corr√©lations crois√©es\nentre multiples facteurs. On propose ici de faire cette analyse\nde mani√®re minimale.\n\nRegarder la corr√©lation entre les variables de cadrage et l‚Äôempreinte carbone. Certaines variables semblent-elles pouvoir potentiellement influer sur l‚Äôempreinte carbone ?\n\n\n\nA l‚Äôissue de la question 5, le graphique des corr√©lations est le suivant :",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#pandas-dans-une-chaine-dop√©rations",
    "href": "content/manipulation/02_pandas_suite.html#pandas-dans-une-chaine-dop√©rations",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "7.1 Pandas dans une chaine d‚Äôop√©rations",
    "text": "7.1 Pandas dans une chaine d‚Äôop√©rations\nEn g√©n√©ral, dans un projet, le nettoyage de donn√©es va consister en un ensemble de\nm√©thodes appliqu√©es √† un DataFrame ou alors une Serie lorsqu‚Äôon travaille exclusivement sur une colonne.\nAutrement dit, ce qui est g√©n√©ralement attendu lorsqu‚Äôon fait du Pandas c‚Äôest d‚Äôavoir une cha√Æne qui prend un DataFrame en entr√©e et ressort ce m√™me DataFrame enrichi, ou une version agr√©g√©e de celui-ci, en sortie.\nCette mani√®re de proc√©der est le coeur de la syntaxe dplyr en R mais n‚Äôest pas forc√©ment native en Pandas selon les op√©rations qu‚Äôon d√©sire mettre en oeuvre. En effet, la mani√®re naturelle de mettre √† jour un dataframe en Pandas passe souvent par une syntaxe du type:\n\nimport numpy as np\nimport pandas as pd\n\ndata = [[8000, 1000], [9500, np.nan], [5000, 2000]]\ndf = pd.DataFrame(data, columns=[\"salaire\", \"autre_info\"])\ndf[\"salaire_net\"] = df[\"salaire\"] * 0.8\n\nEn SQL on pourrait directement mettre √† jour notre base de donn√©es avec la nouvelle colonne :\nSELECT *, salaire*0.8 AS salaire_net FROM df\nL‚Äô√©cosyst√®me du tidyverse en R, l‚Äô√©quivalent de Pandas, fonctionne selon la m√™me logique que SQL de mise √† jour de table. On ferait en effet la commande suivante avec dplyr:\ndf %&gt;% mutate(salaire_net = salaire*0.8) \nTechniquement on pourrait faire ceci avec un assign en Pandas\n\n1df = df.drop(\"salaire_net\", axis=\"columns\")\ndf = df.assign(salaire_net=lambda s: s[\"salaire\"] * 0.8)\n\n\n1\n\nPour effacer la variable afin de repartir de l‚Äôexemple initial\n\n\n\n\nCependant cette syntaxe assign n‚Äôest pas tr√®s naturelle. Il est n√©cessaire de lui passer une lambda function qui attend comme input un DataFrame l√† o√π on voudrait une colonne. Il ne s‚Äôagit donc pas vraiment d‚Äôune syntaxe lisible et pratique.\nIl est n√©anmoins possible d‚Äôencha√Æner des op√©rations sur des jeux de donn√©es gr√¢ce aux pipes. Ceux-ci reprennent la m√™me philosophie que celle de dplyr, elle-m√™me inspir√©e du pipe Linux.\nCette approche permettra de rendre plus lisible le code en d√©finissant des fonctions effectuant des op√©rations sur une ou plusieurs colonnes d‚Äôun DataFrame. Le premier argument √† indiquer √† la fonction est le DataFrame, les autres sont ceux permettant de contr√¥ler son comportement\n\ndef calcul_salaire_net(df: pd.DataFrame, col: str, taux: float = 0.8):\n    df[\"salaire_net\"] = df[col] * taux\n    return df\n\nCe qui transforme notre chaine de production en\n\n(df.pipe(calcul_salaire_net, \"salaire\"))\n\n\n\n\n\n\n\n\n\nsalaire\nautre_info\nsalaire_net\n\n\n\n\n0\n8000\n1000.0\n6400.0\n\n\n1\n9500\nNaN\n7600.0\n\n\n2\n5000\n2000.0\n4000.0",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#quelques-limites-sur-la-syntaxe-de-pandas",
    "href": "content/manipulation/02_pandas_suite.html#quelques-limites-sur-la-syntaxe-de-pandas",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "7.2 Quelques limites sur la syntaxe de Pandas",
    "text": "7.2 Quelques limites sur la syntaxe de Pandas\nIl y a un avant et un apr√®s Pandas dans l‚Äôanalyse de donn√©es en Python. Sans ce package √¥ combien pratique Python, malgr√© toutes les forces de ce langage, aurait eu du mal √† s‚Äôinstaller dans le paysage de l‚Äôanalyse de donn√©es. Cependant, si Pandas propose une syntaxe coh√©rente sur de nombreux aspects, elle n‚Äôest pas parfaite non plus. Les paradigmes plus r√©cents d‚Äôanalyse de donn√©es en Python ont d‚Äôailleurs parfois l‚Äôambition de corriger ces imperfections syntaxiques l√†.\nParmi les points les plus g√©nants au quoditien il y a le besoin de r√©guli√®rement faire des reset_index lorsqu‚Äôon construit des statistiques descriptives. En effet, il peut √™tre dangereux de garder des indices qu‚Äôon ne contr√¥le pas bien car, sans attention de notre part lors des phases de merge, ils peuvent √™tre utilis√©s √† mauvais escient par Pandas pour joindre les donn√©es ce qui peut provoquer des suprises.\nPandas est extr√™mement bien fait pour restructurer des donn√©es du format long to wide ou wide to long. Cependant, ce n‚Äôest pas la seule mani√®re de restructurer un jeu de donn√©es qu‚Äôon peut vouloir mettre en oeuvre. Il arrive r√©guli√®rement qu‚Äôon d√©sire comparer la valeur d‚Äôune observation √† celle d‚Äôun groupe √† laquelle elle appartient. C‚Äôest notamment particuli√®rement utile dans une phase d‚Äôanalyse des anomalies, valeurs aberrantes ou lors d‚Äôune investigation de d√©tection de fraude. De mani√®re native, en Pandas, il faut construire une statistique agr√©g√©e par groupe et refaire un merge aux donn√©es initiales par le biais de la variable de groupe. C‚Äôest un petit peu fastidieux:\n\nemissions_moyennes = emissions.groupby(\"dep\").agg({\"Agriculture\": \"mean\"}).reset_index()\nemissions_enrichies = emissions.merge(\n    emissions_moyennes, on=\"dep\", suffixes=[\"\", \"_moyenne_dep\"]\n)\nemissions_enrichies[\"relatives\"] = (\n    emissions_enrichies[\"Agriculture\"] / emissions_enrichies[\"Agriculture_moyenne_dep\"]\n)\nemissions_enrichies.head()\n\n\n\n\n\n\n\n\n\nid_left\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\nemissions\nAgriculture_moyenne_dep\nrelatives\n\n\n\n\n0\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n01\n5724.424941\n1974.535382\n1.879645\n\n\n1\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n01\n1333.811619\n1974.535382\n0.240730\n\n\n2\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n01\n63261.689119\n1974.535382\n0.252740\n\n\n3\n3\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n01\n6795.867439\n1974.535382\n0.941569\n\n\n4\n4\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n01\n1072.584766\n1974.535382\n0.227378\n\n\n\n\n\n\n\n\nDans le tidyverse, cette op√©ration en deux temps pourrait √™tre faite en une seule √©tape, ce qui est plus pratique\nemissions %&gt;%\n  group_by(dep) %&gt;%\n  mutate(relatives = Agriculture/mean(Agriculture))\nCe n‚Äôest pas si grave mais cela alourdit la longueur des chaines de traitement faites en Pandas et donc la charge de maintenance pour les faire durer dans le temps.\nDe mani√®re plus g√©n√©rale, les cha√Ænes de traitement Pandas peuvent √™tre assez verbeuses, car il faut r√©guli√®rement red√©finir le DataFrame qu‚Äôon utilise plut√¥t que simplement les colonnes. Par exemple, pour faire un filtre sur les lignes et les colonnes, il faudra faire:\n\n(\n    emissions.loc[\n        (emissions[\"dep\"] == \"12\") & (emissions[\"Routier\"] &gt; 500),\n        [\"INSEE commune\", \"Commune\"],\n    ].head(5)\n)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\n\n\n\n\n4058\n12001\nAGEN-D'AVEYRON\n\n\n4059\n12002\nAGUESSAC\n\n\n4062\n12006\nALRANCE\n\n\n4063\n12007\nAMBEYRAC\n\n\n4064\n12008\nANGLARS-SAINT-FELIX\n\n\n\n\n\n\n\n\nEn SQL on pourrait se contenter de faire r√©f√©rence aux colonnes dans le filter\nSELECT \"INSEE commune\", 'Commune'\nFROM emissions \nWHERE dep==\"12\" AND Routier&gt;500\nDans le tidyverse (R) on pourrait aussi faire ceci simplement\ndf %&gt;%\n  filter(dep==\"12\", Routier&gt;500) %&gt;%\n  select(`INSEE commune`, `Commune`)",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#polars",
    "href": "content/manipulation/02_pandas_suite.html#polars",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "8.1 Polars",
    "text": "8.1 Polars\nPolars est certainement le paradigme le plus inspir√© de Pandas, jusqu‚Äôau choix du nom. La premi√®re diff√©rence fondamentale est dans les couches internes utilis√©es. Polars s‚Äôappuie sur l‚Äôimpl√©mentation Rust de Arrow l√† o√π Pandas s‚Äôappuie sur Numpy ce qui est facteur de perte de performance. Cela permet √† Polars d‚Äô√™tre plus efficace sur de gros volumes de donn√©es, d‚Äôautant que de nombreuses op√©rations sont parall√©lis√©es et reposent sur l‚Äô√©valuation diff√©r√©es (lazy evaluation) un principe de programmation qui permet d‚Äôoptimiser les requ√™tes pour ne pas les ex√©cuter dans l‚Äôordre de d√©finition mais dans un ordre logique plus optimal.\nUne autre force de Polars est la syntaxe plus coh√©rente, qui b√©n√©ficie du recul d‚Äôune quinzaine d‚Äôann√©es d‚Äôexistence de Pandas et d‚Äôune petite dizaine d‚Äôann√©es de dplyr (le package de manipulation de donn√©es au sein du paradigme du tidyverse en R). Pour reprendre l‚Äôexemple pr√©c√©dent, il n‚Äôest plus n√©cessaire de forcer la r√©f√©rence au DataFrame, dans une cha√Æne d‚Äôex√©cution toutes les r√©f√©rences ult√©rieures seront faites au regard du DataFrame de d√©part\n\nimport polars as pl\n\nemissions_polars = pl.from_pandas(emissions)\n(\n    emissions_polars.filter(pl.col(\"dep\") == \"12\", pl.col(\"Routier\") &gt; 500)\n    .select(\"INSEE commune\", \"Commune\")\n    .head(5)\n)\n\n\n\nshape: (5, 2)\n\n\n\nINSEE commune\nCommune\n\n\nstr\nstr\n\n\n\n\n\"12001\"\n\"AGEN-D'AVEYRON‚Ä¶\n\n\n\"12002\"\n\"AGUESSAC\"\n\n\n\"12006\"\n\"ALRANCE\"\n\n\n\"12007\"\n\"AMBEYRAC\"\n\n\n\"12008\"\n\"ANGLARS-SAINT-‚Ä¶\n\n\n\n\n\n\n\nPour d√©couvrir Polars, de nombreuses ressources en ligne sont accessibles, notamment ce notebook construit pour le r√©seau des data scientists de la statistique publique.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#duckdb",
    "href": "content/manipulation/02_pandas_suite.html#duckdb",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "8.2 DuckDB",
    "text": "8.2 DuckDB\nDuckDB est le nouveau venu dans l‚Äô√©cosyst√®me de l‚Äôanalyse de donn√©es repoussant les limites des donn√©es pouvant √™tre trait√©es avec Python sans passer par des outils big data comme Spark.\nDuckDB est la quintessence d‚Äôun nouveau paradigme, celui du ‚ÄúBig data is dead‚Äù, o√π on peut traiter des donn√©es de volum√©trie importante sans recourir √† des infrastructures imposantes.\nOutre sa grande efficacit√©, puisqu‚Äôavec DuckDB on peut traiter des donn√©es d‚Äôune volum√©trie sup√©rieure √† la m√©moire vive de l‚Äôordinateur ou du serveur, DuckDB pr√©sente l‚Äôavantage de proposer une syntaxe uniforme quelle que soit le langage qui appelle DuckDB (Python, R, C++ ou Javascript). DuckDB privil√©gie la syntaxe SQL pour traiter les donn√©es avec de nombreuses fonctions pr√©-implement√©es pour simplifier certaines transformations de donn√©es (par exemple pour les donn√©es textuelles, les donn√©es temporelles, etc.).\nPar rapport √† d‚Äôautres syst√®mes s‚Äôappuyant sur SQL, comme PostGreSQL, DuckDB est tr√®s simple d‚Äôinstallation, ce n‚Äôest qu‚Äôune librairie Python l√† o√π beaucoup d‚Äôoutils comme PostGreSQL n√©cessite une infrastructure adapt√©e.\nPour reprendre l‚Äôexemple pr√©c√©dent, on peut utiliser directement le code SQL pr√©c√©dent\n\nimport duckdb\n\nduckdb.sql(\n    \"\"\"\n  SELECT \"INSEE commune\", \"Commune\"\n  FROM emissions\n  WHERE dep=='12' AND Routier&gt;500\n  LIMIT 5\n  \"\"\"\n)\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ INSEE commune ‚îÇ       Commune       ‚îÇ\n‚îÇ    varchar    ‚îÇ       varchar       ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 12001         ‚îÇ AGEN-D'AVEYRON      ‚îÇ\n‚îÇ 12002         ‚îÇ AGUESSAC            ‚îÇ\n‚îÇ 12006         ‚îÇ ALRANCE             ‚îÇ\n‚îÇ 12007         ‚îÇ AMBEYRAC            ‚îÇ\n‚îÇ 12008         ‚îÇ ANGLARS-SAINT-FELIX ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nIci la clause FROM emissions vient du fait qu‚Äôon peut directement ex√©cuter du SQL depuis un objet Pandas par le biais de DuckDB. Si on fait la lecture directement dans la requ√™te, celle-ci se complexifie un petit peu mais la logique est la m√™me\n\nimport duckdb\n\nduckdb.sql(\n    f\"\"\"\n  SELECT \"INSEE commune\", \"Commune\"\n  FROM read_csv_auto(\"{url}\")\n  WHERE\n    substring(\"INSEE commune\",1,2)=='12'\n    AND\n    Routier&gt;500\n  LIMIT 5\n  \"\"\"\n)\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ INSEE commune ‚îÇ       Commune       ‚îÇ\n‚îÇ    varchar    ‚îÇ       varchar       ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 12001         ‚îÇ AGEN-D'AVEYRON      ‚îÇ\n‚îÇ 12002         ‚îÇ AGUESSAC            ‚îÇ\n‚îÇ 12006         ‚îÇ ALRANCE             ‚îÇ\n‚îÇ 12007         ‚îÇ AMBEYRAC            ‚îÇ\n‚îÇ 12008         ‚îÇ ANGLARS-SAINT-FELIX ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nLe rendu du DataFrame est l√©g√®rement diff√©rent de Pandas car, comme Polars et de nombreux syst√®mes de traitement de donn√©es volumineuses, DuckDB repose sur l‚Äô√©valuation diff√©r√©e et donc ne pr√©sente en display qu‚Äôun √©chantillon de donn√©es.\nDuckDB et Polars sont d‚Äôailleurs tr√®s bien int√©gr√©s l‚Äôun √† l‚Äôautre. On peut tr√®s bien faire du SQL sur un objet Polars via DuckDB ou appliquer des fonctions Polars sur un objet initialement lu avec DuckDB.\nL‚Äôun des int√©r√™ts de DuckDB est son excellente int√©gration avec l‚Äô√©cosyst√®me Parquet, le format de donn√©es d√©j√† mentionn√© qui devient un standard dans le partage de donn√©es (il s‚Äôagit, par exemple, de la pierre angulaire du partage de donn√©es sur la plateforme HuggingFace). Pour en savoir plus sur DuckDB et d√©couvrir son int√©r√™t pour lire les donn√©es du recensement de la population fran√ßaise, vous pouvez consulter ce post de blog.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#spark-et-le-big-data",
    "href": "content/manipulation/02_pandas_suite.html#spark-et-le-big-data",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "8.3 Spark et le big data",
    "text": "8.3 Spark et le big data\nDuckDB a repouss√© les fronti√®res du big data qu‚Äôon peut d√©finir comme le volume de donn√©es √† partir duquel on ne peut plus traiter celles-ci sur une machine sans mettre en oeuvre une strat√©gie de parall√©lisation.\nN√©anmoins, pour les donn√©es tr√®s volumineuses, Python est tr√®s bien arm√© gr√¢ce √† la librairie PySpark. Celle-ci est une API en Python pour le langage Spark, un langage big data bas√© sur Scala. Ce paradigme est construit sur l‚Äôid√©e que les utilisateurs de Python y acc√®dent par le biais de cluster avec de nombreux noeuds pour traiter la donn√©e de mani√®re parall√®le. Celle-ci sera lue par blocs, qui seront trait√©s en parall√®le en fonction du nombre de noeuds parall√®les. L‚ÄôAPI DataFrame de Spark pr√©sente une syntaxe proche de celle des paradigmes pr√©c√©dents avec une ing√©nieurie plus complexe en arri√®re-plan li√©e √† la parall√©lisation native.",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#informations-additionnelles",
    "href": "content/manipulation/02_pandas_suite.html#informations-additionnelles",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc6ffbb6\n\n\n2024-05-08 07:38:24\n\n\nlgaliana\n\n\nPutting badges in advanced Pandas\n\n\n\n\nc3873ed\n\n\n2024-05-07 12:19:12\n\n\nlgaliana\n\n\nAjoute code commune\n\n\n\n\ne0d615e\n\n\n2024-05-03 11:15:29\n\n\nLino Galiana\n\n\nRestructure la partie Pandas (#497)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nSplit-apply-combine (Source: unlhcc.github.io)\nDonn√©es long et wide (Source: R for Data Science)\nIllustration du sch√©ma en √©toile (Source: Databricks)\nG√©ographie des codes postaux et des communes dans l‚ÄôAude (11)\nLe num√©ro de s√©curit√© sociale (Source: Am√©li)",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_suite.html#footnotes",
    "href": "content/manipulation/02_pandas_suite.html#footnotes",
    "title": "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nId√©alement il serait plus coh√©rent, pour les donn√©es d√©mographiques, d‚Äôutiliser les populations l√©gales, issues du recensement. N√©anmoins cette base n‚Äôest pas encore int√©gr√©e nativement dans la librairie pynsee que nous allons utiliser dans ce chapitre. Un exercice d‚Äôouverture est propos√© pour construire des agr√©gats de population √† partir des jeux de donn√©es individuels anonymis√©s du recensement (les fichiers d√©tails).‚Ü©Ô∏é\nAutrement, on rentre dans le monde des appariements flous ou des appariements probabilistes. Les appariements flous sont des situations o√π on ne dispose plus d‚Äôun identifiant exact pour associer deux bases mais d‚Äôune information partiellement bruit√©e entre deux sources pour faire cette mise en relation. Par exemple, dans une base de donn√©es produit on aura Coca Cola 33CL et dans une autre Coca Cola canette mais sous ces deux noms sont cach√©s le m√™me produit. Le chapitre d‚Äôouverture aux enjeux de recherche textuelle avec ElasticSearch est consacr√© √† cette probl√©matique. Les appariements probabilistes sont un autre type d‚Äôapproche. Dans ceux-ci, on associe des observations dans deux bases non pas sur la base d‚Äôun identifiant mais sur la distance entre un ensemble de caract√©ristiques dans les deux bases. Cette technique est tr√®s utilis√©e dans les statistiques m√©dicales ou dans l‚Äô√©valuation de politiques publiques sur la base du propensity score matching.‚Ü©Ô∏é\nId√©alement, il serait n√©cessaire de s‚Äôassurer que cette jointure n‚Äôintroduit\npas de biais. En effet, comme nos ann√©es de r√©f√©rence ne sont pas forc√©ment identiques,\nil peut y avoir un mismatch entre nos deux sources. Le TP √©tant d√©j√† long, nous n‚Äôallons pas dans cette voie.\nLes lecteurs int√©ress√©s pourront effectuer une telle analyse en exercice suppl√©mentaire.‚Ü©Ô∏é",
    "crumbs": [
      "Statistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html",
    "href": "content/manipulation/01_numpy.html",
    "title": "Numpy, la brique de base de la data science",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#cr√©er-un-array",
    "href": "content/manipulation/01_numpy.html#cr√©er-un-array",
    "title": "Numpy, la brique de base de la data science",
    "section": "2.1 Cr√©er un array",
    "text": "2.1 Cr√©er un array\nOn peut cr√©er un array de plusieurs mani√®res. Pour cr√©er un array √† partir d‚Äôune liste,\nil suffit d‚Äôutiliser la m√©thode array:\n\nnp.array([1, 2, 5])\n\narray([1, 2, 5])\n\n\nIl est possible d‚Äôajouter un argument dtype pour contraindre le type du array :\n\nnp.array([[\"a\", \"z\", \"e\"], [\"r\", \"t\"], [\"y\"]], dtype=\"object\")\n\narray([list(['a', 'z', 'e']), list(['r', 't']), list(['y'])], dtype=object)\n\n\nIl existe aussi des m√©thodes pratiques pour cr√©er des array:\n\ns√©quences logiques : np.arange (suite) ou np.linspace (interpolation lin√©aire entre deux bornes)\ns√©quences ordonn√©es : array rempli de z√©ros, de 1 ou d‚Äôun nombre d√©sir√© : np.zeros, np.ones ou np.full\ns√©quences al√©atoires : fonctions de g√©n√©ration de nombres al√©atoires : np.rand.uniform, np.rand.normal, etc.\ntableau sous forme de matrice identit√© : np.eye\n\nCeci donne ainsi, pour les s√©quences logiques:\n\nnp.arange(0, 10)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\nnp.arange(0, 10, 3)\n\narray([0, 3, 6, 9])\n\n\n\nnp.linspace(0, 1, 5)\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n\n\nPour un array initialis√© √† 0:\n\nnp.zeros(10, dtype=int)\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\nou initialis√© √† 1:\n\nnp.ones((3, 5), dtype=float)\n\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]])\n\n\nou encore initialis√© √† 3.14:\n\n\narray([[3.14, 3.14, 3.14, 3.14, 3.14],\n       [3.14, 3.14, 3.14, 3.14, 3.14],\n       [3.14, 3.14, 3.14, 3.14, 3.14]])\n\n\nEnfin, pour cr√©er la matrice \\(I_3\\):\n\nnp.eye(3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\n\n Exercice 1\nG√©n√©rer:\n\n\\(X\\) une variable al√©atoire, 1000 r√©p√©titions d‚Äôune loi \\(U(0,1)\\)\n\\(Y\\) une variable al√©atoire, 1000 r√©p√©titions d‚Äôune loi normale de moyenne nulle et de variance √©gale √† 2\nV√©rifier la variance de \\(Y\\) avec np.var",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#logique-dans-le-cas-dun-array-unidimensionnel",
    "href": "content/manipulation/01_numpy.html#logique-dans-le-cas-dun-array-unidimensionnel",
    "title": "Numpy, la brique de base de la data science",
    "section": "3.1 Logique dans le cas d‚Äôun array unidimensionnel",
    "text": "3.1 Logique dans le cas d‚Äôun array unidimensionnel\nLa structure la plus simple est l‚Äôarray unidimensionnel:\n\nx = np.arange(10)\nprint(x)\n\n[0 1 2 3 4 5 6 7 8 9]\n\n\nL‚Äôindexation est dans ce cas similaire √† celle d‚Äôune liste:\n\nle premier √©l√©ment est 0\nle √©ni√®me √©l√©ment est accessible √† la position \\(n-1\\)\n\nLa logique d‚Äôacc√®s aux √©l√©ments est ainsi la suivante :\nx[start:stop:step]\nAvec un array unidimensionnel, l‚Äôop√©ration de slicing (garder une coupe du array) est tr√®s simple.\nPar exemple, pour garder les K premiers √©l√©ments d‚Äôun array, on fera:\nx[: (K - 1)]\nEn l‚Äôoccurrence, on s√©lectionne le K\\(^{eme}\\) √©l√©ment en utilisant\nx[K - 1]\nPour s√©lectionner uniquement un √©l√©ment, on fera ainsi:\n\nx = np.arange(10)\nx[2]\n\n2\n\n\nLes syntaxes qui permettent de s√©lectionner des indices particuliers d‚Äôune liste fonctionnent √©galement\navec les arrays.\n\n\n Exercice 2\nPrenez x = np.arange(10) et‚Ä¶\n\nS√©lectionner les √©l√©ments 0,3,5 de x\nS√©lectionner les √©l√©ments pairs\nS√©lectionner tous les √©l√©ments sauf le premier\nS√©lectionner les 5 premiers √©l√©ments",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#sur-la-performance",
    "href": "content/manipulation/01_numpy.html#sur-la-performance",
    "title": "Numpy, la brique de base de la data science",
    "section": "3.2 Sur la performance",
    "text": "3.2 Sur la performance\nUn √©l√©ment d√©terminant dans la performance de Numpy par rapport aux listes,\nlorsqu‚Äôil est question de\nslicing est qu‚Äôun array ne renvoie pas une\ncopie de l‚Äô√©l√©ment en question (copie qui co√ªte de la m√©moire et du temps)\nmais simplement une vue de celui-ci.\nLorsqu‚Äôil est n√©cessaire d‚Äôeffectuer une copie,\npar exemple pour ne pas alt√©rer l‚Äôarray sous-jacent, on peut\nutiliser la m√©thode copy:\nx_sub_copy = x[:2, :2].copy()",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#filtres-logiques",
    "href": "content/manipulation/01_numpy.html#filtres-logiques",
    "title": "Numpy, la brique de base de la data science",
    "section": "3.3 Filtres logiques",
    "text": "3.3 Filtres logiques\nIl est √©galement possible, et plus pratique, de s√©lectionner des donn√©es √† partir de conditions logiques\n(op√©ration qu‚Äôon appelle un boolean mask).\nCette fonctionalit√© servira principalement √†\neffectuer des op√©rations de filtre sur les donn√©es.\nPour des op√©rations de comparaison simples, les comparateurs logiques peuvent √™tre suffisants.\nCes comparaisons fonctionnent aussi sur les tableaux multidimensionnels gr√¢ce au\nbroadcasting sur lequel nous reviendrons :\n\nx = np.arange(10)\nx2 = np.array([[-1, 1, -2], [-3, 2, 0]])\nprint(x)\nprint(x2)\n\n[0 1 2 3 4 5 6 7 8 9]\n[[-1  1 -2]\n [-3  2  0]]\n\n\n\nx == 2\nx2 &lt; 0\n\narray([[ True, False,  True],\n       [ True, False, False]])\n\n\nPour s√©lectionner les observations relatives √† la condition logique,\nil suffit d‚Äôutiliser la logique de slicing de numpy qui fonctionne avec les conditions logiques\n\n\n Exercice 3\nSoit\nx = np.random.normal(size=10000)\n\nNe conserver que les valeurs dont la valeur absolue est sup√©rieure √† 1.96\nCompter le nombre de valeurs sup√©rieures √† 1.96 en valeur absolue et leur proportion dans l‚Äôensemble\nSommer les valeurs absolues de toutes les observations sup√©rieures (en valeur absolue) √† 1.96\net rapportez les √† la somme des valeurs de x (en valeur absolue)\n\n\n\nLorsque c‚Äôest possible, il est recommand√© d‚Äôutiliser les fonctions logiques de numpy (optimis√©es et\nqui g√®rent bien la dimension).\nParmi elles, on peut retrouver:\n\ncount_nonzero\nisnan\nany ; all ; notamment avec l‚Äôargument axis\nnp.array_equal pour v√©rifier, √©l√©ment par √©l√©ment, l‚Äô√©galit√©\n\nSoit\n\nx = np.random.normal(0, size=(3, 4))\n\nun array multidimensionnel et\n\ny = np.array([np.nan, 0, 1])\n\nun array unidimensionnel pr√©sentant une valeur manquante.\n\n\n Exercice 4\n\nUtiliser count_nonzero sur y\nUtiliser isnan sur y et compter le nombre de valeurs non NaN\nV√©rifier que x comporte au moins une valeur positive dans son ensemble, en parcourant les lignes puis les colonnes.\n\n\n\nAide\n\nJetez un oeil au param√®tre axis en vous documentant sur internet. Par exemple ici.",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#fonctions-de-manipulation",
    "href": "content/manipulation/01_numpy.html#fonctions-de-manipulation",
    "title": "Numpy, la brique de base de la data science",
    "section": "4.1 Fonctions de manipulation",
    "text": "4.1 Fonctions de manipulation\nVoici quelques fonctions pour modifier un array,\n\n\n\n\n\n\n\nOp√©ration\nImpl√©mentation\n\n\n\n\nAplatir un array\nx.flatten() (m√©thode)\n\n\nTransposer un array\nx.T (m√©thode) ou np.transpose(x) (fonction)\n\n\nAjouter des √©l√©ments √† la fin\nnp.append(x, [1,2])\n\n\nAjouter des √©l√©ments √† un endroit donn√© (aux positions 1 et 2)\nnp.insert(x, [1,2], 3)\n\n\nSupprimer des √©l√©ments (aux positions 0 et 3)\nnp.delete(x, [0,3])\n\n\n\nPour combiner des array, on peut utiliser, selon les cas,\nles fonctions np.concatenate, np.vstack ou la m√©thode .r_ (concat√©nation rowwise).\nnp.hstack ou la m√©thode .column_stack ou .c_ (concat√©nation column-wise)\n\nx = np.random.normal(size=10)\n\nPour ordonner un array, on utilise np.sort\n\nx = np.array([7, 2, 3, 1, 6, 5, 4])\n\nnp.sort(x)\n\narray([1, 2, 3, 4, 5, 6, 7])\n\n\nSi on d√©sire faire un r√©-ordonnement partiel pour trouver les k valeurs les plus petites d‚Äôun array sans les ordonner, on utilise partition:\n\nnp.partition(x, 3)\n\narray([2, 1, 3, 4, 6, 5, 7])",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#une-application-programmer-ses-propres-k-nearest-neighbors",
    "href": "content/manipulation/01_numpy.html#une-application-programmer-ses-propres-k-nearest-neighbors",
    "title": "Numpy, la brique de base de la data science",
    "section": "5.1 Une application: programmer ses propres k-nearest neighbors",
    "text": "5.1 Une application: programmer ses propres k-nearest neighbors\n\n\n\n Exercice (un peu plus cors√©)\n\nCr√©er X un tableau √† deux dimensions (i.e.¬†une matrice) comportant 10 lignes\net 2 colonnes. Les nombres dans le tableau sont al√©atoires.\nImporter le module matplotlib.pyplot sous le nom plt. Utiliser\nplt.scatter pour repr√©senter les donn√©es sous forme de nuage de points.\nConstuire une matrice 10x10 stockant, √† l‚Äô√©l√©ment \\((i,j)\\), la distance euclidienne entre les points \\(X[i,]\\) et \\(X[j,]\\). Pour cela, il va falloir jouer avec les dimensions en cr√©ant des tableaux embo√Æt√©s √† partir par des appels √† np.newaxis :\n\n\nEn premier lieu, utiliser X1 = X[:, np.newaxis, :] pour transformer la matrice en tableau embo√Æt√©. V√©rifier les dimensions\nCr√©er X2 de dimension (1, 10, 2) √† partir de la m√™me logique\nEn d√©duire, pour chaque point, la distance avec les autres points pour chaque coordonn√©es. Elever celle-ci au carr√©\nA ce stade, vous devriez avoir un tableau de dimension (10, 10, 2). La r√©duction √† une matrice s‚Äôobtient en sommant sur le dernier axe. Regarder dans l‚Äôaide de np.sum comme effectuer une somme sur le dernier axe.\nEnfin, appliquer la racine carr√©e pour obtenir une distance euclidienne en bonne et due forme.\n\n\nV√©rifier que les termes diagonaux sont bien nuls (distance d‚Äôun point √† lui-m√™me‚Ä¶)\nIl s‚Äôagit maintenant de classer, pour chaque point, les points dont les valeurs sont les plus similaires. Utiliser np.argsort pour obtenir, pour chaque ligne, le classement des points les plus proches\nOn va s‚Äôint√©resser aux k-plus proches voisins. Pour le moment, fixons k=2. Utiliser argpartition pour r√©ordonner chaque ligne de mani√®re √† avoir les 2 plus proches voisins de chaque point d‚Äôabord et le reste de la ligne ensuite\nUtiliser le morceau de code ci-dessous\n\n\n\n\nUn indice pour repr√©senter graphiquement les plus proches voisins\nplt.scatter(X[:, 0], X[:, 1], s=100)\n\n# draw lines from each point to its two nearest neighbors\nK = 2\n\nfor i in range(X.shape[0]):\n    for j in nearest_partition[i, : K + 1]:\n        # plot a line from X[i] to X[j]\n        # use some zip magic to make it happen:\n        plt.plot(*zip(X[j], X[i]), color=\"black\")\n\n\nPour la question 2, vous devriez obtenir un graphique ayant cet aspect :\n\n\n\n\n\n\n\n\n\nLe r√©sultat de la question 7 est le suivant :\n\n\n\n\n\n\n\n\n\nAi-je invent√© cet exercice cors√© ? Pas du tout, il vient de l‚Äôouvrage Python Data Science Handbook. Mais, si je vous l‚Äôavais indiqu√© imm√©diatement, auriez-vous cherch√© √† r√©pondre aux questions ?\nPar ailleurs, il ne serait pas une bonne id√©e de g√©n√©raliser cet algorithme √† de grosses donn√©es. La complexit√© de notre approche est \\(O(N^2)\\). L‚Äôalgorithme impl√©ment√© par Scikit-Learn est\nen \\(O[NlogN]\\).\nDe plus, le calcul de distances matricielles en utilisant la puissance des cartes graphiques serait plus rapide. A cet √©gard, la librairie faiss offre des performances beaucoup plus satisfaisantes que celles que permettraient numpy sur ce probl√®me pr√©cis.",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/manipulation/01_numpy.html#informations-additionnelles",
    "href": "content/manipulation/01_numpy.html#informations-additionnelles",
    "title": "Numpy, la brique de base de la data science",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\na63319a\n\n\n2023-10-04 15:29:04\n\n\nLino Galiana\n\n\nCorrection du TP numpy (#419)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n9e1e6e4\n\n\n2023-07-20 02:27:22\n\n\nLino Galiana\n\n\nChange launch script (#379)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n7e15843\n\n\n2023-02-13 18:57:28\n\n\nLino Galiana\n\n\nfrom_numpy_array no longer in networkx 3.0 (#353)\n\n\n\n\na408cc9\n\n\n2023-02-01 09:07:27\n\n\nLino Galiana\n\n\nAjoute bouton sugg√©rer modification (#347)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\ne2b53ac\n\n\n2022-09-28 17:09:31\n\n\nLino Galiana\n\n\nRetouche les chapitres pandas (#287)\n\n\n\n\nd068cb6\n\n\n2022-09-24 14:58:07\n\n\nLino Galiana\n\n\nCorrections avec echo true (#279)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\na56dd45\n\n\n2022-09-20 15:27:56\n\n\nLino Galiana\n\n\nFix SSPCloud links (#270)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n1ca1a8a\n\n\n2022-05-31 11:44:23\n\n\nLino Galiana\n\n\nRetour du chapitre API (#228)\n\n\n\n\n4fc58e5\n\n\n2022-05-25 18:29:25\n\n\nLino Galiana\n\n\nChange deployment on SSP Cloud with new filesystem organization (#227)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n26ea709\n\n\n2021-09-27 19:11:00\n\n\nLino Galiana\n\n\nR√®gle quelques probl√®mes np (#154)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\nedca391\n\n\n2020-09-21 19:31:02\n\n\nLino Galiana\n\n\nChange np.is_nan to np.isnan\n\n\n\n\nf9f00cc\n\n\n2020-09-15 21:05:54\n\n\nLino Galiana\n\n\nenl√®ve quelques TO DO\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\nc452b83\n\n\n2020-07-28 17:32:06\n\n\nLino Galiana\n\n\nTP Numpy (#9)\n\n\n\n\n200b6c1\n\n\n2020-07-27 12:50:33\n\n\nLino Galiana\n\n\nEncore une coquille\n\n\n\n\n5041b28\n\n\n2020-07-27 12:44:10\n\n\nLino Galiana\n\n\nUne coquille √† cause d‚Äôun bloc jupyter\n\n\n\n\ne8db4cf\n\n\n2020-07-24 12:56:38\n\n\nLino Galiana\n\n\nmodif des markdown\n\n\n\n\nb24a1fe\n\n\n2020-07-23 18:20:09\n\n\nLino Galiana\n\n\nAdd notebook\n\n\n\n\n4f8f1ca\n\n\n2020-07-23 18:19:28\n\n\nLino Galiana\n\n\nfix typo\n\n\n\n\n434d20e\n\n\n2020-07-23 18:18:46\n\n\nLino Galiana\n\n\nEssai de yaml header\n\n\n\n\n5ac02ef\n\n\n2020-07-23 18:05:12\n\n\nLino Galiana\n\n\nEssai de md g√©n√©r√© avec jupytext\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Numpy, la brique de base de la data science"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html",
    "href": "content/getting-started/07_rappels_classes.html",
    "title": "Les classes en Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#quand-utilise-t-on-cela-dans-le-domaine-de-la-data-science",
    "href": "content/getting-started/07_rappels_classes.html#quand-utilise-t-on-cela-dans-le-domaine-de-la-data-science",
    "title": "Les classes en Python",
    "section": "1.1 Quand utilise-t-on cela dans le domaine de la data science ?",
    "text": "1.1 Quand utilise-t-on cela dans le domaine de la data science ?\nLes r√©seaux de neurones programm√©s avec Keras ou PyTorch fonctionnent de\ncette mani√®re. On part d‚Äôune structure de base et modifie les attributs (par\nexemple le nombre de couches) ou les m√©thodes.",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#les-attributs-de-la-classe-chat",
    "href": "content/getting-started/07_rappels_classes.html#les-attributs-de-la-classe-chat",
    "title": "Les classes en Python",
    "section": "3.1 Les attributs de la classe chat",
    "text": "3.1 Les attributs de la classe chat\n\n3.1.1 Classe chat version 1 - premiers attributs\nOn veut pouvoir cr√©er un objet chat() qui nous permettra √† terme de cr√©er une colonie de chats (on sait\njamais ca peut servir ‚Ä¶).\nPour commencer, on va d√©finir un chat avec des attributs de base : une couleur et un nom.\n\nclass chat:  # D√©finition de notre classe chat\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - son nom\n    - sa couleur\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        \"\"\"Pour l'instant, on ne va d√©finir que deux attributs - nom et couleur\"\"\"\n        self.couleur = \"Noir\"\n        self.nom = \"Aucun nom\"\n\n\nmon_chat = chat()\n\nprint(type(mon_chat), mon_chat.couleur, \",\", mon_chat.nom)\n\n&lt;class '__main__.chat'&gt; Noir , Aucun nom\n\n\nOn nous dit bien que Mon chat est d√©fini √† partir de la classe chat,\nc‚Äôest ce que nous apprend la fonction type.\nPour l‚Äôinstant il n‚Äôa pas de nom\n\n\n3.1.2 Classe chat version 2 - autres attributs\nAvec un nom et une couleur, on ne va pas loin. On peut continuer √† d√©finir des attributs pour la classe chat\nde la m√™me fa√ßon que pr√©c√©demment.\n\nclass chat:  # D√©finition de notre classe chat\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.couleur = \"Noir\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        self.nom = \"Aucun nom\"\n\n\nhelp(chat)\n# si on veut savoir ce que fait la classe \"chat\" on appelle l'aide\n\nHelp on class chat in module __main__:\n\nclass chat(builtins.object)\n |  Classe d√©finissant un chat caract√©ris√© par :\n |  - sa couleur\n |  - son √¢ge\n |  - son caract√®re\n |  - son poids\n |  - son maitre\n |  - son nom\n |  \n |  Methods defined here:\n |  \n |  __init__(self)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n\n\n\nmon_chat = chat()\nprint(\"L'√¢ge du chat est\", mon_chat.age, \"ans\")\n# on avait d√©fini l'attribut age de la classe chat comme √©tant √©gal √† 10\n# , si on demande l'attribut age de notre Martin on obtient 10\n\nL'√¢ge du chat est 10 ans\n\n\nPar d√©faut, les attributs de la classe Chat seront toujours les m√™mes √† chaque cr√©ation de chat √† partir\nde la classe Chat.\nMais une fois qu‚Äôune instance de classe est cr√©√©e (ici mon chat est une instance de classe) on peut d√©cider\nde changer la valeur de ses attributs.\n\n\n3.1.3 Un nouveau poids\n\nprint(mon_chat.poids)\n# si on veut changer le poids de mon chat, parce qu'il a un peu grossi apr√®s les f√™tes\nmon_chat.poids = 3.5\nprint(mon_chat.poids)  # maintenant le poids est 3.5\n\n3\n3.5\n\n\n\n\n3.1.4 Un nouveau nom\n\n# on veut aussi lui donner un nom\nmon_chat.nom = \"Martin\"\nmon_chat.nom\n\n'Martin'\n\n\n\n\n3.1.5 Une autre instance de la classe Chat\nOn peut aussi cr√©er d‚Äôautres objets chat √† partir de la classe chat :\n\n# on appelle la classe\nl_autre_chat = chat()\n# on change les attributs qui nous int√©ressent\nl_autre_chat.nom = \"Ginette\"\nl_autre_chat.maitre = \"Roger\"\n# les attributs inchang√©s donnent la m√™me chose\n# que ceux d√©finis par d√©faut pour la classe\nprint(l_autre_chat.couleur)\n\nNoir",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#les-m√©thodes-de-la-classe-chat",
    "href": "content/getting-started/07_rappels_classes.html#les-m√©thodes-de-la-classe-chat",
    "title": "Les classes en Python",
    "section": "3.2 Les m√©thodes de la classe chat",
    "text": "3.2 Les m√©thodes de la classe chat\nLes attributs sont des variables propres √† notre objet, qui servent √† le caract√©riser.\nLes m√©thodes sont plut√¥t des actions, comme nous l‚Äôavons vu dans la partie pr√©c√©dente, agissant sur l‚Äôobjet.\nPar exemple, la m√©thode append de la classe list permet d‚Äôajouter un √©l√©ment dans l‚Äôobjet list manipul√©.\n\n3.2.1 Classe chat version 3 - premi√®re m√©thode\nOn peut d√©finir une premi√®re m√©thode : nourrir\n\nclass chat:  # D√©finition de notre classe chat\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\n\n    L'objet chat a une m√©thode : nourrir\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.couleur = \"Noir\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        self.nom = \"Aucun nom\"\n\n        \"\"\"Par d√©faut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n\n    def nourrir(self, nourriture):\n        \"\"\"M√©thode permettant de donner √† manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"\n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n\nmon_chat = chat()\nmon_chat.nom = \"Martin\"\nmon_chat.ventre  # On n'a rien donn√© √† Martin, son ventre est vide\n\n''\n\n\n\n# on appelle la m√©thode \"nourrir\" de la classe chat,\n# on lui donne un √©l√©ment, ici des croquettes\nmon_chat.nourrir(\"Croquettes\")\nprint(\"Le contenu du ventre de martin : \", mon_chat.ventre)\n\nLe contenu du ventre de martin :  Croquettes\n\n\n\nmon_chat.nourrir(\"Saumon\")\nprint(\"Le contenu du ventre de martin : \", mon_chat.ventre)\n\nLe contenu du ventre de martin :  Croquettes,Saumon\n\n\n\n\n3.2.2 Classe chat version 4 - autre m√©thode\nAvec un chat, on peut imaginer plein de m√©thodes. Ici on va d√©finir une action ‚Äúnourrir‚Äù et une autre action\n‚Äúlitiere‚Äù, qui consiste √† vider l‚Äôestomac du chat.\n\nclass chat:  # D√©finition de notre classe Personne\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\n\n    L'objet chat a deux m√©thodes : nourrir et litiere\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.nom = \"\"\n        self.couleur = \"Roux\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        \"\"\"Par d√©faut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n\n    def nourrir(self, nourriture):\n        \"\"\"M√©thode permettant de donner √† manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"\n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n    def litiere(self):\n        \"\"\"M√©thode permettant au chat d'aller √† sa liti√®re :\n        en cons√©quence son ventre est vide\"\"\"\n        self.ventre = \"\"\n        print(self.nom, \"a le ventre vide\")\n\n\n# on d√©finit Martin le chat\nmon_chat = chat()\nmon_chat.nom = \"Martin\"\n# on le nourrit avec des croquettes\nmon_chat.nourrir(\"croquettes\")\nprint(\"Le contenu du ventre de martin\", mon_chat.ventre)\n\n\n# Il va dans sa litiere\nmon_chat.litiere()\n\nLe contenu du ventre de martin croquettes\nMartin a le ventre vide\n\n\n\nhelp(mon_chat.nourrir)\nhelp(mon_chat.litiere)\n\nHelp on method nourrir in module __main__:\n\nnourrir(nourriture) method of __main__.chat instance\n    M√©thode permettant de donner √† manger au chat.\n    Si le ventre n'est pas vide, on met une virgule avant de rajouter\n    la nourriture\n\nHelp on method litiere in module __main__:\n\nlitiere() method of __main__.chat instance\n    M√©thode permettant au chat d'aller √† sa liti√®re : \n    en cons√©quence son ventre est vide\n\n\n\n\n\n3.2.3 Les m√©thodes sp√©ciales (facultatif)\nSi on reprend notre classe chat, il y a en r√©alit√© des m√©thodes sp√©ciales que nous n‚Äôavons pas d√©finies mais\nqui sont implicites.\nPython comprend seul ce que doivent faire ces m√©thodes. Il a une id√©e pr√©concue de ce qu‚Äôelles doivent\neffectuer comme op√©ration. Si vous ne red√©finissez par une m√©thode sp√©ciale pour qu‚Äôelle fasse ce que vous\nsouhaitez, ca peut donner des r√©sultats inattendus.\nElles servent √† plusieurs choses :\n\n√† initialiser l‚Äôobjet instanci√© : __init__\n√† modifier son affichage : __repr__\n\n\n# pour avoir la valeur de l'attribut \"nom\"\n\nprint(mon_chat.__getattribute__(\"nom\"))\n# on aurait aussi pu faire plus simple :\nprint(mon_chat.nom)\n\nMartin\nMartin\n\n\n# si l'attribut n'existe pas : on a une erreur\n# Python recherche l'attribut et, s'il ne le trouve pas dans l'objet et si une m√©thode __getattr__ est sp√©cifi√©e,\n# il va l'appeler en lui passant en param√®tre le nom de l'attribut recherch√©, sous la forme d'une cha√Æne de caract√®res.\n\nprint(mon_chat.origine)\n## Error in py_call_impl(callable, dots$args, dots$keywords): AttributeError: 'chat' object has no attribute 'origine'\n## \n## Detailed traceback: \n##   File \"&lt;string&gt;\", line 1, in &lt;module&gt;\nMais on peut modifier les m√©thodes sp√©ciales de notre classe chat pour √©viter d‚Äôavoir des erreurs d‚Äôattributs. On va aussi en profiter pour modifier la repr√©sentation de l‚Äôinstance chat qui pour l‚Äôinstant donne &lt;_main_.chat object at 0x0000000005AB4C50&gt;\n\n\n3.2.4 Classe chat version 5 - m√©thode sp√©ciale\n\nclass chat:  # D√©finition de notre classe Personne\n    \"\"\"Classe d√©finissant un chat caract√©ris√© par :\n    - sa couleur\n    - son √¢ge\n    - son caract√®re\n    - son poids\n    - son maitre\n    - son nom\n\n    L'objet chat a deux m√©thodes : nourrir et litiere\"\"\"\n\n    def __init__(self):  # Notre m√©thode constructeur -\n        # self c'est notre objet qu'on est en train de cr√©er\n        self.nom = \"\"\n        self.couleur = \"Roux\"\n        self.age = 10\n        self.caractere = \"Joueur\"\n        self.poids = 3\n        self.maitre = \"Jeanne\"\n        \"\"\"Par d√©faut, notre ventre est vide\"\"\"\n        self.ventre = \"\"\n\n    def nourrir(self, nourriture):\n        \"\"\"M√©thode permettant de donner √† manger au chat.\n        Si le ventre n'est pas vide, on met une virgule avant de rajouter\n        la nourriture\"\"\"\n        if self.ventre != \"\":\n            self.ventre += \",\"\n        self.ventre += nourriture\n\n    def litiere(self):\n        \"\"\"M√©thode permettant au chat d'aller √† sa liti√®re :\n        en cons√©quence son ventre est vide\"\"\"\n        self.ventre = \"\"\n        print(self.nom, \"a le ventre vide\")\n\n    def __getattribute__(self, key):\n        return print(key, \"n'est pas un attribut de la classe chat\")\n\n    def __repr__(self):\n        return \"Je suis une instance de la classe chat\"\n\n\n# j'ai gard√© l'exemple chat d√©fini selon la classe version 4\n# Martin, le chat\n# on a vu pr√©c√©demment qu'il n'avait pas d'attribut origine\n# et que cela levait une erreur AttributeError\nprint(mon_chat.nom)\n\n\n# on va d√©finir un nouveau chat avec la version 5\n# on appelle √† nouveau un attribut qui n'existe pas \"origine\"\n# on a bien le message d√©fini par la m√©thode sp√©ciale _gettattribute\n\nmon_chat_nouvelle_version = chat()\nmon_chat_nouvelle_version.origine\n\n# Maintenant on a aussi une d√©finition de l'objet plus clair\nprint(mon_chat)\nprint(mon_chat_nouvelle_version)\n\nMartin\norigine n'est pas un attribut de la classe chat\n&lt;__main__.chat object at 0x7f328d3d51d0&gt;\nJe suis une instance de la classe chat",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#conclusion-sur-les-classes-ce-quon-retient",
    "href": "content/getting-started/07_rappels_classes.html#conclusion-sur-les-classes-ce-quon-retient",
    "title": "Les classes en Python",
    "section": "3.3 Conclusion sur les classes : ce qu‚Äôon retient",
    "text": "3.3 Conclusion sur les classes : ce qu‚Äôon retient\n\nLes m√©thodes se d√©finissent comme des fonctions, sauf qu‚Äôelles se trouvent dans le corps de la classe.\nOn d√©finit les attributs d‚Äôune instance dans le constructeur de sa classe, en suivant cette syntaxe : self.nom_attribut = valeur.\nfacultatif : Les m√©thodes d‚Äôinstance prennent en premier param√®tre ‚Äúself‚Äù, l‚Äôinstance de l‚Äôobjet manipul√©.\nfacultatif : On construit une instance de classe en appelant son constructeur, une m√©thode d‚Äôinstance appel√©e init.",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/07_rappels_classes.html#informations-additionnelles",
    "href": "content/getting-started/07_rappels_classes.html#informations-additionnelles",
    "title": "Les classes en Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\na1b8aaf\n\n\n2021-09-20 09:05:55\n\n\nLino Galiana\n\n\nBadges de telechargement dans les premiers TP (#146)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\nc3c7433\n\n\n2020-09-15 12:41:26\n\n\nLino Galiana\n\n\nImprove CI with gitlab and jupyter nb conversion (#35)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Les classes en Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html",
    "href": "content/getting-started/05_rappels_types.html",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nPandas et Numpy sont\nessentiels pour manipuler les donn√©es.\nN√©anmoins, il est n√©cessaire de ne pas faire l‚Äôimpasse sur les fondements\ndu langage Python. Une bonne compr√©hension des √©l√©ments structurants le\nlangage entra√Æne une plus grande productivit√© et libert√©.\nCe chapitre est inspir√© du mat√©riel qui √©tait propos√©\npar Xavier Dupr√©,\nle pr√©c√©dent professeur de ce cours.\nVoir aussi Essential Cheat Sheets for Machine Learning and Deep Learning Engineers.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#le-print",
    "href": "content/getting-started/05_rappels_types.html#le-print",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "2.1 Le print",
    "text": "2.1 Le print\n\n# on calcule : dans le cas d'une op√©ration par exemple une somme\n2 + 3  # Python calcule le r√©sultat mais n'affiche rien dans la sortie\n\n# le print : on affiche\n\nprint(2 + 3)  # Python calcule et on lui demande juste de l'afficher\n# le r√©sultat est en dessous du code\n\n5\n\n\n\n# le print dans une fonction\n\n\ndef addition_v1(a, b):\n    print(a + b)\n\n\nresultat_print = addition_v1(2, 0)\nprint(type(resultat_print))\n\n# dans la sortie on a l'affichage du r√©sultat, car la sortie de la fonction est un print\n# en plus on lui demande quel est le type du r√©sultat. Un print ne renvoie aucun type, ce n'est ni un num√©rique,\n# ni une chaine de charact√®res, le r√©sultat d'un print n'est pas un format utilisable\n\n2\n&lt;class 'NoneType'&gt;\n\n\nLe r√©sultat de l‚Äôaddition est affich√©\ncar la fonction addition_v1 effectue un print\nPar contre, l‚Äôobjet cr√©√© n‚Äôa pas de type, il n‚Äôest pas un chiffre,\nce n‚Äôest qu‚Äôun affichage.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#le-return",
    "href": "content/getting-started/05_rappels_types.html#le-return",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "2.2 Le return",
    "text": "2.2 Le return\nPour cr√©er un objet avec le r√©sultat de la fonction, il faut utiliser return\n\n# le return dans une fonction\ndef addition_v2(a, b):\n    return a + b\n\n\nresultat_return = addition_v2(2, 5)  #\nprint(type(resultat_return))\n## l√† on a bien un r√©sultat qui est du type \"entier\"\n\n&lt;class 'int'&gt;\n\n\nLe r√©sultat de addition_v2 n‚Äôest pas affich√© comme dans addition_v1\nPar contre, la fonction addition_v2 permet d‚Äôavoir un objet de type int,\nun entier donc.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-variables-immuables",
    "href": "content/getting-started/05_rappels_types.html#les-variables-immuables",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "3.1 Les variables immuables",
    "text": "3.1 Les variables immuables\nLes variables immuables ne peuvent √™tre modifi√©es\n\nNone : ce type est une convention de programmation pour dire que la valeur n‚Äôest pas calcul√©e\nbool : un bool√©en\nint : un entier\nfloat : un r√©el\nstr : une chaine de caract√®res\ntuple : un vecteur\n\n\ni = 3  # entier = type num√©rique (type int)\nr = 3.3  # r√©el   = type num√©rique (type float)\ns = \"exemple\"  # cha√Æne de caract√®res = type str\nn = None  # None signifie que la variable existe mais qu'elle ne contient rien\n# elle est souvent utilis√©e pour signifier qu'il n'y a pas de r√©sultat\na = (1, 2)  # tuple\n\nprint(i, r, s, n, a)\n\n3 3.3 exemple None (1, 2)\n\n\nSi on essaie de changer le premier √©l√©ment de la chaine de caract√®res s on va avoir un peu de mal.\nPar exemple si on voulait mettre une majuscule √† ‚Äúexemple‚Äù,\non aurait envie d‚Äô√©crire que le premier √©l√©ment de la chaine s est ‚ÄúE‚Äù majuscule\nMais Python ne va pas nous laisser faire, il nous dit que les objets ‚Äúchaine de caract√®re‚Äù ne peuvent √™tre modifi√©s\n\ns[0] = \"E\"  # d√©clenche une exception\n\nTypeError: 'str' object does not support item assignment\n\n\nTout ce qu‚Äôon peut faire avec une variable immuable,\nc‚Äôest la r√©affecter √† une autre valeur : elle ne peut pas √™tre modifi√©e.\nPour s‚Äôen convaincre, utilisons la fonction id() qui donne un identifiant √† chaque objet.\n\nprint(s)\nid(s)\n\nexemple\n\n\n140038838169392\n\n\n\ns = \"autre_mot\"\nid(s)\n\n140037351086384\n\n\nOn voit bien que s a chang√© d‚Äôidentifiant : il peut avoir le m√™me nom, ce n‚Äôest plus le m√™me objet",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-types-modifiable-listes-et-dictionnaires",
    "href": "content/getting-started/05_rappels_types.html#les-types-modifiable-listes-et-dictionnaires",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "3.2 Les types modifiable : listes et dictionnaires",
    "text": "3.2 Les types modifiable : listes et dictionnaires\nHeureusement, il existe des variables modifiables comme les listes et les dictionnaires.\n\n3.2.1 Les listes - elles s‚Äô√©crivent entre [ ]\nLes listes sont des √©lements tr√®s utiles, notamment quand vous souhaitez faire des boucles.\nPour faire appel aux √©lements d‚Äôune liste, on donne leur position dans la liste : le 1er est le 0, le 2√®me est le 1 ‚Ä¶\n\nma_liste = [1, 2, 3, 4]\n\n\nprint(\"La longueur de ma liste est de\", len(ma_liste))\nprint(\"Le premier √©l√©ment de ma liste est :\", ma_liste[0])\nprint(\"Le dernier √©l√©ment de ma liste est :\", ma_liste[3])\nprint(\"Le dernier √©l√©ment de ma liste est :\", ma_liste[-1])\n\nLa longueur de ma liste est de 4\nLe premier √©l√©ment de ma liste est : 1\nLe dernier √©l√©ment de ma liste est : 4\nLe dernier √©l√©ment de ma liste est : 4\n\n\nPour effectuer des boucles sur les listes, la m√©thode la plus lisible\nest d‚Äôutiliser les list comprehension. Cette approche consiste\n√† it√©rer les √©l√©ments d‚Äôune liste √† la vol√©e.\nPar exemple, si on reprend cet exemple,\nun code qui repose sur les list comprehension sera le suivant :\n\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = [x for x in fruits if \"a\" in x]\nprint(newlist)\n\n['apple', 'banana', 'mango']\n\n\nLe m√™me code, ne reposant pas sur les compr√©hensions de liste, sera beaucoup\nmoins concis et ainsi inutilement verbeux:\n\nfruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\nnewlist = []\n\nfor x in fruits:\n    if \"a\" in x:\n        newlist.append(x)\n\nprint(newlist)\n\n['apple', 'banana', 'mango']\n\n\n\n\n3.2.2 Les dictionnaires - ils s‚Äô√©crivent entre accolades {}\nUn dictionnaire associe √† une cl√© un autre √©l√©ment, appel√© une valeur : un chiffre, un nom, une liste, un autre dictionnaire etc.\nLe format d‚Äôun dictionnaire est le suivant : {Cl√© : valeur}. Il s‚Äôagit\nd‚Äôun objet tr√®s pratique pour la recherche, beaucoup plus que les listes\nqui ne permettent pas de stocker de l‚Äôinformation diverse de mani√®re\nhi√©rarchis√©e.\n\n\n3.2.3 Dictionnaire avec des valeurs int\nOn peut par exemple associer √† un nom, un nombre\n\nmon_dictionnaire_notes = {\"Nicolas\": 18, \"Pimprenelle\": 15}\n# un dictionnaire qui √† chaque nom associe un nombre\n# √† Nicolas, on associe 18\n\nprint(mon_dictionnaire_notes)\n\n{'Nicolas': 18, 'Pimprenelle': 15}\n\n\n\n\n3.2.4 Dictionnaire avec des valeurs qui sont des listes\nPour chaque cl√© d‚Äôun dictionnaire, il ne faut pas forc√©ment garder la m√™me forme de valeur\nDans l‚Äôexemple, la valeur de la cl√© ‚ÄúNicolas‚Äù est une liste, alors que celle de ‚ÄúPhilou‚Äù est une liste de liste\n\nmon_dictionnaire_loisirs = {\n    \"Nicolas\": [\"Rugby\", \"Pastis\", \"Belote\"],\n    \"Pimprenelle\": [\"Gin Rami\", \"Tisane\", \"Tara Jarmon\", \"Barcelone\", \"Mickey Mouse\"],\n    \"Philou\": [[\"Maths\", \"Jeux\"], [\"Guillaume\", \"Jeanne\", \"Thimoth√©e\", \"Adrien\"]],\n}\n\nPour acc√©der √† un √©l√©ment du dictionnaire, on fait appel √† la cl√© et non plus √† la position, comme c‚Äô√©tait le cas dans les listes.\nC‚Äôest beaucoup plus pratique pour rechercher de l‚Äôinformation:\n\nprint(mon_dictionnaire_loisirs[\"Nicolas\"])  # on affiche une liste\n\n['Rugby', 'Pastis', 'Belote']\n\n\n\nprint(mon_dictionnaire_loisirs[\"Philou\"])  # on affiche une liste de listes\n\n[['Maths', 'Jeux'], ['Guillaume', 'Jeanne', 'Thimoth√©e', 'Adrien']]\n\n\nSi on ne veut avoir que la premi√®re liste des loisirs de Philou, on demande le premier √©l√©ment de la liste\n\nprint(mon_dictionnaire_loisirs[\"Philou\"][0])  # on affiche alors juste la premi√®re liste\n\n['Maths', 'Jeux']\n\n\nOn peut aussi avoir des valeurs qui sont des int et des list\n\nmon_dictionnaire_patchwork_good = {\n    \"Nicolas\": [\"Rugby\", \"Pastis\", \"Belote\"],\n    \"Pimprenelle\": 18,\n}",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#a-retenir",
    "href": "content/getting-started/05_rappels_types.html#a-retenir",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "3.3 A retenir",
    "text": "3.3 A retenir\n\nL‚Äôindentation du code est importante (4 espaces et pas une tabulation)\nUne liste est entre [] et on peut appeler les positions par leur place\nUn dictionnaire, cl√© x valeur, s‚Äô√©crit entre {} et on appelle un √©l√©ment en fonction de la cl√©",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#premiers-exemples-de-m√©thodes",
    "href": "content/getting-started/05_rappels_types.html#premiers-exemples-de-m√©thodes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "5.1 Premiers exemples de m√©thodes",
    "text": "5.1 Premiers exemples de m√©thodes\nAvec les √©l√©ments d√©finis dans la partie 1\n(les listes, les dictionnaires) on peut faire appel √† des m√©thodes qui sont directement li√©es √† ces objets.\n\n5.1.1 Une m√©thode pour les listes\nPour ajouter un √©l√©ment (item) dans une liste : on va utiliser la m√©thode .append()\n\nma_liste = [\"Nicolas\", \"Michel\", \"Bernard\"]\n\nma_liste.append(\"Philippe\")\n\nprint(ma_liste)\n\n['Nicolas', 'Michel', 'Bernard', 'Philippe']\n\n\n\n\n5.1.2 Une m√©thode pour les dictionnaires\nPour connaitre l‚Äôensemble des cl√©s d‚Äôun dictionnaire, on appelle la m√©thode .keys()\n\nmon_dictionnaire = {\n    \"Marc\": \"Lion\",\n    \"Matthieu\": [\"Ange\", \"Homme ail√©\"],\n    \"Jean\": \"Aigle\",\n    \"Luc\": \"Taureau\",\n}\n\nprint(mon_dictionnaire.keys())\n\ndict_keys(['Marc', 'Matthieu', 'Jean', 'Luc'])",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#connaitre-les-m√©thodes-dun-objet",
    "href": "content/getting-started/05_rappels_types.html#connaitre-les-m√©thodes-dun-objet",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "5.2 Connaitre les m√©thodes d‚Äôun objet",
    "text": "5.2 Connaitre les m√©thodes d‚Äôun objet\nPour savoir quelles sont les m√©thodes d‚Äôun objet vous pouvez :\n\ntaper help(mon_objet) ou mon_objet? dans la console Python\ntaper mon_objet. + touche tabulation dans la console Python ou dans le Notebook.\nPython permet la compl√©tion, c‚Äôest-√†-dire que vous pouvez faire appa√Ætre la liste\ndes m√©thodes possibles.",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#cr√©er-une-liste",
    "href": "content/getting-started/05_rappels_types.html#cr√©er-une-liste",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.1 Cr√©er une liste",
    "text": "6.1 Cr√©er une liste\nPour cr√©er un objet de la classe list, il suffit de le d√©clarer. Ici on affecte √† x une liste\n\nx = [4, 5]  # cr√©ation d‚Äôune liste compos√©e de deux entiers\nx = [\"un\", 1, \"deux\", 2]  # cr√©ation d‚Äôune liste compos√©e de 2 cha√Ænes de caract√®res\n# et de deux entiers, l‚Äôordre d‚Äô√©criture est important\nx = [3]  # cr√©ation d‚Äôune liste d‚Äôun √©l√©ment, sans la virgule,\nx = []  # cr√©e une liste vide\nx = list()  # cr√©e une liste vide",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#un-premier-test-sur-les-listes",
    "href": "content/getting-started/05_rappels_types.html#un-premier-test-sur-les-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.2 Un premier test sur les listes",
    "text": "6.2 Un premier test sur les listes\nSi on veut tester la pr√©sence d‚Äôun √©l√©ment dans une liste, on l‚Äô√©crit de la mani√®re suivante :\n\n# Exemple\n\nx = \"Marcel\"\n\nl = [\"Marcel\", \"Edith\", \"Maurice\", \"Jean\"]\n\nprint(x in l)\n\n# vrai si x est un des √©l√©ments de l\n\nTrue",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#une-m√©thode-pour-concat√©ner-deux-listes",
    "href": "content/getting-started/05_rappels_types.html#une-m√©thode-pour-concat√©ner-deux-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.3 +: une m√©thode pour concat√©ner deux listes",
    "text": "6.3 +: une m√©thode pour concat√©ner deux listes\nOn utilise le symbole +\n\nt = [\"Antoine\", \"David\"]\nprint(l + t)  # concat√©nation de l et t\n\n['Marcel', 'Edith', 'Maurice', 'Jean', 'Antoine', 'David']",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#pour-trouver-certains-√©l√©ments-dune-liste",
    "href": "content/getting-started/05_rappels_types.html#pour-trouver-certains-√©l√©ments-dune-liste",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.4 Pour trouver certains √©l√©ments d‚Äôune liste",
    "text": "6.4 Pour trouver certains √©l√©ments d‚Äôune liste\nPour chercher des √©lements dans une liste, on utilise la position dans la liste.\n\nl[1]  # donne l'√©l√©ment qui est en 2√®me position de la liste\n\n'Edith'\n\n\n\nl[1:3]  # donne les √©l√©ments de la 2√®me position de la liste √† la 4√®me exclue\n\n['Edith', 'Maurice']",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#quelques-fonctions-des-listes",
    "href": "content/getting-started/05_rappels_types.html#quelques-fonctions-des-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.5 Quelques fonctions des listes",
    "text": "6.5 Quelques fonctions des listes\nLes listes embarquent ainsi nativement un certain nombre de m√©thodes\nqui sont pratiques. Cependant, pour avoir certaines informations\nsur une liste, il faut parfois plut√¥t passer par\ndes fonctions natives comme les suivantes :\n\nlongueur = len(l)  # nombre d‚Äô√©l√©ments de l\nminimum = min(l)  # plus petit √©l√©ment de l, ici par ordre alphab√©tique\nmaximum = max(l)  # plus grand √©l√©ment de l, ici par ordre alphab√©tique\nprint(longueur, minimum, maximum)\n\n4 Edith Maurice\n\n\n\ndel l[0:2]  # supprime les √©l√©ments entre la position 0 et 2 exclue\nprint(l)\n\n['Maurice', 'Jean']",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#les-m√©thodes-des-listes",
    "href": "content/getting-started/05_rappels_types.html#les-m√©thodes-des-listes",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.6 Les m√©thodes des listes",
    "text": "6.6 Les m√©thodes des listes\nOn les trouve dans l‚Äôaide de la liste.\nOn distingue les m√©thodes et les m√©thodes sp√©ciales : visuellement,\nles m√©thodes sp√©ciales sont celles qui pr√©c√©d√©es et suivis de deux caract√®res de soulignement,\nles autres sont des m√©thodes classiques.\n\nhelp(l)\n\nHelp on list object:\n\nclass list(object)\n |  list(iterable=(), /)\n |  \n |  Built-in mutable sequence.\n |  \n |  If no argument is given, the constructor creates a new empty list.\n |  The argument must be an iterable if specified.\n |  \n |  Methods defined here:\n |  \n |  __add__(self, value, /)\n |      Return self+value.\n |  \n |  __contains__(self, key, /)\n |      Return key in self.\n |  \n |  __delitem__(self, key, /)\n |      Delete self[key].\n |  \n |  __eq__(self, value, /)\n |      Return self==value.\n |  \n |  __ge__(self, value, /)\n |      Return self&gt;=value.\n |  \n |  __getattribute__(self, name, /)\n |      Return getattr(self, name).\n |  \n |  __getitem__(...)\n |      x.__getitem__(y) &lt;==&gt; x[y]\n |  \n |  __gt__(self, value, /)\n |      Return self&gt;value.\n |  \n |  __iadd__(self, value, /)\n |      Implement self+=value.\n |  \n |  __imul__(self, value, /)\n |      Implement self*=value.\n |  \n |  __init__(self, /, *args, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __iter__(self, /)\n |      Implement iter(self).\n |  \n |  __le__(self, value, /)\n |      Return self&lt;=value.\n |  \n |  __len__(self, /)\n |      Return len(self).\n |  \n |  __lt__(self, value, /)\n |      Return self&lt;value.\n |  \n |  __mul__(self, value, /)\n |      Return self*value.\n |  \n |  __ne__(self, value, /)\n |      Return self!=value.\n |  \n |  __repr__(self, /)\n |      Return repr(self).\n |  \n |  __reversed__(self, /)\n |      Return a reverse iterator over the list.\n |  \n |  __rmul__(self, value, /)\n |      Return value*self.\n |  \n |  __setitem__(self, key, value, /)\n |      Set self[key] to value.\n |  \n |  __sizeof__(self, /)\n |      Return the size of the list in memory, in bytes.\n |  \n |  append(self, object, /)\n |      Append object to the end of the list.\n |  \n |  clear(self, /)\n |      Remove all items from list.\n |  \n |  copy(self, /)\n |      Return a shallow copy of the list.\n |  \n |  count(self, value, /)\n |      Return number of occurrences of value.\n |  \n |  extend(self, iterable, /)\n |      Extend list by appending elements from the iterable.\n |  \n |  index(self, value, start=0, stop=9223372036854775807, /)\n |      Return first index of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  insert(self, index, object, /)\n |      Insert object before index.\n |  \n |  pop(self, index=-1, /)\n |      Remove and return item at index (default last).\n |      \n |      Raises IndexError if list is empty or index is out of range.\n |  \n |  remove(self, value, /)\n |      Remove first occurrence of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  reverse(self, /)\n |      Reverse *IN PLACE*.\n |  \n |  sort(self, /, *, key=None, reverse=False)\n |      Sort the list in ascending order and return None.\n |      \n |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the\n |      order of two equal elements is maintained).\n |      \n |      If a key function is given, apply it once to each list item and sort them,\n |      ascending or descending, according to their function values.\n |      \n |      The reverse flag can be set to sort in descending order.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  __class_getitem__(...) from builtins.type\n |      See PEP 585\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  __new__(*args, **kwargs) from builtins.type\n |      Create and return a new object.  See help(type) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#a-retenir-et-questions",
    "href": "content/getting-started/05_rappels_types.html#a-retenir-et-questions",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "6.7 A retenir et questions",
    "text": "6.7 A retenir et questions\nA retenir :\n\nChaque objet Python a des attributs et des m√©thodes\nVous pouvez cr√©er des classes avec des attributs et des m√©thodes\nLes m√©thodes des listes et des dictionnaires qui sont les plus utilis√©es :\n\nlist.count()\nlist.sort()\nlist.append()\ndict.keys()\ndict.items()\ndict.values()\n\n\n\n\n Exercice 2\n\nD√©finir la liste allant de 1 √† 10, puis effectuez les actions suivantes :\n\n\ntriez et affichez la liste\najoutez l‚Äô√©l√©ment 11 √† la liste et affichez la liste\nrenversez et affichez la liste\naffichez l‚Äô√©l√©ment d‚Äôindice 7\nenlevez l‚Äô√©l√©ment 9 et affichez la liste\naffichez la sous-liste du 2e au 3e √©l√©ments inclus ;\naffichez la sous-liste du d√©but au 2e √©l√©ment inclus ;\naffichez la sous-liste du 3e √©l√©ment √† la fin de la liste ;\n\n\nConstruire le dictionnaire des 6 premiers mois de l‚Äôann√©e avec comme valeurs le nombre de jours respectif.\n\n\nRenvoyer la liste des mois\nRenvoyer la liste des jours\nAjoutez la cl√© du mois de Juillet",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/05_rappels_types.html#informations-additionnelles",
    "href": "content/getting-started/05_rappels_types.html#informations-additionnelles",
    "title": "Quelques rappels sur les principes de base de Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\na1b8aaf\n\n\n2021-09-20 09:05:55\n\n\nLino Galiana\n\n\nBadges de telechargement dans les premiers TP (#146)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n4c9ebb8\n\n\n2020-09-17 14:09:07\n\n\nLino Galiana\n\n\nCorrige typo incr√©mentation\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Quelques rappels sur les principes de base de Python"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html",
    "href": "content/getting-started/03_data_analysis.html",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "",
    "text": "Pour bien d√©buter des travaux sur une base de donn√©es,\nil est n√©cessaire de se poser quelques questions de bon sens\net de suivre une d√©marche scientifique dont un certain\nnombre de gestes sont assez simple.\nDans un projet sur des jeux de donn√©es, on peut sch√©matiquement\ns√©parer les √©tapes en quatre grandes parties :\nCe cours explore ces diff√©rentes √©tapes de mani√®re progressive gr√¢ce √†\nl‚Äô√©cosyst√®me Python qui est tr√®s complet. Chaque chapitre du cours\npeut √™tre vu comme une mani√®re de progresser dans ce fil conducteur.\nDans ce chapitre, nous allons plut√¥t mettre en avant quelques r√©flexions\n√† avoir avant de se lancer dans chaque √©tape.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#r√©flexions-√†-mener-en-amont",
    "href": "content/getting-started/03_data_analysis.html#r√©flexions-√†-mener-en-amont",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "1.1 R√©flexions √† mener en amont",
    "text": "1.1 R√©flexions √† mener en amont\nLa phase de constitution de son jeu de donn√©es sous-tend tout le projet qui suit.\nLa premi√®re question √† se poser est\n‚Äúde quelles donn√©es ai-je besoin pour r√©pondre √† ma probl√©matique ?‚Äù.\nCette probl√©matique pourra √©ventuellement\n√™tre affin√©e en fonction des besoins mais les travaux sont g√©n√©ralement\nde meilleure qualit√© lorsque la probl√©matique am√®ne √† la r√©flexion sur les donn√©es\ndisponibles plut√¥t que l‚Äôinverse.\nEnsuite, ‚Äúqui produit et met √† disposition ces donn√©es‚Äù ?\nLes sources disponibles sur internet sont-elles fiables ?\nPar exemple, les sites d‚Äôopen data gouvernementaux sont par exemple assez fiables mais autorisent parfois l‚Äôarchivage de donn√©es restructur√©es par des tiers et non des producteurs officiels. A l‚Äôinverse, sur Kaggle ou sur Github la source de certains jeux de donn√©es n‚Äôest pas trac√©e ce qui rend compliqu√©e la confiance sur la qualit√© de la donn√©e\nUne fois identifi√© une ou plusieurs sources de donn√©es,\nest-ce que je peux les compl√©ter avec d‚Äôautres donn√©es ?\n(dans ce cas, faire attention √† avoir des niveaux de granularit√© ad√©quats).",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#structuration-des-donn√©es",
    "href": "content/getting-started/03_data_analysis.html#structuration-des-donn√©es",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "1.2 Structuration des donn√©es",
    "text": "1.2 Structuration des donn√©es\nVient ensuite la phase de mise en forme et nettoyage des jeux de donn√©es r√©cup√©r√©s.\nCette √©tape est primordiale et est g√©n√©ralement celle qui mobilise le plus\nde temps. Pendant quelques ann√©es, on parlait de data cleaning. Cependant,\ncela a pu, implicitement, laisser penser qu‚Äôil s‚Äôagissait d‚Äôune t√¢che\nsubalterne. On commence √† lui pr√©f√©rer le concept de feature engineering\nqui souligne bien qu‚Äôil s‚Äôagit d‚Äôune comp√©tence qui n√©cessite beaucoup\nde comp√©tences.\nUn jeu de donn√©es propre est un jeu de donn√©es dont la structure est\nad√©quate et n‚Äôentra√Ænera pas d‚Äôerreur, visible ou non,\nlors de la phase d‚Äôanalyse. Voici quelques √©l√©ments structurants\nd‚Äôun jeu de donn√©es propre :\n\nles informations manquantes sont bien comprises et trait√©es. numpy et\npandas proposent un certain formalisme sur le sujet qu‚Äôil est utile\nd‚Äôadopter en rempla√ßant par NaN les observations manquantes. Cela\nimplique de faire attention √† la mani√®re dont certains producteurs\ncodent les valeurs manquantes : certains ont la facheuse tendance √†\n√™tre imaginatifs sur les codes pour valeurs manquantes : ‚Äú-999‚Äù, ‚ÄúXXX‚Äù, ‚ÄúNA‚Äù\nles variables servant d‚Äôidentifiants sont bien les m√™mes d‚Äôune table √† l‚Äôautre (notamment dans le cas de jointure) : m√™me format, m√™me modalit√©s\npour des variables textuelles, qui peuvent etre mal saisies, avoir corrig√© les √©ventuelles fautes (ex ‚ÄúRolland Garros‚Äù -&gt; ‚ÄúRoland Garros‚Äù)\ncr√©er des variables qui synth√©tisent l‚Äôinformation dont vous avez besoin\nsupprimer les √©l√©ments inutiles (colonne ou ligne vide)\nrenommer les colonnes avec des noms compr√©hensibles",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#valorisation-des-travaux",
    "href": "content/getting-started/03_data_analysis.html#valorisation-des-travaux",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "3.1 Valorisation des travaux",
    "text": "3.1 Valorisation des travaux\nLa mise √† disposition de code sur Github ou Gitlab est une incitation\ntr√®s forte pour produire du code de qualit√©. Il est ainsi recommand√© de\nsyst√©matiquement utiliser ces plateformes pour la mise √† disposition de\ncode. Cependant, il ne s‚Äôagit que d‚Äôune petite partie des gains √†\nl‚Äôutiliser.\nLe cours que je donne avec Romain Avouac en troisi√®me ann√©e d‚ÄôENSAE\n(ensae-reproductibilite.github.io/website/) √©voque\nl‚Äôun des principaux gains √† utiliser ces plateformes, √† savoir\nla possibilit√© de mettre √† disposition automatiquement diff√©rents livrables\npour valoriser son travail aupr√®s de diff√©rents publics.\nSelon le public vis√©, la communication ne sera pas identique. Le code peut\nint√©resser les personnes d√©sirant avoir des d√©tails sur la m√©thodologie mise\nen oeuvre en pratique mais il peut s‚Äôagir d‚Äôun format rebutant pour d‚Äôautres\npublics. Une visualisation de donn√©es dynamiques parlera √† des publics\nmoins experts de la donn√©e mais est plus dure √† mettre en oeuvre\nqu‚Äôun graphique standard.\n\n\n Note\nLes Notebooks Jupyter ont eu beaucoup de succ√®s dans le monde de\nla data science pour valoriser des travaux. Pourtant il ne s‚Äôagit\npas forc√©ment toujours du meilleur format. En effet, beaucoup\nde notebooks tentent √† empiler des pav√©s de code et du texte, ce\nqui les rend difficilement lisibles.\nSur un projet cons√©quent, il vaut mieux reporter le plus de code\npossible dans des scripts bien structur√©s et avoir un notebook\nqui appelle ces scripts pour produire des outputs. Ou alors ne\npas utiliser un notebook et privil√©gier un autre format (un\ntableau de bord, un site web, une appli r√©active‚Ä¶).\nDans le cours de derni√®re ann√©e de\nl‚ÄôENSAE, Mise en production de projets data science, Romain\nAvouac et moi revenons sur les moyens de communication et de partage de code alternatifs au notebook.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#la-reproductibilit√©-est-importante",
    "href": "content/getting-started/03_data_analysis.html#la-reproductibilit√©-est-importante",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.1 La reproductibilit√© est importante",
    "text": "4.1 La reproductibilit√© est importante\nLes donn√©es sont une repr√©sentation synth√©tique de la r√©alit√© et les\nconclusions de certaines analyses peuvent avoir un vrai impact sur\nla vie des citoyens. Les chiffres erron√©s de\nReinhart et Rogoff ont ainsi pu servir de justification th√©orique √† des\npolitiques d‚Äôaust√©rit√© qui ont pu avoir des cons√©quences violentes\npour certains citoyens de\npays en crise1. En Grande-Bretagne, le recensement des personnes\ncontamin√©es par le Covid en 2020, et donc de leurs proches pour le\nsuivi de l‚Äô√©pid√©mie,\na √©t√© incomplet √† cause de\ntroncatures dues √† l‚Äôutilisation d‚Äôun format non adapt√© de stockage\ndes donn√©es (tableur Excel)2.\nDernier exemple avec le credit scoring mis en oeuvre aux Etats-Unis.\nLa citation ci-dessous, issue de l‚Äôarticle de Hurley and Adebayo (2016),\nillustre tr√®s bien les cons√©quences et les aspects probl√©matiques\nd‚Äôun syst√®me de construction automatis√©e d‚Äôun score de cr√©dit :\n\nConsumers have limited ability to identify and contest unfair credit\ndecisions, and little chance to understand what steps they\nshould take to improve their credit. Recent studies have also\nquestioned the accuracy of the data used by these tools, in some\ncases identifying serious flaws that have a substantial bearing\non lending decisions. Big-data tools may also risk creating a\nsystem of ‚Äúcreditworthinessby association‚Äù in which consumers‚Äô\nfamilial, religious, social, and other affiliations determine their\neligibility for an affordable loan.\nHurley and Adebayo (2016)",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#lutter-contre-les-biais-cognitifs",
    "href": "content/getting-started/03_data_analysis.html#lutter-contre-les-biais-cognitifs",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.2 Lutter contre les biais cognitifs",
    "text": "4.2 Lutter contre les biais cognitifs\nLa transparence sur les int√©r√™ts et limites d‚Äôune m√©thode mise en oeuvre\nest donc importante.\nCette exigence de la recherche, parfois oubli√©e √† cause de la course\naux r√©sultats novateurs, m√©rite √©galement d‚Äô√™tre appliqu√©e\nen entreprise ou administration.\nM√™me sans intention manifeste de la part de la personne qui analyse des donn√©es,\nune mauvaise interpr√©tation est toujours possible. Tout en valorisant un\nr√©sultat, il est possible d‚Äôalerter sur certaines limites. Il est important,\ndans ses recherches comme dans les discussions avec d‚Äôautres interlocuteurs,\nde faire attention au biais de confirmation qui consiste\n√† ne retenir que l‚Äôinformation qui correspond √† nos conceptions a priori et\n√† ne pas consid√©rer celles qui pourraient aller √† l‚Äôencontre de celles-ci :\n\nCertaines repr√©sentations de donn√©es sont √† exclure car des biais cognitifs\npeuvent amener √† des interpr√©tations erron√©es3. Dans le domaine de la\nvisualisation de donn√©es, les camemberts (pie chart) ou les diagrammes\nradar sont par exemple\n√† exclure car l‚Äôoeil humain per√ßoit mal ces formes circulaires. Pour une raison\nsimilaire, les cartes avec aplat de couleur (cartes\nchoropl√®thes) sont trompeuses.\nLes posts de blog pour datawrapper\nde Lisa Charlotte Muth ou ceux d‚ÄôEric Mauvi√®re sont d‚Äôexcellentes ressources\npour apprendre les bonnes et mauvaises pratiques de\nvisualisation (voir la partie visualisation de ce cours\npour plus de d√©tails).",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#r√©glementation-des-donn√©es",
    "href": "content/getting-started/03_data_analysis.html#r√©glementation-des-donn√©es",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.3 R√©glementation des donn√©es",
    "text": "4.3 R√©glementation des donn√©es\nLe cadre r√©glementaire de protection des donn√©es a √©volu√© ces derni√®res\nann√©es avec le RGPD. Cette r√©glementation a permis de mieux faire\nsaisir le fait que la collecte de donn√©es se justifie au nom\nde finalit√©s plus ou moins bien identifi√©es. Prendre conscience que\nla confidentialit√© des donn√©es se justifie pour √©viter la diss√©mination\nnon contr√¥l√©e d‚Äôinformations sur une personne est important.\nDes donn√©es particuli√®rement sensibles, notamment les donn√©es de sant√©,\npeuvent √™tre plus contraignantes √† traiter que des donn√©es peu sensibles.\nEn Europe, par exemple, les agents du service statistique public\n(Insee ou services statistiques minist√©riels) sont tenus au secret professionnel\n(article L121-6 du Code g√©n√©ral de la fonction publique),\nqui leur interdit la communication des informations confidentielles\ndont ils sont d√©positaires au titre de leurs missions ou fonctions,\nsous peine des sanctions pr√©vues par l‚Äôarticle 226-13 du Code p√©nal\n(jusqu‚Äô√† un an d‚Äôemprisonnement et 15 000 ‚Ç¨ d‚Äôamende).\nLe secret statistique, d√©fini dans une loi de 1951,\nrenforce cette obligation dans le cas de donn√©es d√©tenues pour des usages statistiques.\nIl interdit strictement la communication de donn√©es individuelles\nou susceptibles d‚Äôidentifier les personnes,\nissues de traitements √† finalit√©s statistiques,\nque ces traitements proviennent d‚Äôenqu√™tes ou de bases de donn√©es.\nLe secret statistique exclut par principe de diffuser des donn√©es\nqui permettraient l‚Äôidentification des personnes concern√©es,\npersonnes physiques comme personnes morales.\nCette obligation limite la finesse des informations disponibles en diffusion\nCe cadre contraignant s‚Äôexplique par l‚Äôh√©ritage de la Seconde Guerre Mondiale\net le d√©sir de ne plus revivre une situation o√π la collecte d‚Äôinformation\nsert une action publique bas√©e sur la discrimination entre cat√©gories\nde la population.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#partager-les-moyens-de-reproduire-une-analyse",
    "href": "content/getting-started/03_data_analysis.html#partager-les-moyens-de-reproduire-une-analyse",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.4 Partager les moyens de reproduire une analyse",
    "text": "4.4 Partager les moyens de reproduire une analyse\nUn article r√©cent de Nature,\nqui reprend les travaux d‚Äôune √©quipe d‚Äô√©pid√©miologistes (Gabelica, Bojƒçiƒá, and Puljak 2022)\n√©voque le probl√®me de l‚Äôacc√®s aux donn√©es pour des chercheurs d√©sirant reproduire\nune √©tude. M√™me dans les articles scientifiques o√π il est mentionn√© que les\ndonn√©es peuvent √™tre mises √† disposition d‚Äôautres chercheurs, le partage\nde celles-ci est rare :\n\nGraphique issu de l‚Äôarticle de Nature\nCe constat, quelque peu inqui√©tant, est confirm√© par une √©tude r√©cente\nde Samuel and Mietchen (2023) qui a tent√© d‚Äôex√©cuter un peu moins de\n30 000 notebooks associ√©s √† des √©tudes scientifiques. Seuls 3%\ndes notebooks reproduisent les r√©sultats esp√©r√©s.\nAfin de partager les moyens de reproduire des publications sans diffuser des\ndonn√©es potentiellement confidentielles, les jeux de donn√©es synth√©tiques\nsont de plus en plus utilis√©s. Par le biais de mod√®les de deep learning,\nil est ainsi possible de g√©n√©rer des jeux de donn√©es synth√©tiques complexes\nqui permettent de reproduire les principales caract√©ristiques d‚Äôun jeu de donn√©es\ntout en √©vitant, si le mod√®le a √©t√© bien calibr√©, de diffuser une information\nindividuelle.\nDans l‚Äôadministration fran√ßaise, les codes sources sont\nconsid√©r√©s comme des documents administratifs et peuvent\ndonc √™tre mis √† disposition de tout citoyen sur demande √† la\nCommission d‚Äôacc√®s aux documents administratifs (CADA):\n\n¬´ Sont consid√©r√©s comme documents administratifs, au sens des titres Ier, III et IV du pr√©sent livre, quels que soient leur date, leur lieu de conservation, leur forme et leur support, les documents produits ou re√ßus, dans le cadre de leur mission de service public, par l‚Äô√âtat, les collectivit√©s territoriales ainsi que par les autres personnes de droit public ou les personnes de droit priv√© charg√©es d‚Äôune telle mission. Constituent de tels documents notamment les dossiers, rapports, √©tudes, comptes rendus, proc√®s-verbaux, statistiques, instructions, circulaires, notes et r√©ponses minist√©rielles, correspondances, avis, pr√©visions, codes sources et d√©cisions. ¬ª\nAvis 20230314 - S√©ance du 30/03/2023 de la Commission d‚Äôacc√®s aux documents administratifs\n\nEn revanche, les poids des mod√®les utilis√©s par l‚Äôadministration, notamment ceux\ndes mod√®les de machine learning ne sont pas r√©glement√©s de la m√™me\nmani√®re (Avis 20230314 de la CADA).\nEn effet, comme il existe toujours\nun risque de r√©tro-ing√©nierie amenant √† une r√©v√©lation partielle\ndes donn√©es\nd‚Äôentra√Ænement lors d‚Äôun partage de mod√®le, les mod√®les\nentra√Æn√©s sur des donn√©es\nsensibles (comme les d√©cisions de justice √©tudi√©es\npar (l‚Äôavis 20230314 de la CADA))\nn‚Äôont pas vocation √† √™tre partag√©s.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#adopter-une-approche-√©cologique",
    "href": "content/getting-started/03_data_analysis.html#adopter-une-approche-√©cologique",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "4.5 Adopter une approche √©cologique",
    "text": "4.5 Adopter une approche √©cologique\nLe num√©rique constitue une part croissante des\n√©missions de gaz √† effet de serre.\nRepr√©sentant aujourd‚Äôhui 4 % des √©missions mondiales\nde CO2, cette part devrait encore cro√Ætre (Arcep 2019).\nLe monde de la data science est √©galement\nconcern√©.\nL‚Äôutilisation de donn√©es de plus en\nplus massives, notamment la constitution\nde corpus monumentaux de textes,\nr√©cup√©r√©s par scraping, est une premi√®re source\nde d√©pense d‚Äô√©nergie. De m√™me, la r√©cup√©ration\nen continu de nouvelles traces num√©riques\nn√©cessite d‚Äôavoir des serveurs fonctionnels\nen continu. A cette premi√®re source de\nd√©pense d‚Äô√©nergie, s‚Äôajoute l‚Äôentra√Ænement\ndes mod√®les qui peut prendre des jours,\ny compris sur des architectures tr√®s\npuissantes. Strubell, Ganesh, and McCallum (2019)\nestime que l‚Äôentra√Ænement d‚Äôun mod√®le √†\nl‚Äô√©tat de l‚Äôart dans le domaine du\nNLP n√©cessite autant d‚Äô√©nergie que ce que\nconsommeraient cinq voitures, en moyenne,\nau cours de l‚Äôensemble de leur\ncycle de vie.\nL‚Äôutilisation accrue de l‚Äôint√©gration\ncontinue, qui permet de mettre en oeuvre de mani√®re\nautomatis√©e l‚Äôex√©cution de certains scripts ou\nla production de livrables en continu,\nam√®ne √©galement √† une d√©pense d‚Äô√©nergie importante.\nIl convient donc d‚Äôessayer de limiter l‚Äôint√©gration\ncontinue √† la production d‚Äôoutput vraiment nouveaux.\n\n\n Note\nPar exemple, cet ouvrage utilise de mani√®re intensive\ncette approche. N√©anmoins, pour essayer de limiter\nles effets pervers de la production en continu d‚Äôun\nouvrage extensif, seuls les chapitres modifi√©s\nsont produits lors des pr√©visualisations mises en\noeuvre √† chaque pull request sur le d√©p√¥t\nGithub.\n\n\nLes data scientists doivent √™tre conscients\ndes implications de leur usage intensif de\nressources et essayer de minimiser leur\nimpact. Par exemple, plut√¥t que r√©-estimer\nun mod√®le de NLP,\nla m√©thode de l‚Äôapprentissage par transfert,\nqui permet de transf√©rer les poids d‚Äôapprentissage\nd‚Äôun mod√®le √† une nouvelle source, permet\nde r√©duire les besoins computationnels.\nDe m√™me, il peut √™tre utile, pour prendre\nconscience de l‚Äôeffet d‚Äôun code trop long,\nde convertir le temps de calcul en\n√©missions de gaz √† effet de serre.\nLe package codecarbon\npropose cette solution en adaptant l‚Äôestimation\nen fonction du mix √©nerg√©tique du pays\nen question. Mesurer √©tant le\npr√©requis pour prendre conscience puis comprendre,\nce type d‚Äôinitiatives peut amener √† responsabiliser\nles data scientists et ainsi permettre un\nmeilleur partage des ressources.",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#informations-additionnelles",
    "href": "content/getting-started/03_data_analysis.html#informations-additionnelles",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6f20643\n\n\n2023-09-25 14:33:20\n\n\nLino Galiana\n\n\nCorrection lien mort cours ENSAE\n\n\n\n\n6dee48d\n\n\n2023-08-31 11:47:07\n\n\nlinogaliana\n\n\nD√©marche scientifique\n\n\n\n\nfb186dd\n\n\n2023-08-31 08:42:58\n\n\nlinogaliana\n\n\nAjoute avis CADA\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n22d4b5a\n\n\n2022-06-30 12:40:41\n\n\nLino Galiana\n\n\nCorrige la typo pour la ref (#245)\n\n\n\n\n5123634\n\n\n2022-06-30 11:24:49\n\n\nLino Galiana\n\n\nAm√©lioration de la premi√®re partie (#244)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/03_data_analysis.html#footnotes",
    "href": "content/getting-started/03_data_analysis.html#footnotes",
    "title": "D√©marche √† adopter face √† un jeu de donn√©es",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe livre de Reinhart et Rogoff, This time is different, s‚Äôappuyait\nsur un Excel constitu√© √† la main. Un doctorant s‚Äôest aper√ßu d‚Äôerreurs\ndans celui-ci et a remarqu√© que lorsqu‚Äôon\nsubstituait les chiffres officiels, les r√©sultats n‚Äô√©taient plus valides.‚Ü©Ô∏é\nOn suppose ici que le message erron√© est transmis sans volont√© de\nmanipulation. La manipulation manifeste est un probl√®me encore plus grave.‚Ü©Ô∏é\nOn suppose ici que le message erron√© est transmis sans volont√© de\nmanipulation. La manipulation manifeste est un probl√®me encore plus grave.‚Ü©Ô∏é",
    "crumbs": [
      "D√©marche √† adopter face √† un jeu de donn√©es"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html",
    "href": "content/getting-started/01_installation.html",
    "title": "Configuration de Python",
    "section": "",
    "text": "Les exercices sont pr√©sent√©s sous la\nforme de notebook jupyter. Ils peuvent √™tre ex√©cut√©s\ndans plusieurs environnement, au gr√© des pr√©f√©rences et des connaissances\nde chacun :\nConcernant la premi√®re m√©thode, qui est celle recommand√©e,\nchaque\nchapitre pr√©sente les badges suivants qui permettent d‚Äôouvrir\nla page web en question dans l‚Äôenvironnement de pr√©dilection.\nPar exemple, pour ouvrir le chapitre relatif √†\nnumpy dans l‚Äôun des environnements temporaires propos√©s,\nles badges suivants sont propos√©s :\nQuel que soit l‚Äôenvironnement d‚Äôex√©cution des scripts, l‚Äôun des objectifs\nde ce cours est d‚Äôadopter un environnement favorable √† la reproductibilit√©\ndes traitements. Ils devraient donc fonctionner, d√®s lors que l‚Äôenvironnement\nest bien configur√©, d‚Äôune mani√®re similaire quel que soit\nla machine qui ex√©cute le code.\nComme la reproductibilit√© est une notion centrale dans une d√©marche\nscientifique mais √©galement importante dans le monde\nde l‚Äôentreprise ou de l‚Äôadministration, en suppl√©ment des notions relatives\n√† Python, ce cours montrera comment utiliser Git avec Python et\n√©voquera un\ncertain nombre de crit√®res de qualit√© du code qui sont devenus\ndes standards dans la communaut√© open-source, dans l‚Äôindustrie et dans\nl‚Äôadministration. Ces comp√©tences ne sont pas\npropres √† Python et seront\nutiles pour tout projet ult√©rieur. Un cours d√©di√© √† cette question\nest propos√© par Romain Avouac et moi en derni√®re ann√©e de l‚ÄôENSAE. Son\ncontenu est disponible sur https://ensae-reproductibilite.github.io/website/.\nLe projet final devra imp√©rativement\n√™tre associ√© √† un d√©p√¥t\nsur Github (nous reviendrons dessus) et r√©pondre √†\nces crit√®res de qualit√©, qui serviront toute la vie.\nCe cours vise √† acculturer √† la conduite de projets de data-science avec\nPython. L‚Äôenvironnement foisonnant de la data-science n√©cessite un\ncertain nombre d‚Äô√©l√©ments suppl√©mentaires √† Python. La suite\nde ce chapitre permettra de d√©crire les configurations √† mettre\nen oeuvre pour √™tre en mesure d‚Äôexploiter la richesse de l‚Äô√©cosyst√®me Python.",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#installer-python-en-local",
    "href": "content/getting-started/01_installation.html#installer-python-en-local",
    "title": "Configuration de Python",
    "section": "1.1 Installer Python en local",
    "text": "1.1 Installer Python en local\nPour installer Python, il est recommand√© d‚Äôutiliser\nla distribution Anaconda\nqui permet d‚Äôinstaller une distribution minimale de Python ainsi qu‚Äô√©ventuellement\nun environnement plus complet :\n\nSous Windows, il suffit de t√©l√©charger l‚Äôex√©cutable puis\nl‚Äôex√©cuter (cf.¬†la doc officielle ;\nSous Mac, se reporter √† la doc officielle ;\nSous Linux, suivre les instructions de la doc officielle selon sa distribution\n\nPasser par Anaconda permet:\n\nd‚Äôinstaller Python ;\nd‚Äôinstaller par d√©faut une multitude de packages utiles ;\nde pouvoir utiliser un gestionnaire de package nomm√© conda.\n\nAnaconda permet de cr√©er des environnements isol√©s et facilite l‚Äôinstallation\nde certaines librairies qui n√©cessitent l‚Äôusage de langages externes (par exemple\ndu C++).",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#installer-un-environnement-de-d√©veloppement",
    "href": "content/getting-started/01_installation.html#installer-un-environnement-de-d√©veloppement",
    "title": "Configuration de Python",
    "section": "1.2 Installer un environnement de d√©veloppement",
    "text": "1.2 Installer un environnement de d√©veloppement\nLes notebooks Jupyter (extension .ipynb)\nsont tr√®s utilis√©s en data science. Ils sont en\nparticulier tr√®s adapt√©s √† la r√©alisation d‚Äôanalyses exploratoires.\nLes notebooks permettent de m√™ler du code, du texte et des sorties\ngraphiques ou des tableaux. L‚Äôint√©r√™t principal des notebooks est qu‚Äôils\npermettent d‚Äôex√©cuter du code tr√®s facilement dans un environnement\nPython donn√© (le kernel Jupyter). Ils sont particuli√®rement pratiques\npour ajouter du code ou du texte √† un document d√©j√† existant, d‚Äôo√π le\nterme de notebook.\nN√©anmoins, pass√©e l‚Äô√©tape d‚Äôexploration, il est recommand√© de plut√¥t recourir √† des\nscripts au format .py. L‚Äôutilisation du format .py est l‚Äôun des premiers\ngestes pour favoriser la reproductibilit√© des analyses.\nCes scripts peuvent √™tre √©dit√©s √† l‚Äôaide d‚Äô√©diteurs de texte adapt√©s au code, comme\nVisual Studio\n(mon pr√©f√©r√©),\nSublime Text,\nou PyCharm (privil√©gier Pycharm Community Edition)\nentre autres.\nCes √©diteurs\noffrent des fonctionalit√©s suppl√©mentaires pratiques :\n\nnombreux plugins pour une pleine utilisation de l‚Äô√©cosyst√®me Python: √©diteur de Markdown,\ninterface Git, etc.\nfonctionalit√©s classiques d‚Äôun IDE dont manque Jupyter: autocompl√©tion, diagnostic du code, etc.\nint√©gration avec les environnements Conda",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#installation-de-git",
    "href": "content/getting-started/01_installation.html#installation-de-git",
    "title": "Configuration de Python",
    "section": "1.3 Installation de Git",
    "text": "1.3 Installation de Git\nLe principe de Git ainsi que son usage avec Python sont pr√©sent√©s dans\nune partie d√©di√©e. Cette partie se concentre ainsi sur la question\nde la configuration de Git.\nGit est un langage dont la fonction est de tracer l‚Äôhistorique de modification\nd‚Äôun fichier. Pour disposer de ce langage, il est n√©cessaire d‚Äôinstaller\nle logiciel Git Bash. Gr√¢ce √† lui, Git sera disponible et des outils\nexternes, notamment les interfaces de d√©veloppement comme\nVisual Studio, pourront l‚Äôutiliser.",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#informations-additionnelles",
    "href": "content/getting-started/01_installation.html#informations-additionnelles",
    "title": "Configuration de Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nfd439f0\n\n\n2022-09-19 09:37:50\n\n\navouacr\n\n\nfix ssp cloud links\n\n\n\n\n3056d41\n\n\n2022-09-02 12:19:55\n\n\navouacr\n\n\nfix all SSP Cloud launcher links\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n61922f0\n\n\n2022-08-03 17:06:55\n\n\nLino Galiana\n\n\nanaconda toss (#251)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n5123634\n\n\n2022-06-30 11:24:49\n\n\nLino Galiana\n\n\nAm√©lioration de la premi√®re partie (#244)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n66fc843\n\n\n2021-11-08 11:19:12\n\n\nLino Galiana\n\n\nAdd badge open in vsode (#176)\n\n\n\n\nf95b174\n\n\n2021-11-03 12:08:34\n\n\nLino Galiana\n\n\nEnrichi la section sur la gestion des d√©pendances (#175)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "content/getting-started/01_installation.html#footnotes",
    "href": "content/getting-started/01_installation.html#footnotes",
    "title": "Configuration de Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLes gains de performance peuvent √™tre assez impressionnants.\nLa cr√©ation de l‚Äôenvironnement n√©cessaire √† la construction automatis√©e\nde ce site web a ainsi √©t√© divis√©e par 12 en utilisant mamba plut√¥t\nque conda pour installer des packages dans un environnement.‚Ü©Ô∏é\nLes gains de performance peuvent √™tre assez impressionnants.\nLa cr√©ation de l‚Äôenvironnement n√©cessaire √† la construction automatis√©e\nde ce site web a ainsi √©t√© divis√©e par 12 en utilisant mamba plut√¥t\nque conda pour installer des packages dans un environnement.‚Ü©Ô∏é",
    "crumbs": [
      "Configuration de Python"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python pour la data science",
    "section": "",
    "text": "Python pour la data science \n\n\nLino Galiana\n\n\nStar this website on Github\n\nSite web du cours Python pour la data science\n, une introduction √† Python pour\nla deuxi√®me ann√©e du cursus d‚Äôing√©nieur de l‚ÄôENSAE (Master 1).\n\nL‚Äôensemble du contenu de ce groupe est librement disponible ici\nou sur Github\n et peut √™tre test√©\nsous forme de notebooks Jupyter.\n\n\n\nExemple avec l‚Äôintroduction √† Pandas\n\n\nhtml`${printBadges({fpath: \"content/manipulation/02_pandas_intro.qmd\"})}`\n\n\n\n\n\n\n\n\n\nAu programme:\n\nGlobalement, ce cours propose un contenu tr√®s complet pouvant autant\nsatisfaire des d√©butants en\ndata science que des personnes √† la recherche de contenu plus avanc√© :\n\n\nManipulation de donn√©es : manipulation de donn√©es standards (Pandas), donn√©es g√©ographiques (Geopandas), r√©cup√©ration de donn√©es (webscraping, API)‚Ä¶\nVisualisation de donn√©es : visualisations classiques (Matplotlib, Seaborn), cartographie, visualisations r√©actives (Plotly, Folium)\nMod√©lisation : machine learning (Scikit), √©conom√©trie\nTraitement de donn√©es textuelles (NLP): d√©couverte de la tokenisation avec NLTK et SpaCy, mod√©lisation‚Ä¶\nIntroduction √† la data science moderne : cloud computing, ElasticSearch, int√©gration continue‚Ä¶\n\n\nL‚Äôensemble du contenu de ce site s‚Äôappuie sur des donn√©es\nouvertes, qu‚Äôil s‚Äôagisse de donn√©es fran√ßaises (principalement\nissues de la plateforme\ncentralisatrice data.gouv ou du site\nweb de l‚ÄôInsee) ou de donn√©es\nam√©ricaines.\nUn bon compl√©ment du contenu du site web est le cours que nous donnons avec Romain Avouac en derni√®re ann√©e de l‚ÄôENSAE plus tourn√© autour de la mise en production de projets data science : https://ensae-reproductibilite.github.io/website/"
  },
  {
    "objectID": "index.html#th√®mes-en-vrac",
    "href": "index.html#th√®mes-en-vrac",
    "title": "Python pour la data science",
    "section": "Th√®mes en vrac",
    "text": "Th√®mes en vrac\nPour d√©couvrir Python  de mani√®re th√©matique\n\n\n\n\n\n\n\n\n\n\nQuelques √©l√©ments pour comprendre les enjeux du NLP\n\n\n\nNLP\n\n\nTutoriel\n\n\n\nLes corpus textuels √©tant des objets de tr√®s grande dimension\no√π le ratio signal/bruit est faible, il est n√©cessaire de mettre\nen oeuvre une s√©rie d‚Äô√©tapes de nettoyage de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words\n\n\n\nNLP\n\n\nExercice\n\n\n\nCe chapitre continue de pr√©senter l‚Äôapproche de nettoyage de donn√©es\ndu NLP en s‚Äôappuyant sur le corpus de trois auteurs\nanglo-saxons : Mary Shelley, Edgar Allan Poe‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLatent Dirichlet Allocation (LDA)\n\n\n\nTutoriel\n\n\nNLP\n\n\n\nLa Latent Dirichlet Allocation (LDA)\nest un mod√®le probabiliste g√©n√©ratif qui permet\nde d√©crire des‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM√©thodes de vectorisation : comptages et word embeddings\n\n\n\nTutoriel\n\n\nNLP\n\n\n\nPour pouvoir utiliser des donn√©es textuelles dans des algorithmes\nde machine learning, il faut les vectoriser, c‚Äôest √† dire transformer\nle texte en donn√©es num√©riques.‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercices suppl√©mentaires\n\n\n\nExercice\n\n\nNLP\n\n\n\nDes exercices suppl√©mentaires pour pratiquer les concepts du NLP\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 4 : Natural Language Processing (NLP)\n\n\n\nIntroduction\n\n\nNLP\n\n\n\nL‚Äôun des grands avantages comparatifs de  par rapport aux\nlangages concurrents ( notamment) est dans\nla richesse des‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrections\n\n\nNotebooks corrig√©s des diff√©rents chapitres du cours\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation\n\n\nR√©sum√© des attentes pour les projets de fin d‚Äôann√©e\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nL‚Äôenvironnement que propose Python pour la data science\nest tr√®s riche. Afin de b√©n√©ficier du meilleur environnement\npour tirer parti du langage, ce chapitre‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôenvironnement Python pour la data science\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nPython propose un √©cosyst√®me tr√®s riche pour la\ndata science. Ce chapitre fait un tour\nd‚Äôhorizon de celui-ci en pr√©sentant les principaux\npackages qui seront pr√©sent√©s‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD√©marche √† adopter face √† un jeu de donn√©es\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nQuelques √©l√©ments pour adopter une d√©marche\nscientifique et √©thique face √† un\njeu de donn√©es.\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonne pratique de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLes normes communautaires du monde de\nl‚Äôopen-source ont permis une\nharmonisation de la structure des projets\nPython et des scripts. Ce chapitre\n√©voque quelques-unes de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuelques rappels sur les principes de base de Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nRappels d‚Äô√©l√©ments essentiels en Python: les r√®gles de syntaxes, les classes,\nles m√©thodes, etc.\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModules, tests, boucles, fonctions\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLes fonctions permettent de g√©n√©raliser des\ninstructions. Il s‚Äôagit ainsi d‚Äôun outil privil√©gi√©\npour automatiser des t√¢ches r√©p√©titives ou r√©duire\nla complexit√© d‚Äôune cha√Æne‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes classes en Python\n\n\n\nTutoriel\n\n\nRappels\n\n\n\nLa programmation orient√©e objet (POO) est\nl‚Äôun des atouts de Python. Elle permet\nd‚Äôadapter des‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\n\nCette introduction propose quelques √©l√©ments de\nr√©vision des concepts de base en Python et\npr√©sente l‚Äô√©cosyst√®me Python que nous allons\nd√©couvrir tout au long de ce‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUn cadavre exquis pour d√©couvrir Git\n\n\n\nExercice\n\n\nGit\n\n\n\nCe chapitre propose une mise en application de quelques principes\ncentraux du langage Git vus pr√©c√©demment.\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGit: un outil n√©cessaire pour les data scientists\n\n\n\nGit\n\n\n\nUne partie annexe au cours pour d√©couvrir Git,\nun outil\ndevenu indispensable pour les data scientists\nafin de mener des projets impliquant\ndu code Python.\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGit : un √©l√©ment essentiel au quotidien\n\n\n\nTutoriel\n\n\nGit\n\n\n\nGit est un syst√®me de contr√¥le de version qui facilite la\nsauvegarde, la gestion des √©volutions et le partage\nd‚Äôun projet informatique. Il s‚Äôagit d‚Äôun √©l√©ment‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumpy, la brique de base de la data science\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nNumpy constitue la brique de base de l‚Äô√©cosyst√®me de la data science en\nPython. Toutes les librairies de manipulation de donn√©es, de mod√©lisation\net de visualisation‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction √† Pandas\n\n\n\nTutoriel\n\n\nExercices\n\n\nManipulation\n\n\n\nPandas est l‚Äô√©l√©ment central de l‚Äô√©cosyst√®me Python pour la data science. Ce chapitre pr√©sente les premi√®res\nmanipulations de donn√©es qu‚Äôon peut faire gr√¢ce √† Pandas‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistiques par groupe et association de plusieurs jeux de donn√©es avec Pandas\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nLe chapitre d‚Äôintroduction √† Pandas a permis de pr√©senter le principe de donn√©es organis√©es sous une forme de DataFrame et la praticit√© de l‚Äô√©cosyst√®me Pandas pour‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction √† Pandas\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nPandas est l‚Äô√©l√©ment central de l‚Äô√©cosyst√®me Python pour la data science.\nLe succ√®s r√©cent de Python dans l‚Äôanalyse de donn√©es tient beaucoup √† Pandas qui a permis‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPratique de pandas : un exemple complet\n\n\n\nManipulation\n\n\nExercice\n\n\n\nApr√®s avoir pr√©sent√© la logique de Pandas dans le chapitre pr√©c√©dent,\nce chapitre vise √† illustrer les fonctionalit√©s du package\n√† partir de donn√©es d‚Äô√©missions de gaz √†‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPratique de geopandas avec les donn√©es v√©lib\n\n\n\nManipulation\n\n\nExercice\n\n\n\nCe chapitre illustre les fonctionalit√©s de GeoPandas √† partir des\nd√©comptes de v√©lo fournis par la ville de Paris\nen‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction aux donn√©es spatiales avec Geopandas\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nLes donn√©es g√©olocalis√©es se sont multipli√©es depuis quelques ann√©es, qu‚Äôil\ns‚Äôagisse de donn√©es open-data ou de traces num√©riques g√©olocalis√©es de\ntype big-data. Pour les‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDonn√©es spatiales : d√©couverte de geopandas\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nLes donn√©es g√©olocalis√©es se sont multipli√©es depuis quelques ann√©es, qu‚Äôil\ns‚Äôagisse de donn√©es open-data ou de traces num√©riques g√©olocalis√©es de\ntype big-data. Pour les‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping avec Python\n\n\n\nExercice\n\n\nManipulation\n\n\n\nPython permet de facilement r√©cup√©rer une page web pour en extraire des\ndonn√©es √† restructurer. Le web scraping, que les Canadiens nomment\n‚Äúmoissonnage du web‚Äù, est‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMa√Ætriser les expressions r√©guli√®res\n\n\n\nTutoriel\n\n\nManipulation\n\n\n\nLes expressions r√©guli√®res fournissent un cadre tr√®s pratique pour manipuler\nde mani√®re flexible des donn√©es textuelles. Elles sont tr√®s utiles\nnotamment pour les t√¢ches de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR√©cup√©rer des donn√©es avec des API depuis Python\n\n\n\nExercice\n\n\nManipulation\n\n\n\nLes API (Application Programming Interface) sont un mode d‚Äôacc√®s aux\ndonn√©es en expansion. Gr√¢ce aux API, l‚Äôautomatisation de scripts\nest facilit√©e puisqu‚Äôil n‚Äôest‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 1: manipuler des donn√©es\n\n\n\nManipulation\n\n\nIntroduction\n\n\n\nPython s‚Äôest impos√© comme une alternative tr√®s cr√©dible √† R dans\nla manipulation de donn√©es. L‚Äô√©cosyst√®me Pandas a permis de d√©mocratiser\nl‚Äôutilisation des DataFrames‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPr√©paration des donn√©es pour construire un mod√®le\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nAfin d‚Äôavoir des donn√©es coh√©rentes avec les hypoth√®ses de mod√©lisation,\nil est absolument fondamental de prendre le temps de\npr√©parer les donn√©es √† fournir √† un mod√®le. La‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluer la qualit√© d‚Äôun mod√®le\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nFaire preuve de m√©thode pour √©valuer la qualit√© d‚Äôun mod√®le\npermet de proposer des pr√©dictions plus robustes, ayant\nde meilleures performances sur un nouveau jeu de‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification: premier mod√®le avec les SVM\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nLa classification permet d‚Äôattribuer une classe d‚Äôappartenance (label\ndans la terminologie du machine learning)\ndiscr√®te √† des donn√©es √† partir de certaines variables‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR√©gression : une introduction\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nLa r√©gression lin√©aire est la premi√®re mod√©lisation statistique\nqu‚Äôon d√©couvre dans un cursus quantitatif. Il s‚Äôagit en effet d‚Äôune\nm√©thode tr√®s intuitive et tr√®s riche. Le‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS√©lection de variables : une introduction\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nL‚Äôacc√®s √† des bases de donn√©es de plus en plus riches permet\ndes mod√©lisations de plus en plus raffin√©es. Cependant,\nles mod√®les parcimonieux sont g√©n√©ralement‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustering\n\n\n\nMod√©lisation\n\n\nExercice\n\n\n\nLe clustering consiste √† r√©partir des observations dans des groupes,\ng√©n√©ralement non observ√©s,\nen fonction de caract√©ristiques observables. Il s‚Äôagit d‚Äôune\napplication‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPremier pas vers l‚Äôindustrialisation avec les pipelines scikit\n\n\n\nMod√©lisation\n\n\nTutoriel\n\n\n\nLes pipelines Scikit permettent d‚Äôint√©grer de mani√®re tr√®s flexible\nun ensemble d‚Äôop√©rations de pre-processing et d‚Äôentra√Ænement de mod√®les\ndans une cha√Æne d‚Äôop√©rations.‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMettre √† disposition un mod√®le par le biais d‚Äôune API\n\n\n\nMod√©lisation\n\n\nTutoriel\n\n\n\nTO BE COMPLETED\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 3: mod√©liser\n\n\n\nIntroduction\n\n\nMod√©lisation\n\n\n\nLa facilit√© √† mod√©liser des processus tr√®s diverses a grandement\nparticip√© au succ√®s de Python. La librairie scikit offre une\ngrande vari√©t√© de mod√®les et permet ainsi‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInt√©gration continue avec Python\n\n\nUn chapitre plus avanc√© sur l‚Äôint√©gration continue\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApprofondissement ElasticSearch pour des recherches de proximit√© g√©ographique\n\n\n\nTutoriel\n\n\nAvanc√©\n\n\n\nUn chapitre plus approfondi sur ElasticSearch\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction √† ElasticSearch pour la recherche textuelle\n\n\n\nTutoriel\n\n\nAvanc√©\n\n\n\nElasticSearch est un moteur de recherche extr√™mement rapide et flexible.\nCette technologie s‚Äôest impos√©e dans le domaine du traitement des\ndonn√©es textuelles. L‚ÄôAPI‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart\n\n\n\nIntroduction\n\n\nAvanc√©\n\n\n\nApr√®s avoir abord√© les diff√©rents champs de la\ndata science, nous pouvons maintenant\nintroduire √† quelques outils et m√©thodes plus avanc√©s\nqui correspondent √† des aspects‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud\n\n\n\nTutoriel\n\n\nAvanc√©\n\n\n\n\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartie 2: communiquer √† partir de donn√©es\n\n\n\nIntroduction\n\n\nVisualisation\n\n\n\nCette partie pr√©sente les outils pour visualiser des\ndonn√©es avec Python, qu‚Äôil s‚Äôagisse de graphiques\nfig√©s (matplotlib, seaborn, geoplot‚Ä¶) ou de\nvisualisation‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe belles cartes avec python : mise en pratique\n\n\n\nVisualisation\n\n\nExercice\n\n\n\nLa cartographie est un excellent moyen de diffuser\nune connaissance, y compris √† des publics peu\nfamiliers de la statistique. Ce chapitre permet\nde d√©couvrir la mani√®re dont‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe beaux graphiques avec python : mise en pratique\n\n\n\nVisualisation\n\n\nExercice\n\n\n\nUne partie essentielle du travail du\ndata scientist est d‚Äô√™tre en mesure\nde synth√©tiser une information dans des\nrepr√©sentations graphiques percutantes. Ce\nchapitre permet‚Ä¶\n\n\n\nLino Galiana\n\n\n2024-05-27\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}"
  },
  {
    "objectID": "content/getting-started/index.html",
    "href": "content/getting-started/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours rassemble l‚Äôensemble du contenu du cours\nPython  pour la data science que je donne\n√† l‚ÄôENSAE\ndepuis 2018.\nCe cours √©tait auparavant donn√© par Xavier Dupr√©.\nQuelques √©l√©ments suppl√©mentaires sont disponibles dans\nles slides d‚Äôintroduction.\nDes √©l√©ments plus avanc√©s sont pr√©sents dans un autre cours consacr√©\n√† la mise en production de projets data science\nque je donne avec Romain Avouac\n√† l‚ÄôENSAE (ensae-reproductibilite.github.io/website)\nPython est un langage qui a d√©j√† plus de trente ans\nmais qui a connu, au cours de la d√©cennie 2010, une\nnouvelle jeunesse du fait de l‚Äôengouement pour\nla data science.\nPython, plus que tout autre\nlangage informatique, r√©unit des communaut√©s aussi\ndiverses que des statisticiens, des d√©veloppeurs,\ndes gestionnaires\nd‚Äôapplications ou d‚Äôinfrastructures informatiques,\ndes lyc√©es - Python est au programme du bac fran√ßais\ndepuis quelques ann√©es - ou des chercheurs\ndans des champs √† la fois th√©oriques et appliqu√©s. Contrairement\n√† beaucoup de langages informatiques qui f√©d√®rent\nune communaut√© assez homog√®ne, Python est parvenu √† r√©unir\nlargement gr√¢ce √† quelques principes centraux : la lisibilit√©\ndu langage, la simplicit√© √† utiliser des modules,\nla simplicit√© √† l‚Äôassocier √† des langages plus performants\npour certaines t√¢ches donn√©es, l‚Äô√©norme volume de documentation\ndisponible en ligne‚Ä¶\n√ätre le deuxi√®me meilleur langage pour r√©aliser telle ou telle\nt√¢che\npeut ainsi √™tre une source de succ√®s lorsque la concurrence ne dispose\npas d‚Äôun √©ventail aussi large d‚Äôavantages.\nLe succ√®s de Python, de par sa nature de\nlangage couteau-suisse, est indissociable\nde l‚Äô√©mergence du profil du data scientist, individu\ncapable de s‚Äôint√©grer √† diff√©rents niveaux dans la valorisation\nde donn√©es.\nDavenport and Patil (2012a), dans la Harvard Business Review,\nont ainsi pu parler du ‚Äúboulot le plus sexy du 21e si√®cle‚Äù\net ont pu, dix ans plus tard, faire un panorama complet de l‚Äô√©volution\ndes comp√©tences attendues d‚Äôun data scientist dans\nla m√™me revue (Davenport and Patil 2012b).\nLa richesse de Python permet de l‚Äôutiliser dans toutes les phases\ndu traitement de la donn√©e, de sa r√©cup√©ration et structuration √† partir de\nsources diverses √† sa valorisation.\nPar le prisme de la data science, nous verrons que Python est\nun tr√®s bon candidat pour assister les data scientists dans tous\nles aspects du travail de donn√©es.\nCe cours introduit diff√©rents outils qui permettent de mettre en relation\ndes donn√©es et des th√©ories gr√¢ce √† Python. N√©anmoins, ce cours\nva au-del√† d‚Äôune simple introduction au langage et propose\ndes √©l√©ments plus approfondis, notamment sur les derni√®res\ninnovations permises par la data science dans les m√©thodes de travail.\n\n\nLe succ√®s de scikit-learn et\nde Tensorflow dans la communaut√©\nde la Data-Science ont beaucoup contribu√© √† l‚Äôadoption de Python. Cependant,\nr√©sumer Python √† ces quelques librairies serait r√©ducteur tant il s‚Äôagit\nd‚Äôun v√©ritable couteau-suisse pour les data scientists,\nles social scientists ou les √©conomistes.\nL‚Äôint√©r√™t de Python pour un data scientist ou data economist\nva au-del√† du champ du Machine Learning.\nComme pour R, l‚Äôint√©r√™t de Python est son r√¥le central dans un\n√©cosyst√®me plus large autour d‚Äôoutils puissants, flexibles et open-source.\nPython concurrence tr√®s bien R dans son domaine de pr√©dilection, √†\nsavoir l‚Äôanalyse statistique sur des bases de donn√©es structur√©es.\nComme dans R, les dataframes sont un concept central de Python.\nPython est n√©anmoins bien plus complet dans certains domaines.\nOutre le Machine Learning,\nPython est mieux adapt√© aux donn√©es volumineuses que\nR. Python est √©galement meilleur que R pour faire\ndu webscraping ou acc√©der √† des donn√©es par le biais d‚ÄôAPI.\nDans le domaine de l‚Äô√©conom√©trie, Python offre\nl‚Äôavantage de la simplicit√© avec un nombre restreint de packages (scikit et\nstatsmodels) permettant d‚Äôavoir des mod√®les tr√®s g√©n√©raux\n(les generalized estimating equations)\nalors qu‚Äôil faut\nchoisir parmi une grande vari√©t√© de packages en R pour obtenir les\nmod√®les √©quivalents. Dans le domaine du Deep Learning, Python √©crase\nla concurrence.\nAu contraire, dans certains domaines, R reste meilleur, m√™me si les\n√©volutions tr√®s r√©centes de certains outils peuvent amener √† r√©viser\nce constat. Historiquement,\nR √©tait tr√®s bien int√©gr√© au langage de publication Markdown ce qui,\npermet la construction de documents reproductibles tr√®s raffin√©s.\nL‚Äô√©mergence r√©cente de Quarto, h√©ritier de R Markdown d√©velopp√© par\nla soci√©t√© Posit permet aux utilisateur de Python de b√©n√©ficier\n√©galement de la richesse de cette approche pour leur langage de pr√©dilection.\nCe site web, √† l‚Äôarborescence relativement complexe, est ainsi\nconstruit gr√¢ce √† cet outil qui permet √† la fois de tester les blocs\nde code pr√©sent√©s mais aussi de produire de mani√®re automatis√©e les\ntableaux et graphiques pr√©sent√©s. S‚Äôil fallait trouver un point faible\n√† Python par rapport √† R dans le domaine de la data science\nc‚Äôest sur la production de graphiques. matplotlib et seaborn, qui sont\npr√©sent√©s dans la partie visualisation, sont d‚Äôexcellents outils. N√©anmoins,\nggplot2, l‚Äô√©quivalent en R est plus facile de prise en main et\npropose une syntaxe extr√™mement flexible, qu‚Äôil est difficile de ne pas\nappr√©cier. Cependant, l‚Äô√©cosyst√®me de la\nvisualisation de donn√©es est en pleine r√©volution avec le succ√®s\nd‚ÄôObservable qui\nrapproche l‚Äô√©cosyst√®me JavaScript des d√©veloppeurs web\nde la communaut√© des analystes de donn√©es.\nUn des avantages comparatifs de Python par rapport √† d‚Äôautres\nlangages (notamment R et Julia) est sa dynamique,\nce que montre l‚Äôexplosion du nombre de questions\nsur Stack Overflow.\nCependant, il ne s‚Äôagit pas b√™tement d‚Äôenterrer R.\nAu contraire, outre leur logique tr√®s proche,\nles deux langages sont dans une phase de convergence avec des initiatives comme\nreticulate,\nquarto ou\nsnakemake qui\npermettent, de mani√®re diff√©rente, de cr√©er des cha√Ænes de traitement\nm√©langeant R et Python.\nUne autre raison pour laquelle cette gu√©guerre R/Python n‚Äôa pas\nde sens est que les bonnes\npratiques peuvent √™tre transpos√©es de mani√®re presque transparente d‚Äôun\nlangage √† l‚Äôautre. Il s‚Äôagit d‚Äôun point qui est d√©velopp√© plus amplement\ndans le cours plus avanc√© que je donne avec Romain Avouac en derni√®re ann√©e\nd‚ÄôENSAE : ensae-reproductibilite.github.io/website.\nA terme, les data scientists et chercheurs en sciences sociales ou\n√©conomie utiliseront\nde mani√®re presque indiff√©rente, et en alternance, Python et R. Ce cours\npr√©sentera ainsi r√©guli√®rement des analogies avec R pour aider les\npersonnes d√©couvrant Python, mais connaissant d√©j√† bien R, √†\nmieux comprendre certains messages.\n\n\n\nLe but de ce cours est de rendre autonome sur\nl‚Äôutilisation de Python\ndans un contexte de travail de data scientist ou de\nsocial scientist (√©conomie, sociologie, g√©ographie‚Ä¶).\nAutrement dit,\nil pr√©suppose qu‚Äôon d√©sire faire un usage intense\nde donn√©es dans un cadre statistique rigoureux.\nLa data science est un ensemble de techniques\nvisant √† donner du sens √† des sources de donn√©es\ndiverses. Selon les organisations,\nles data scientists peuvent ainsi √™tre √†\nl‚Äôinterface de projets n√©cessitant un\nlarge spectre de comp√©tences\n(analyse\nde donn√©es textuelles, repr√©sentation\ngraphique interactive‚Ä¶),\navoir des interactions avec des profils\ntr√®s diff√©rents (experts m√©tiers,\nd√©veloppeurs, data architect,\ndata engineer‚Ä¶) voire adopter\nun peu tous ces r√¥les.\nLes innovations\nr√©centes de la data science ne se r√©duisent\nn√©anmoins\npas qu‚Äô√† des d√©couvertes m√©thodologiques.\nLa data science propose un ensemble de\ntechniques et de m√©thodes de travail\npour r√©duire les co√ªts de passage\nd‚Äôun protype √† une chaine\nde production p√©renne.\nCe cours introduit √† quelques notions\nsur le sujet, notamment les\npipelines scikit, pour adopter\nd√®s l‚Äôapprentissage du langage\nquelques bons r√©flexes (ensae-reproductibilite.github.io/website).\n\n\n\nCe cours ne revient que de mani√®re secondaire\nsur les fondements statistiques ou algorithmiques\nderri√®re certaines des techniques √©voqu√©es.\nNe pas conna√Ætre ces notions n‚Äôemp√™che n√©anmoins pas de comprendre\nle contenu de ce site web. En effet, la facilit√© d‚Äôusage de Python\n√©vite de devoir programmer soi-m√™me un mod√®le, ce qui rend\npossible l‚Äôapplication\nde mod√®les dont on n‚Äôest pas expert. La connaissance des mod√®les sera\nplut√¥t n√©cessaire dans l‚Äôinterpr√©tation des r√©sultats.\nCependant, la facilit√© avec laquelle il est possible de construire des mod√®les complexes\navec Python peut laisser appara√Ætre que conna√Ætre les sp√©cifit√©s de chaque\nmod√®le est inutile. Il\ns‚Äôagirait d‚Äôune grave erreur : m√™me si l‚Äôimpl√©mentation de mod√®les est ais√©e, il\nest n√©cessaire de bien comprendre la structure des donn√©es et leur ad√©quation\navec les hypoth√®ses d‚Äôun mod√®le.\n\n\n\nCe cours donne une place centrale √†\nla notion de reproductibilit√©. Cette exigence se traduit de diverses\nmani√®res dans cet enseignement, en particulier en insistant sur un\noutil indispensable pour favoriser le partage de codes informatiques,\n√† savoir Git.\nL‚Äôensemble du contenu du site web est reproductible dans des environnements\ninformatiques divers. Il est bien s√ªr possible de copier-coller les morceaux\nde code pr√©sents dans ce site. Cette m√©thode montrant rapidement ses limites,\nle site pr√©sente un certain nombre de boutons disponibles pour\nouvrir la page sous un format Jupyter Notebook sur divers\npages web :\n\nSur l‚Äôensemble du site web,\nil est possible de cliquer\nsur la petite icone \npour √™tre redirig√© vers le d√©p√¥t Github associ√© √† ce cours.\nUn certain nombre de boutons permettent de transformer chaque\npage web en Jupyter Notebooks s‚Äôil est n√©cessaire de\nvisualiser ou ex√©cuter du code Python.\n\nVoici, par exemple, ces boutons pour le tutoriel numpy :\n\n\n\n\n\n\n\n\n\n\nPour les agents de la fonction publique, ou\nles √©l√®ves des √©coles partenaires, il est recommand√©\nde privil√©gier le bouton SSPCloud qui est\nune infrastructure cloud moderne, puissante et flexible\nd√©velopp√©e par l‚ÄôInsee et accessible √† l‚Äôurl\nhttps://datalab.sspcloud.fr1.\nL‚Äôensemble du contenu de ce site s‚Äôappuie sur des donn√©es\nouvertes, qu‚Äôil s‚Äôagisse de donn√©es fran√ßaises (principalement\nissues de la plateforme\ncentralisatrice data.gouv ou du site\nweb de l‚ÄôInsee) ou de donn√©es\nam√©ricaines. Les r√©sultats sont donc reproductibles pour quelqu‚Äôun\ndisposant d‚Äôun environnement identique.\n\n\n\nCe cours pr√©sente\ndes tutoriels et des exercices complets.\nChaque page est structur√©e sous la forme\nd‚Äôun probl√®me concret et pr√©sente la\nd√©marche g√©n√©rique pour r√©soudre ce probl√®me g√©n√©ral.\nVous pouvez naviguer dans l‚Äôarchitecture du site via la table des mati√®res\nou par les liens vers le contenu ant√©rieur ou post√©rieur √† la fin de chaque\npage. Certaines parties, notamment celle consacr√©e √† la mod√©lisation,\nproposent des exemples fil-rouge pour illustrer la d√©marche de mani√®re\nplus extensive.\n\n\n\nLes √©l√®ves de l‚ÄôENSAE valident le cours gr√¢ce √†\nun projet approfondi.\nLes √©l√©ments relatifs √† l‚Äô√©valuation du cours, ainsi qu‚Äôune\nliste des projets d√©j√† effectu√©s, sont disponibles dans la\nSection Evaluation.\n\n\n\n\n\nDavenport, Thomas H, and DJ Patil. 2012a. ‚ÄúData Scientist, the Sexiest Job of the 21st Century.‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n‚Äî‚Äî‚Äî. 2012b. ‚ÄúIs Data Scientist Still the Sexiest Job of the 21st Century?‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n\n\n\n{{&lt; list_children  &gt;}}\n\n\n\n\n\n\n\n\n\n\n{{&lt; list_children  &gt;}}\n\n\n\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\ndde3e93\n\n\n2023-07-21 22:22:05\n\n\nLino Galiana\n\n\nFix bug on chapter order (#385)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#pourquoi-faire-du-python-pour-lanalyse-de-donn√©es",
    "href": "content/getting-started/index.html#pourquoi-faire-du-python-pour-lanalyse-de-donn√©es",
    "title": "Introduction",
    "section": "",
    "text": "Le succ√®s de scikit-learn et\nde Tensorflow dans la communaut√©\nde la Data-Science ont beaucoup contribu√© √† l‚Äôadoption de Python. Cependant,\nr√©sumer Python √† ces quelques librairies serait r√©ducteur tant il s‚Äôagit\nd‚Äôun v√©ritable couteau-suisse pour les data scientists,\nles social scientists ou les √©conomistes.\nL‚Äôint√©r√™t de Python pour un data scientist ou data economist\nva au-del√† du champ du Machine Learning.\nComme pour R, l‚Äôint√©r√™t de Python est son r√¥le central dans un\n√©cosyst√®me plus large autour d‚Äôoutils puissants, flexibles et open-source.\nPython concurrence tr√®s bien R dans son domaine de pr√©dilection, √†\nsavoir l‚Äôanalyse statistique sur des bases de donn√©es structur√©es.\nComme dans R, les dataframes sont un concept central de Python.\nPython est n√©anmoins bien plus complet dans certains domaines.\nOutre le Machine Learning,\nPython est mieux adapt√© aux donn√©es volumineuses que\nR. Python est √©galement meilleur que R pour faire\ndu webscraping ou acc√©der √† des donn√©es par le biais d‚ÄôAPI.\nDans le domaine de l‚Äô√©conom√©trie, Python offre\nl‚Äôavantage de la simplicit√© avec un nombre restreint de packages (scikit et\nstatsmodels) permettant d‚Äôavoir des mod√®les tr√®s g√©n√©raux\n(les generalized estimating equations)\nalors qu‚Äôil faut\nchoisir parmi une grande vari√©t√© de packages en R pour obtenir les\nmod√®les √©quivalents. Dans le domaine du Deep Learning, Python √©crase\nla concurrence.\nAu contraire, dans certains domaines, R reste meilleur, m√™me si les\n√©volutions tr√®s r√©centes de certains outils peuvent amener √† r√©viser\nce constat. Historiquement,\nR √©tait tr√®s bien int√©gr√© au langage de publication Markdown ce qui,\npermet la construction de documents reproductibles tr√®s raffin√©s.\nL‚Äô√©mergence r√©cente de Quarto, h√©ritier de R Markdown d√©velopp√© par\nla soci√©t√© Posit permet aux utilisateur de Python de b√©n√©ficier\n√©galement de la richesse de cette approche pour leur langage de pr√©dilection.\nCe site web, √† l‚Äôarborescence relativement complexe, est ainsi\nconstruit gr√¢ce √† cet outil qui permet √† la fois de tester les blocs\nde code pr√©sent√©s mais aussi de produire de mani√®re automatis√©e les\ntableaux et graphiques pr√©sent√©s. S‚Äôil fallait trouver un point faible\n√† Python par rapport √† R dans le domaine de la data science\nc‚Äôest sur la production de graphiques. matplotlib et seaborn, qui sont\npr√©sent√©s dans la partie visualisation, sont d‚Äôexcellents outils. N√©anmoins,\nggplot2, l‚Äô√©quivalent en R est plus facile de prise en main et\npropose une syntaxe extr√™mement flexible, qu‚Äôil est difficile de ne pas\nappr√©cier. Cependant, l‚Äô√©cosyst√®me de la\nvisualisation de donn√©es est en pleine r√©volution avec le succ√®s\nd‚ÄôObservable qui\nrapproche l‚Äô√©cosyst√®me JavaScript des d√©veloppeurs web\nde la communaut√© des analystes de donn√©es.\nUn des avantages comparatifs de Python par rapport √† d‚Äôautres\nlangages (notamment R et Julia) est sa dynamique,\nce que montre l‚Äôexplosion du nombre de questions\nsur Stack Overflow.\nCependant, il ne s‚Äôagit pas b√™tement d‚Äôenterrer R.\nAu contraire, outre leur logique tr√®s proche,\nles deux langages sont dans une phase de convergence avec des initiatives comme\nreticulate,\nquarto ou\nsnakemake qui\npermettent, de mani√®re diff√©rente, de cr√©er des cha√Ænes de traitement\nm√©langeant R et Python.\nUne autre raison pour laquelle cette gu√©guerre R/Python n‚Äôa pas\nde sens est que les bonnes\npratiques peuvent √™tre transpos√©es de mani√®re presque transparente d‚Äôun\nlangage √† l‚Äôautre. Il s‚Äôagit d‚Äôun point qui est d√©velopp√© plus amplement\ndans le cours plus avanc√© que je donne avec Romain Avouac en derni√®re ann√©e\nd‚ÄôENSAE : ensae-reproductibilite.github.io/website.\nA terme, les data scientists et chercheurs en sciences sociales ou\n√©conomie utiliseront\nde mani√®re presque indiff√©rente, et en alternance, Python et R. Ce cours\npr√©sentera ainsi r√©guli√®rement des analogies avec R pour aider les\npersonnes d√©couvrant Python, mais connaissant d√©j√† bien R, √†\nmieux comprendre certains messages.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#objectif-du-cours",
    "href": "content/getting-started/index.html#objectif-du-cours",
    "title": "Introduction",
    "section": "",
    "text": "Le but de ce cours est de rendre autonome sur\nl‚Äôutilisation de Python\ndans un contexte de travail de data scientist ou de\nsocial scientist (√©conomie, sociologie, g√©ographie‚Ä¶).\nAutrement dit,\nil pr√©suppose qu‚Äôon d√©sire faire un usage intense\nde donn√©es dans un cadre statistique rigoureux.\nLa data science est un ensemble de techniques\nvisant √† donner du sens √† des sources de donn√©es\ndiverses. Selon les organisations,\nles data scientists peuvent ainsi √™tre √†\nl‚Äôinterface de projets n√©cessitant un\nlarge spectre de comp√©tences\n(analyse\nde donn√©es textuelles, repr√©sentation\ngraphique interactive‚Ä¶),\navoir des interactions avec des profils\ntr√®s diff√©rents (experts m√©tiers,\nd√©veloppeurs, data architect,\ndata engineer‚Ä¶) voire adopter\nun peu tous ces r√¥les.\nLes innovations\nr√©centes de la data science ne se r√©duisent\nn√©anmoins\npas qu‚Äô√† des d√©couvertes m√©thodologiques.\nLa data science propose un ensemble de\ntechniques et de m√©thodes de travail\npour r√©duire les co√ªts de passage\nd‚Äôun protype √† une chaine\nde production p√©renne.\nCe cours introduit √† quelques notions\nsur le sujet, notamment les\npipelines scikit, pour adopter\nd√®s l‚Äôapprentissage du langage\nquelques bons r√©flexes (ensae-reproductibilite.github.io/website).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#public-cible",
    "href": "content/getting-started/index.html#public-cible",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours ne revient que de mani√®re secondaire\nsur les fondements statistiques ou algorithmiques\nderri√®re certaines des techniques √©voqu√©es.\nNe pas conna√Ætre ces notions n‚Äôemp√™che n√©anmoins pas de comprendre\nle contenu de ce site web. En effet, la facilit√© d‚Äôusage de Python\n√©vite de devoir programmer soi-m√™me un mod√®le, ce qui rend\npossible l‚Äôapplication\nde mod√®les dont on n‚Äôest pas expert. La connaissance des mod√®les sera\nplut√¥t n√©cessaire dans l‚Äôinterpr√©tation des r√©sultats.\nCependant, la facilit√© avec laquelle il est possible de construire des mod√®les complexes\navec Python peut laisser appara√Ætre que conna√Ætre les sp√©cifit√©s de chaque\nmod√®le est inutile. Il\ns‚Äôagirait d‚Äôune grave erreur : m√™me si l‚Äôimpl√©mentation de mod√®les est ais√©e, il\nest n√©cessaire de bien comprendre la structure des donn√©es et leur ad√©quation\navec les hypoth√®ses d‚Äôun mod√®le.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#reproductibilit√©",
    "href": "content/getting-started/index.html#reproductibilit√©",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours donne une place centrale √†\nla notion de reproductibilit√©. Cette exigence se traduit de diverses\nmani√®res dans cet enseignement, en particulier en insistant sur un\noutil indispensable pour favoriser le partage de codes informatiques,\n√† savoir Git.\nL‚Äôensemble du contenu du site web est reproductible dans des environnements\ninformatiques divers. Il est bien s√ªr possible de copier-coller les morceaux\nde code pr√©sents dans ce site. Cette m√©thode montrant rapidement ses limites,\nle site pr√©sente un certain nombre de boutons disponibles pour\nouvrir la page sous un format Jupyter Notebook sur divers\npages web :\n\nSur l‚Äôensemble du site web,\nil est possible de cliquer\nsur la petite icone \npour √™tre redirig√© vers le d√©p√¥t Github associ√© √† ce cours.\nUn certain nombre de boutons permettent de transformer chaque\npage web en Jupyter Notebooks s‚Äôil est n√©cessaire de\nvisualiser ou ex√©cuter du code Python.\n\nVoici, par exemple, ces boutons pour le tutoriel numpy :\n\n\n\n\n\n\n\n\n\n\nPour les agents de la fonction publique, ou\nles √©l√®ves des √©coles partenaires, il est recommand√©\nde privil√©gier le bouton SSPCloud qui est\nune infrastructure cloud moderne, puissante et flexible\nd√©velopp√©e par l‚ÄôInsee et accessible √† l‚Äôurl\nhttps://datalab.sspcloud.fr1.\nL‚Äôensemble du contenu de ce site s‚Äôappuie sur des donn√©es\nouvertes, qu‚Äôil s‚Äôagisse de donn√©es fran√ßaises (principalement\nissues de la plateforme\ncentralisatrice data.gouv ou du site\nweb de l‚ÄôInsee) ou de donn√©es\nam√©ricaines. Les r√©sultats sont donc reproductibles pour quelqu‚Äôun\ndisposant d‚Äôun environnement identique.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#architecture-du-site-web",
    "href": "content/getting-started/index.html#architecture-du-site-web",
    "title": "Introduction",
    "section": "",
    "text": "Ce cours pr√©sente\ndes tutoriels et des exercices complets.\nChaque page est structur√©e sous la forme\nd‚Äôun probl√®me concret et pr√©sente la\nd√©marche g√©n√©rique pour r√©soudre ce probl√®me g√©n√©ral.\nVous pouvez naviguer dans l‚Äôarchitecture du site via la table des mati√®res\nou par les liens vers le contenu ant√©rieur ou post√©rieur √† la fin de chaque\npage. Certaines parties, notamment celle consacr√©e √† la mod√©lisation,\nproposent des exemples fil-rouge pour illustrer la d√©marche de mani√®re\nplus extensive.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#evaluation",
    "href": "content/getting-started/index.html#evaluation",
    "title": "Introduction",
    "section": "",
    "text": "Les √©l√®ves de l‚ÄôENSAE valident le cours gr√¢ce √†\nun projet approfondi.\nLes √©l√©ments relatifs √† l‚Äô√©valuation du cours, ainsi qu‚Äôune\nliste des projets d√©j√† effectu√©s, sont disponibles dans la\nSection Evaluation.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#r√©f√©rences",
    "href": "content/getting-started/index.html#r√©f√©rences",
    "title": "Introduction",
    "section": "",
    "text": "Davenport, Thomas H, and DJ Patil. 2012a. ‚ÄúData Scientist, the Sexiest Job of the 21st Century.‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.\n\n\n‚Äî‚Äî‚Äî. 2012b. ‚ÄúIs Data Scientist Still the Sexiest Job of the 21st Century?‚Äù Harvard Business Review 90 (5): 70‚Äì76. https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#contenu-g√©n√©ral",
    "href": "content/getting-started/index.html#contenu-g√©n√©ral",
    "title": "Introduction",
    "section": "",
    "text": "{{&lt; list_children  &gt;}}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#structuration-de-cette-partie",
    "href": "content/getting-started/index.html#structuration-de-cette-partie",
    "title": "Introduction",
    "section": "",
    "text": "{{&lt; list_children  &gt;}}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#informations-additionnelles",
    "href": "content/getting-started/index.html#informations-additionnelles",
    "title": "Introduction",
    "section": "",
    "text": "environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n6178ebe\n\n\n2023-09-26 14:18:34\n\n\nLino Galiana\n\n\nChange quarto project type (#409)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\ndde3e93\n\n\n2023-07-21 22:22:05\n\n\nLino Galiana\n\n\nFix bug on chapter order (#385)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/index.html#footnotes",
    "href": "content/getting-started/index.html#footnotes",
    "title": "Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour les utilisateurs de cette infrastructure, les notebooks\nsont √©galement list√©s, parmi de nombreuses autres\nressources de qualit√©, sur la\npage Formation‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html",
    "href": "content/getting-started/02_DS_environment.html",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "",
    "text": "La richesse des langages open-source est la possibilit√©\nd‚Äôutiliser des packages\nd√©velopp√©s par des sp√©cialistes. Python est particuli√®rement\nbien dot√© dans le domaine. Pour caricaturer, on lit parfois\nque Python est le deuxi√®me meilleur langage pour toutes les\nt√¢ches, ce qui en fait le meilleur langage.\nEn effet, la mall√©abilit√© de Python fait qu‚Äôon peut\nl‚Äôaborder de mani√®re tr√®s diff√©rentes\nselon que l‚Äôon est plut√¥t SysAdmin, d√©veloppeur web ou\ndata scientist. C‚Äôest ce dernier profil qui va ici nous\nint√©resser.\nLe data scientist devant disposer de nombreuses cordes\n√† son arc. Cela se refl√®te sur l‚Äô√©cosyst√®me de la data science\nqui est assez √©clat√©. Cependant, ce foisonnement\nn‚Äôest pas propre √† Python puisque R propose encore plus de\npackages que Python o√π un certain nombre de framework\nnormalis√©s limitent l‚Äô√©clatement de l‚Äô√©cosyst√®me. De plus,\nle foisonnement de l‚Äôenvironnement du data scientist\nest une v√©ritable opportunit√© puisqu‚Äôelle permet\naux packages de se sp√©cialiser dans un\ndomaine, o√π ils sont plus efficaces, et aux concepteurs\nde package d‚Äôoser mettre en oeuvre de nouvelles m√©thodes,\nindispensables pour que le langage suive les √©volutions\nrapides de la recherche ou de la technologie.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#numpy",
    "href": "content/getting-started/02_DS_environment.html#numpy",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "numpy",
    "text": "numpy\nnumpy g√®re tout ce qui est calcul matriciel.\nLe langage Python est un des langages les plus lents qui soient1.\nTous les calculs rapides ne sont pas √©crits en Python mais en C++, voire Fortran.\nC‚Äôest le cas du package numpy. Celui-ci est incontournable\nd√®s qu‚Äôon veut √™tre rapide. Le package\nscipy est une extension o√π l‚Äôon peut trouver\ndes fonctions statistiques, d‚Äôoptimisation.\nLa Cheat Sheet de numpy est pratique:\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\nComme numpy est la brique de base de l‚Äôanalyse de donn√©es, un chapitre\nde ce cours lui est consacr√©.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#pandas",
    "href": "content/getting-started/02_DS_environment.html#pandas",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "pandas",
    "text": "pandas\nAvant tout, un bon data scientist doit √™tre capable de\ns‚Äôapproprier et manipuler des donn√©es rapidement. Pour cette raison,\npandas est incontournable.\nIl g√®re la plupart des formats de donn√©es. Pour √™tre efficace,\nil est lui aussi impl√©ment√© en C++.\nLe package est rapide si on utilise les m√©thodes pr√©-impl√©ment√©es sur\ndes donn√©es d‚Äôune taille raisonnable (par rapport √† la RAM disponible). Il faut\nn√©anmoins s‚Äôen m√©fier avec des donn√©es volumineuses.\nEn r√®gle g√©n√©rale, un jeu de donn√©es n√©cessite\ntrois fois plus d‚Äôespace en m√©moire que les\ndonn√©es n‚Äôen prennent sur le disque.\nLa Cheat Sheet de pandas :\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Pandas_Cheat_Sheet_2.pdf\npandas √©tant un √©l√©ment incontournable, deux chapitres y sont consacr√©s.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#matplotlib-et-seaborn",
    "href": "content/getting-started/02_DS_environment.html#matplotlib-et-seaborn",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "matplotlib et seaborn",
    "text": "matplotlib et seaborn\nmatplotlib existe depuis une vingtaine d‚Äôann√©es pour doter Python de\nfonctionalit√©s graphiques. Il s‚Äôagit d‚Äôun package tr√®s flexible, offrant\nde nombreuses fonctionalit√©s. N√©anmoins, ces derni√®res ann√©es,\nseaborn a √©merg√© pour simplifier la cr√©ation de certains graphiques\nstandards de l‚Äôanalyse de donn√©es (histogrammes, diagramme en barre, etc. ).\nLe succ√®s de seaborn n‚Äô√©clipse n√©anmoins pas matplotlib puisque ce\ndernier est souvent n√©cessaire pour finaliser la customisation d‚Äôun\ngraphique produit par seaborn2",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#scikit-learn",
    "href": "content/getting-started/02_DS_environment.html#scikit-learn",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "scikit-learn",
    "text": "scikit-learn\nscikit-learn est le module de machine learning le plus populaire pour\ntrois raisons:\n\nil s‚Äôappuie sur une API extr√™mement consistante (m√©thodes fit, transform\net predict, respectivement pour apprendre des donn√©es, appliquer des transformations et pr√©dire sur de nouvelles donn√©es) ;\nil permet de construire\ndes analyses reproductibles en construisant des pipelines de donn√©es ;\nsa documentation est un mod√®le √† suivre.\n\nL‚ÄôINRIA, institution fran√ßaise, est l‚Äôun des √©l√©ments moteurs dans\nla cr√©ation et la maintenance de scikit-learn",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#tensorflow-pytorch-et-keras",
    "href": "content/getting-started/02_DS_environment.html#tensorflow-pytorch-et-keras",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "TensorFlow, PyTorch et Keras",
    "text": "TensorFlow, PyTorch et Keras\nLes librairies essentielles pour impl√©menter et utiliser des mod√®les\nde deep learning en Python ont √©t√© d√©velopp√©es par des acteurs du\nnum√©rique.\nTensorFlow est la librairie la plus mature, mais pas n√©cessairement la plus facile √† prendre en main. D‚Äôailleurs, Google semble l‚Äôabandonner en usage interne pour lui\npr√©f√©rer JAX.\nKeras propose une interface high-level,\ndonc plus facile d‚Äôutilisation,\nmais qui n‚Äôen reste pas moins suffisante pour une grande vari√©t√© d‚Äôusages.\nLa documentation de Keras est tr√®s bien faite.\nPyTorch est un framework plus r√©cent mais tr√®s complet,\ndont la syntaxe plaira aux amateurs de programmation orient√©-objet.\nD√©velopp√© par Facebook,\nil est tr√®s utilis√© dans certains domaines de recherche, comme le NLP.\nIl s‚Äôagit du framework dont la dynamique r√©cente a √©t√© la plus\nascensionnelle.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#statsmodels",
    "href": "content/getting-started/02_DS_environment.html#statsmodels",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "statsmodels",
    "text": "statsmodels\nstatsmodels plaira plus aux statisticiens, il impl√©mente des mod√®les\n√©conom√©triques similaires √† scikit-learn.\nPar rapport √† scikit-learn,\nstatsmodels est plus orient√© √©conom√©trie. La pr√©sentation des\nr√©sultats est tr√®s proche de ce qu‚Äôon trouve en R.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#requests-et-beautifulsoup",
    "href": "content/getting-started/02_DS_environment.html#requests-et-beautifulsoup",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "requests et beautifulsoup",
    "text": "requests et beautifulsoup\nrequests est l‚Äôune des librairies de base de Python, d√©di√©e\n√† g√©rer la connexion avec internet. Les amateurs d‚ÄôAPI\nseront des utilisateurs fr√©quents de celle-ci. Les\npersonnes plus sp√©cialistes de web scraping l‚Äôutiliseront avec\nbeautifulsoup qui offre une syntaxe extr√™mement puissante\npour r√©cup√©rer automatiquement du contenu de pages web.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#nltk-et-spacy",
    "href": "content/getting-started/02_DS_environment.html#nltk-et-spacy",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "nltk et spaCy",
    "text": "nltk et spaCy\nDans le domaine du traitement automis√© du langage, plus connu\nsous son acronyme anglais NLP, les deux packages phares sont\nnltk et spaCy.\nnltk est le package historique. Il existe depuis les ann√©es\n1990 et propose de nombreuses ressources utiles pour l‚Äôanalyse\ntextuelle. N√©anmoins, ces derni√®res ann√©es, spaCy est venu\nmoderniser l‚Äôapproche en proposant une approche permettant\nde mieux int√©grer les diff√©rentes phases du traitement de donn√©es\ntextuelles, une excellente documentation et un meilleur support\ndes langues non anglo-saxonnes, comme le Fran√ßais.\nMais Python est √©galement un outil privil√©gi√© pour communiquer:\n\nUne bonne int√©gration de Python √† Markdown (gr√¢ce notamment √† ‚Ä¶ R Markdown) qui facilite la construction de documents HTML ou PDF (via Latex)\nSphynx et JupyterBook proposent des mod√®les de documentation\ntr√®s complets\nbokeh ou streamlit comme alternative √† shiny (R)\nDjango et Flask permettent de construire des applications web en Python\nLes librairies dynamiques, notamment\nfolium ou\nplotly, sont tr√®s appr√©ci√©es pour construire des\nvisualisations dynamiques qui sont pratiques dans une analyse exploratoire\nmais √©galement lorsqu‚Äôil faut valoriser ses travaux aupr√®s de\npublics non experts de la donn√©e.\n\nL‚Äôun des nouveaux arrivants dans cet √©cosyst√®me d√©j√† riche\nest FastAPI). Avec ce package,\nil est tr√®s facile de transformer un code Python en API ce qui facilite\nla mise √† disposition de donn√©es mais aussi de productions par Python (comme\nla mise √† disposition d‚Äôune API pour permettre √† des personnes de tester\nles r√©sultats d‚Äôun mod√®le de machine learning).\nCe n‚Äôest qu‚Äôune petite partie de l‚Äô√©cosyst√®me Python, d‚Äôune richesse rare.",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#informations-additionnelles",
    "href": "content/getting-started/02_DS_environment.html#informations-additionnelles",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n5123634\n\n\n2022-06-30 11:24:49\n\n\nLino Galiana\n\n\nAm√©lioration de la premi√®re partie (#244)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n90641c2\n\n\n2020-09-15 21:16:38\n\n\nLino Galiana\n\n\najout √©l√©ments ecosysteme\n\n\n\n\nf9f00cc\n\n\n2020-09-15 21:05:54\n\n\nLino Galiana\n\n\nenl√®ve quelques TO DO\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/02_DS_environment.html#footnotes",
    "href": "content/getting-started/02_DS_environment.html#footnotes",
    "title": "L‚Äôenvironnement Python pour la data science",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPython est un langage interpr√©t√©, comme R. Cela le rend tr√®s\nintelligible, y compris par un non-expert. C‚Äôest une des raisons de son\nsucc√®s. Le cr√©ateur de Python, Guido Van Rossum,\nen a fait un des principes philosophiques\n√† l‚Äôorigine de Python: un code est plus souvent lu qu‚Äô√©crit.\nLa contrepartie est qu‚Äôil s‚Äôagit d‚Äôune surcouche √† des langages\nplus bas-niveau, notamment C. Ces derniers proposent beaucoup moins de\nsurcouches. En r√©alit√©, les fonctions Python font appel, plus ou moins\ndirectement, √† du C. Une mani√®re d‚Äôoptimiser le code est ainsi d‚Äôarriver,\navec le moins de surcouches possible, √† la fonction C sous-jacente,\nbeaucoup plus rapide.‚Ü©Ô∏é\nLa situation est diff√©rente en R o√π ggplot2 a quasiment √©clips√©\nl‚Äôoutil de graphique de base de R.‚Ü©Ô∏é",
    "crumbs": [
      "L'environnement Python pour la data science"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html",
    "href": "content/getting-started/04_python_practice.html",
    "title": "Bonne pratique de Python",
    "section": "",
    "text": "Une r√©f√©rence utile √† lire est le\nHitchhiker‚Äôs Guide to Python",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#import-des-modules",
    "href": "content/getting-started/04_python_practice.html#import-des-modules",
    "title": "Bonne pratique de Python",
    "section": "2.1 Import des modules",
    "text": "2.1 Import des modules\nLes √©l√©ments suivants concernent plut√¥t les scripts finaux, qui appellent de multiples fonctions, que des\nscripts qui d√©finissent des fonctions.\nUn module est un ensemble de fonctions stock√©es dans un fichier .py. Lorsqu‚Äôon √©crit dans un script\nimport modu\nPython commence par chercher le fichier modu.py dans le dossier de travail. Il n‚Äôest donc pas une bonne\nid√©e d‚Äôappeler un fichier du nom d‚Äôun module standard de python, par exemple math.py ou os.py. Si le fichier\nmodu.py n‚Äôest pas trouv√© dans le dossier de travail, Python va chercher dans le chemin et s‚Äôil ne le trouve pas\nretournera une erreur.\nUne fois que modu.py est trouv√©, il sera ex√©cut√© dans un environnement isol√© (reli√© de mani√®re coh√©rente\naux d√©pendances renseign√©es) et le r√©sultat rendu disponible √† l‚Äôinterpr√©teur Python pour un usage\ndans la session via le namespace (espace o√π Python associe les noms donn√©s aux objets).\nEn premier lieu, ne jamais utiliser la syntaxe suivante :\n# A NE PAS UTILISER\nfrom modu import *\n\nx = sqrt(4)  # Is sqrt part of modu? A builtin? Defined above?\nL‚Äôutilisation de la syntaxe import * cr√©√© une ambiguit√© sur les fonctions disponibles dans l‚Äôenvironnement. Le code\nest ainsi moins clair, moins compartiment√© et ainsi moins robuste. La syntaxe √† privil√©gier est la suivante :\nimport modu\n\nx = modu.sqrt(4)  # Is sqrt part of modu? A builtin? Defined above?",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#aux-arguments-optionnels",
    "href": "content/getting-started/04_python_practice.html#aux-arguments-optionnels",
    "title": "Bonne pratique de Python",
    "section": "4.1 ‚ö†Ô∏è aux arguments optionnels",
    "text": "4.1 ‚ö†Ô∏è aux arguments optionnels\nLa fonction la plus lisible (mais la plus contraignante) est celle\nqui utilise exclusivement des arguments positionnels avec des noms explicites.\nDans le cadre d‚Äôune utilisation avanc√©e des fonctions (par exemple un gros mod√®le de microsimulation), il est\ndifficile d‚Äôanticiper tous les objets qui seront n√©cessaires √† l‚Äôutilisateur. Dans ce cas, on retrouve g√©n√©ralement\ndans la d√©finition d‚Äôune fonction le mot-cl√© **kwargs (√©quivalent du ... en R) qui capture les\narguments suppl√©mentaires et les stocke sous forme de dictionnaire. Il s‚Äôagit d‚Äôune technique avanc√©e de\nprogrammation qui est √† utiliser avec parcimonie.",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#informations-additionnelles",
    "href": "content/getting-started/04_python_practice.html#informations-additionnelles",
    "title": "Bonne pratique de Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2f7b52d\n\n\n2021-07-20 17:37:03\n\n\nLino Galiana\n\n\nImprove notebooks automatic creation (#120)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\nf9f00cc\n\n\n2020-09-15 21:05:54\n\n\nLino Galiana\n\n\nenl√®ve quelques TO DO\n\n\n\n\nc3c7433\n\n\n2020-09-15 12:41:26\n\n\nLino Galiana\n\n\nImprove CI with gitlab and jupyter nb conversion (#35)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n725d4e1\n\n\n2020-07-24 13:00:45\n\n\nLino Galiana\n\n\nMerge branch ‚Äòmaster‚Äô into pandas_intro\n\n\n\n\n66176dc\n\n\n2020-07-23 17:00:57\n\n\nLino Galiana\n\n\nfix typo in footnotes\n\n\n\n\n0b4d3d1\n\n\n2020-07-23 11:53:00\n\n\nLino Galiana\n\n\nEcnore un mot\n\n\n\n\naa9d09f\n\n\n2020-07-23 11:48:18\n\n\nLino Galiana\n\n\nR√©f√©rence au hitch guide\n\n\n\n\na2facfb\n\n\n2020-07-23 11:46:04\n\n\nLino Galiana\n\n\nUn peu de d√©tails\n\n\n\n\nd2c7518\n\n\n2020-07-23 11:45:48\n\n\nLino Galiana\n\n\nAjout sur les tests et gitignore\n\n\n\n\n304985b\n\n\n2020-07-23 10:47:30\n\n\nLino Galiana\n\n\nMot sur sphinx\n\n\n\n\ne8395c3\n\n\n2020-07-23 10:12:09\n\n\nLino Galiana\n\n\nOn verra pour les fonctions imbriqu√©es\n\n\n\n\ndcff627\n\n\n2020-07-23 10:08:46\n\n\nLino Galiana\n\n\nchange title level\n\n\n\n\n98b6102\n\n\n2020-07-23 10:02:17\n\n\nLino Galiana\n\n\nElements suppl√©mentaires sur la lisibilit√©\n\n\n\n\nc376c32\n\n\n2020-07-23 09:45:51\n\n\nLino Galiana\n\n\nPlus sur la structure\n\n\n\n\ndf95626\n\n\n2020-07-22 18:36:06\n\n\nLino Galiana\n\n\nMet le lien quelque part\n\n\n\n\n179b4bc\n\n\n2020-07-22 18:33:04\n\n\nLino Galiana\n\n\nTopo sur la lisibilit√© du code\n\n\n\n\n0556057\n\n\n2020-07-22 18:02:29\n\n\nLino Galiana\n\n\ntests apr√®s\n\n\n\n\n6ddd071\n\n\n2020-07-22 17:52:30\n\n\nLino Galiana\n\n\nPartager\n\n\n\n\n97419d0\n\n\n2020-07-22 17:42:09\n\n\nLino Galiana\n\n\nquelques mots sur les d√©pendances\n\n\n\n\n2849bac\n\n\n2020-07-22 17:23:35\n\n\nLino Galiana\n\n\nquelques mots sur les d√©pendances\n\n\n\n\n77f71f6\n\n\n2020-07-22 16:20:12\n\n\nLino Galiana\n\n\nptit mot sur les tests\n\n\n\n\nf17fc8d\n\n\n2020-07-22 14:36:48\n\n\nLino Galiana\n\n\nGriffoner des choses\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/04_python_practice.html#footnotes",
    "href": "content/getting-started/04_python_practice.html#footnotes",
    "title": "Bonne pratique de Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n1‚Ü©Ô∏é\n1:‚Ü©Ô∏é\n2‚Ü©Ô∏é\n2:‚Ü©Ô∏é",
    "crumbs": [
      "Bonne pratique de Python"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html",
    "href": "content/getting-started/06_rappels_fonctions.html",
    "title": "Modules, tests, boucles, fonctions",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#import-module",
    "href": "content/getting-started/06_rappels_fonctions.html#import-module",
    "title": "Modules, tests, boucles, fonctions",
    "section": "1.1 Import module",
    "text": "1.1 Import module\nOn charge un module gr√¢ce √† la commande import.\nPour chaque code que vous ex√©cutez,\nil faut charger les modules en introduction.\nUne fois qu‚Äôon a charg√© le module,\non peut faire appel aux commandes qui en d√©pendent en les appelant\napr√®s avoir tap√© le nom du module.\nSi vous ne pr√©cisez pas le nom du module avant celui de la fonction,\nil ne la trouvera pas forc√©ment.\nVoici un exemple avec le module numpy\nqui est tr√®s courant et permet de faire des\ncalculs matriciels sous Python.\n\nimport numpy\n\nprint(numpy.arange(5))\n\n[0 1 2 3 4]",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#import-module-as-md---donner-un-nom-au-module",
    "href": "content/getting-started/06_rappels_fonctions.html#import-module-as-md---donner-un-nom-au-module",
    "title": "Modules, tests, boucles, fonctions",
    "section": "1.2 Import module as md - donner un nom au module",
    "text": "1.2 Import module as md - donner un nom au module\nOn peut aussi donner un pseudonyme au module pour\n√©viter de taper un nom trop long √† chaque fois\nqu‚Äôon utilise une fonction.\nClassiquement le nom raccourci de numpy est np,\ncelui de pandas est pd.\n\nimport pandas as pd\nimport numpy as np\n\nsmall_array = np.array([[1, 2], [3, 4]])\ndata = pd.DataFrame(small_array)\ndata.head()\n\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n1\n2\n\n\n1\n3\n4",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#from-module-import-fonction---seulement-une-partie-du-module",
    "href": "content/getting-started/06_rappels_fonctions.html#from-module-import-fonction---seulement-une-partie-du-module",
    "title": "Modules, tests, boucles, fonctions",
    "section": "1.3 from Module Import fonction - seulement une partie du module",
    "text": "1.3 from Module Import fonction - seulement une partie du module\nSi on ne veut pas √™tre oblig√© de donner\nle nom du module avant d‚Äôappeler\nla fonction,\nil y a toujours la possibilit√© de n‚Äôimporter qu‚Äôune fonction du module.\nDans le cas de l‚Äôexemple, Python sait que la fonction arrange est celle de numpy.\nMais attention : si deux fonctions de modules diff√©rents\nont le m√™me nom,\nc‚Äôest toujours la derni√®re import√©e qui gagne.\nOn voit souvent from _module_ import *.\nC‚Äôest-√†-dire qu‚Äôon importe toutes\nles fonctions du module\nmais on n‚Äôa pas besoin de sp√©cifier le nom du module avant les m√©thodes.\n\n\n Warning\nLa m√©thode from _module_ import * n‚Äôest pas recommand√©e car elle rend le code moins intelligible.\nEn effet, d‚Äôo√π vient la fonction floor ? De maths ou de numpy ?\nElle risque\naussi de cr√©er des conflits de fonction, qui malgr√© un nom commun peuvent ne\npas attendre les m√™mes arguments ou objets.\n\n\n\nfrom numpy import array\n\nprint(array(5))\n\n5",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#test-avec-contrepartie-if-et-else",
    "href": "content/getting-started/06_rappels_fonctions.html#test-avec-contrepartie-if-et-else",
    "title": "Modules, tests, boucles, fonctions",
    "section": "2.1 Test avec contrepartie : if et else",
    "text": "2.1 Test avec contrepartie : if et else\nComme dans les autres langages,\non teste une condition. Si elle est v√©rifi√©e,\nalors une instruction suit et sinon, une autre instruction est ex√©cut√©e.\nIl est conseill√© de toujours indiquer une contrepartie afin d‚Äô√©viter les surprises.\n\n2.1.1 Test d‚Äôune √©galit√© ou in√©galit√©\n\nx = 6\n\nif x &gt; 5:\n    print(\"x est plus grand que 5\")\nelse:  # la contrepartie si la condition if n'est pas r√©alis√©e\n    print(\"x est plus petit que 5\")\n\nx est plus grand que 5\n\n\n\n\n2.1.2 Test dans un intervalle\n\n# on peut avoir des intervalles directement\nx = 6\nif 5 &lt; x &lt; 10:\n    print(\"x est entre 5 et 10\")\nelse:\n    print(\"x est plus grand que 10\")\n\nx est entre 5 et 10\n\n\n\n# tester plusieurs valeurs avec l'op√©rateur logique \"or\"\nx = 5\nif x == 5 or x == 10:\n    print(\"x vaut 5 ou 10\")\nelse:\n    print(\"x est diff√©rent de 5 et 10\")\n\nx vaut 5 ou 10",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#tests-successifs-if-elif-et-else",
    "href": "content/getting-started/06_rappels_fonctions.html#tests-successifs-if-elif-et-else",
    "title": "Modules, tests, boucles, fonctions",
    "section": "2.2 Tests successifs : if, elif et else",
    "text": "2.2 Tests successifs : if, elif et else\nAvec if et elif,\nd√®s qu‚Äôon rencontre une condition qui est r√©alis√©e,\non n‚Äôen cherche pas d‚Äôautres potentiellement v√©rifi√©es.\nPlusieurs if √† la suite peuvent quant √† eux √™tre v√©rifi√©s.\nSuivant ce que vous souhaitez faire, les op√©rateurs ne sont pas substituables.\nNotez la diff√©rence entre ces deux bouts de code :\n\n# code 1\nx = 5\n\nif x != 10:\n    print(\"x ne vaut pas 10\")\nelif x &gt;= 5:\n    print(\"x est √©gal ou sup√©rieur √† 5\")\n\nx ne vaut pas 10\n\n\nDans le cas de elif, on s‚Äôarr√™te √† la premi√®re condition v√©rifi√©e et dans le cas suivant, on continue √† chaque condition v√©rifi√©e\n\n# code 2\nx = 5\n\nif x != 10:\n    print(\"x ne vaut pas 10\")\nif x &gt;= 5:\n    print(\"x est √©gal ou sup√©rieur √† 5\")\n\nx ne vaut pas 10\nx est √©gal ou sup√©rieur √† 5",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#boucle-for",
    "href": "content/getting-started/06_rappels_fonctions.html#boucle-for",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.1 Boucle for",
    "text": "3.1 Boucle for\n\n3.1.1 Parcourir une liste croissantes d‚Äôentiers\n\n# parcourt les entiers de 0 √† n-1 inclus\nfor i in range(0, 3):\n    print(i)\n\n0\n1\n2\n\n\n\n\n3.1.2 Parcourir une liste d√©croissante d‚Äôentiers\n\n# parcourt les entiers de 3 √† n+1 inclus\nfor i in range(3, 0, -1):\n    print(i)\n\n3\n2\n1\n\n\n\n\n3.1.3 Parcourir une liste de chaines de caract√®res\nOn va faire une boucle sur les √©l√©ments d‚Äôune liste\n\n\n3.1.4 Boucle sur les √©l√©ments d‚Äôune liste\n\nliste_elements = [\"Nicolas\", \"Romain\", \"Florimond\"]\n\n# pour avoir l'ensemble des √©l√©ments de la liste\nfor item in liste_elements:\n    print(item)\n\nNicolas\nRomain\nFlorimond\n\n\n\n\n3.1.5 Boucle sur les √©l√©ments d‚Äôune liste dans une autre liste\n\n# pour avoir la place des √©l√©ments de la premi√®re liste dans la seconde liste\n\nliste_globale = [\"Violette\", \"Nicolas\", \"Mathilde\", \"Romain\", \"Florimond\", \"Helene\"]\n\nfor item in liste_elements:\n    print(item, liste_globale.index(item))\n\nNicolas 1\nRomain 3\nFlorimond 4",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#bonus-les-list-comprehension",
    "href": "content/getting-started/06_rappels_fonctions.html#bonus-les-list-comprehension",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.2 Bonus : les list comprehension",
    "text": "3.2 Bonus : les list comprehension\nAvec les listes, il existe aussi un moyen tr√®s √©l√©gant de condenser son code pour √©viter de faire apparaitre des boucles sans arr√™t. Comme les boucles doivent etre indent√©es, le code peut rapidement devenir illisible.\nGrace aux list comprehension, vous pouvez en une ligne faire ce qu‚Äôune boucle vous permettait de faire en 3 lignes.\nPar exemple, imaginez que vous vouliez faire la liste de toutes les lettres contenues dans un mot, avec un boucle vous devrez d‚Äôabord cr√©er une liste vide, puis ajouter √† cette liste toutes les lettres en question avec un .append()\n\nliste_lettres = []\n\nfor lettre in \"ENSAE\":\n    liste_lettres.append(lettre)\n\nprint(liste_lettres)\n\n['E', 'N', 'S', 'A', 'E']\n\n\navec une list comprehension, on condense la syntaxe de la mani√®re suivante :\n\nh_letters = [letter for letter in \"ENSAE\"]\nprint(h_letters)\n\n['E', 'N', 'S', 'A', 'E']\n\n\nAvec une list comprehension\n[expression for item in list if conditional]\nest √©quivalent √†\nfor item in list:\n    if conditional:\n        expression\n\n3.2.1 Mise en application\nMettez sous forme de list comprehension le bout de code suivant\n\nsquares = []\n\nfor x in range(10):\n    squares.append(x**2)\nprint(squares)\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#boucle-while",
    "href": "content/getting-started/06_rappels_fonctions.html#boucle-while",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.3 Boucle while",
    "text": "3.3 Boucle while\nLe bloc d‚Äôinstruction d‚Äôune boucle while est ex√©cut√© tant que la condition est v√©rifi√©e.\nLe pi√®ge de ces boucles : la boucle while infinie ! Il faut toujours v√©rifier que votre boucle s‚Äôarr√™tera un jour, il faut qu‚Äô√† un moment ou √† un autre, il y ait un √©l√©ment qui s‚Äôincr√©mente ou qui soit modifi√©.\n\nx = 10\ny = 8\n# tant que y est plus petit que 10, je continue de lui ajouter 1\nwhile y &lt;= x:\n    print(\"y n'est pas encore plus grand que x\")\n    y += 1  # l'incr√©ment\nelse:\n    print(\"y est plus grand que x et vaut\", y)\n\ny n'est pas encore plus grand que x\ny n'est pas encore plus grand que x\ny n'est pas encore plus grand que x\ny est plus grand que x et vaut 11",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#break-et-continue",
    "href": "content/getting-started/06_rappels_fonctions.html#break-et-continue",
    "title": "Modules, tests, boucles, fonctions",
    "section": "3.4 Break et continue",
    "text": "3.4 Break et continue\nDans les boucles for ou while on peut avoir besoin d‚Äôignorer ou de ne pas effectuer certaines it√©rations. 2 instructions utiles :\n\nl‚Äôinstruction break : permet de sortir de la boucle\nl‚Äôinstruction continue : permet de passer √† l‚Äôit√©ration suivante sans ex√©cuter les instructions qui suivent\n\n\n# utilisation de break\nfor x in range(5):\n    if x == 2:\n        break\n    else:\n        print(x)\n\n0\n1\n\n\n\n# utilisation de continue\nfor x in range(5):\n    if x == 2:\n        continue\n    else:\n        print(x)\n\n0\n1\n3\n4",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#a-retenir",
    "href": "content/getting-started/06_rappels_fonctions.html#a-retenir",
    "title": "Modules, tests, boucles, fonctions",
    "section": "6.1 A retenir",
    "text": "6.1 A retenir\n\nToujours mettre ‚Äú:‚Äù avant un bloc d‚Äôinstructions\nIndenter avant un bloc d‚Äôinstructions (avec 4 espaces et non une tabulation !)\nIndiquer les modules n√©cessaires √† l‚Äôex√©cution en d√©but de code\nDocumenter les fonctions cr√©√©es\nPr√©ciser le type d‚Äôerreur pour les exceptions et potentiellement diff√©rencier les blocs d‚Äôinstructions en fonction de l‚Äôerreur",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#questions",
    "href": "content/getting-started/06_rappels_fonctions.html#questions",
    "title": "Modules, tests, boucles, fonctions",
    "section": "6.2 Questions",
    "text": "6.2 Questions\n\nQue fait ce programme ?\n\n\ndef inverse(x):\n    try:\n        y = 1 / x\n    except ZeroDivisionError:\n        y = None\n        return y\n\n\nEcrivez un programme qui peut trouver tous les nombres divisibles par 7 et non multiples de 5 entre 6523 et 8463 (inclus)\nEcrivez un programme qui prend une phrase en entr√©e et qui calcule le nombre de voyelles en Majuscules et de consonnes en minuscules :\n\nphrase = ‚ÄúVous savez, moi je ne crois pas qu‚Äôil y ait de bonne ou de mauvaise situation. Moi, si je devais r√©sumer ma vie aujourd‚Äôhui avec vous, je dirais que c‚Äôest d‚Äôabord des rencontres. Des gens qui m‚Äôont tendu la main, peut-√™tre √† un moment o√π je ne pouvais pas, o√π j‚Äô√©tais seul chez moi. Et c‚Äôest assez curieux de se dire que les hasards, les rencontres forgent une destin√©e‚Ä¶ Parce que quand on a le go√ªt de la chose, quand on a le go√ªt de la chose bien faite, le beau geste, parfois on ne trouve pas l‚Äôinterlocuteur en face je dirais, le miroir qui vous aide √† avancer. Alors √ßa n‚Äôest pas mon cas, comme je disais l√†, puisque moi au contraire, j‚Äôai pu : et je dis merci √† la vie, je lui dis merci, je chante la vie, je danse la vie‚Ä¶ je ne suis qu‚Äôamour ! Et finalement, quand beaucoup de gens aujourd‚Äôhui me disent ‚ÄòMais comment fais-tu pour avoir cette humanit√© ?‚Äô, et bien je leur r√©ponds tr√®s simplement, je leur dis que c‚Äôest ce go√ªt de l‚Äôamour ce go√ªt donc qui m‚Äôa pouss√© aujourd‚Äôhui √† entreprendre une construction m√©canique, mais demain qui sait ? Peut-√™tre simplement √† me mettre au service de la communaut√©, √† faire le don, le don de soi‚Ä¶‚Äù",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/getting-started/06_rappels_fonctions.html#informations-additionnelles",
    "href": "content/getting-started/06_rappels_fonctions.html#informations-additionnelles",
    "title": "Modules, tests, boucles, fonctions",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\ne8d0062\n\n\n2023-09-26 15:54:49\n\n\nKim A\n\n\nRelecture KA 25/09/2023 (#412)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\nf95b174\n\n\n2021-11-03 12:08:34\n\n\nLino Galiana\n\n\nEnrichi la section sur la gestion des d√©pendances (#175)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\na1b8aaf\n\n\n2021-09-20 09:05:55\n\n\nLino Galiana\n\n\nBadges de telechargement dans les premiers TP (#146)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\naeb3995\n\n\n2021-07-06 11:11:03\n\n\navouacr\n\n\nRelecture et ajouts sur anaconda + jupyter (#116)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n18be8f4\n\n\n2020-10-01 17:08:53\n\n\nLino Galiana\n\n\nInt√©gration de box inspir√©es du th√®me pydata sphinx (#58)\n\n\n\n\nc3c7433\n\n\n2020-09-15 12:41:26\n\n\nLino Galiana\n\n\nImprove CI with gitlab and jupyter nb conversion (#35)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n56f8532\n\n\n2020-09-08 10:40:03\n\n\nLino Galiana\n\n\nReprise des √©l√©ments de la premi√®re s√©ance dans le site web (#14)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Modules, tests, boucles, fonctions"
    ]
  },
  {
    "objectID": "content/manipulation/index.html",
    "href": "content/manipulation/index.html",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "",
    "text": "Si on associe souvent les data scientists √† la mise en oeuvre\nde mod√®les d‚Äôintelligence artificielle, il est important\nde ne pas oublier que l‚Äôentra√Ænement et l‚Äôutilisation\nde ces mod√®les ne repr√©sente pas\nforc√©ment le quotidien des data scientists.\nEn pratique,\nla r√©cup√©ration de sources de donn√©es h√©t√©rog√®nes, la structuration\net harmonisation de celles-ci en vue d‚Äôune analyse exploratoire\npr√©alable √† la mod√©lisation ou la visualisation\nrepr√©sente une part importante du travail des data scientists.\nDans de nombreux environnements c‚Äôest m√™me l‚Äôessence du travail\ndu data scientist.\nL‚Äô√©laboration de mod√®les pertinents requiert en effet une r√©flexion approfondie sur les donn√©es ;\nune √©tape que l‚Äôon ne saurait n√©gliger.\nCe cours,\ncomme de nombreuses ressources introductives sur\nla data science (Wickham, √áetinkaya-Rundel, and Grolemund 2023; VanderPlas 2016; McKinney 2012),\nproposera donc beaucoup d‚Äô√©l√©ments sur la manipulation de donn√©es, comp√©tence\nessentielle pour les data scientists.\nLes logiciels de programmation\norient√©s autour du concept de base de donn√©es\nsont devenus les outils principaux des data scientists.\nLe fait de pouvoir appliquer un certain nombre d‚Äôop√©rations\nstandards sur des bases de donn√©es, quelle que soit leur nature,\npermet aux programmeurs d‚Äô√™tre plus efficaces que s‚Äôils devaient\nr√©p√©ter ces op√©rations √† la main, comme dans Excel.\nTous les langages de programmation dominants dans l‚Äô√©cosyst√®me\nde la data science reposent sur le principe du dataframe.\nIl s‚Äôagit m√™me d‚Äôun objet central dans certains logiciels,\nnotamment R.\nLa logique SQL,\nun langage de d√©claration d‚Äôop√©rations sur des donn√©es qui a d√©j√† plus de cinquante ans,\noffre un cadre pertinent pour effectuer des op√©rations standardis√©es\nsur les colonnes (cr√©ation de nouvelles colonnes, s√©lection de sous-ensemble de lignes‚Ä¶).\nN√©anmoins, le dataframe ne s‚Äôest impos√© que r√©cemment en Python,\ngr√¢ce au package Pandas cr√©√©\npar Wes McKinney.\nL‚Äôessor de la librairie Pandas (t√©l√©charg√©e plus de 5 millions de fois\npar jour en 2023) est pour beaucoup dans le succ√®s de Python\ndans l‚Äô√©cosyst√®me de la data science et a amen√©, en quelques ann√©es,\na un renouvellement complet de la mani√®re de coder en Python, ce\nlangage si mall√©able, autour de l‚Äôanalyse de donn√©es.\nCette partie du cours est une introduction\ng√©n√©rale √† l‚Äô√©cosyst√®me tr√®s riche de\nla manipulation de donn√©es avec Python.\nCes chapitres √©voquent aussi bien la r√©cup√©ration de donn√©es\nque la restructuration et la production d‚Äôanalyse\n√† partir de celles-ci.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#r√©sum√©-de-cette-partie",
    "href": "content/manipulation/index.html#r√©sum√©-de-cette-partie",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "R√©sum√© de cette partie",
    "text": "R√©sum√© de cette partie\nPandas est devenu incontournable dans l‚Äô√©cosyst√®me Python pour la data science.\nPandas est lui-m√™me construit √† partir du package Numpy, qu‚Äôil est utile de comprendre\npour √™tre √† l‚Äôaise avec Pandas. Numpy est une librairie bas-niveau\npour stocker et manipuler des donn√©es.\nNumpy est au coeur de l‚Äô√©cosyst√®me de la data science car la plupart des librairies, m√™me celles\nqui manient des objets destructur√©s,\nutilisent des objets construits √† partir de Numpy1.\nL‚Äôapproche Pandas, qui offre un point d‚Äôentr√©e harmonis√© pour manipuler\ndes jeux de donn√©es de nature tr√®s diff√©rente,\na √©t√© √©tendue aux objets g√©ographiques avec Geopandas.\nIl est ainsi possible de manipuler des donn√©es g√©ographiques comme s‚Äôil\ns‚Äôagissait de donn√©es structur√©es classiques. Les donn√©es g√©ographiques et\nla repr√©sentation cartographique deviennent de plus en plus commun avec\nla multiplication de donn√©es ouvertes localis√©es et de big-data g√©olocalis√©es.\nCependant, les donn√©es structur√©es, import√©es depuis des fichiers plats\nne repr√©sentent pas l‚Äôunique source de donn√©es. Les API et le webscraping\npermettent de t√©l√©charger ou d‚Äôextraire\ndes donn√©es de mani√®re tr√®s flexible depuis des pages web ou des guichets\nsp√©cialis√©s. Ces donn√©es, notamment\ncelles obtenues par webscraping n√©cessitent souvent un peu plus de travail\nde nettoyage de donn√©es, notamment des cha√Ænes de caract√®re.\nL‚Äô√©cosyst√®me Pandas repr√©sente donc un couteau-suisse\npour l‚Äôanalyse de donn√©es. C‚Äôest pour cette raison que ce cours\nd√©veloppera beaucoup de contenu dessus.\nAvant d‚Äôessayer de mettre en oeuvre une solution ad hoc, il est\nsouvent utile de se poser la question suivante : ‚Äúne pourrais-je pas le faire\navec les fonctionalit√©s de base de Pandas ?‚Äù Se poser cette question peut\n√©viter des chemins ardus et faire √©conomiser beaucoup de temps.\nN√©anmoins, Pandas n‚Äôest pas\nadapt√© √† des donn√©es ayant une volum√©trie\nimportante. Pour traiter de telles\ndonn√©es, il est plut√¥t recommander\nde privil√©gier Polars ou Dask qui reprennent la logique de Pandas mais\noptimisent son fonctionnement, Spark si on a une infrastructure adapt√©e, g√©n√©ralement dans\ndes environnements big data, ou\nDuckDB si on est pr√™t √† utiliser des requ√™tes SQL plut√¥t qu‚Äôune librairie haut-niveau.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#exercices",
    "href": "content/manipulation/index.html#exercices",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Exercices",
    "text": "Exercices\nCette partie pr√©sente √† la fois des tutoriels d√©taill√©s\net des exercices guid√©s.\nIl est\npossible de les consulter sur ce site ou d‚Äôutiliser l‚Äôun des\nbadges pr√©sents en d√©but de chapitre, par exemple\nceux-ci pour ouvrir\nle chapitre d‚Äôexercices sur Pandas:",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#pour-aller-plus-loin",
    "href": "content/manipulation/index.html#pour-aller-plus-loin",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nCe cours n‚Äôaborde pas vraiment les questions de volum√©trie ou de vitesse de\ncalcul.\nPandas peut montrer ses limites dans ce domaine sur des jeux de donn√©es\nd‚Äôune volum√©trie cons√©quente (plusieurs Gigas).\nIl est ainsi int√©ressant de porter attention √†:\n\nLe livre Modern Pandas\npour obtenir des √©l√©ments suppl√©mentaires sur la question de la performance\navec Pandas ;\nLa question des\nobjets sparse ;\nLes packages Dask ou Polars pour acc√©l√©rer les calculs ;\nDuckDB pour effectuer de mani√®re tr√®s efficace des requ√™tes SQL ;\nPySpark pour des donn√©es tr√®s volumineuses.\n\n\nR√©f√©rences\nVoici une bibliographie s√©lective des ouvrages\nint√©ressants en compl√©ment des chapitres de la partie ‚ÄúManipulation‚Äù de ce cours :\n\n\nMcKinney, Wes. 2012. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython. \" O‚ÄôReilly Media, Inc.\".\n\n\nVanderPlas, Jake. 2016. Python Data Science Handbook: Essential Tools for Working with Data. \" O‚ÄôReilly Media, Inc.\".\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#informations-additionnelles",
    "href": "content/manipulation/index.html#informations-additionnelles",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n5cac236\n\n\n2021-12-16 19:46:43\n\n\nLino Galiana\n\n\nun petit mot sur mercator (#201)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/index.html#footnotes",
    "href": "content/manipulation/index.html#footnotes",
    "title": "Partie 1: manipuler des donn√©es",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCertaines librairies commencent, petit √† petit, √† s‚Äô√©manciper\nde Numpy qui n‚Äôest pas toujours le plus adapt√© pour la gestion\nde certains types de donn√©es. Le framework Arrow tend √† devenir\nla couche basse utilis√©e par de plus en plus de librairies de data science.\nCe post de blog approfondit\nde mani√®re tr√®s p√©dagogique ce sujet.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html",
    "href": "content/manipulation/02_pandas_intro.html",
    "title": "Introduction √† Pandas",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#donn√©es",
    "href": "content/manipulation/02_pandas_intro.html#donn√©es",
    "title": "Introduction √† Pandas",
    "section": "1.1 Donn√©es",
    "text": "1.1 Donn√©es\nDans ce tutoriel Pandas, nous allons utiliser :\n\nLes √©missions de gaz √† effet de serre estim√©es au niveau communal par l‚ÄôADEME. Le jeu de donn√©es est\ndisponible sur data.gouv\net requ√™table directement dans Python avec\ncet url ;\n\nLe chapitre suivant permettra de mettre en application des √©l√©ments pr√©sents dans ce chapitre avec\nles donn√©es ci-dessus associ√©es √† des donn√©es de contexte au niveau communal.\n\n\n Comp√©tences √† l'issue de ce chapitre\n\nImporter un jeu de donn√©es sous forme de dataframe Pandas et explorer sa structure ;\nEffectuer des manipulations sur les colonnes et les lignes ;\nConstruire des statistiques agr√©g√©es et cha√Æner les op√©rations ;\nUtiliser les m√©thodes graphiques de Pandas pour se repr√©senter rapidement la distribution des donn√©es.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#environnement",
    "href": "content/manipulation/02_pandas_intro.html#environnement",
    "title": "Introduction √† Pandas",
    "section": "1.2 Environnement",
    "text": "1.2 Environnement\nNous suivrons les conventions habituelles dans l‚Äôimport des packages :\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nPour obtenir des r√©sultats reproductibles, on peut fixer la racine du g√©n√©rateur\npseudo-al√©atoire.\n\nnp.random.seed(123)\n\nAu cours de cette d√©monstration des principales fonctionalit√©s de Pandas, et\nlors du chapitre suivant,\nje recommande de se r√©f√©rer r√©guli√®rement aux ressources suivantes :\n\nL‚Äôaide officielle de Pandas.\nNotamment, la\npage de comparaison des langages\nqui est tr√®s utile ;\nCe tutoriel,\npens√© certes pour les utilisateurs d‚ÄôObservable Javascript,\nmais qui offre de nombreux exemples int√©ressants pour les afficionados de Pandas ;\nLa cheatsheet suivante, issue de ce post\n\nPour rappel, afin d‚Äôex√©cuter les exemples de code dans un notebook interactif, vous pouvez utiliser les raccourcis en haut de la page pour lancer celui-ci dans votre environnement de pr√©dilection.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#anatomie-dune-table-pandas",
    "href": "content/manipulation/02_pandas_intro.html#anatomie-dune-table-pandas",
    "title": "Introduction √† Pandas",
    "section": "2.1 Anatomie d‚Äôune table Pandas",
    "text": "2.1 Anatomie d‚Äôune table Pandas\nL‚Äôobjet central dans la logique Pandas est le DataFrame.\nIl s‚Äôagit d‚Äôune structure particuli√®re de donn√©es\n√† deux dimensions, structur√©es en alignant des lignes et colonnes.\nContrairement √† une matrice, les colonnes\npeuvent √™tre de types diff√©rents.\nUn DataFrame est compos√© des √©l√©ments suivants :\n\nl‚Äôindice de la ligne ;\nle nom de la colonne ;\nla valeur de la donn√©e ;\n\n\n\n\nStructuration d‚Äôun DataFrame Pandas,\nemprunt√©e √† https://medium.com/epfl-extension-school/selecting-data-from-a-pandas-dataframe-53917dc39953",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#avant-le-dataframe-la-serie",
    "href": "content/manipulation/02_pandas_intro.html#avant-le-dataframe-la-serie",
    "title": "Introduction √† Pandas",
    "section": "2.2 Avant le DataFrame, la Serie",
    "text": "2.2 Avant le DataFrame, la Serie\nEn fait, un DataFrame est une collection d‚Äôobjets appel√©s pandas.Series.\nCes Series sont des objets d‚Äôune dimension qui sont des extensions des\narray-unidimensionnels Numpy3. En particulier, pour faciliter le traitement\nde donn√©es cat√©gorielles ou temporelles, des types de variables\nsuppl√©mentaires sont disponibles dans Pandas par rapport √†\nNumpy (categorical, datetime64 et timedelta64). Ces\ntypes sont associ√©s √† des m√©thodes optimis√©es pour faciliter le traitement\nde ces donn√©es.\nIl existe plusieurs types possibles pour un pandas.Series, extension des types de donn√©es de base en Python qui d√©termineront ensuite le comportement de cette variable. En effet, de nombreuses op√©rations n‚Äôont pas le m√™me sens selon qu‚Äôon a une valeur num√©rique ou non.\nLes types les plus simples (int ou float) correspondent aux valeurs num√©riques:\n\npoids = pd.Series([3, 7, 12])\npoids\n\n0     3\n1     7\n2    12\ndtype: int64\n\n\n\n\n Le pi√®ge des valeurs manquantes\nDe mani√®re g√©n√©rale, si Pandas d√©tecte exclusivement des valeurs enti√®res dans une variable, il utilisera le type int pour optimiser la m√©moire. Ce choix fait sens. Il a n√©anmoins un inconv√©nient: Numpy, et donc par extension Pandas, ne sait se repr√©senter des valeurs manquantes pour le type int (plus d‚Äô√©l√©ments sur les valeurs manquantes ci-dessous).\nEn attendant le changement de couche basse en faveur d‚ÄôArrow, qui lui sait g√©rer les valeurs manquantes dans les int, la m√©thode √† mettre en oeuvre est de convertir au type float si la variable sera amen√©e √† avoir des valeurs manquantes, ce qui est assez simple:\nx.astype(double)\n\n\nPour des donn√©es textuelles, c‚Äôest tout aussi simple:\n\nanimal = pd.Series([\"chat\", \"chien\", \"koala\"])\nanimal\n\n0     chat\n1    chien\n2    koala\ndtype: object\n\n\nLe type object correspond est une voiture-balais pour les types de donn√©es exclusivement textuelles (type str) ou m√©langeant donn√©es textuelles et num√©riques (type mixed). Historiquement, c‚Äô√©tait un type interm√©diaire entre le factor et le character de R. Cependant, depuis quelques temps, il existe un type √©quivalent au factor de R dans Pandas pour\nles variables dont le nombre de valeurs\nest une liste finie et relativement courte, le type category. Le type object pouvant provoquer des erreurs inattendues par sa nature mixte, il est recommand√©, lorsqu‚Äôon d√©sire se concentrer sur une variable, de faire un choix sur la nature de celle-ci et de la convertir:\n\n\n0     chat\n1    chien\n2    koala\ndtype: object\n\n\n\nPour convertir en category (le choix qui fait sens ici)\nPour convertir en str (si on d√©sire faire des op√©rations textuelles ult√©rieures)\n\nIl faut bien examiner les types de ses objets Pandas et les convertir s‚Äôils ne font pas sens ; Pandas fait certes des choix optimis√©s mais il est parfois n√©cessaire de les corriger car Pandas ne conna√Æt pas vos usages ult√©rieurs des donn√©es. C‚Äôest l‚Äôune des op√©rations √† faire lors\ndu feature engineering, ensemble des √©tapes de pr√©paration des donn√©es pour un usage ult√©rieur.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#lindexation",
    "href": "content/manipulation/02_pandas_intro.html#lindexation",
    "title": "Introduction √† Pandas",
    "section": "3.1 L‚Äôindexation",
    "text": "3.1 L‚Äôindexation\nLa diff√©rence essentielle entre une Series et un objet Numpy est l‚Äôindexation.\nDans Numpy,\nl‚Äôindexation est implicite ; elle permet d‚Äôacc√©der √† une donn√©e (celle √†\nl‚Äôindex situ√© √† la position i).\nAvec une Series, on peut bien s√ªr utiliser un indice de position mais on peut\nsurtout faire appel √† des indices plus explicites.\nCeci permet d‚Äôacc√©der √† la donn√©e de mani√®re plus naturelle, en utilisant les noms de colonne par exemple:\n\nanimaux[\"poids\"]\n\n0     3\n1     7\n2    12\nName: poids, dtype: int64\n\n\nL‚Äôexistence d‚Äôindice rend le subsetting, c‚Äôest-√†-dire\nla s√©lection de lignes ou de colonnes, particuli√®rement ais√©. Les DataFrames pendant pr√©sentent deux indices: ceux des lignes et ceux des colonnes. On pourra faire des s√©lections sur ces deux dimensions.\nEn anticipant sur les exercices\nult√©rieurs, on peut voir que cela va nous faciliter la s√©lection de ligne:\n\nanimaux.loc[animaux[\"animal\"] == \"chat\", \"poids\"]\n\n0    3\nName: poids, dtype: int64\n\n\nCette instruction est √©quivalente √† la commande SQL:\nSELECT poids FROM animaux WHERE animal == \"chat\"\nSi on revient sur notre jeu de donn√©es animaux,\non peut voir sur la gauche l‚Äôaffichage du num√©ro de la ligne:\n\nanimaux\n\n\n\n\n\n\n\n\n\nanimal\npoids\n\n\n\n\n0\nchat\n3\n\n\n1\nchien\n7\n\n\n2\nkoala\n12\n\n\n\n\n\n\n\n\nIl s‚Äôagit de l‚Äôindice par d√©faut pour la dimension ligne car nous n‚Äôen n‚Äôavons pas configur√© un. Ce n‚Äôest pas obligatoire, il est tout √† fait possible d‚Äôavoir un indice correspondant √† une variable d‚Äôint√©r√™t (nous d√©couvrirons cela lorsque nous explorerons groupby dans le prochain chapitre). Cependant, cela peut √™tre pi√©geux et il est recommand√© que cela ne soit que transitoire, d‚Äôo√π l‚Äôint√©r√™t de faire r√©guli√®rement des reset_index.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#le-concept-de-tidy-data",
    "href": "content/manipulation/02_pandas_intro.html#le-concept-de-tidy-data",
    "title": "Introduction √† Pandas",
    "section": "3.2 Le concept de tidy data",
    "text": "3.2 Le concept de tidy data\nLe concept de tidy data, popularis√© par Hadley Wickham via ses packages R (voir Wickham, √áetinkaya-Rundel, and Grolemund (2023)),\nest parfaitement pertinent pour d√©crire la structure d‚Äôun DataFrame Pandas.\nLes trois r√®gles des donn√©es tidy sont les suivantes :\n\nChaque variable poss√®de sa propre colonne ;\nChaque observation poss√®de sa propre ligne ;\nUne valeur, mat√©rialisant une observation d‚Äôune variable,\nse trouve sur une unique cellule.\n\n\n\n\nIllustration du concept de tidy data (emprunt√© √† H. Wickham)\n\n\nCes principes peuvent vous appara√Ætre de bon sens mais vous d√©couvrirez que de nombreux formats de donn√©es ne correspondent pas √† ce principe. Par exemple, des tableurs Excel proposent r√©guli√®rement des valeurs √† cheval sur plusieurs colonnes ou plusieurs lignes fusionn√©es. Restructurer cette donn√©e selon le principe des tidy data sera un enjeu pour √™tre en mesure d‚Äôeffectuer des traitements sur celle-ci.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#lire-des-donn√©es-depuis-un-chemin-local",
    "href": "content/manipulation/02_pandas_intro.html#lire-des-donn√©es-depuis-un-chemin-local",
    "title": "Introduction √† Pandas",
    "section": "4.1 Lire des donn√©es depuis un chemin local",
    "text": "4.1 Lire des donn√©es depuis un chemin local\nCet exercice vise √† pr√©senter l‚Äôint√©r√™t d‚Äôutiliser un chemin relatif\nplut√¥t qu‚Äôun chemin absolu pour favoriser la reproductibilit√© du code. Nous pr√©coniserons n√©anmoins par la suite de privil√©gier directement la lecture depuis internet lorsqu‚Äôelle est possible et n‚Äôimplique pas le t√©l√©chargement r√©current d‚Äôun fichier volumineux.\nPour pr√©parer cet exercice, le code suivant permettra de\nt√©l√©charger des donn√©es qu‚Äôon va √©crire en local\n\nimport requests\n\nurl = \"https://www.insee.fr/fr/statistiques/fichier/6800675/v_commune_2023.csv\"\nresponse = requests.get(url)\n\n# Assurez-vous que la requ√™te a r√©ussi\nif response.status_code == 200:\n    with open(\"cog_2023.csv\", \"wb\") as file:\n        file.write(response.content)\nelse:\n    print(\"√âchec du t√©l√©chargement du fichier. Statut HTTP :\", response.status_code)\n\n\n\n Exercice pr√©liminaire: Importer un CSV (optionnel)\n\nUtiliser le code ci-dessus ‚òùÔ∏è pour t√©l√©charger les donn√©es. Utiliser Pandas pour lire le fichier t√©l√©charg√©.\nChercher o√π les donn√©es ont √©t√© √©crites. Observer la structure de ce dossier.\nCr√©er un dossier depuis l‚Äôexplorateur de fichiers (√† gauche dans Jupyter ou VSCode). D√©placer le CSV et le notebook. Red√©marrer le kernel et adaptez votre code si besoin. Refaire cette manipulation plusieurs fois avec des dossiers diff√©rents. Quel peut √™tre le probl√®me rencontr√© ?\n\n\n\n\n\n\n\n\n\n\n\n\n\nTYPECOM\nCOM\nREG\nDEP\nCTCD\nARR\nTNCC\nNCC\nNCCENR\nLIBELLE\nCAN\nCOMPARENT\n\n\n\n\n0\nCOM\n01001\n84.0\n01\n01D\n012\n5\nABERGEMENT CLEMENCIAT\nAbergement-Cl√©menciat\nL'Abergement-Cl√©menciat\n0108\nNaN\n\n\n1\nCOM\n01002\n84.0\n01\n01D\n011\n5\nABERGEMENT DE VAREY\nAbergement-de-Varey\nL'Abergement-de-Varey\n0101\nNaN\n\n\n\n\n\n\n\n\nLe principal probl√®me de la lecture depuis des\nfichiers stock√©s en local est le risque de\nse rendre adh√©rant √† un syst√®me de fichier\nqui n‚Äôest pas forc√©ment partag√©. Il vaut mieux,\nlorsque c‚Äôest possible, directement lire la donn√©e\navec un lien HTTPS, ce que Pandas sait faire.\nDe plus, lorsqu‚Äôon travaille sur de l‚Äôopen data cela assure qu‚Äôon utilise la derni√®re donn√©e\ndisponible et non une duplication en local qui peut ne pas √™tre √† jour.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#lecture-depuis-un-csv-disponible-sur-internet",
    "href": "content/manipulation/02_pandas_intro.html#lecture-depuis-un-csv-disponible-sur-internet",
    "title": "Introduction √† Pandas",
    "section": "4.2 Lecture depuis un CSV disponible sur internet",
    "text": "4.2 Lecture depuis un CSV disponible sur internet\nL‚ÄôURL d‚Äôacc√®s aux donn√©es peut √™tre conserv√© dans une variable ad hoc :\n\nurl = \"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\"\n\nL‚Äôobjectif du prochain exercice est de se familiariser √† l‚Äôimport et l‚Äôaffichage de donn√©es\navec Pandas et √† l‚Äôaffichage de quelques observations.\n\n\n Exercice 1: Importer un CSV et explorer la structure de donn√©es\n\nImporter les donn√©es de l‚ÄôAdeme √† l‚Äôaide du package Pandas et de la commande consacr√©e pour l‚Äôimport de csv. Nommer le DataFrame obtenu emissions4.\nUtiliser les m√©thodes ad√©quates afin d‚Äôafficher pour les 10 premi√®res valeurs, les 15 derni√®res et un √©chantillon al√©atoire de 10 valeurs gr√¢ce aux m√©thodes ad√©quates du package Pandas.\nTirer 5 pourcents de l‚Äô√©chantillon sans remise.\nNe conserver que les 10 premi√®res lignes et tirer al√©atoirement dans celles-ci pour obtenir un DataFrame de 100 donn√©es.\nFaire 100 tirages √† partir des 6 premi√®res lignes avec une probabilit√© de 1/2 pour la premi√®re observation et une probabilit√© uniforme pour les autres.\n\n\n\nEn cas de blocage √† la question 1\n\nLire la documentation de read_csv (tr√®s bien faite) ou chercher des exemples\nen ligne pour d√©couvrir cette fonction.\n\n\n\nComme l‚Äôillustre cet exercice, l‚Äôaffichage des DataFrames dans les notebooks est assez ergonomique.\nLes premi√®res et derni√®res lignes s‚Äôaffichent\nautomatiquement. Pour des tables de valorisation pr√©sentes dans un\nrapport ou un article de recherche, le chapitre suivant\npr√©sente great_tables qui offre de tr√®s riches\nfonctionnalit√©s de mise en forme des tableaux.\n\n\n Warning\nIl faut faire attention au display et aux\ncommandes qui r√©v√®lent des donn√©es (head, tail, etc.)\ndans un notebook qui exploite\ndes donn√©es confidentielles lorsqu‚Äôon utilise\nle logiciel de contr√¥le de version Git (cf.¬†chapitres d√©di√©s).\nEn effet, on peut se\nretrouver √† partager des donn√©es, involontairement, dans l‚Äôhistorique\nGit. Comme cela sera expliqu√© dans le chapitre d√©di√© √† Git,\nun fichier, nomm√© le .gitignore, suffit pour cr√©er quelques r√®gles\n√©vitant le partage involontaire de donn√©es avec Git.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#dimensions-et-structure-dun-dataframe",
    "href": "content/manipulation/02_pandas_intro.html#dimensions-et-structure-dun-dataframe",
    "title": "Introduction √† Pandas",
    "section": "5.1 Dimensions et structure d‚Äôun DataFrame",
    "text": "5.1 Dimensions et structure d‚Äôun DataFrame\nLes premi√®res m√©thodes utiles permettent d‚Äôafficher quelques\nattributs d‚Äôun DataFrame.\n\ndf.axes\n\n[RangeIndex(start=0, stop=35798, step=1),\n Index(['INSEE commune', 'Commune', 'Agriculture', 'Autres transports',\n        'Autres transports international', 'CO2 biomasse hors-total', 'D√©chets',\n        'Energie', 'Industrie hors-√©nergie', 'R√©sidentiel', 'Routier',\n        'Tertiaire'],\n       dtype='object')]\n\n\n\ndf.columns\n\nIndex(['INSEE commune', 'Commune', 'Agriculture', 'Autres transports',\n       'Autres transports international', 'CO2 biomasse hors-total', 'D√©chets',\n       'Energie', 'Industrie hors-√©nergie', 'R√©sidentiel', 'Routier',\n       'Tertiaire'],\n      dtype='object')\n\n\n\ndf.index\n\nRangeIndex(start=0, stop=35798, step=1)\n\n\nPour conna√Ætre les dimensions d‚Äôun DataFrame, on peut utiliser quelques m√©thodes\npratiques :\n\ndf.ndim\n\n2\n\n\n\ndf.shape\n\n(35798, 12)\n\n\n\ndf.size\n\n429576\n\n\nPour d√©terminer le nombre de valeurs uniques d‚Äôune variable, plut√¥t que chercher √† √©crire soi-m√™me une fonction,\non utilise la\nm√©thode nunique. Par exemple,\n\ndf[\"Commune\"].nunique()\n\n33338\n\n\nPandas propose √©norm√©ment de m√©thodes utiles.\nVoici un premier r√©sum√© de celles relatives √† la structure des donn√©es, accompagn√© d‚Äôun comparatif avec R :\n\n\n\n\n\n\n\n\n\nOp√©ration\npandas\ndplyr (R)\ndata.table (R)\n\n\n\n\nR√©cup√©rer le nom des colonnes\ndf.columns\ncolnames(df)\ncolnames(df)\n\n\nR√©cup√©rer les dimensions\ndf.shape\ndim(df)\ndim(df)\n\n\nR√©cup√©rer le nombre de valeurs uniques d‚Äôune variable\ndf['myvar'].nunique()\ndf %&gt;%  summarise(distinct(myvar))\ndf[,uniqueN(myvar)]",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#acc√©der-√†-des-√©l√©ments-dun-dataframe",
    "href": "content/manipulation/02_pandas_intro.html#acc√©der-√†-des-√©l√©ments-dun-dataframe",
    "title": "Introduction √† Pandas",
    "section": "5.2 Acc√©der √† des √©l√©ments d‚Äôun DataFrame",
    "text": "5.2 Acc√©der √† des √©l√©ments d‚Äôun DataFrame\nEn SQL, effectuer des op√©rations sur les colonnes se fait avec la commande\nSELECT. Avec Pandas,\npour acc√©der √† une colonne dans son ensemble on peut\nutiliser plusieurs approches :\n\ndataframe.variable, par exemple df.Energie.\nCette m√©thode requiert n√©anmoins d‚Äôavoir des\nnoms de colonnes sans espace ou caract√®res sp√©ciaux, ce qui exclut\nsouvent des jeux de donn√©es r√©els. Elle n‚Äôest pas recommand√©e. ;\ndataframe[['variable']] pour renvoyer la variable sous\nforme de DataFrame. Cette m√©thode peut √™tre assez pi√©geuse pour une variable seule, il vaut mieux lui privil√©gier dataframe.loc[:,['variable']] qui est plus explicite sur la nature de l‚Äôobjet qu‚Äôon d√©sire en sortie ;\ndataframe['variable'] pour\nrenvoyer la variable sous forme de Series. Par exemple, df[['Autres transports']]\nou df['Autres transports']. C‚Äôest une mani√®re pr√©f√©rable de proc√©der.\n\nPour r√©cup√©rer plusieurs colonnes √† la fois, il y a deux approches, la seconde √©tant pr√©f√©rable :\n\ndataframe[['variable1', 'variable2']] ;\ndataframe.loc[:, ['variable1', 'variable2']]\n\nCela est √©quivalent √† SELECT variable1, variable2 FROM dataframe en SQL.\nLe .loc peut appara√Ætre excessivement verbeux. Il permet n√©anmoins de s‚Äôassurer qu‚Äôon effectue bien un subset sur la dimension des colonnes. Les DataFrame ayant deux indices, ceux des lignes et des colonnes, on peut avoir parfois des surprises avec l‚Äôimplicite, il est plus fiable d‚Äô√™tre explicite.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#acc√©der-√†-des-lignes",
    "href": "content/manipulation/02_pandas_intro.html#acc√©der-√†-des-lignes",
    "title": "Introduction √† Pandas",
    "section": "5.3 Acc√©der √† des lignes",
    "text": "5.3 Acc√©der √† des lignes\nPour acc√©der √† une ou plusieurs valeurs d‚Äôun DataFrame,\nil existe deux mani√®res conseill√©es de proc√©der, selon la\nforme des indices de lignes ou colonnes utilis√©es :\n\ndf.iloc : utilise les indices. C‚Äôest une m√©thode moyennement fiable car les indices d‚Äôun DataFrame peuvent √©voluer au cours d‚Äôun traitement (notamment lorsqu‚Äôon fait des op√©rations par groupe).\ndf.loc : utilise les labels. Cette m√©thode est recommand√©e.\n\n\n\n Warning\nLes bouts de code utilisant la structure df.ix\nsont √† bannir car la fonction est deprecated et peut\nainsi dispara√Ætre √† tout moment.\n\n\niloc va se r√©f√©rer √† l‚Äôindexation de 0 √† N o√π N est √©gal √† df.shape[0] d‚Äôun\npandas.DataFrame. loc va se r√©f√©rer aux valeurs de l‚Äôindex\nde df.\nPar exemple, avec le pandas.DataFrame df_example:\n\ndf_example = pd.DataFrame(\n    {\"month\": [1, 4, 7, 10], \"year\": [2012, 2014, 2013, 2014], \"sale\": [55, 40, 84, 31]}\n)\ndf_example = df_example.set_index(\"month\")\ndf_example\n\n\n\n\n\n\n\n\n\nyear\nsale\n\n\nmonth\n\n\n\n\n\n\n1\n2012\n55\n\n\n4\n2014\n40\n\n\n7\n2013\n84\n\n\n10\n2014\n31\n\n\n\n\n\n\n\n\n\ndf_example.loc[1, :] donnera la premi√®re ligne de df (ligne o√π l‚Äôindice month est √©gal √† 1) ;\ndf_example.iloc[1, :] donnera la deuxi√®me ligne (puisque l‚Äôindexation en Python commence √† 0) ;\ndf_example.iloc[:, 1] donnera la deuxi√®me colonne, suivant le m√™me principe.\n\nLes exercices ult√©rieurs permettront de pratiquer cette syntaxe sur notre jeu de donn√©es des √©missions de gaz carbonique.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#op√©rations-sur-les-colonnes-ajouter-ou-retirer-des-variables-les-renommer-etc.",
    "href": "content/manipulation/02_pandas_intro.html#op√©rations-sur-les-colonnes-ajouter-ou-retirer-des-variables-les-renommer-etc.",
    "title": "Introduction √† Pandas",
    "section": "6.1 Op√©rations sur les colonnes : ajouter ou retirer des variables, les renommer, etc.",
    "text": "6.1 Op√©rations sur les colonnes : ajouter ou retirer des variables, les renommer, etc.\nSur le plan technique, les DataFrames Pandas sont des objets mutables en langage Python,\nc‚Äôest-√†-dire qu‚Äôil est possible de faire √©voluer le DataFrame au gr√®s\ndes op√©rations mises en oeuvre.\nL‚Äôop√©ration la plus classique consiste √† ajouter ou retirer des variables √† la table de donn√©es.\nLa mani√®re la plus simple d‚Äôop√©rer pour ajouter des colonnes est\nd‚Äôutiliser la r√©assignation. Par exemple, pour cr√©er une variable dep qui correspond aux deux premiers num√©ros du code commune (code Insee), il suffit de prendre la variable et lui appliquer le traitement adapt√© (en l‚Äôoccurrence ne garder que ses deux premi√®res caract√®res):\n\ndf[\"dep\"] = df[\"INSEE commune\"].str[:2]\ndf.head(3)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n01\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n01\n\n\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n01\n\n\n\n\n\n\n\n\nEn SQL, la mani√®re de proc√©der d√©pend du moteur d‚Äôex√©cution. En pseudo-code cela donne\nSELECT everything(), SUBSTR(\"code_insee\", 2) AS dep FROM df\nIl est possible d‚Äôappliquer cette approche de cr√©ation de colonnes sur plusieurs colonnes. Un des\nint√©r√™ts de cette approche est qu‚Äôelle permet de recycler le nom de colonnes.\n\nvars = [\"Agriculture\", \"D√©chets\", \"Energie\"]\n\ndf[[v + \"_log\" for v in vars]] = np.log(df.loc[:, vars])\ndf.head(3)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\nAgriculture_log\nD√©chets_log\nEnergie_log\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n01\n8.219171\n4.619374\n0.856353\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n01\n6.164010\n4.946455\n0.856353\n\n\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n01\n6.212693\n8.578159\n6.906086\n\n\n\n\n\n\n\n\nLa requ√™te √©quivalente en SQL serait assez fastidieuse √† √©crire. Sur ce genre d‚Äôop√©rations, on voit bien l‚Äôint√©r√™t d‚Äôavoir une librairie haut niveau comme Pandas.\n\n\n Warning\nCela est possible gr√¢ce √† la vectorisation native des op√©rations de Numpy et √† la magie Pandas qui r√©arrange tout ceci. Ce n‚Äôest pas utilisable avec n‚Äôimporte quelle fonction. Pour d‚Äôautres fonctions, il faudra utiliser assign, g√©n√©ralement par le biais de lambda functions, des fonctions temporaires faisant office de passe plat. Par exemple, pour cr√©er une variable selon cette approche, il faudrait faire:\n\ndf.assign(Energie_log=lambda x: np.log(x[\"Energie\"]))\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nEnergie\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\nAgriculture_log\nD√©chets_log\nEnergie_log\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n01\n8.219171\n4.619374\n0.856353\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n01\n6.164010\n4.946455\n0.856353\n\n\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n01\n6.212693\n8.578159\n6.906086\n\n\n3\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n01\n7.527881\n5.376285\n4.545232\n\n\n4\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n01\n6.106949\n3.879532\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35793\n95676\nVILLERS-EN-ARTHIES\n1628.065094\nNaN\nNaN\n165.045396\n65.063617\n11.772789\n34.556067\n176.098160\n309.627908\n235.439109\n95\n7.395148\n4.175366\n2.465791\n\n\n35794\n95678\nVILLIERS-ADAM\n698.630772\nNaN\nNaN\n1331.126598\n111.480954\n2.354558\n6.911213\n1395.529811\n18759.370071\n403.404815\n95\n6.549122\n4.713854\n0.856353\n\n\n35795\n95680\nVILLIERS-LE-BEL\n107.564967\nNaN\nNaN\n8367.174532\n225.622903\n534.484607\n1568.845431\n22613.830247\n12217.122402\n13849.512001\n95\n4.678095\n5.418865\n6.281303\n\n\n35796\n95682\nVILLIERS-LE-SEC\n1090.890170\nNaN\nNaN\n326.748418\n108.969749\n2.354558\n6.911213\n67.235487\n4663.232127\n85.657725\n95\n6.994749\n4.691070\n0.856353\n\n\n35797\n95690\nWY-DIT-JOLI-VILLAGE\n1495.103542\nNaN\nNaN\n125.236417\n97.728612\n4.709115\n13.822427\n117.450851\n504.400972\n147.867245\n95\n7.309951\n4.582194\n1.549500\n\n\n\n\n35798 rows √ó 16 columns\n\n\n\n\nAvec des m√©thodes de Pandas ou de Numpy comme ici, cela n‚Äôa pas d‚Äôint√©r√™t, c‚Äôest m√™me contreproductif car cela ralentit le code.\n\n\nOn peut facilement renommer des variables avec la m√©thode rename qui\nfonctionne bien avec des dictionnaires. Pour renommer des colonnes il faut\npr√©ciser le param√®tre axis = 'columns' ou axis=1. Le param√®tre axis est souvent n√©cessaire car par d√©faut de nombreuses m√©thodes de Pandas supposent que l‚Äôindice sur lequel les op√©rations sont faites est l‚Äôindice des lignes :\n\ndf = df.rename({\"Energie\": \"eneg\", \"Agriculture\": \"agr\"}, axis=1)\ndf.head()\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nagr\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\neneg\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\nAgriculture_log\nD√©chets_log\nEnergie_log\n\n\n\n\n0\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n01\n8.219171\n4.619374\n0.856353\n\n\n1\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n01\n6.164010\n4.946455\n0.856353\n\n\n2\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n01\n6.212693\n8.578159\n6.906086\n\n\n3\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n01\n7.527881\n5.376285\n4.545232\n\n\n4\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n01\n6.106949\n3.879532\nNaN\n\n\n\n\n\n\n\n\nEnfin, pour effacer des colonnes, on utilise la m√©thode drop avec l‚Äôargument\ncolumns:\n\ndf = df.drop(columns=[\"eneg\", \"agr\"])",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#r√©ordonner-les-observations",
    "href": "content/manipulation/02_pandas_intro.html#r√©ordonner-les-observations",
    "title": "Introduction √† Pandas",
    "section": "6.2 R√©ordonner les observations",
    "text": "6.2 R√©ordonner les observations\nLa m√©thode sort_values permet de r√©ordonner les observations d‚Äôun DataFrame, en laissant l‚Äôordre des colonnes identiques.\nPar exemple,\nsi on d√©sire classer par ordre d√©croissant de consommation de CO2 du secteur\nr√©sidentiel, on fera\n\ndf = df.sort_values(\"R√©sidentiel\", ascending=False)\ndf.head(3)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\nAgriculture_log\nD√©chets_log\nEnergie_log\n\n\n\n\n12167\n31555\nTOULOUSE\n4482.980062\n130.792683\n576394.181208\n88863.732538\n277062.573234\n410675.902028\n586054.672836\n288175.400126\n31\n7.268255\n11.394859\n11.424640\n\n\n16774\n44109\nNANTES\n138738.544337\n250814.701179\n193478.248177\n18162.261628\n77897.138554\n354259.013785\n221068.632724\n173447.582779\n44\n5.513507\n9.807101\n9.767748\n\n\n27294\n67482\nSTRASBOURG\n124998.576639\n122266.944279\n253079.442156\n119203.251573\n135685.440035\n353586.424577\n279544.852332\n179562.761386\n67\n6.641974\n11.688585\n9.885411\n\n\n\n\n\n\n\n\nAinsi, en une ligne de code, on identifie les villes o√π le secteur\nr√©sidentiel consomme le plus. En SQL on ferait\nSELECT * FROM df ORDER BY DESC \"R√©sidentiel\"",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#filter",
    "href": "content/manipulation/02_pandas_intro.html#filter",
    "title": "Introduction √† Pandas",
    "section": "6.3 Filter",
    "text": "6.3 Filter\nL‚Äôop√©ration de s√©lection de lignes s‚Äôappelle FILTER en SQL. Elle s‚Äôutilise\nen fonction d‚Äôune condition logique (clause WHERE). On s√©lectionne les\ndonn√©es sur une condition logique.\nIl existe plusieurs m√©thodes en Pandas. La plus simple est d‚Äôutiliser les boolean mask, d√©j√† vus dans le chapitre\nnumpy.\nPar exemple, pour s√©lectionner les communes dans les Hauts-de-Seine, on\npeut commencer par utiliser le r√©sultat de la m√©thode str.startswith (qui renvoie\nTrue ou False) :\n\ndf[\"INSEE commune\"].str.startswith(\"92\")\n\n12167    False\n16774    False\n27294    False\n12729    False\n22834    False\n         ...  \n20742    False\n20817    False\n20861    False\n20898    False\n20957    False\nName: INSEE commune, Length: 35798, dtype: bool\n\n\nstr. est une m√©thode particuli√®re en Pandas qui permet de traiter chaque valeur d‚Äôun vecteur comme un string natif en Python sur lequel appliquer une m√©thode ult√©rieure (en l‚Äôoccurrence startswith).\nL‚Äôinstruction ci-dessus renvoie un vecteur de bool√©ens. Nous avons vu pr√©c√©demment que la m√©thode loc servait √† faire du subsetting sur l‚Äôindice des lignes comme des colonnes. Elle fonctionne avec des vecteurs bool√©ens. Dans ce cas, si on fait un subsetting sur la dimension ligne (resp. colonne), elle va renvoyer toutes les observations (resp. variable) qui\nsatisfont cette condition.\nAinsi, en mettant bout √† bout ces deux √©lements, on peut filter nos donn√©es pour n‚Äôavoir que les r√©sultats\ndu 92:\n\ndf.loc[df[\"INSEE commune\"].str.startswith(\"92\")].head(2)\n\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nD√©chets\nIndustrie hors-√©nergie\nR√©sidentiel\nRoutier\nTertiaire\ndep\nAgriculture_log\nD√©chets_log\nEnergie_log\n\n\n\n\n35494\n92012\nBOULOGNE-BILLANCOURT\n1250.483441\n34.234669\n51730.704250\n964.828694\n25882.493998\n92216.971456\n64985.280901\n60349.109482\n92\nNaN\n6.871951\n9.084530\n\n\n35501\n92025\nCOLOMBES\n411.371588\n14.220061\n53923.847088\n698.685861\n50244.664227\n87469.549463\n52070.927943\n41526.600867\n92\nNaN\n6.549201\n9.461557\n\n\n\n\n\n\n\n\nLe code SQL √©quivalent peu varier selon le moteur d‚Äôex√©cution (DuckDB, PostGre, MySQL) mais prendrait une forme similaire √† celle-ci:\nSELECT * FROM df WHERE STARTSWITH(\"INSEE commune\", \"92\")",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#r√©sum√©-des-principales-op√©rations",
    "href": "content/manipulation/02_pandas_intro.html#r√©sum√©-des-principales-op√©rations",
    "title": "Introduction √† Pandas",
    "section": "6.4 R√©sum√© des principales op√©rations",
    "text": "6.4 R√©sum√© des principales op√©rations\nLes principales manipulations sont les suivantes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR√©ordonner le DataFrame",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#comptages",
    "href": "content/manipulation/02_pandas_intro.html#comptages",
    "title": "Introduction √† Pandas",
    "section": "7.1 Comptages",
    "text": "7.1 Comptages\nLe premier type de statistiques qu‚Äôon peut vouloir mettre en oeuvre rel√®ve du comptage ou d√©nombrement des valeurs.\nSi on d√©sire, par exemple, conna√Ætre le nombre de communes dans notre jeu de donn√©es, on pourra utiliser la m√©thode count ou alors nunique si on s‚Äôint√©resse aux valeurs non dupliqu√©es.\n\ndf[\"Commune\"].count()\n\n35798\n\n\n\ndf[\"Commune\"].nunique()\n\n33338\n\n\nEn SQL, la premi√®re instruction serait SELECT COUNT(Commune) FROM df, la seconde SELECT COUNT DISTINCT Commune FROM df.\nIci, cela ne permet donc de comprendre qu‚Äôil peut y avoir des doublons dans la colonne Commune, ce dont il faudra tenir compte si on d√©sire identifier nos communes de mani√®re unique (ce sera un sujet lorsque le prochain chapitre abordera la question du croisement des donn√©es).\nLa coh√©rence de la syntaxe Pandas permet de faire cela pour plusieurs colonnes de mani√®re simultan√©e. En SQL cela serait possible mais le code √† mettre en oeuvre commence √† devenir assez verbeux:\n\ndf.loc[:, [\"Commune\", \"INSEE commune\"]].count()\n\nCommune          35798\nINSEE commune    35798\ndtype: int64\n\n\n\ndf.loc[:, [\"Commune\", \"INSEE commune\"]].nunique()\n\nCommune          33338\nINSEE commune    35798\ndtype: int64\n\n\nAvec ces deux commandes simples, on comprend donc\nque notre variable INSEE commune (le code Insee)\nsera plus fiable pour identifier des communes\nque les noms, qui ne sont pas forc√©ment uniques. C‚Äôest justement l‚Äôobjectif du code Insee de proposer\nun identifiant unique, a contrario du code postal qui peut\n√™tre partag√© par plusieurs communes.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#statistiques-agr√©g√©es",
    "href": "content/manipulation/02_pandas_intro.html#statistiques-agr√©g√©es",
    "title": "Introduction √† Pandas",
    "section": "7.2 Statistiques agr√©g√©es",
    "text": "7.2 Statistiques agr√©g√©es\nPandas embarque plusieurs m√©thodes pour construire des statistiques sur plusieurs colonnes: somme, moyenne, variance, etc.\nLes m√©thodes sont assez transparentes:\n\ndf[\"Agriculture\"].sum()\ndf[\"Agriculture\"].mean()\n\n2459.975759687974\n\n\nL√† encore, la coh√©rence de Pandas nous permet de g√©n√©raliser le calcul de statistiques √† plusieurs colonnes\n\ndf.loc[:, [\"Agriculture\", \"R√©sidentiel\"]].sum()\ndf.loc[:, [\"Agriculture\", \"R√©sidentiel\"]].mean()\n\nAgriculture    2459.975760\nR√©sidentiel    1783.677872\ndtype: float64\n\n\nIl est possible de g√©n√©raliser ceci √† toutes les colonnes.\nCependant, il est n√©cessaire d‚Äôintroduire le param√®tre numeric_only pour ne faire la t√¢che d‚Äôagr√©gation que sur les variables pertinentes\n\ndf.mean(numeric_only=True)\n\nAgriculture                        2459.975760\nAutres transports                   654.919940\nAutres transports international    7692.344960\nCO2 biomasse hors-total            1774.381550\nD√©chets                             410.806329\nEnergie                             662.569846\nIndustrie hors-√©nergie             2423.127789\nR√©sidentiel                        1783.677872\nRoutier                            3535.501245\nTertiaire                          1105.165915\ndtype: float64\n\n\n\n\n Warning\nLa version 2.0 de Pandas a introduit un changement\nde comportement dans les m√©thodes d‚Äôagr√©gation.\nIl est dor√©navant n√©cessaire de pr√©ciser quand on d√©sire\neffectuer des op√©rations si on d√©sire ou non le faire\nexclusivement sur les colonnes num√©riques. C‚Äôest pour cette\nraison qu‚Äôon explicite ici l‚Äôargument numeric_only = True.\nCe comportement\n√©tait par le pass√© implicite.\n\n\nLa m√©thode pratique √† conna√Ætre est agg. Celle-ci permet de d√©finir les statistiques qu‚Äôon d√©sire calculer pour chaque variable\n\ndf.agg(\n    {\n        \"Agriculture\": [\"sum\", \"mean\"],\n        \"R√©sidentiel\": [\"mean\", \"std\"],\n        \"Commune\": \"nunique\",\n    }\n)\n\n\n\n\n\n\n\n\n\nAgriculture\nR√©sidentiel\nCommune\n\n\n\n\nsum\n8.790969e+07\nNaN\nNaN\n\n\nmean\n2.459976e+03\n1783.677872\nNaN\n\n\nstd\nNaN\n8915.902379\nNaN\n\n\nnunique\nNaN\nNaN\n33338.0\n\n\n\n\n\n\n\n\nLa sortie des m√©thodes d‚Äôagr√©gation est une Serie index√©e (les m√©thodes du type df.sum()) ou directement un DataFrame (la m√©thode agg). Il est en g√©n√©ral plus pratique d‚Äôavoir un DataFrame qu‚Äôune Serie index√©e si on d√©sire retravailler le tableau pour en tirer des conclusions. Il est donc utile de transformer les sorties sous forme de Serie en DataFrame puis appliquer la m√©thode reset_index pour transformer l‚Äôindice en colonne. A partir de l√†, il sera possible de modifier le DataFrame pour rendre celui-ci plus lisible.\nPar exemple si on s‚Äôint√©resse √† la part de chaque secteur dans les √©missions totales, on pourra proc√©der en deux temps.\nD‚Äôabord on va cr√©er une observation par secteur repr√©sentant les √©missions totales de celui-ci:\n\n# Etape 1: cr√©ation d'un DataFrame propre\nemissions_totales = pd.DataFrame(\n    df.sum(numeric_only=True), columns=[\"emissions\"]\n).reset_index(names=\"secteur\")\nemissions_totales\n\n\n\n\n\n\n\n\n\nsecteur\nemissions\n\n\n\n\n0\nAgriculture\n8.790969e+07\n\n\n1\nAutres transports\n6.535446e+06\n\n\n2\nAutres transports international\n2.223857e+07\n\n\n3\nCO2 biomasse hors-total\n6.351931e+07\n\n\n4\nD√©chets\n1.470358e+07\n\n\n5\nEnergie\n2.285203e+07\n\n\n6\nIndustrie hors-√©nergie\n8.357368e+07\n\n\n7\nR√©sidentiel\n6.384140e+07\n\n\n8\nRoutier\n1.264932e+08\n\n\n9\nTertiaire\n3.956273e+07\n\n\n\n\n\n\n\n\nIl ne reste plus qu‚Äô√† travailler a minima le jeu de donn√©es afin d‚Äôavoir d√©j√† quelques conclusions int√©ressantes sur la structure des √©missions en France:\n\nemissions_totales[\"emissions (%)\"] = (\n    100 * emissions_totales[\"emissions\"] / emissions_totales[\"emissions\"].sum()\n)\n(emissions_totales.sort_values(\"emissions\", ascending=False).round())\n\n\n\n\n\n\n\n\n\nsecteur\nemissions\nemissions (%)\n\n\n\n\n8\nRoutier\n126493164.0\n24.0\n\n\n0\nAgriculture\n87909694.0\n17.0\n\n\n6\nIndustrie hors-√©nergie\n83573677.0\n16.0\n\n\n7\nR√©sidentiel\n63841398.0\n12.0\n\n\n3\nCO2 biomasse hors-total\n63519311.0\n12.0\n\n\n9\nTertiaire\n39562729.0\n7.0\n\n\n5\nEnergie\n22852034.0\n4.0\n\n\n2\nAutres transports international\n22238569.0\n4.0\n\n\n4\nD√©chets\n14703580.0\n3.0\n\n\n1\nAutres transports\n6535446.0\n1.0\n\n\n\n\n\n\n\n\nCe tableau n‚Äôest pas vraiment mis en forme donc encore loin d‚Äô√™tre communiquable mais il pr√©sente d√©j√† un int√©r√™t dans une perspective exploratoire. Il nous permet de comprendre les secteurs les plus √©metteurs, √† savoir le transport, l‚Äôagriculture et l‚Äôindustrie, hors √©nergie. Le fait que l‚Äô√©nergie soit relativement peu √©mettrice s‚Äôexplique bien du fait du mix √©nerg√©tique fran√ßais o√π le nucl√©aire repr√©sente une majorit√© de la production √©lectrique.\nPour aller plus loin dans la mise en forme de ce tableau afin d‚Äôavoir des statistiques communiquables en dehors de Python, nous d√©couvrirons au prochain chapitre great_tables.\n\n\n Note\nLa structure de donn√©es issue de df.sum est assez pratique (elle est tidy). On pourrait faire exactement la m√™me op√©ration que df.sum(numeric_only = True) avec le code suivant:\n\ndf.select_dtypes(include=\"number\").agg(func=sum)\n\n/tmp/ipykernel_1025/2580944462.py:1: FutureWarning:\n\nThe provided callable &lt;built-in function sum&gt; is currently using DataFrame.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n\n\n\nAgriculture                        8.790969e+07\nAutres transports                  6.535446e+06\nAutres transports international    2.223857e+07\nCO2 biomasse hors-total            6.351931e+07\nD√©chets                            1.470358e+07\nEnergie                            2.285203e+07\nIndustrie hors-√©nergie             8.357368e+07\nR√©sidentiel                        6.384140e+07\nRoutier                            1.264932e+08\nTertiaire                          3.956273e+07\ndtype: float64",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#valeurs-manquantes",
    "href": "content/manipulation/02_pandas_intro.html#valeurs-manquantes",
    "title": "Introduction √† Pandas",
    "section": "7.3 Valeurs manquantes",
    "text": "7.3 Valeurs manquantes\nJusqu‚Äô√† pr√©sent nous n‚Äôavons pas √©voqu√© ce qui pourrait √™tre un caillou dans la chaussure du data scientist, les valeurs manquantes.\nLes jeux de donn√©es r√©els sont rarement complets et les valeurs manquantes peuvent refl√©ter de nombreuses r√©alit√©s: probl√®me de remont√©e d‚Äôinformation, variable non pertinente pour cette observation‚Ä¶\nSur le plan technique, Pandas ne rencontre pas de probl√®me √† g√©rer les valeurs manquantes (sauf pour les variables int mais c‚Äôest une exception).\nPar d√©faut, les valeurs manquantes sont affich√©es NaN et sont de type np.nan (pour\nles valeurs temporelles, i.e.¬†de type datatime64, les valeurs manquantes sont\nNaT).\nOn a un comportement coh√©rent d‚Äôagr√©gation lorsqu‚Äôon combine deux colonnes dont l‚Äôune comporte des valeurs manquantes.\n\nventes = pd.DataFrame(\n    {\n        \"prix\": np.random.uniform(size=5),\n        \"client1\": [i + 1 for i in range(5)],\n        \"client2\": [i + 1 for i in range(4)] + [np.nan],\n        \"produit\": [np.nan] + [\"yaourt\", \"pates\", \"riz\", \"tomates\"],\n    }\n)\nventes\n\n\n\n\n\n\n\n\n\nprix\nclient1\nclient2\nproduit\n\n\n\n\n0\n0.846498\n1\n1.0\nNaN\n\n\n1\n0.688088\n2\n2.0\nyaourt\n\n\n2\n0.183628\n3\n3.0\npates\n\n\n3\n0.697141\n4\n4.0\nriz\n\n\n4\n0.260635\n5\nNaN\ntomates\n\n\n\n\n\n\n\n\nPandas va bien refuser de faire l‚Äôagr√©gation car pour lui une valeur manquante n‚Äôest pas un z√©ro:\n\nventes[\"client1\"] + ventes[\"client2\"]\n\n0    2.0\n1    4.0\n2    6.0\n3    8.0\n4    NaN\ndtype: float64\n\n\nIl est possible de supprimer les valeurs manquantes gr√¢ce √† dropna().\nCette m√©thode va supprimer toutes les lignes o√π il y a au moins une valeur manquante.\n\nventes.dropna()\n\n\n\n\n\n\n\n\n\nprix\nclient1\nclient2\nproduit\n\n\n\n\n1\n0.688088\n2\n2.0\nyaourt\n\n\n2\n0.183628\n3\n3.0\npates\n\n\n3\n0.697141\n4\n4.0\nriz\n\n\n\n\n\n\n\n\nEn l‚Äôoccurrence, on perd deux lignes. Il est aussi possible de supprimer seulement les colonnes o√π il y a des valeurs manquantes\ndans un DataFrame avec dropna() en utilisant le param√®tre subset.\n\nventes.dropna(subset=[\"produit\"])\n\n\n\n\n\n\n\n\n\nprix\nclient1\nclient2\nproduit\n\n\n\n\n1\n0.688088\n2\n2.0\nyaourt\n\n\n2\n0.183628\n3\n3.0\npates\n\n\n3\n0.697141\n4\n4.0\nriz\n\n\n4\n0.260635\n5\nNaN\ntomates\n\n\n\n\n\n\n\n\nCette fois on ne perd plus qu‚Äôune ligne, celle o√π produit est manquant.\nPandas donne la possibilit√© d‚Äôimputer les valeurs manquantes gr√¢ce √† la m√©thode fillna(). Par exemple, si on pense que les valeurs manquantes dans produit sont des valeurs nulles, on pourra faire\n\nventes.dropna(subset=[\"produit\"]).fillna(0)\n\n\n\n\n\n\n\n\n\nprix\nclient1\nclient2\nproduit\n\n\n\n\n1\n0.688088\n2\n2.0\nyaourt\n\n\n2\n0.183628\n3\n3.0\npates\n\n\n3\n0.697141\n4\n4.0\nriz\n\n\n4\n0.260635\n5\n0.0\ntomates\n\n\n\n\n\n\n\n\nSi on d√©sire faire une imputation √† la m√©diane pour la variable client2, on changera marginalement ce code\nen encapsulant √† l‚Äôint√©rieur le calcul de la m√©diane\n\n(ventes[\"client2\"].fillna(ventes[\"client2\"].median()))\n\n0    1.0\n1    2.0\n2    3.0\n3    4.0\n4    2.5\nName: client2, dtype: float64\n\n\nSur des jeux de donn√©es du monde r√©el, il est utile d‚Äôutiliser la m√©thode isna (ou isnull) combin√©es avec sum ou mean pour conna√Ætre l‚Äôampleur des valeurs manquantes dans un jeu de donn√©es.\n\ndf.isnull().mean().sort_values(ascending=False)\n\nAutres transports international    0.919241\nAutres transports                  0.721241\nEnergie                            0.036538\nIndustrie hors-√©nergie             0.036538\nAgriculture                        0.001732\nRoutier                            0.000559\nD√©chets                            0.000168\nR√©sidentiel                        0.000168\nINSEE commune                      0.000000\nCommune                            0.000000\nCO2 biomasse hors-total            0.000000\nTertiaire                          0.000000\ndtype: float64\n\n\nCette √©tape pr√©paratoire est utile pour anticiper la question de l‚Äôimputation ou du filtre sur les valeurs manquantes: sont-elles missing at random ou refl√®tent-elles un sujet sur la remont√©e des donn√©es ? Les choix relatifs au traitement des valeurs manquantes ne sont pas des choix m√©thodologiques neutres. Pandas donne les outils techniques\npour faire ceci mais la question de la l√©gitimit√© de ces choix et de la pertinence est propre √† chaque donn√©e. Les explorations sur les donn√©es visent √† d√©tecter des indices pour faire un choix √©clair√©.",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#informations-additionnelles",
    "href": "content/manipulation/02_pandas_intro.html#informations-additionnelles",
    "title": "Introduction √† Pandas",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n91bfa52\n\n\n2024-05-27 15:01:32\n\n\nLino Galiana\n\n\nRestructuration partie geopandas (#500)\n\n\n\n\ne0d615e\n\n\n2024-05-03 11:15:29\n\n\nLino Galiana\n\n\nRestructure la partie Pandas (#497)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nStructuration d‚Äôun DataFrame Pandas,\nemprunt√©e √† https://medium.com/epfl-extension-school/selecting-data-from-a-pandas-dataframe-53917dc39953\nIllustration du concept de tidy data (emprunt√© √† H. Wickham)\nR√©ordonner le DataFrame",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/02_pandas_intro.html#footnotes",
    "href": "content/manipulation/02_pandas_intro.html#footnotes",
    "title": "Introduction √† Pandas",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nL‚Äô√©cosyst√®me √©quivalent en R, le tidyverse, d√©velopp√©\npar Posit, est de conception plus r√©cente que Pandas. Sa philosophie\na ainsi pu s‚Äôinspirer de celle de Pandas tout en pouvant rem√©dier √† quelques limites\nde la syntaxe Pandas. Les deux syntaxes √©tant une mise en oeuvre en Python ou R\nde la philosophie SQL, il est naturel qu‚Äôelles se ressemblent beaucoup et\nqu‚Äôil soit pertinent pour les data scientists de conna√Ætre les deux langages.‚Ü©Ô∏é\nA vrai dire, ce n‚Äôest pas l‚Äôempreinte carbone\nmais l‚Äôinventaire national\npuisque la base de donn√©es correspond √† une vision production,\npas consommation. Les √©missions faites dans une commune pour satisfaire\nla consommation d‚Äôune autre seront imput√©es √† la premi√®re l√†\no√π le concept d‚Äôempreinte carbone voudrait qu‚Äôon l‚Äôimpute\naux secondes. De plus, les √©missions pr√©sent√©es ici ne comportent pas\nles √©missions produites par des biais produits √† l‚Äô√©tranger. Il ne s‚Äôagit pas, avec cet exercice, de construire une\nstatistique fiable mais plut√¥t de comprendre la logique de\nl‚Äôassociation de donn√©es pour construire des statistiques descriptives.‚Ü©Ô∏é\nL‚Äôobjectif originel de Pandas est de fournir une librairie haut-niveau vers des couches basses plus abstraites que sont les array Numpy. Pandas est progressivement en train de changer ces couches basses pour privil√©gier Arrow √† Numpy\nsans d√©stabiliser les commandes haut-niveau auxquelles les utilisateurs de Pandas sont habitu√©s. Ce changement s‚Äôexplique par le fait qu‚ÄôArrow, une librairie bas niveau de calcul, est plus puissante et plus flexible que Numpy. Cette derni√®re, par exemple, propose des types textuels limit√©s l√† o√π Arrow offre une plus grande libert√©.‚Ü©Ô∏é\nPar manque d‚Äôimagination, on est souvent tent√© d‚Äôappeler notre\ndataframe principal df ou data. C‚Äôest souvent une mauvaise id√©e puisque\nce nom n‚Äôest pas tr√®s informatif quand on relit le code quelques semaines\nplus tard. L‚Äôautodocumentation, approche qui consiste √† avoir un code\nqui se comprend de lui-m√™me, est une bonne pratique et il est donc recommand√©\nde donner un nom simple mais efficace pour conna√Ætre la nature du dataset en question.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction √† Pandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html",
    "href": "content/manipulation/03_geopandas_intro.html",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#quelle-diff√©rence-avec-des-donn√©es-traditionnelles",
    "href": "content/manipulation/03_geopandas_intro.html#quelle-diff√©rence-avec-des-donn√©es-traditionnelles",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "1.1 Quelle diff√©rence avec des donn√©es traditionnelles ?",
    "text": "1.1 Quelle diff√©rence avec des donn√©es traditionnelles ?\nLes chapitres pr√©c√©dents ont permis de d√©couvrir la mani√®re\ndont des donn√©es structur√©es peuvent √™tre valoris√©es\ngr√¢ce √† la librairie Pandas. Nous allons maintenant d√©couvrir l‚Äôanalyse\nde donn√©es plus complexes, √† savoir les donn√©es spatiales.\nCes\nderni√®res sont une sophistication des donn√©es tabulaires puisqu‚Äôen plus\nde partager les propri√©t√©s de celles-ci (donn√©es aplaties dans une structure de colonnes et de lignes), elles comportent une dimension g√©ographique suppl√©mentaire. Celle-ci est plus ou moins complexe selon la nature des donn√©es: cela peut √™tre des points (coordonn√©es de localisation en deux dimensions), des lignes (une suite de points), des lignes directionnelles (la m√™me structure pr√©c√©demment mais avec une direction), des polygones (un ensemble de points)‚Ä¶ Cette diversit√© des objets g√©ographiques vise √† permettre des syst√®mes d‚Äôinformation et de repr√©sentation de nombreux objets g√©ographiques.\nPar la suite, nous entendrons par ‚Äúdonn√©es spatiales‚Äù l‚Äôensemble des donn√©es qui portent sur les caract√©ristiques g√©ographiques des objets (localisation, contours, liens).\nLes caract√©ristiques g√©ographiques des objets sont d√©crites √† l‚Äôaide d‚Äôun syst√®me de coordonn√©es. Celles-ci\npermettent de repr√©senter l‚Äôobjet g√©ographique dans un espace euclidien √† deux dimensions \\((x,y)\\).\nLe passage de l‚Äôespace r√©el (la Terre, qui est une sph√®re en trois dimensions) √† l‚Äôespace plan\nse fait gr√¢ce √† un syst√®me de projection.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#structure-des-donn√©es-spatiales",
    "href": "content/manipulation/03_geopandas_intro.html#structure-des-donn√©es-spatiales",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "1.2 Structure des donn√©es spatiales",
    "text": "1.2 Structure des donn√©es spatiales\nLes donn√©es spatiales rassemblent classiquement deux types de donn√©es :\n\ndes donn√©es g√©ographiques (ou g√©om√©tries) : objets g√©om√©triques tels que des points, des vecteurs, des polygones, ou des maillages (raster). Exemple: la forme de chaque commune, les coordonn√©es d‚Äôun b√¢timent;\ndes donn√©es attributaires (ou attributs) : des mesures et des caract√©ristiques associ√©es aux objets g√©om√©triques. Exemple: la population de chaque commune, le nombre de fen√™tres et le nombre d‚Äô√©tages d‚Äôun b√¢timent.\n\nLes donn√©es spatiales sont fr√©quemment trait√©es √† l‚Äôaide d‚Äôun syst√®me d‚Äôinformation g√©ographique (SIG), c‚Äôest-√†-dire un syst√®me d‚Äôinformation capable de stocker, d‚Äôorganiser et de pr√©senter des donn√©es alphanum√©riques spatialement r√©f√©renc√©es par des coordonn√©es dans un syst√®me de r√©f√©rence (CRS). Python dispose de fonctionnalit√©s lui permettant de r√©aliser les m√™mes t√¢ches qu‚Äôun SIG (traitement de donn√©es spatiales, repr√©sentations cartographiques).",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#les-donn√©es-spatiales-sont-incontournables",
    "href": "content/manipulation/03_geopandas_intro.html#les-donn√©es-spatiales-sont-incontournables",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "1.3 Les donn√©es spatiales sont incontournables",
    "text": "1.3 Les donn√©es spatiales sont incontournables\nD‚Äôun usage initialement essentiellement militaire ou administratif, la production cartographique est, depuis au moins le XIXe si√®cle, tr√®s fr√©quente\npour repr√©senter de l‚Äôinformation socio√©conomique. La repr√©sentation la plus connue dans ce domaine\nest la carte par aplat de couleur, dite carte choropl√®the1.\nD‚Äôapr√®s Chen et al. (2008), la premi√®re repr√©sentation de ce type\na √©t√© propos√©e par Charles Dupin en 1926\npour repr√©senter les niveaux d‚Äôinstruction sur le territoire fran√ßais.\nL‚Äô√©mergence des cartes choropl√®thes est en effet indissociable\nde l‚Äôorganisation du pouvoir sous forme d‚Äôentit√©s pens√©es\npolitiques suppos√©es unitaires:\nles cartes du monde repr√©sentent souvent des aplats de couleurs √† partir\ndes nations, les cartes nationales √† partir d‚Äô√©chelons administratifs\n(r√©gions, d√©partements, communes, mais aussi Etats ou landers).\n.\nSi la production d‚Äôinformation g√©ographique a pu √™tre tr√®s li√©e √† un usage militaire puis √† la gestion administrative d‚Äôun territoire, la\nnum√©risation de l‚Äô√©conomie ayant d√©multipli√©e les acteurs concern√©s par la collecte et la mise √† disposition de donn√©es g√©ographique, la manipulation et la repr√©sentation de donn√©es spatiales n‚Äôest plus l‚Äôapanage des g√©ographes et g√©omaticiens. Les data scientists doivent √™tre capables de rapidement explorer la structure d‚Äôun jeu de donn√©es g√©ographique comme ils le feraient d‚Äôun jeu de donn√©es tabulaires classiques.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#o√π-trouver-la-donn√©e-spatiale-fran√ßaise",
    "href": "content/manipulation/03_geopandas_intro.html#o√π-trouver-la-donn√©e-spatiale-fran√ßaise",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "1.4 O√π trouver la donn√©e spatiale fran√ßaise ?",
    "text": "1.4 O√π trouver la donn√©e spatiale fran√ßaise ?\nLors de notre p√©riple de d√©couverte de Pandas,\nnous avons d√©j√† rencontr√© quelques sources g√©olocalis√©es,\nnotamment produites par l‚ÄôInsee. Cette institution publie\nde nombreuses statistiques locales, par exemple les donn√©es\nFilosofi que nous avons rencontr√©es au chapitre pr√©c√©dent. Au-del√†\nde l‚ÄôInsee, l‚Äôensemble des institutions du syst√®me\nstatistique public (Insee et services statistiques minist√©riels)\npublie de nombreuses sources de donn√©es agr√©g√©es √† diff√©rentes\nmailles g√©ographiques: √† un niveau infracommunal (par exemple par carreaux de 200m),\nau niveau communal ou √† des niveaux supracommunaux (zonages administratifs ou zonages d‚Äô√©tudes).\nPlus g√©n√©ralement, de nombreuses administrations fran√ßaises hors\ndu syst√®me statistique public diffusent des donn√©es\ng√©ographiques sur data.gouv. Nous avons par exemple pr√©c√©demment exploit√© un jeu de donn√©es de l‚ÄôAdeme dont la dimension g√©ographique √©tait la commune.\nL‚Äôacteur central de l‚Äô√©cosyst√®me public de la donn√©e g√©ographique est l‚ÄôIGN. Bien connu des amateurs de randonn√©es pour ses cartes ‚ÄúTop 25‚Äù qui peuvent √™tre retrouv√©es sur le geoportail, l‚ÄôIGN est √©galement en charge de la cartographie des limites l√©gales des entit√©s administratives fran√ßaises (base AdminExpress), des for√™ts (BDFor√™t), des routes (BDRoute), des b√¢timents (BDTopo), etc. Nous avons succinctement √©voqu√© la librairie cartiflette lors du chapitre pr√©c√©dent, qui permet de r√©cup√©rer les fonds de carte administratifs (base AdminExpress) de mani√®re flexible avec Python ; nous irons plus loin dans ce chapitre.\nLa puissance publique n‚Äôest plus l‚Äôunique acteur qui produit et diffuse de la donn√©e spatiale. La collecte de coordonn√©es GPS √©tant devenue presque automatique, de nombreux acteurs collectent, exploitent et m√™me revendent de la donn√©e spatiale sur leurs utilisateurs. Ces donn√©es peuvent √™tre tr√®s pr√©cises et tr√®s riches sur certaines probl√©matiques, par exemple sur les d√©placements. Il est n√©anmoins n√©cessaire d‚Äôavoir √† l‚Äôesprit lorsqu‚Äôon d√©sire\nextrapoler des statistiques construites sur ces donn√©es que celles-ci concernent les utilisateurs du service en question, qui ne sont pas n√©cessairement repr√©sentatifs des comportements de la population dans son ensemble.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#donn√©es-utilis√©es-dans-ce-chapitre",
    "href": "content/manipulation/03_geopandas_intro.html#donn√©es-utilis√©es-dans-ce-chapitre",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "1.5 Donn√©es utilis√©es dans ce chapitre",
    "text": "1.5 Donn√©es utilis√©es dans ce chapitre\nDans ce tutoriel, nous allons utiliser les donn√©es suivantes :\n\nLocalisations des stations velib ;\nfonds de carte AdminExpress √†\ntravers un package Python nomm√© cartiflette\nfacilitant la r√©cup√©ration de cette source.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#installations-pr√©alables",
    "href": "content/manipulation/03_geopandas_intro.html#installations-pr√©alables",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "1.6 Installations pr√©alables",
    "text": "1.6 Installations pr√©alables\n\n# √† faire obligatoirement en premier pour utiliser rtree ou pygeos pour les jointures spatiales\n!pip install pandas fiona shapely pyproj rtree \n!pip install contextily\n!pip install geopandas\n!pip install topojson\n\nPour √™tre en mesure d‚Äôex√©cuter ce tutoriel, les imports suivants\nseront utiles.\n\nimport geopandas as gpd\nimport contextily as ctx\nimport matplotlib.pyplot as plt\n\n\n\n Note\nLe package cartiflette est exp√©rimental\net n‚Äôest disponible que sur\nGithub, pas sur PyPi.\nIl est amen√© √† √©voluer rapidement et cette page sera mise √† jour\nquand de nouvelles fonctionalit√©s (notamment l‚Äôutilisation d‚ÄôAPI)\nseront disponibles pour encore simplifier la r√©cup√©ration de\ncontours g√©ographiques.\n\n\nPour installer cartiflette, il est n√©cessaire d‚Äôutiliser les commandes suivantes\ndepuis un Jupyter Notebook (si vous utilisez la ligne de commande directement,\nvous pouvez retirer les ! en d√©but de ligne):\n\n!pip install py7zr geopandas openpyxl tqdm s3fs\n!pip install PyYAML xlrd\n!pip install git+https://github.com/inseefrlab/cartiflette",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#anatomie-dun-objet-geopandas",
    "href": "content/manipulation/03_geopandas_intro.html#anatomie-dun-objet-geopandas",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "2.1 Anatomie d‚Äôun objet GeoPandas",
    "text": "2.1 Anatomie d‚Äôun objet GeoPandas\nEn r√©sum√©, un objet GeoPandas comporte les √©l√©ments suivants :\n\n\nLes attributs. Ce sont les valeurs associ√©es √† chaque niveau g√©ographique.\nIl s‚Äôagit de la dimension tabulaire usuelle, dont le traitement est similaire\n√† celui d‚Äôun objet Pandas classique.\nLes g√©om√©tries. Ce sont les valeurs num√©riques interpr√©t√©es pour repr√©senter la dimension g√©ographique. Elles permettent de repr√©senter dans un certain\nr√©f√©rentiel (le syst√®me de r√©f√©rence) la dimension g√©ographique.\nLe syst√®me de r√©f√©rence. Il s‚Äôagit du syst√®me permettant de transformer les positions sur\nle globe (3 dimensions avec une boule asym√©trique) en un plan en deux dimensions.\nIl en existe une multitude, identifiables √† partir d‚Äôun code EPSG (4326, 2154‚Ä¶).\nLeur manipulation est facilit√©e par Geopandas qui s‚Äôappuie sur Shapely, de la m√™me\nmani√®re que Pandas s‚Äôappuie sur Numpy ou Arrow.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#objectifs-de-ce-chapitre",
    "href": "content/manipulation/03_geopandas_intro.html#objectifs-de-ce-chapitre",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "2.2 Objectifs de ce chapitre",
    "text": "2.2 Objectifs de ce chapitre\nCe chapitre illustre √† partir d‚Äôexemples pratiques certains principes centraux de l‚Äôanalyse de donn√©es :\n\nManipulations sur les attributs des jeux de donn√©es ;\nManipulations g√©om√©triques ;\nGestion des projections cartographiques ;\nCr√©ation rapide de cartes (ce sera approfondi dans un prochain chapitre).\n\n\n\n Note\nSi vous √™tes int√©ress√©s par R et le package sf,\nune version tr√®s proche de ce TP est\ndisponible dans ce cours.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#le-format-shapefile-.shp-et-le-geopackage-.gpkg",
    "href": "content/manipulation/03_geopandas_intro.html#le-format-shapefile-.shp-et-le-geopackage-.gpkg",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "3.1 Le format shapefile (.shp) et le geopackage (.gpkg)",
    "text": "3.1 Le format shapefile (.shp) et le geopackage (.gpkg)\nLe format historique de stockage de donn√©es spatiales est le shapefile. Il s‚Äôagit d‚Äôun format propri√©taire, d√©velopp√© par ESRI, qui est n√©anmoins devenu une norme de facto. Dans ce format, la donn√©e est stock√©e dans plusieurs fichiers:\n\ndata.shp : contient les g√©om√©tries des entit√©s spatiales (points, lignes, polygones‚Ä¶).\ndata.shx : un index pour acc√©der rapidement aux g√©om√©tries stock√©es dans le fichier .shp.\ndata.dbf : une table attributaire au format dBase qui contient les informations descriptives des entit√©s spatiales.\ndata.prj : contient les informations de projection et de syst√®me de coordonn√©es (nous reviendrons sur ce concept ult√©rieurement).\n\nCe format pr√©sente plusieurs inconv√©nients. Tout d‚Äôabord il est assez volumineux ; certains formats modernes seront plus optimis√©s pour r√©duire la volum√©trie sur disque et le temps de chargement des donn√©es. Surtout, le probl√®me principal du shapefile est que pour lire les donn√©es de mani√®re int√®gre, il est n√©cessaire de partager de mani√®re syst√©matique ces quatre fichiers, sous peine d‚Äôintroduire un risque de corruption ou d‚Äôincompl√©tude de la donn√©e. En faisant gpd.read_file(\"data.shp\"), GeoPandas\nfait lui-m√™me le lien entre les observations et leur repr√©sentation spatiale qui sont pr√©sents dans plusieurs fichiers.\nLe format GeoPackage est un h√©ritier spirituel du shapefile visant √† r√©soudre ces deux limites. Il s‚Äôagit d‚Äôun format libre recommand√© par l‚Äôopen geospatial consortium (OGC). Les g√©omaticiens appr√©cient ce format, il s‚Äôagit d‚Äôailleurs du format par d√©faut de QGIS, le logiciel sp√©cialis√© pour les SIG. N√©anmoins, m√™me si GeoPandas fonctionne bien avec ce format, celui-ci est moins connu par les data scientists que le shapefile ou que le geojson que nous allons d√©crire par la suite.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#le-geojson-et-le-topojson",
    "href": "content/manipulation/03_geopandas_intro.html#le-geojson-et-le-topojson",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "3.2 Le GeoJSON et le TopoJSON",
    "text": "3.2 Le GeoJSON et le TopoJSON\nLe d√©veloppement d‚Äôun format concurrent l‚Äôh√©g√©monie du shapefile est intrins√®quement li√© √† l‚Äô√©mergence des technologies web dans le secteur de la cartographie. Ces technologies web s‚Äôappuient sur Javascript et reposent sur les standards du format JSON.\nLe format GeoJSON stocke dans un seul fichier √† la fois les attributs et les g√©om√©tries. Il est donc assez pratique √† l‚Äôusage et s‚Äôest impos√© comme le format pr√©f√©r√© des d√©veloppeurs web. Le fait de stocker l‚Äôensemble de l‚Äôinformation dans un seul fichier peut cependant le rendre assez volumineux si les g√©om√©tries sont tr√®s pr√©cises, mais le volume reste moindre que celui du shapefile. GeoPandas est tr√®s bien fait pour lire des fichiers au format GeoJSON et les plateformes de partage de donn√©es, comme data.gouv privil√©gient ce format √† celui du shapefile.\nPour all√©ger le fichier, le format TopoJSON a r√©c√©mment √©merg√©. Celui-ci est construit selon les m√™mes principes que le GeoJSON mais r√©duit le volume de donn√©es g√©om√©triques stock√©es en ne conservant pas tous les points en appliquant une simplification pour ne conserver que les arcs et les directions entre ceux-ci. Ce format √©tant r√©cent, il n‚Äôest pas encore bien int√©gr√© √† l‚Äô√©cosyst√®me Python.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#les-autres-formats-de-donn√©es",
    "href": "content/manipulation/03_geopandas_intro.html#les-autres-formats-de-donn√©es",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "3.3 Les autres formats de donn√©es",
    "text": "3.3 Les autres formats de donn√©es\nL‚Äô√©cosyst√®me des formats de donn√©es g√©ographiques est bien plus √©clat√© que celui des donn√©es structur√©es. Chaque format pr√©sente des avantages qui le rendent int√©ressant pour un type de donn√©es mais des limites qui l‚Äôemp√™chent de devenir un standard pour d‚Äôautres types de donn√©es.\nPar exemple, les donn√©es GPS extraites de diverses applications (par exemple Strava) sont stock√©es au format GPX. Ce dernier est particuli√®rement adapt√© pour des traces g√©olocalis√©es avec une altitude. Mais ce n‚Äôest pas le format le plus appropri√© pour stocker des lignes directionnelles, un pr√©requis indispensable pour les applications d‚Äôitin√©raires.\nLes formats shapefile et geojson sont suffisamment mall√©ables pour s‚Äôadapter aux diff√©rents types de donn√©es g√©ographiques m√™me s‚Äôil ne s‚Äôagit\npas du format optimal pour tel ou tel type de donn√©es. Dans cette classe g√©n√©raliste de formats, le Geoparquet pourrait √™tre le prochain format √† la mode. Comme son nom l‚Äôindique, il s‚Äôagit d‚Äôune extension du format Parquet √† des donn√©es g√©ographiques. Ce format n‚Äôest pas encore m√ªr mais reste √† suivre, la masse d‚Äôutilisateurs de l‚Äô√©cosyst√®me Parquet pouvant amener √† un changement rapide si une impl√©mentation stable de Geoparquet √©merge.\nCette page compare plus en d√©tail les principes formats de donn√©es g√©ographiques.\nL‚Äôaide de Geopandas propose des bouts de code en fonction des diff√©rentes situations dans lesquelles on se trouve.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#exercice-de-d√©couverte",
    "href": "content/manipulation/03_geopandas_intro.html#exercice-de-d√©couverte",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "3.4 Exercice de d√©couverte",
    "text": "3.4 Exercice de d√©couverte\nL‚Äôobjectif de cet exercice est d‚Äôillustrer la similarit√© des objets\nGeoPandas avec les objets Pandas que nous avons d√©couverts pr√©c√©demment.\nNous allons importer directement les donn√©es AdminExpress (limites officielles des communes produites par l‚ÄôIGN) avec cartiflette:\n\nfrom cartiflette import carti_download\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed\n\n\n\n\n Exercice 1: d√©couverte des objets g√©ographiques\nEn premier lieu, on r√©cup√®re des donn√©es g√©ographiques gr√¢ce\nau package cartiflette et √† sa fonction carti_download.\n\nUtiliser\nle code ci-dessous pour\nt√©l√©charger les donn√©es communales (produit Admin Express de l‚ÄôIGN)\ndes d√©partements de la petite couronne (75, 92, 93 et 94)\nde mani√®re simplifi√©e gr√¢ce au package\ncartiflette:\n\n\ncommunes_borders = carti_download(\n    crs=4326,\n    values=[\"75\", \"92\", \"93\", \"94\"],\n    borders=\"COMMUNE\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"DEPARTEMENT\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\n\nRegarder les premi√®res lignes des donn√©es. Identifier la diff√©rence avec\nun dataframe standard.\nAfficher le syst√®me de projection (attribut crs) de communes_borders. Ce dernier contr√¥le la\ntransformation de l‚Äôespace tridimensionnel terrestre en une surface plane.\nUtiliser to_crs pour transformer les donn√©es en Lambert 93, le\nsyst√®me officiel (code EPSG 2154).\nAfficher les communes des Hauts de Seine (d√©partement 92) et utiliser la m√©thode\nplot\nNe conserver que Paris et r√©pr√©senter les fronti√®res sur une carte : quel est le probl√®me pour\nune analyse de Paris intramuros?\n\nOn remarque rapidement le probl√®me.\nOn ne dispose ainsi pas des limites des arrondissements parisiens, ce\nqui appauvrit grandement la carte de Paris.\n\nCette fois, utiliser l‚Äôargument borders=\"COMMUNE_ARRONDISSEMENT\" pour obtenir\nun fonds de carte consolid√© des communes avec les arrondissements dans les grandes villes.\nConvertir en Lambert 93.\n\n\n\nLa visualisation propos√©e √† la question permet de voir que notre DataFrame\ncomporte la colonne geometry qui contient les informations n√©cessaires pour conna√Ætre les contours communaux\n\n\n\n\n\n\n\n\n\nA la question 5, on remarque facilement le probl√®me pour Paris:\nil manque les limites des arrondissements.\nCela appauvrit grandement la carte de Paris.\n\n\n\n\n\n\n\n\n\nA l‚Äôissue de la question 6, on obtient la carte attendue pour\nParis intramuros:",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#principe",
    "href": "content/manipulation/03_geopandas_intro.html#principe",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "4.1 Principe",
    "text": "4.1 Principe\nLes donn√©es spatiales sont\nplus riches que les donn√©es traditionnelles car elles\nincluent, habituellement, des √©l√©ments suppl√©mentaires pour placer dans\nun espace cart√©sien les objets. Cette dimension suppl√©mentaire peut √™tre simple\n(un point comporte deux informations suppl√©mentaire: \\(x\\) et \\(y\\)) ou\nassez complexe (polygones, lignes avec direction, etc.).\nL‚Äôanalyse cartographique emprunte d√®s lors √† la g√©om√©trie\ndes concepts\npour repr√©senter des objets dans l‚Äôespace. Les projections\nsont au coeur de la gestion des donn√©es spatiales.\nCes derni√®res consistent √† transformer une position dans l‚Äôespace\nterrestre √† une position sur un plan. Il s‚Äôagit donc d‚Äôune op√©ration\nde projection d‚Äôun espace tri-dimensionnel dans un espace\n√† deux dimensions.\nCe post propose de riches √©l√©ments sur le\nsujet, notamment l‚Äôimage suivante qui montre bien le principe d‚Äôune projection :\n\n\n\nLes diff√©rents types de projection\n\n\nCette op√©ration n‚Äôest pas neutre. L‚Äôune des cons√©quences du\nth√©or√®me remarquable de Gauss\nest que la surface de la Terre ne peut √™tre cartographi√©e sans distortion.\nUne projection ne peut simultan√©ment conserver intactes les distances et les\nangles (i.e.¬†les positions).\nIl n‚Äôexiste ainsi pas de projection universellement meilleure, ce qui ouvre\nla porte √† la coexistence de nombreuses projections diff√©rentes, pens√©es\npour des t√¢ches diff√©rentes.\nUn mauvais syst√®me de repr√©sentation\nfausse l‚Äôappr√©ciation visuelle mais peut aussi entra√Æner des erreurs dans\nles calculs sur la dimension spatiale.\nLes syst√®mes de projection font l‚Äôobjet de standards internationaux et sont souvent d√©sign√©s par des codes dits codes EPSG. Ce site est un bon aide-m√©moire. Les plus fr√©quents, pour les utilisateurs fran√ßais, sont les suivants (plus d‚Äôinfos ici) :\n\n2154 : syst√®me de projection Lambert 93. Il s‚Äôagit du syst√®me de projection officiel. La plupart des donn√©es diffus√©es par l‚Äôadministration pour la m√©tropole sont disponibles dans ce syst√®me de projection.\n27572 : Lambert II √©tendu. Il s‚Äôagit de l‚Äôancien syst√®me de projection officiel. Les donn√©es spatiales anciennes peuvent √™tre dans ce format.\n4326 : WGS 84 ou syst√®me de pseudo-Mercator ou encore Web Mercator. Ce n‚Äôest en r√©alit√© pas un syst√®me de projection mais un syst√®me de coordonn√©es (longitude / latitude) qui permet simplement un rep√©rage angulaire sur l‚Äôellipso√Øde. Il est utilis√© pour les donn√©es GPS. Il s‚Äôagit du syst√®me le plus\nusuel, notamment quand on travaille avec des fonds de carte web.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#le-syst√®me-mercator",
    "href": "content/manipulation/03_geopandas_intro.html#le-syst√®me-mercator",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "4.2 Le syst√®me Mercator",
    "text": "4.2 Le syst√®me Mercator\nComme √©voqu√© plus haut, l‚Äôune des projections les plus connues est la\nprojection Web Mercator dite WGS84 (code EPSG 4326). Il\ns‚Äôagit d‚Äôune projection conservant intacte les angles, ce\nqui implique qu‚Äôelle alt√®re les distances. Celle-ci a en effet √©t√©\npens√©e, √† l‚Äôorigine, pour repr√©senter l‚Äôh√©misph√®re Nord. Plus\non s‚Äô√©loigne de celui-ci, plus les distances sont distordues. Cela\nam√®ne √† des distorsions bien\nconnues (le Groenland hypertrophi√©, l‚ÄôAfrique de taille r√©duite, l‚ÄôAntarctique d√©mesur√©‚Ä¶).\nEn revanche, la projection Mercator conserve intacte les positions.\nC‚Äôest cette propri√©t√© qui explique son utilisation dans les syst√®mes\nGPS et ainsi dans les fonds de carte de navigation du type Google Maps.\nIl s‚Äôagit d‚Äôune projection pens√©e d‚Äôabord pour la navigation, non pour la repr√©sentation d‚Äôinformations socio√©conomiques sur la terre. Cette projection est indissociable des grandes explorations de la Renaissance, comme le rappelle ce fil sur Twitter de Jules Grandin.\n\n\n\nExemple de reprojection de pays depuis le site thetruesize.com\n\n\n\n\n\n\n\n\nFigure¬†4.1: ‚ÄúDon‚Äôt trust the Mercator projection‚Äù sur Reddit\n\n\n\nObservez les variations significatives\nde proportions pour certains pays selon les projections\nchoisies:\n\nhtml`&lt;div&gt;${container_projection}&lt;/div&gt;`\n\n\n\n\n\n\n\ncontainer_projection = html`&lt;div class=\"container\"&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projection\"&gt;\n      &lt;div class=\"projection-label\"&gt;Choisir une projection&lt;/div&gt;\n      ${viewof projection}\n    &lt;/div&gt;\n  &lt;/div&gt;\n  &lt;div class=\"row\"&gt;\n    &lt;div class=\"projectedMap\"&gt;\n      ${projectedMap}\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\nviewof projection = projectionInput({\n  name: \"\",\n  value: \"Mercator\"\n})\n\n\n\n\n\n\n\nimport {projectionInput} from \"@fil/d3-projections\"\nimport {map} from \"@linogaliana/base-map\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprojectedMap = map(projection,\n                   {\n                     //svg: true,\n                     value: projection.options,\n                     width: width_projected_map,\n                     //height: 300,\n                     //rotate: [0, -90],\n                     //inertia: true,\n                     show_equator: true,\n                     background: \"#f1f0eb\"\n                     \n                     //show_structure: true\n                   })\n\n\n\n\n\n\n\nwidth_projected_map = screen.width/2\n\n\n\n\n\n\nPour aller plus loin, la carte interactive\nsuivante, construite par Nicolas Lambert, issue de\nce notebook Observable, illustre l‚Äôeffet\nd√©formant de la projection Mercator, et de quelques-unes autres,\nsur notre perception de la taille des pays.\n\n\nVoir la carte interactive\n\n\nhtml`&lt;div class=\"grid-container\"&gt;\n  &lt;div class=\"viewof-projection\"&gt;${viewof projectionBertin}&lt;/div&gt;\n  &lt;div class=\"viewof-mycountry\"&gt;${viewof mycountry}&lt;/div&gt;\n  &lt;div class=\"map-bertin\"&gt;${mapBertin}&lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\nimport {map as mapBertin, viewof projection as projectionBertin, viewof mycountry} from \"@neocartocnrs/impact-of-projections-on-areas\"\n\n\n\n\n\n\nIl existe en fait de nombreuses repr√©sentations possibles du monde, plus ou moins\nalambiqu√©es. Les projections sont tr√®s nombreuses et certaines peuvent avoir une forme suprenante.\nPar exemple,\nla projection de Spillhaus\npropose de centrer la vue sur les oc√©ans et non une terre. C‚Äôest pour\ncette raison qu‚Äôon parle parfois de monde tel que vu par les poissons\n√† son propos.\n\nhtml`&lt;div class=\"centered\"&gt;${spilhaus}&lt;/div&gt;`\n\n\n\n\n\n\n\nspilhaus = {\n  const width = 600;\n  const height = width;\n\n  const context = DOM.context2d(width, height);\n  const projection = d3.geoStereographic()\n    .rotate([95, 45])\n    .translate([width / 2, height / 2])\n    .scale(width / 10.1)\n    .center([30, -5])\n    .clipAngle(166);\n  const path = d3.geoPath(projection, context);\n\n  const land = topojson.feature(world, world.objects.land);\n\n  context.lineJoin = \"round\";\n  context.lineCap = \"round\";\n  context.fillStyle = \"#f2f1ed\";\n  context.fillRect(0, 0, width, height);\n\n  context.beginPath();\n  path({type: \"Sphere\"});\n  path(land);\n  context.lineWidth = 0.5;\n  context.stroke();\n  context.clip(\"evenodd\");\n\n  context.save();\n  context.beginPath();\n  path(land);\n  context.filter = \"blur(12px)\";\n  context.fillStyle = \"#006994\";\n  context.fill(\"evenodd\");\n  context.restore();\n  \n  context.beginPath();\n  path(d3.geoGraticule10());\n  context.globalAlpha = 0.2;\n  context.strokeStyle = \"#000\";\n  context.stroke();\n\n  return context.canvas;\n}\n\n\n\n\n\n\n\n//import {map as spilhausmap} with {height, width} from \"@d3/spilhaus-shoreline-map\"\nimport { world } from \"@d3/spilhaus-shoreline-map\"\n\n\n\n\n\n\n\n\n Astuce pour la France\nPour la France, dans le syst√®me WGS84 (4326) :\n\nLongitude (\\(x\\)) tourne autour de 0¬∞ (de -5.2 √† +9.6 pour √™tre plus pr√©cis)\nLa latitude (\\(y\\)) autour de 45 (entre +41.3 √† +51.1)\n\nDans le syst√®me Lambert 93 (2154) :\n\nCoordonn√©es \\(x\\): entre 100 000 et 1 300 000\nLa latitude (\\(y\\)): entre 6 000 000 et 7 200 000\n\nPlus de d√©tails",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#gestion-avec-geopandas",
    "href": "content/manipulation/03_geopandas_intro.html#gestion-avec-geopandas",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "4.3 Gestion avec GeoPandas",
    "text": "4.3 Gestion avec GeoPandas\nConcernant la gestion des projections avec GeoPandas,\nla documentation officielle est tr√®s bien\nfaite. Elle fournit notamment l‚Äôavertissement suivant qu‚Äôil est\nbon d‚Äôavoir en t√™te :\n\nBe aware that most of the time you don‚Äôt have to set a projection. Data loaded from a reputable source (using the geopandas.read_file() command) should always include projection information. You can see an objects current CRS through the GeoSeries.crs attribute.\nFrom time to time, however, you may get data that does not include a projection. In this situation, you have to set the CRS so geopandas knows how to interpret the coordinates.\n\n\n\n\nImage emprunt√©e √† XKCD https://xkcd.com/2256/ qu‚Äôon peut √©galement trouver sur https://blog.chrislansdown.com/2020/01/17/a-great-map-projection-joke/\n\n\nLes deux principales m√©thodes pour d√©finir le syst√®me de projection utilis√© sont :\n\ndf.set_crs : cette commande sert √† pr√©ciser quel est le syst√®me de projection utilis√©, c‚Äôest-√†-dire comment les coordonn√©es (x,y) sont reli√©es √† la surface terrestre. Cette commande ne doit pas √™tre utilis√©e pour transformer le syst√®me de coordonn√©es, seulement pour le d√©finir.\ndf.to_crs : cette commande sert √† projeter les points d‚Äôune g√©om√©trie dans une autre, c‚Äôest-√†-dire √† recalculer les coordonn√©es selon un autre syst√®me de projection.\n\nDans le cas particulier de production de carte avec un fond OpenStreetMaps ou une carte dynamique leaflet, il est n√©cessaire de d√©-projeter les donn√©es (par exemple √† partir du Lambert-93) pour atterrir dans le syst√®me non-projet√© WGS 84 (code EPSG 4326). Ce site d√©di√© aux projections g√©ographiques peut √™tre utile pour retrouver le syst√®me de projection d‚Äôun fichier o√π il n‚Äôest pas indiqu√©.\nLe prochain exercice permettra, avec quelques cas pathologiques, de se convaincre de l‚Äôimportance de d√©l√©guer le plus possible la gestion du syst√®me de projection √† GeoPandas. La question n‚Äôest pas que sur la pertinence de la repr√©sentation des objets g√©ographiques sur la carte. En effet, l‚Äôensemble des op√©rations g√©om√©triques (calculs d‚Äôaires, de distance, etc.) peut √™tre affect√© par les choix faits sur le syst√®me de projection.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#exercice-pour-comprendre-limportance-du-syst√®me-de-projection",
    "href": "content/manipulation/03_geopandas_intro.html#exercice-pour-comprendre-limportance-du-syst√®me-de-projection",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "4.4 Exercice pour comprendre l‚Äôimportance du syst√®me de projection",
    "text": "4.4 Exercice pour comprendre l‚Äôimportance du syst√®me de projection\nVoici un code utilisant encore\ncartiflette\npour r√©cup√©rer les fronti√®res fran√ßaises (d√©coup√©es par r√©gion):\n\nfrance = carti_download(\n    values=[\"France\"],\n    crs=4326,\n    borders=\"REGION\",\n    vectorfile_format=\"geojson\",\n    simplification=50,\n    filter_by=\"FRANCE_ENTIERE\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\nfrance = france.loc[france[\"INSEE_REG\"] &gt; 10]\n\n\n\n Exercice 2 : Les projections, repr√©sentations et approximations\n\nS‚Äôamuser √† repr√©senter les limites de la France avec plusieurs projections:\n\n\nMercator WGS84 (EPSG: 4326)\nProjection healpix (+proj=healpix +lon_0=0 +a=1)\nProjection pr√©vue pour Tahiti (EPSG: 3304)\nProjection Albers pr√©vue pour Etats-Unis (EPSG: 5070)\n\n\nCalculer la superficie en \\(km^2\\)\ndes r√©gions fran√ßaises dans les deux syst√®mes de projection suivants :\nWorld Mercator WGS84 (EPSG: 3395) et Lambert 93 (EPSG: 2154). Calculer la diff√©rence en \\(km^2\\)\npour chaque r√©gion.\n\n\n\nAvec la question 1 illustrant quelques cas pathologiques,\non comprend que les projections ont un effet d√©formant\nqui se voit bien lorsqu‚Äôon les repr√©sente c√¥te √† c√¥te sous\nforme de cartes :\n\n\n\n\n\n\n\n\n\n\n\n(a) Mercator WGS84 (EPSG: 4326)\n\n\n\n\n\n\n\n\n\n\n\n(b) Projection healpix (+proj=healpix +lon_0=0 +a=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Projection pr√©vue pour Tahiti (EPSG: 3304)\n\n\n\n\n\n\n\n\n\n\n\n(d) Projection Albers pr√©vue pour Etats-Unis (EPSG: 5070)\n\n\n\n\n\n\n\nFigure¬†4.2: Comparaison des projections\n\n\n\nCependant le probl√®me n‚Äôest pas que visuel, il est √©galement\nnum√©rique. Les calculs g√©om√©triques am√®nent √† des diff√©rences\nassez notables selon le syst√®me de r√©f√©rence utilis√©.\nOn peut repr√©senter ces approximations sur une carte2 pour se faire une id√©e des r√©gions o√π l‚Äôerreur de mesure est la plus importante (objet de la question 2).\n\n\n\n\n\n\n\n\n\nCe type d‚Äôerreur de mesure est normal √† l‚Äô√©chelle du territoire fran√ßais.\nLes projections h√©rit√®res du Mercator d√©forment les distances,\nsurtout lorqu‚Äôon se rapproche de l‚Äô√©quateur ou des p√¥les.\nIl faut donc syst√©matiquement\nrepasser les donn√©es dans le syst√®me de projection Lambert 93 (le\nsyst√®me officiel pour la m√©tropole) avant d‚Äôeffectuer des calculs g√©om√©triques.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#localiser-les-donn√©es-sur-une-carte",
    "href": "content/manipulation/03_geopandas_intro.html#localiser-les-donn√©es-sur-une-carte",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "5.1 Localiser les donn√©es sur une carte",
    "text": "5.1 Localiser les donn√©es sur une carte\nLa premi√®re √©tape, avant l‚Äôexploration approfondie des donn√©es, consiste √† afficher celles-ci sur une carte contextuelle, afin de s‚Äôassurer de l‚Äôemprise g√©ographique des donn√©es.\nDans notre cas, cela nous donnera une intuition sur la localisation des stations et notamment la densit√© h√©t√©rog√®ne de celles-ci dans l‚Äôespace urbain parisien.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#exercice-dapplication",
    "href": "content/manipulation/03_geopandas_intro.html#exercice-dapplication",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "5.2 Exercice d‚Äôapplication",
    "text": "5.2 Exercice d‚Äôapplication\nDans le prochain exercice, nous proposons de cr√©er rapidement une\ncarte comprenant trois couches :\n\nLes localisations de stations sous forme de points ;\nLes bordures des communes et arrondissements pour contextualiser ;\nLes bordures des d√©partements en traits plus larges pour contextualiser √©galement.\n\nNous irons plus loin dans le travail cartographique dans le prochain\nchapitre. Mais √™tre en mesure de positionner rapidement\nses donn√©es sur une carte est\ntoujours utile dans un travail exploratoire.\nEn amont de l‚Äôexercice,\nutiliser la fonction suivante du package cartiflette pour r√©cup√©rer\nle fonds de carte des d√©partements de la petite couronne:\n\nidf = carti_download(\n    values=[\"11\"],\n    crs=4326,\n    borders=\"DEPARTEMENT\",\n    vectorfile_format=\"geojson\",\n    filter_by=\"REGION\",\n    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n    year=2022,\n)\n\npetite_couronne_departements = idf.loc[\n    idf[\"INSEE_DEP\"].isin([\"75\", \"92\", \"93\", \"94\"])\n].to_crs(2154)\n\n\n\n Exercice 3: importer et explorer les donn√©es velib\nOn commence par r√©cup√©rer les donn√©es n√©cessaires √† la production\nde cette carte.\n\nV√©rifier la projection g√©ographique de station (attribut crs). Si celle-ci est diff√©rente des donn√©es communales, reprojeter ces\nderni√®res dans le m√™me syst√®me de projection que les stations de v√©lib\nNe conserver que les 50 principales stations (variable capacity)\n\nOn peut maintenant construire la carte de mani√®re s√©quentielle avec la m√©thode plot en s‚Äôaidant de cette documentation\n\nEn premier lieu, gr√¢ce √† boundary.plot,\nrepr√©senter la couche de base des limites des communes et arrondissements:\n\nUtiliser les options edgecolor = \"black\" et linewidth = 0.5\nNommer cet objet base\n\nAjouter la couche des d√©partements avec les options edgecolor = \"blue\" et linewidth = 0.7\nAjouter les positions des stations\net ajuster la taille en fonction de la variable capacity. L‚Äôesth√©tique des points obtenus peut √™tre contr√¥l√© gr√¢ce aux options color = \"red\" et alpha = 0.4.\nRetirer les axes et ajouter un titre avec les options ci-dessous:\n\nbase.set_axis_off()\nbase.set_title(\"Les 50 principales stations de V√©lib\")\n\nEn suivant le mod√®le suivant, gr√¢ce au package contextily, ajouter un fond de carte contextuel openstreetmap\n\nimport contextily as ctx\n\nax = ...\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n‚ö†Ô∏è contextily attend des donn√©es dans le syst√®me de repr√©sentation Pseudo Mercator (EPSG: 3857), il sera donc n√©cessaire de reprojeter vos donn√©es avant de r√©aliser la carte.\n\n\nLa couche de base obtenue √† l‚Äôissue de la question 3.\n\n\n\n\n\n\n\n\n\nPuis en y ajoutant les limites d√©partementales (question 4).\n\n\n\n\n\n\n\n\n\nPuis les stations (question 5).\n\n\n\n\n\n\n\n\n\nEnsuite, si on retire les axes (question 6), on obtient:\n\n\n\n\n\n\n\n\n\nLa carte est d√©j√† parlante en soi. N√©anmoins, pour des personnes moins famili√®res de la g√©ographie parisienne, elle pourrait √™tre encore plus limpide avec l‚Äôajout d‚Äôun fond de carte contextuel openstreetmap. In fine, cela donne la carte suivante:",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#op√©rations-sur-les-g√©om√©tries",
    "href": "content/manipulation/03_geopandas_intro.html#op√©rations-sur-les-g√©om√©tries",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "5.3 Op√©rations sur les g√©om√©tries",
    "text": "5.3 Op√©rations sur les g√©om√©tries\nOutre la repr√©sentation graphique simplifi√©e,\nl‚Äôint√©r√™t principal d‚Äôutiliser\nGeoPandas est l‚Äôexistence de m√©thodes efficaces pour\nmanipuler la dimension spatiale. Un certain nombre proviennent du\npackage\nShapely.\nNous avons d√©j√† vu la m√©thode to_crs pour reprojeter les donn√©es de mani√®re vectoris√©e sans avoir √† s‚Äôinqui√©ter.\nNous avons √©galement √©voqu√© la m√©thode area\npour calculer des surfaces. Il en existe de nombreuses et l‚Äôobjectif de ce chapitre n‚Äôest pas d‚Äô√™tre exhaustif sur le sujet mais plut√¥t de servir d‚Äôintroduction g√©n√©rale pour amener √† approfondir ult√©rieurement.\nParmi les m√©thodes les plus utiles, on peut citer centroid qui, comme son nom l‚Äôindique,\nrecherche le centro√Øde de chaque polygone et transforme ainsi des donn√©es\nsurfaciques en donn√©es ponctuelles. Par exemple, pour\nrepr√©senter approximativement les centres des villages de la\nHaute-Garonne (31), apr√®s avoir t√©l√©charg√© le fonds de carte adapt√©, on\nfera\n\n\n\n\n\n\n\n\n\nPar cons√©quent, avec Geopandas, l‚Äôensemble de la grammaire Pandas peut √™tre mobilis√©e pour traiter la dimension attributaire des donn√©es alors que la dimension g√©ographique pourra √™tre manipul√©e avec des m√©thodes adapt√©es.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#principe-1",
    "href": "content/manipulation/03_geopandas_intro.html#principe-1",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "6.1 Principe",
    "text": "6.1 Principe\nLa carte pr√©c√©dente illustre d√©j√† la puissance de la repr√©sentation cartographique. En quelques lignes de code, avec tr√®s peu d‚Äôop√©rations sur nos donn√©es, on comprend d√©j√† mieux le ph√©nom√®ne qu‚Äôon d√©sire observer. En l‚Äôoccurrence, on d√©tecte tr√®s clairement une structure centre-p√©riph√©rie dans nos donn√©es, ce qui n‚Äôest pas surprenant mais qu‚Äôil est rassurant de retrouver au premier abord.\nOn remarque √©galement que les stations les plus utilis√©es, √† l‚Äôext√©rieur de l‚Äôhypercentre parisien, sont g√©n√©ralement situ√©es sur les grands axes ou √† proximit√© des parcs. L√† encore, rien de surprenant mais il est rassurant de retrouver ceci dans nos donn√©es.\nOn peut maintenant explorer de mani√®re plus approfondie la structure de notre jeu de donn√©es. Cependant si on observe celui-ci, on remarque qu‚Äôon a peu d‚Äôinformations dans le jeu de donn√©es brutes\n\nstations.head(2)\n\n\n\n\n\n\n\n\n\ncapacity\nname\nstationcode\ngeometry\n\n\n\n\n0\n22\nBasilique\n32017\nPOINT (653030.096 6870890.081)\n\n\n1\n30\nDe Toqueville - Terrasse\n17048\nPOINT (649691.343 6864930.800)\n\n\n\n\n\n\n\n\nDans le chapitre pr√©c√©dent, nous avons pr√©sent√© la mani√®re dont l‚Äôassociation de jeux de donn√©es par une dimension commune permet d‚Äôaccro√Ætre la valeur de celles-ci. En l‚Äôoccurrence, il s‚Äôagissait d‚Äôappariements de donn√©es sur la base d‚Äôinformations communes dans les deux jeux de donn√©es.\nNous avons maintenant une information suppl√©mentaire implicite dans nos deux de donn√©es: la dimension g√©ographique. On parle de jointure spatiale pour d√©signer l‚Äôassociation de jeux de donn√©es sur la dimension g√©ographique. Il existe de nombreux types diff√©rents de jointures spatiales: trouver des points dans un polygone, trouver l‚Äôintersection entre plusieurs aires, relier un point √† son plus proche voisin dans une autre source, etc.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#exemple-localiser-les-stations-dans-leur-arrondissement",
    "href": "content/manipulation/03_geopandas_intro.html#exemple-localiser-les-stations-dans-leur-arrondissement",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "6.2 Exemple: localiser les stations dans leur arrondissement",
    "text": "6.2 Exemple: localiser les stations dans leur arrondissement\nDans cet exercice, on va supposer que :\n\nles localisations des stations velib\nsont stock√©es dans un dataframe nomm√© stations\nles donn√©es administratives\nsont dans un dataframe nomm√© petite_couronne.\n\n\n\n Exercice 4: Associer les stations aux communes et arrondissements auxquels elles appartiennent\n\nFaire une jointure spatiale pour enrichir les donn√©es de stations en y ajoutant des informations de petite_couronne. Appeler cet objet stations_info.\nCompter le nombre de stations et la taille m√©diane des stations par arrondissements\nCr√©er les objets stations_19e et arrondissement_19e pour stocker, respectivement,\nles stations appartenant au 19e et les limites de l‚Äôarrondissement.\nCompter le nombre de stations velib et le nombre de places velib par arrondissement ou commune. Repr√©senter sur une carte chacune des informations\nRepr√©senter la carte des stations du 19e arrondissement avec le code suivant :\n\nbase = petite_couronne.loc[petite_couronne[\"INSEE_DEP\"] == \"75\"].boundary.plot(\n    edgecolor=\"k\", linewidth=0.5\n)\narrondissement_19e.boundary.plot(ax=base, edgecolor=\"red\", linewidth=0.9)\nstations_19.plot(ax=base, color=\"red\", alpha=0.4)\nbase.set_axis_off()\nbase.set_title(\"Les stations V√©lib du 19e arrondissement\")\nbase\nEn reprenant les exemples pr√©c√©dents, ne repr√©senter que le 19e et ajouter un fond de carte openstreetmap pour mieux localiser les stations.\n\nRepr√©senter les m√™mes informations mais en densit√© (diviser par la surface de l‚Äôarrondissement ou commune en km2)\n\n\n\nA l‚Äôissue de la jointure spatiale, le jeu de donn√©es\npr√©sente la structure suivante\n\n\n\n\n\n\n\n\n\n\ncapacity\nname\nstationcode\ngeometry\nindex_right\nINSEE_DEP\nINSEE_REG\nID\nNOM\nINSEE_COM\n...\nAAV2020\nTAAV2017\nTDAAV2017\nCATEAAV2020\nBV2012\nLIBELLE_DEPARTEMENT\nLIBELLE_REGION\nPAYS\nSOURCE\nAREA\n\n\n\n\n0\n22\nBasilique\n32017\nPOINT (653030.096 6870890.081)\n56\n93\n11\nCOMMUNE_0000000009735515\nSaint-Denis\n93066\n...\n001\n5\n50\n12\n75056\nSeine-Saint-Denis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nmetropole\n\n\n1\n30\nDe Toqueville - Terrasse\n17048\nPOINT (649691.343 6864930.800)\n11\n75\n11\nARR_MUNI0000000009736041\nParis 17e Arrondissement\n75056\n...\n001\n5\n50\n11\n75056\nParis\n√éle-de-France\nFrance\nIGN:EXPRESS-COG-CARTO-TERRITOIRE\nNaN\n\n\n\n\n2 rows √ó 31 columns\n\n\n\n\nOn peut donc calculer des statistiques par arrondissement, comme on le ferait avec un DataFrame Pandas (question 2):\n\n\n\n\n\n\n\n\n\n\nNOM\ncapacity\n\n\n\n\ncount\nmedian\n\n\n\n\n77\nVille-d'Avray\n1\n24.0\n\n\n64\nPuteaux\n2\n29.0\n\n\n27\nJoinville-le-Pont\n2\n42.5\n\n\n79\nVilleneuve-la-Garenne\n2\n37.5\n\n\n28\nLa Courneuve\n2\n31.0\n\n\n...\n...\n...\n...\n\n\n50\nParis 16e Arrondissement\n64\n32.0\n\n\n46\nParis 12e Arrondissement\n66\n38.5\n\n\n47\nParis 13e Arrondissement\n66\n33.5\n\n\n55\nParis 20e Arrondissement\n70\n25.0\n\n\n49\nParis 15e Arrondissement\n90\n34.5\n\n\n\n\n82 rows √ó 3 columns\n\n\n\n\nN√©anmoins des cartes seront sans doute plus parlante. Pour commencer, avec la question 3, on peut repr√©senter les stations du 19e arrondissement, d‚Äôabord dans l‚Äôensemble de Paris.\n\n\n\n\n\n\n\n\n\nOn peut ensuite zoomer sur cet arrondissement et faire une carte avec un fond plus travaill√©:\n\n\n\n\n\n\n\n\n\nCarte obtenue √† la question 5 :\n\n\n\n\n\n\n\n\n\nAvec cette carte, bas√©e sur des aplats de couleurs (choropleth map), le lecteur est victime d‚Äôune illusion classique. Les arrondissements les plus visibles sur la carte sont les plus grands. D‚Äôailleurs c‚Äôest assez logique qu‚Äôils soient √©galement mieux pourvus en velib. M√™me si l‚Äôoffre de velib est probablement plus reli√©e √† la densit√© de population et d‚Äô√©quipements, on peut penser que l‚Äôeffet taille joue et que celui-ci est certainement le ph√©nom√®ne le plus visible sur notre carte alors qu‚Äôil ne s‚Äôagit peut-√™tre pas du facteur de premier ordre en r√©alit√©.\nSi on repr√©sente plut√¥t la capacit√© sous forme de densit√©, pour tenir compte de la taille diff√©rente des arrondissements, les conclusions sont invers√©es et correspondent mieux aux attentes d‚Äôun mod√®le centre-p√©riph√©rie. Les arrondissements centraux sont mieux pourvus. Si nous faisions une carte avec des ronds proportionnels plut√¥t qu‚Äôune carte chorol√®pthe, cela serait encore plus visible ; n√©anmoins la cartographie n‚Äôest pas l‚Äôobjet de ce chapitre.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#exercice-suppl√©mentaire",
    "href": "content/manipulation/03_geopandas_intro.html#exercice-suppl√©mentaire",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "6.3 Exercice suppl√©mentaire",
    "text": "6.3 Exercice suppl√©mentaire\nLes exercices pr√©c√©dents ont permis de se familiariser au traitement de donn√©es\nspatiales. N√©anmoins il arrive fr√©quemment de devoir jongler de mani√®re plus ardue avec la\ndimension g√©om√©trique. Il peut s‚Äôagir, par exemple, de changer d‚Äô√©chelle territoriale dans les donn√©es ou d‚Äôintroduire\ndes fusions/dissolutions de g√©om√©tries.\nNous allons illustrer cela avec un exercice suppl√©mentaire illustrant, en pratique, comment travailler des donn√©es dans les mod√®les d‚Äô√©conomie urbaine o√π on fait l‚Äôhypoth√®se de d√©placements au plus proche point (mod√®le d‚ÄôHotelling).\nImaginons que chaque utilisateur de velib se d√©place exclusivement\nvers la station la plus proche (√† supposer qu‚Äôil n‚Äôy a jamais p√©nurie\nou surcapacit√©). Quelle est la carte de la couverture des v√©libs ?\nPour r√©pondre √† ce type de question, on utilise fr√©quemment la\nla tesselation de Vorono√Ø,\nune op√©ration classique pour transformer des points en polygones.\nL‚Äôexercice suivant\npermet de se familiariser avec la construction de voronoi 3.\n\n\n Exercice optionnel: La carte de couverture des stations\nCet exercice est plus complexe parce qu‚Äôil implique de revenir √† Shapely, une librairie plus bas niveau que GeoPandas.\nCet exercice est laiss√© libre. Une source d‚Äôinspiration possible est cette discussion sur StackExchange.\nL‚Äôobjectif est de faire deux cartes de couverture: une au niveau de la petite couronne et l‚Äôautre seulement au sein de Paris intramuros.\n\n\nLa premi√®re carte de couverture, au niveau de l‚Äôagglom√©ration dans son ensemble,\npermet de voir la densit√© plus importante des\nstations velib dans le centre parisien:\n\n\n\n\n\n\n\n\n\nSi on zoome sur Paris intramuros, on a √©galement une h√©t√©rog√©n√©it√© dans la couverture.\nOn a moins d‚Äôh√©t√©rog√©n√©it√© dans les surfaces de couverture puisque la densit√© est importante mais on remarque n√©anmoins des divergences entre certains espaces.",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#informations-additionnelles",
    "href": "content/manipulation/03_geopandas_intro.html#informations-additionnelles",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n16b1021\n\n\n2024-05-27 14:11:57\n\n\nlgaliana\n\n\nTypo dans le chapitre geopandas\n\n\n\n\n91bfa52\n\n\n2024-05-27 15:01:32\n\n\nLino Galiana\n\n\nRestructuration partie geopandas (#500)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nLes diff√©rents types de projection\nExemple de reprojection de pays depuis le site thetruesize.com\nFigure¬†4.1: ‚ÄúDon‚Äôt trust the Mercator projection‚Äù sur Reddit\nImage emprunt√©e √† XKCD https://xkcd.com/2256/ qu‚Äôon peut √©galement trouver sur https://blog.chrislansdown.com/2020/01/17/a-great-map-projection-joke/\nFigure¬†4.2¬†(a): Mercator WGS84 (EPSG: 4326)\nFigure¬†4.2¬†(b): Projection healpix (+proj=healpix +lon_0=0 +a=1)\nFigure¬†4.2¬†(c): Projection pr√©vue pour Tahiti (EPSG: 3304)\nFigure¬†4.2¬†(d): Projection Albers pr√©vue pour Etats-Unis (EPSG: 5070)",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/03_geopandas_intro.html#footnotes",
    "href": "content/manipulation/03_geopandas_intro.html#footnotes",
    "title": "Introduction aux donn√©es spatiales avec Geopandas",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMalgr√© toutes ses limites, sur lesquelles nous reviendrons, la carte\nchoropl√®the est tout de m√™me instructive. Savoir en produire une rapidement,\npour saisir les principaux faits structurants d‚Äôun jeu de donn√©es, est\nparticuli√®rement utile.‚Ü©Ô∏é\nCette carte n‚Äôest pas trop soign√©e, c‚Äôest normal nous verrons comment\nfaire de belles cartes ult√©rieurement.‚Ü©Ô∏é\nDans ce document de travail sur donn√©es de t√©l√©phonie mobile, on montre n√©anmoins que cette approche n‚Äôest pas sans biais\nsur des ph√©nom√®nes o√π l‚Äôhypoth√®se de proximit√© spatiale est\ntrop simplificatrice.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction aux donn√©es spatiales avec Geopandas"
    ]
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html",
    "href": "content/manipulation/02b_pandas_TP.html",
    "title": "Pratique de pandas : un exemple complet",
    "section": "",
    "text": "La partie Pandas a √©volu√© r√©cemment. Vous pouvez retrouver les contenus li√©s √† Pandas dans les chapitres suivants:"
  },
  {
    "objectID": "content/manipulation/02b_pandas_TP.html#informations-additionnelles",
    "href": "content/manipulation/02b_pandas_TP.html#informations-additionnelles",
    "title": "Pratique de pandas : un exemple complet",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\ne0d615e\n\n\n2024-05-03 11:15:29\n\n\nLino Galiana\n\n\nRestructure la partie Pandas (#497)\n\n\n\n\n4d678bf\n\n\n2024-04-23 12:09:46\n\n\nlinogaliana\n\n\nTypo\n\n\n\n\nd75641d\n\n\n2024-04-22 18:59:01\n\n\nLino Galiana\n\n\nEditorialisation des chapitres de manipulation de donn√©es (#491)\n\n\n\n\n7298c6c\n\n\n2024-04-19 21:34:00\n\n\nLino Galiana\n\n\nExercice great_tables (#489)\n\n\n\n\nc03aa61\n\n\n2024-01-16 17:33:18\n\n\nLino Galiana\n\n\nExercice sur les chemins relatifs (#483)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n8071bbb\n\n\n2023-10-23 17:43:37\n\n\ntomseimandi\n\n\nMake minor changes to 02b, 03, 04a (#440)\n\n\n\n\ndf01f01\n\n\n2023-10-10 15:55:04\n\n\nLino Galiana\n\n\nMenus automatis√©s (#432)\n\n\n\n\n7221e7b\n\n\n2023-10-10 14:00:44\n\n\nThomas Faria\n\n\nRelecture Thomas TD Pandas (#431)\n\n\n\n\n98bb886\n\n\n2023-10-09 11:50:03\n\n\nLino Galiana\n\n\ntypo\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\nac80862\n\n\n2023-10-07 21:05:25\n\n\nLino Galiana\n\n\nRelecture antuki (#427)\n\n\n\n\n5ab34aa\n\n\n2023-10-04 14:54:20\n\n\nKim A\n\n\nRelecture Kim pandas & git (#416)\n\n\n\n\n7e03cea\n\n\n2023-10-04 14:07:17\n\n\nLino Galiana\n\n\nClean pandas tutorial and exercises (#417)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\n89d0798\n\n\n2022-11-02 10:19:58\n\n\nLino Galiana\n\n\nAjoute icone aux autres TP (#317)\n\n\n\n\na3eadd4\n\n\n2022-11-01 18:51:14\n\n\nRomain Avouac\n\n\nMod√®le de notebooks de correction ex√©cutables (#304)\n\n\n\n\naf763cc\n\n\n2022-10-12 10:17:56\n\n\nLino Galiana\n\n\nReprise exercice geopandas (#294)\n\n\n\n\n1ef97df\n\n\n2022-10-11 12:14:03\n\n\nLino Galiana\n\n\nRelecture chapitre geopandas (#289)\n\n\n\n\ne2b53ac\n\n\n2022-09-28 17:09:31\n\n\nLino Galiana\n\n\nRetouche les chapitres pandas (#287)\n\n\n\n\neb8f922\n\n\n2022-09-22 17:40:43\n\n\nLino Galiana\n\n\nCorrige bug TP pandas (#276)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb138cf3\n\n\n2021-10-21 18:05:59\n\n\nLino Galiana\n\n\nMise √† jour TP webscraping et API (#164)\n\n\n\n\n4870662\n\n\n2021-10-05 08:29:33\n\n\nRomain Avouac\n\n\nfix and simplify pyinsee install (#157)\n\n\n\n\n0677932\n\n\n2021-10-03 15:32:51\n\n\nLino Galiana\n\n\nAjoute un code pour download pynsee (#156)\n\n\n\n\n2fa78c9\n\n\n2021-09-27 11:24:19\n\n\nLino Galiana\n\n\nRelecture de la partie numpy/pandas (#152)\n\n\n\n\n85ba119\n\n\n2021-09-16 11:27:56\n\n\nLino Galiana\n\n\nRelectures des TP KA avant 1er cours (#142)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\nbf5ebc5\n\n\n2021-09-01 14:41:17\n\n\nLino Galiana\n\n\nFix problem import pynsee (#128)\n\n\n\n\n4a317e3\n\n\n2021-08-31 12:38:17\n\n\nLino Galiana\n\n\npynsee pour importer des donn√©es Insee üöÄ (#127)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\n5c1e76d\n\n\n2020-09-09 11:25:38\n\n\nLino Galiana\n\n\nAjout des √©l√©ments webscraping, regex, API (#21)\n\n\n\n\nd48e68f\n\n\n2020-09-08 18:35:07\n\n\nLino Galiana\n\n\nContinuer la partie pandas (#13)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')"
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html",
    "href": "content/manipulation/03_geopandas_TP.html",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "",
    "text": "La partie GeoPandas a √©volu√© r√©cemment. Vous pouvez retrouver les contenus li√©s √† GeoPandas dans le chapitre suivant (√©l√©ments magistraux et exercices):"
  },
  {
    "objectID": "content/manipulation/03_geopandas_TP.html#informations-additionnelles",
    "href": "content/manipulation/03_geopandas_TP.html#informations-additionnelles",
    "title": "Pratique de geopandas avec les donn√©es v√©lib",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n91bfa52\n\n\n2024-05-27 15:01:32\n\n\nLino Galiana\n\n\nRestructuration partie geopandas (#500)\n\n\n\n\nc80ffa8\n\n\n2024-04-06 16:12:43\n\n\nlinogaliana\n\n\nProblem with geopandas\n\n\n\n\n3f7fff1\n\n\n2024-04-06 13:55:28\n\n\nLino Galiana\n\n\nUpdate 03_geopandas_TP.qmd\n\n\n\n\ne57f9cc\n\n\n2024-04-06 13:12:25\n\n\nLino Galiana\n\n\nRetire commentaire inutile\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\nce33d5d\n\n\n2024-01-16 15:47:22\n\n\nLino Galiana\n\n\nAdapte les exemples de code de cartiflette (#482)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n8728352\n\n\n2023-10-24 11:50:08\n\n\nLino Galiana\n\n\nCorrection coquilles geopandas (#444)\n\n\n\n\n8071bbb\n\n\n2023-10-23 17:43:37\n\n\ntomseimandi\n\n\nMake minor changes to 02b, 03, 04a (#440)\n\n\n\n\n102ce9f\n\n\n2023-10-22 11:39:37\n\n\nThomas Faria\n\n\nRelecture Thomas, premi√®re partie (#438)\n\n\n\n\ne918be6\n\n\n2023-10-09 12:39:31\n\n\nlinogaliana\n\n\nchange featured\n\n\n\n\nf8831e7\n\n\n2023-10-09 10:53:34\n\n\nLino Galiana\n\n\nRelecture antuki geopandas (#429)\n\n\n\n\n20432f7\n\n\n2023-09-27 15:31:22\n\n\nLino Galiana\n\n\nRestructure le TP GeoPandas (#414)\n\n\n\n\n338c07e\n\n\n2023-09-26 13:44:45\n\n\nlinogaliana\n\n\neval false\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nbdf396d\n\n\n2023-06-11 17:22:29\n\n\nLino Galiana\n\n\nupdate geopandas part for pandas v2 (#360)\n\n\n\n\n3912a7e\n\n\n2023-02-07 17:18:25\n\n\nLino Galiana\n\n\nBack to IGN provider (#350)\n\n\n\n\n3b8715e\n\n\n2022-12-11 18:52:23\n\n\nLino Galiana\n\n\nTP geopandas (#333)\n\n\n\n\n2e215a9\n\n\n2022-10-28 14:35:09\n\n\nLino Galiana\n\n\nSolve problem geopandas TP (#309)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\naf763cc\n\n\n2022-10-12 10:17:56\n\n\nLino Galiana\n\n\nReprise exercice geopandas (#294)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6777f03\n\n\n2021-10-29 09:38:09\n\n\nLino Galiana\n\n\nNotebooks corrections (#171)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n735e677\n\n\n2021-10-19 09:46:12\n\n\nLino Galiana\n\n\nR√®gle probl√®me des cartes qui s‚Äôaffichent pas (#165)\n\n\n\n\n5ad057f\n\n\n2021-10-10 15:13:16\n\n\nLino Galiana\n\n\nRelectures pandas & geopandas (#159)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n6d010fa\n\n\n2020-09-29 18:45:34\n\n\nLino Galiana\n\n\nSimplifie l‚Äôarborescence du site, partie 1 (#57)\n\n\n\n\n66f9f87\n\n\n2020-09-24 19:23:04\n\n\nLino Galiana\n\n\nIntroduction des figures g√©n√©r√©es par python dans le site (#52)\n\n\n\n\nbadc492\n\n\n2020-09-22 18:36:33\n\n\nLino Galiana\n\n\nFinalize geopandas section (#48)\n\n\n\n\n15b7dad\n\n\n2020-09-18 11:03:41\n\n\nLino Galiana\n\n\nFinalisation TP geopandas (#33)\n\n\n\n\nffb05cf\n\n\n2020-09-10 17:18:15\n\n\nLino Galiana\n\n\nPartie sur les donn√©es spatiales (#20) :warning: pas fini\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')"
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html",
    "href": "content/manipulation/04c_API_TP.html",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLa partie utilisant l‚ÄôAPI DVF n‚Äôest plus √† jour, elle sera mise √† jour prochainement.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#d√©finition",
    "href": "content/manipulation/04c_API_TP.html#d√©finition",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "1.1 D√©finition",
    "text": "1.1 D√©finition\nPour expliquer le principe d‚Äôune API, je vais reprendre le d√©but de\nla fiche d√©di√©e dans la documentation collaborative\nutilitR que je recommande de lire :\n\nUne Application Programming Interface (ou API) est une interface de programmation qui permet d‚Äôutiliser une application existante pour restituer des donn√©es. Le terme d‚ÄôAPI peut √™tre para√Ætre intimidant, mais il s‚Äôagit simplement d‚Äôune fa√ßon de mettre √† disposition des donn√©es : plut√¥t que de laisser l‚Äôutilisateur consulter directement des bases de donn√©es (souvent volumineuses et complexes), l‚ÄôAPI lui propose de formuler une requ√™te qui est trait√©e par le serveur h√©bergeant la base de donn√©es, puis de recevoir des donn√©es en r√©ponse √† sa requ√™te.\nD‚Äôun point de vue informatique, une API est une porte d‚Äôentr√©e clairement identifi√©e par laquelle un logiciel offre des services √† d‚Äôautres logiciels (ou utilisateurs). L‚Äôobjectif d‚Äôune API est de fournir un point d‚Äôacc√®s √† une fonctionnalit√© qui soit facile √† utiliser et qui masque les d√©tails de la mise en oeuvre. Par exemple, l‚ÄôAPI Sirene permet de r√©cup√©rer la raison sociale d‚Äôune entreprise √† partir de son identifiant Siren en interrogeant le r√©f√©rentiel disponible sur Internet directement depuis un script R, sans avoir √† conna√Ætre tous les d√©tails du r√©pertoire Sirene.\n√Ä l‚ÄôInsee comme ailleurs, la connexion entre les bases de donn√©es pour les nouveaux projets tend √† se r√©aliser par des API. L‚Äôacc√®s √† des donn√©es par des API devient ainsi de plus en plus commun et est amen√© √† devenir une comp√©tence de base de tout utilisateur de donn√©es.\nutilitR",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#avantages-des-api",
    "href": "content/manipulation/04c_API_TP.html#avantages-des-api",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "1.2 Avantages des API",
    "text": "1.2 Avantages des API\nA nouveau, citons la documentation utilitR :\nLes API pr√©sentent de multiples avantages :\n\n\nLes API rendent les programmes plus reproductibles. En effet, gr√¢ce aux API, il est possible de mettre √† jour facilement les donn√©es utilis√©es par un programme si celles-ci √©voluent. Cette flexibilit√© accrue pour l‚Äôutilisateur √©vite au producteur de donn√©es d‚Äôavoir √† r√©aliser de multiples extractions, et r√©duit le probl√®me de la coexistence de versions diff√©rentes des donn√©es.\nGr√¢ce aux API, l‚Äôutilisateur peut extraire facilement une petite partie d‚Äôune base de donn√©es plus cons√©quente.\nLes API permettent de mettre √† disposition des donn√©es tout en limitant le nombre de personnes ayant acc√®s aux bases de donn√©es elles-m√™mes.\nGr√¢ce aux API, il est possible de proposer des services sur mesure pour les utilisateurs (par exemple, un acc√®s sp√©cifique pour les gros utilisateurs).\n\nutilitR\n\nL‚Äôutilisation accrue d‚ÄôAPI dans le cadre de strat√©gies open-data est l‚Äôun\ndes piliers des 15 feuilles de route minist√©rielles\nen mati√®re d‚Äôouverture, de circulation et de valorisation des donn√©es publiques.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#utilisation-des-api",
    "href": "content/manipulation/04c_API_TP.html#utilisation-des-api",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "1.3 Utilisation des API",
    "text": "1.3 Utilisation des API\nCitons encore une fois\nla documentation utilitR :\n\nUne API peut souvent √™tre utilis√©e de deux fa√ßons : par une interface Web, et par l‚Äôinterm√©diaire d‚Äôun logiciel (R, Python‚Ä¶). Par ailleurs, les API peuvent √™tre propos√©es avec un niveau de libert√© variable pour l‚Äôutilisateur :\n\nsoit en libre acc√®s (l‚Äôutilisation n‚Äôest pas contr√¥l√©e et l‚Äôutilisateur peut utiliser le service comme bon lui semble)‚ÄØ;\nsoit via la g√©n√©ration d‚Äôun compte et d‚Äôun jeton d‚Äôacc√®s qui permettent de s√©curiser l‚Äôutilisation de l‚ÄôAPI et de limiter le nombre de requ√™tes.\n\nutilitR\n\nDe nombreuses API n√©cessitent une authentification, c‚Äôest-√†-dire un\ncompte utilisateur afin de pouvoir acc√©der aux donn√©es.\nDans un premier temps,\nnous regarderons exclusivement les API ouvertes sans restriction d‚Äôacc√®s.\nCertains exercices et exemples permettront n√©anmoins d‚Äôessayer des API\navec restrictions d‚Äôacc√®s.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#principe-g√©n√©ral",
    "href": "content/manipulation/04c_API_TP.html#principe-g√©n√©ral",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "2.1 Principe g√©n√©ral",
    "text": "2.1 Principe g√©n√©ral\n\nL‚Äôutilisation de l‚Äôinterface Web est utile dans une d√©marche exploratoire mais trouve rapidement ses limites, notamment lorsqu‚Äôon consulte r√©guli√®rement l‚ÄôAPI. L‚Äôutilisateur va rapidement se rendre compte qu‚Äôil est beaucoup plus commode d‚Äôutiliser une API via un logiciel de traitement pour automatiser la consultation ou pour r√©aliser du t√©l√©chargement de masse. De plus, l‚Äôinterface Web n‚Äôexiste pas syst√©matiquement pour toutes les API.\nLe mode principal de consultation d‚Äôune API consiste √† adresser une requ√™te √† cette API via un logiciel adapt√© (R, Python, Java‚Ä¶). Comme pour l‚Äôutilisation d‚Äôune fonction, l‚Äôappel d‚Äôune API comprend des param√®tres qui sont d√©taill√©es dans la documentation de l‚ÄôAPI.\nutilitR\n\nVoici les √©l√©ments importants √† avoir en t√™te sur les requ√™tes (j‚Äôemprunte encore\n√† utilitR) :\n\nLe point d‚Äôentr√©e d‚Äôun service offert par une API se pr√©sente sous la forme d‚Äôune URL (adresse web).\nChaque service propos√© par une API a sa propre URL. Par exemple, dans le cas de l‚ÄôOpenFood Facts,\nl‚ÄôURL √† utiliser pour obtenir des informations sur un produit particulier (l‚Äôidentifiant 737628064502)\nest https://world.openfoodfacts.org/api/v0/product/737628064502.json\nCette URL doit √™tre compl√©t√©e avec diff√©rents param√®tres qui pr√©cisent la requ√™te (par exemple l‚Äôidentifiant Siren). Ces param√®tres viennent s‚Äôajouter √† l‚ÄôURL, souvent √† la suite de ?. Chaque service propos√© par une API a ses propres param√®tres, d√©taill√©s dans la documentation.\nLorsque l‚Äôutilisateur soumet sa requ√™te, l‚ÄôAPI lui renvoie une r√©ponse structur√©e contenant l‚Äôensemble des informations demand√©es. Le r√©sultat envoy√© par une API est majoritairement aux formats JSON ou XML (deux formats dans lesquels les informations sont hi√©rarchis√©es de mani√®re emboit√©e). Plus rarement, certains services proposent une information sous forme plate (de type csv).\n\nDu fait de la dimension hi√©rarchique des formats JSON ou XML,\nle r√©sultat n‚Äôest pas toujours facile √† r√©cup√©rer mais\nPython propose d‚Äôexcellents outils pour cela (meilleurs que ceux de R).\nCertains packages, notamment json, facilitent l‚Äôextraction de champs d‚Äôune sortie d‚ÄôAPI.\nDans certains cas, des packages sp√©cifiques √† une API ont √©t√© cr√©√©s pour simplifier l‚Äô√©criture d‚Äôune requ√™te ou la r√©cup√©ration du r√©sultat. Par exemple, le package\npynsee\npropose des options qui seront retranscrites automatiquement dans l‚ÄôURL de\nrequ√™te pour faciliter le travail sur les donn√©es Insee.",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#illustration-avec-une-api-de-lademe-pour-obtenir-des-diagnostics-energ√©tiques",
    "href": "content/manipulation/04c_API_TP.html#illustration-avec-une-api-de-lademe-pour-obtenir-des-diagnostics-energ√©tiques",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "2.2 Illustration avec une API de l‚ÄôAdeme pour obtenir des diagnostics energ√©tiques",
    "text": "2.2 Illustration avec une API de l‚ÄôAdeme pour obtenir des diagnostics energ√©tiques\nLe diagnostic de performance √©nerg√©tique (DPE)\nrenseigne sur la performance √©nerg√©tique d‚Äôun logement ou d‚Äôun b√¢timent,\nen √©valuant sa consommation d‚Äô√©nergie et son impact en terme d‚Äô√©missions de gaz √† effet de serre.\nLes donn√©es des performances √©nerg√©tiques des b√¢timents sont\nmises √† disposition par l‚ÄôAdeme.\nComme ces donn√©es sont relativement\nvolumineuses, une API peut √™tre utile lorsqu‚Äôon ne s‚Äôint√©resse\nqu‚Äô√† un sous-champ des donn√©es.\nUne documentation et un espace de test de l‚ÄôAPI sont disponibles\nsur le site API GOUV1.\nSupposons qu‚Äôon d√©sire r√©cup√©rer une centaine de valeurs pour la commune\nde Villieu-Loyes-Mollon dans l‚ÄôAin (code Insee 01450).\nL‚ÄôAPI comporte plusieurs points d‚Äôentr√©e. Globalement, la racine\ncommune est :\n\nhttps://koumoul.com/data-fair/api/v1/datasets/dpe-france\n\nEnsuite, en fonction de l‚ÄôAPI d√©sir√©e, on va ajouter des √©l√©ments\n√† cette racine. En l‚Äôoccurrence, on va utiliser\nl‚ÄôAPI field qui permet de r√©cup√©rer des lignes en fonction d‚Äôun\nou plusieurs crit√®res (pour nous, la localisation g√©ographique):\nL‚Äôexemple donn√© dans la documentation technique est\n\nGET https://koumoul.com/data-fair/api/v1/datasets/dpe-france/values/{field}\n\nce qui en Python se traduira par l‚Äôutilisation de la m√©thode get du\npackage Request\nsur un url dont la structure est la suivante :\n\nil commencera par https://koumoul.com/data-fair/api/v1/datasets/dpe-france/values/ ;\nil sera ensuite suivi par des param√®tres de recherche. Le champ {field}\ncommence ainsi g√©n√©ralement par un ? qui permet ensuite de sp√©cifier des param√®tres\nsous la forme nom_parameter=value\n\nA la lecture de la documentation, les premiers param√®tres qu‚Äôon d√©sire :\n\nLe nombre de pages, ce qui nous permet d‚Äôobtenir un certain nombre d‚Äô√©chos. On\nva seulement r√©cup√©rer 10 pages ce qui correspond √† une centaine d‚Äô√©chos. On va\nn√©anmoins pr√©ciser qu‚Äôon veut 100 √©chos\nLe format de sortie. On va privil√©gier le JSON qui est un format standard dans le\nmonde des API. Python offre beaucoup de flexibilit√© gr√¢ce √† l‚Äôun de\nses objets de base, √† savoir le dictionnaire (type dict), pour manipuler de tels\nfichiers\nLe code commune des donn√©es qu‚Äôon d√©sire obtenir. Comme on l‚Äôa √©voqu√©,\non va r√©cup√©rer les donn√©es dont le code commune est 01450. D‚Äôapr√®s la doc,\nil convient de passer le code commune sous le format:\ncode_insee_commune_actualise:{code_commune}. Pour √©viter tout risque de\nmauvais formatage, on va utiliser %3A pour signifier :, %2A pour signifier * et\n%22 pour signifier \".\nD‚Äôautres param√®tres annexes, sugg√©r√©s par la documentation\n\nCela nous donne ainsi un URL dont la structure est la suivante :\n\ncode_commune = \"01450\"\nsize = 100\napi_root = \"https://koumoul.com/data-fair/api/v1/datasets/dpe-france/lines\"\nurl_api = (\n    f\"{api_root}?format=json&q_mode=simple&qs=code_insee_commune_actualise\"\n    + \"%3A%22\"\n    + f\"{code_commune}\"\n    + \"%22\"\n    + f\"&size={size}&select=\"\n    + \"%2A&sampling=neighbors\"\n)\n\nSi vous introduisez cet URL dans votre navigateur, vous devriez aboutir\nsur un JSON non format√©2. En Python,\non peut utiliser requests pour r√©cup√©rer les donn√©es3 :\n\nimport requests\nimport pandas as pd\n\nreq = requests.get(url_api)\nwb = req.json()\n\nPrenons par exemple les 1000 premiers caract√®res du r√©sultat, pour se donner\nune id√©e du r√©sultat et se convaincre que notre filtre au niveau\ncommunal est bien pass√© :\nprint(req.content[:1000])\nb‚Äô{‚Äútotal‚Äù: 121,‚Äúnext‚Äù: ‚Äúhttps://koumoul.com/data-fair/api/v1/datasets/dpe-france/lines?format=json&q_mode=simple&qs=code_insee_commune_actualise%3A%2201450%22&size=100&select=*&sampling=neighbors&after=102719%2C912454‚Äù,‚Äúresults‚Äù: [\\n {‚Äúclasse_consommation_energie‚Äù: ‚ÄúE‚Äù,‚Äútr001_modele_dpe_type_libelle‚Äù: ‚ÄúVente‚Äù,‚Äúannee_construction‚Äù: 1,‚Äú_geopoint‚Äù: ‚Äú45.927488,5.230195‚Äù,‚Äúlatitude‚Äù: 45.927488,‚Äúsurface_thermique_lot‚Äù: 106.87,‚Äú_i‚Äù: 2,‚Äútr002_type_batiment_description‚Äù: ‚ÄúMaison Individuelle‚Äù,‚Äúgeo_adresse‚Äù: ‚ÄúRue du Chateau 01800 Villieu-Loyes-Mollon‚Äù,‚Äú_rand‚Äù: 959550,‚Äúcode_insee_commune_actualise‚Äù: ‚Äú01450‚Äù,‚Äúestimation_ges‚Äù: 9,‚Äúgeo_score‚Äù: 0.58,‚Äúclasse_estimation_ges‚Äù: ‚ÄúB‚Äù,‚Äúnom_methode_dpe‚Äù: ‚ÄúM9thode Facture‚Äù,‚Äútv016_departement_code‚Äù: ‚Äú01‚Äù,‚Äúconsommation_energie‚Äù: 286,‚Äúdate_etablissement_dpe‚Äù: ‚Äú2013-04-15‚Äù,‚Äúlongitude‚Äù: 5.230195,‚Äú_score‚Äù: null,‚Äô\nIci, il n‚Äôest m√™me pas n√©cessaire en premi√®re approche\nd‚Äôutiliser le package json, l‚Äôinformation\n√©tant d√©j√† tabul√©e dans l‚Äô√©cho renvoy√© (on a la m√™me information pour tous les pays):\nOn peut donc se contenter de Pandas pour transformer nos donn√©es en\nDataFrame et Geopandas pour convertir en donn√©es\ng√©ographiques :\n\nimport pandas as pandas\nimport geopandas as gpd\n\n\ndef get_dpe_from_url(url):\n\n    req = requests.get(url)\n    wb = req.json()\n    df = pd.json_normalize(wb[\"results\"])\n\n    dpe = gpd.GeoDataFrame(\n        df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=4326\n    )\n    dpe = dpe.dropna(subset=[\"longitude\", \"latitude\"])\n\n    return dpe\n\n\ndpe = get_dpe_from_url(url_api)\ndpe.head(2)\n\n\n\n\n\n\n\n\n\nclasse_consommation_energie\ntr001_modele_dpe_type_libelle\nannee_construction\n_geopoint\nlatitude\nsurface_thermique_lot\n_i\ntr002_type_batiment_description\ngeo_adresse\n_rand\n...\nclasse_estimation_ges\nnom_methode_dpe\ntv016_departement_code\nconsommation_energie\ndate_etablissement_dpe\nlongitude\n_score\n_id\nversion_methode_dpe\ngeometry\n\n\n\n\n0\nE\nVente\n1\n45.927488,5.230195\n45.927488\n106.87\n2\nMaison Individuelle\nRue du Chateau 01800 Villieu-Loyes-Mollon\n959550\n...\nB\nM√©thode Facture\n01\n286.0\n2013-04-15\n5.230195\nNone\nHJt4TdUa1W0wZiNoQkskk\nNaN\nPOINT (5.23020 45.92749)\n\n\n1\nG\nVente\n1960\n45.931376,5.230461\n45.931376\n70.78\n9\nMaison Individuelle\n552 Rue Royale 01800 Villieu-Loyes-Mollon\n681070\n...\nD\nM√©thode 3CL\n01\n507.0\n2013-04-22\n5.230461\nNone\nUhMxzza1hsUo0syBh9DxH\n3CL-DPE, version 1.3\nPOINT (5.23046 45.93138)\n\n\n\n\n2 rows √ó 23 columns\n\n\n\n\nEssayons de repr√©senter sur une carte ces DPE avec les\nann√©es de construction des logements.\nAvec Folium, on obtient la carte interactive suivante :\n\nimport seaborn as sns\nimport folium\n\npalette = sns.color_palette(\"coolwarm\", 8)\n\n\ndef interactive_map_dpe(dpe):\n\n    # convert in number\n    dpe[\"color\"] = [\n        ord(dpe.iloc[i][\"classe_consommation_energie\"].lower()) - 96\n        for i in range(len(dpe))\n    ]\n    dpe = dpe.loc[dpe[\"color\"] &lt;= 7]\n    dpe[\"color\"] = [palette.as_hex()[x] for x in dpe[\"color\"]]\n\n    center = dpe[[\"latitude\", \"longitude\"]].mean().values.tolist()\n    sw = dpe[[\"latitude\", \"longitude\"]].min().values.tolist()\n    ne = dpe[[\"latitude\", \"longitude\"]].max().values.tolist()\n\n    m = folium.Map(location=center, tiles=\"OpenStreetMap\")\n\n    # I can add marker one by one on the map\n    for i in range(0, len(dpe)):\n        folium.Marker(\n            [dpe.iloc[i][\"latitude\"], dpe.iloc[i][\"longitude\"]],\n            popup=f\"Ann√©e de construction : {dpe.iloc[i]['annee_construction']}, &lt;br&gt;DPE : {dpe.iloc[i]['classe_consommation_energie']}\",\n            icon=folium.Icon(\n                color=\"black\", icon=\"home\", icon_color=dpe.iloc[i][\"color\"]\n            ),\n        ).add_to(m)\n\n    m.fit_bounds([sw, ne])\n\n    return m\n\n\nm = interactive_map_dpe(dpe)\n\n/opt/mamba/lib/python3.11/site-packages/geopandas/geodataframe.py:1443: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n# Afficher la carte\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#un-catalogue-incomplet-dapi-existantes",
    "href": "content/manipulation/04c_API_TP.html#un-catalogue-incomplet-dapi-existantes",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "2.3 Un catalogue incomplet d‚ÄôAPI existantes",
    "text": "2.3 Un catalogue incomplet d‚ÄôAPI existantes\nDe plus en plus de sites mettent des API √† disposition des d√©veloppeurs et autres curieux.\nPour en citer quelques-unes tr√®s connues :\n\nTwitter  : https://dev.twitter.com/rest/public\nFacebook  : https://developers.facebook.com/\nInstagram  : https://www.instagram.com/developer/\nSpotify  : https://developer.spotify.com/web-api/\n\nCependant, il est int√©ressant de ne pas se restreindre √† celles-ci dont les\ndonn√©es ne sont pas toujours les plus int√©ressantes. Beaucoup\nde producteurs de donn√©es, priv√©s comme publics, mettent √† disposition\nleurs donn√©es sous forme d‚ÄôAPI.\n\nAPI gouv : beaucoup d‚ÄôAPI officielles de l‚ÄôEtat fran√ßais\net acc√®s √† de la documentation\nInsee : https://api.insee.fr/catalogue/ et pynsee\nP√¥le Emploi : https://www.emploi-store-dev.fr/portail-developpeur-cms/home.html\nSNCF : https://data.sncf.com/api\nBanque Mondiale : https://datahelpdesk.worldbank.org/knowledgebase/topics/125589",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#utiliser-lapi-ban",
    "href": "content/manipulation/04c_API_TP.html#utiliser-lapi-ban",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "4.1 Utiliser l‚ÄôAPI BAN",
    "text": "4.1 Utiliser l‚ÄôAPI BAN\nLa documentation officielle de l‚ÄôAPI\npropose un certain nombre d‚Äôexemples de mani√®re de g√©olocaliser des donn√©es.\nDans notre situation, deux points d‚Äôentr√©e paraissent int√©ressants:\n\nL‚ÄôAPI /search/ qui repr√©sente un point d‚Äôentr√©e avec des URL de la forme\nhttps://api-adresse.data.gouv.fr/search/?q=\\&lt;adresse\\&gt;&postcode=\\&lt;codepostal\\&gt;&limit=1\nL‚ÄôAPI /search/csv qui prend un CSV en entr√©e et retourne ce m√™me CSV avec\nles observations g√©ocod√©es. La requ√™te prend la forme suivante, en apparence\nmoins simple √† mettre en oeuvre :\ncurl -X POST -F data=@search.csv -F columns=adresse -F columns=postcode https://api-adresse.data.gouv.fr/search/csv/\n\nLa tentation serait forte d‚Äôutiliser la premi√®re m√©thode avec une boucle sur les\nlignes de notre DataFrame pour g√©ocoder l‚Äôensemble de notre jeu de donn√©es.\nCela serait n√©anmoins une mauvaise id√©e car les communications entre notre\nsession Python et les serveurs de l‚ÄôAPI seraient beaucoup trop nombreuses\npour offrir des performances satisfaisantes.\nPour vous en convaincre, vous pouvez ex√©cuter le code suivant sur un petit\n√©chantillon de donn√©es (par exemple 100 comme ici) et remarquer que le temps\nd‚Äôex√©cution est assez important\n\nimport time\n\ndfgeoloc = df.loc[:, [\"Adresse\", \"CP\", \"Ville\"]].apply(\n    lambda s: s.str.lower().str.replace(\",\", \" \")\n)\ndfgeoloc[\"url\"] = (\n    dfgeoloc[\"Adresse\"] + \"+\" + dfgeoloc[\"Ville\"].str.replace(\"-\", \"+\")\n).str.replace(\" \", \"+\")\ndfgeoloc[\"url\"] = (\n    \"https://api-adresse.data.gouv.fr/search/?q=\"\n    + dfgeoloc[\"url\"]\n    + \"&postcode=\"\n    + df[\"CP\"]\n    + \"&limit=1\"\n)\ndfgeoloc = dfgeoloc.dropna()\n\nstart_time = time.time()\n\n\ndef get_geoloc(i):\n    print(i)\n    return gpd.GeoDataFrame.from_features(\n        requests.get(dfgeoloc[\"url\"].iloc[i]).json()[\"features\"]\n    )\n\n\nlocal = [get_geoloc(i) for i in range(len(dfgeoloc.head(10)))]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\nComme l‚Äôindique la documentation, si on d√©sire industrialiser notre processus\nde g√©ocodage, on va privil√©gier l‚ÄôAPI CSV.\nPour obtenir une requ√™te CURL coh√©rente avec le format d√©sir√© par l‚ÄôAPI\non va √† nouveau utiliser Requests mais cette fois avec des param√®tres\nsuppl√©mentaires:\n\ndata va nous permettre de passer des param√®tres √† CURL (√©quivalents aux -F\nde la requ√™te CURL) :\n\ncolumns: Les colonnes utilis√©es pour localiser une donn√©e. En l‚Äôoccurrence,\non utilise l‚Äôadresse et la ville (car les codes postaux n‚Äô√©tant pas uniques,\nun m√™me nom de voirie peut se trouver dans plusieurs villes partageant le m√™me\ncode postal) ;\npostcode: Le code postal de la ville. Id√©alement nous aurions utilis√©\nle code Insee mais nous ne l‚Äôavons pas dans nos donn√©es ;\nresult_columns: on restreint les donn√©es √©chang√©es avec l‚ÄôAPI aux\ncolonnes qui nous int√©ressent. Cela permet d‚Äôacc√©l√©rer les processus (on\n√©change moins de donn√©es) et de r√©duire l‚Äôimpact carbone de notre activit√©\n(moins de transferts = moins d‚Äô√©nergie d√©pens√©e). En l‚Äôoccurrence, on ne ressort\nque les donn√©es g√©olocalis√©es et un score de confiance en la g√©olocalisation ;\n\nfiles: permet d‚Äôenvoyer un fichier via CURL.\n\nLes donn√©es sont r√©cup√©r√©es avec request.post. Comme il s‚Äôagit d‚Äôune\ncha√Æne de caract√®re, nous pouvons directement la lire avec Pandas en\nutilisant io.StringIO pour √©viter d‚Äô√©crire des donn√©es interm√©diaires.\nLe nombre d‚Äô√©chos semblant √™tre limit√©, il\nest propos√© de proc√©der par morceaux\n(ici, le jeu de donn√©es est d√©coup√© en 5 morceaux).\n\nimport requests\nimport io\nimport numpy as np\nimport time\n\nparams = {\n    \"columns\": [\"Adresse\", \"Ville\"],\n    \"postcode\": \"CP\",\n    \"result_columns\": [\"result_score\", \"latitude\", \"longitude\"],\n}\n\ndf[[\"Adresse\", \"CP\", \"Ville\"]] = df.loc[:, [\"Adresse\", \"CP\", \"Ville\"]].apply(\n    lambda s: s.str.lower().str.replace(\",\", \" \")\n)\n\n\ndef geoloc_chunk(x):\n    dfgeoloc = x.loc[:, [\"Adresse\", \"CP\", \"Ville\"]]\n    dfgeoloc.to_csv(\"datageocodage.csv\", index=False)\n    response = requests.post(\n        \"https://api-adresse.data.gouv.fr/search/csv/\",\n        data=params,\n        files={\"data\": (\"datageocodage.csv\", open(\"datageocodage.csv\", \"rb\"))},\n    )\n    geoloc = pd.read_csv(io.StringIO(response.text), dtype={\"CP\": \"str\"})\n    return geoloc\n\n\nstart_time = time.time()\ngeodata = [geoloc_chunk(dd) for dd in np.array_split(df, 10)]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\nCette m√©thode est beaucoup plus rapide et permet ainsi, une fois retourn√© √† nos\ndonn√©es initiales, d‚Äôavoir un jeu de donn√©es g√©olocalis√©.\n\n# Retour aux donn√©es initiales\ngeodata = pd.concat(geodata, ignore_index=True)\ndf_xy = df.merge(geodata, on=[\"Adresse\", \"CP\", \"Ville\"])\ndf_xy = df_xy.dropna(subset=[\"latitude\", \"longitude\"])\n\n# Mise en forme pour le tooltip\ndf_xy[\"text\"] = (\n    df_xy[\"Raison_Sociale\"]\n    + \"&lt;br&gt;\"\n    + df_xy[\"Adresse\"]\n    + \"&lt;br&gt;\"\n    + df_xy[\"Ville\"]\n    + \"&lt;br&gt;Nombre de candidats:\"\n    + df_xy[\"B_NB\"].astype(str)\n)\ndf_xy.filter(\n    [\"Raison_Sociale\", \"Adresse\", \"CP\", \"Ville\", \"latitude\", \"longitude\"],\n    axis=\"columns\",\n).sample(10)\n\n\n\n\n\n\n\n\n\nRaison_Sociale\nAdresse\nCP\nVille\nlatitude\nlongitude\n\n\n\n\n11469\nDE BELLEMENE.\n173 ter cd 4\n97460\nsaint paul\n-21.008380\n55.318018\n\n\n6447\nBELLIME\n4 route de maringues\n63920\npont de dore\n45.838799\n3.498704\n\n\n3749\nKLODZINSKI\ncarreau rive gauche batiment k\n38610\ngieres\n45.192472\n5.770928\n\n\n5171\nCOCHEVELOU ROZENN AUTO ECOLE\n22 place l le montagner\n56520\nguidel\n47.791904\n-3.494025\n\n\n4456\nDOS SANTOS\n108 avenue de la republique\n46130\nbiars sur cere\n44.919132\n1.840091\n\n\n4939\nNCY EDG Conduite\n2 rue pierre de sivry\n54000\nnancy\n48.675080\n6.170603\n\n\n8245\nLES ORMEAUX\n22/24 rue des ormeaux\n77181\ncourtry\n48.912920\n2.597686\n\n\n6828\nPERRINE CONDUITE\n46 rue des foss√©s\n67720\nweyersheim\n48.718430\n7.800963\n\n\n7359\nAPTITUDES PERMIS\n23 route de beaune\n71400\nautun\n46.956482\n4.315519\n\n\n3034\nCIGALE 30\nrue de l'ancienne poste\n30310\nvergeze\n43.743259\n4.220556\n\n\n\n\n\n\n\n\nIl ne reste plus qu‚Äô√† utiliser Geopandas\net nous serons en mesure de faire une carte des localisations des auto-√©coles :\n\n# Transforme en geopandas pour les cartes\nimport geopandas as gpd\n\ndfgeo = gpd.GeoDataFrame(\n    df_xy, geometry=gpd.points_from_xy(df_xy.longitude, df_xy.latitude)\n)\n\nNous allons repr√©senter les stations dans l‚ÄôEssonne avec un zoom initialement\nsur les villes de Massy et Palaiseau. Le code est le suivant :\n\nimport folium\n\n# Repr√©senter toutes les auto√©coles de l'Essonne\ndf_91 = df_xy.loc[df_xy[\"Dept\"] == \"091\"]\n\n# Centrer la vue initiale sur Massy-Palaiseau\ndf_pal = df_xy.loc[df_xy[\"Ville\"].isin([\"massy\", \"palaiseau\"])]\ncenter = df_pal[[\"latitude\", \"longitude\"]].mean().values.tolist()\nsw = df_pal[[\"latitude\", \"longitude\"]].min().values.tolist()\nne = df_pal[[\"latitude\", \"longitude\"]].max().values.tolist()\n\nm = folium.Map(location=center, tiles=\"OpenStreetMap\")\n\n# I can add marker one by one on the map\nfor i in range(0, len(df_91)):\n    folium.Marker(\n        [df_91.iloc[i][\"latitude\"], df_91.iloc[i][\"longitude\"]],\n        popup=df_91.iloc[i][\"text\"],\n        icon=folium.Icon(icon=\"car\", prefix=\"fa\"),\n    ).add_to(m)\n\nm.fit_bounds([sw, ne])\n\nCe qui permet d‚Äôobtenir la carte:\n\n# Afficher la carte\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nVous pouvez aller plus loin avec l‚Äôexercice suivant.\n\n\n Exercice 2 : Quelles sont les auto-√©coles les plus proches de chez moi ?\nOn va supposer que vous cherchez, dans un rayon donn√© autour d‚Äôun centre ville,\nles auto-√©coles disponibles.\n\n\nFonction n√©cessaire pour cet exercice\n\nCet exercice n√©cessite une fonction pour cr√©er un cercle\nautour d‚Äôun point\n(source ici).\nLa voici :\nfrom functools import partial\nimport pyproj\nfrom shapely.ops import transform\nfrom shapely.geometry import Point\n\nproj_wgs84 = pyproj.Proj(\"+proj=longlat +datum=WGS84\")\n\n\ndef geodesic_point_buffer(lat, lon, km):\n    # Azimuthal equidistant projection\n    aeqd_proj = \"+proj=aeqd +lat_0={lat} +lon_0={lon} +x_0=0 +y_0=0\"\n    project = partial(\n        pyproj.transform, pyproj.Proj(aeqd_proj.format(lat=lat, lon=lon)), proj_wgs84\n    )\n    buf = Point(0, 0).buffer(km * 1000)  # distance in metres\n    return transform(project, buf).exterior.coords[:]\n\n\nPour commencer, utiliser l‚ÄôAPI Geo\npour la ville de Palaiseau.\nAppliquer la fonction geodesic_point_buffer au centre ville de Palaiseau\nNe conserver que les auto-√©coles dans ce cercle et les ordonner\n\nSi vous avez la r√©ponse √† la question 3, n‚Äôh√©sitez pas √† la soumettre sur Github afin que je compl√®te la correction üòâ !\n\n\n\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed\n\n\n\n\n/opt/mamba/lib/python3.11/site-packages/shapely/ops.py:276: FutureWarning:\n\nThis function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n\n\n\nPour se convaincre, de notre cercle constitu√© lors de\nla question 2, on peut repr√©senter une carte.\nOn a bien un cercle centr√© autour de Palaiseau :",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#d√©couvrir-lapi-dopenfoodfacts",
    "href": "content/manipulation/04c_API_TP.html#d√©couvrir-lapi-dopenfoodfacts",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "5.1 D√©couvrir l‚ÄôAPI d‚ÄôOpenFoodFacts",
    "text": "5.1 D√©couvrir l‚ÄôAPI d‚ÄôOpenFoodFacts\nPour vous aidez, vous pouvez regarder une exemple de structure du JSON ici :\nhttps://world.openfoodfacts.org/api/v0/product/3274080005003.json en particulier la cat√©gorie nutriments.\n\n\n Exercice 3 : Retrouver des produits dans l'openfood facts üçï\nVoici une liste de code-barres:\n3274080005003,  5449000000996, 8002270014901, 3228857000906, 3017620421006, 8712100325953\nUtiliser l‚ÄôAPI d‚Äôopenfoodfacts\n(l‚ÄôAPI, pas depuis le CSV !)\npour retrouver les produits correspondants\net leurs caract√©ristiques nutritionnelles.\nLe panier para√Æt-il √©quilibr√© ? üç´\nR√©cup√©rer l‚ÄôURL d‚Äôune des images et l‚Äôafficher dans votre navigateur.\n\n\nVoici par exemple la photo du produit ayant le code-barre 5449000000996. Vous le reconnaissez ?",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#informations-additionnelles",
    "href": "content/manipulation/04c_API_TP.html#informations-additionnelles",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n04ce567\n\n\n2023-10-23 19:04:01\n\n\nLino Galiana\n\n\nMise en forme chapitre API (#442)\n\n\n\n\n3eb0aeb\n\n\n2023-10-23 11:59:24\n\n\nThomas Faria\n\n\nRelecture jusqu‚Äôaux API (#439)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\na63319a\n\n\n2023-10-04 15:29:04\n\n\nLino Galiana\n\n\nCorrection du TP numpy (#419)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n130ed71\n\n\n2023-07-18 19:37:11\n\n\nLino Galiana\n\n\nRestructure les titres (#374)\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nef28fef\n\n\n2023-07-07 08:14:42\n\n\nLino Galiana\n\n\nListing pour la premi√®re partie (#369)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n62aeec1\n\n\n2023-06-10 17:40:39\n\n\nLino Galiana\n\n\nAvertissement sur la partie API (#358)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\n3c880d5\n\n\n2022-12-27 17:34:59\n\n\nLino Galiana\n\n\nChapitre regex + Change les boites dans plusieurs chapitres (#339)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\n2dc82e7\n\n\n2022-10-18 22:46:47\n\n\nLino Galiana\n\n\nRelec Kim (visualisation + API) (#302)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n1239e3e\n\n\n2022-06-21 14:05:15\n\n\nLino Galiana\n\n\nEnonces (#239)\n\n\n\n\nbb38643\n\n\n2022-06-08 16:59:40\n\n\nLino Galiana\n\n\nR√©pare bug leaflet (#234)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n1ca1a8a\n\n\n2022-05-31 11:44:23\n\n\nLino Galiana\n\n\nRetour du chapitre API (#228)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/manipulation/04c_API_TP.html#footnotes",
    "href": "content/manipulation/04c_API_TP.html#footnotes",
    "title": "R√©cup√©rer des donn√©es avec des API depuis Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLa documentation est √©galement disponible ici‚Ü©Ô∏é\nLe JSON est un format tr√®s appr√©ci√© dans le domaine du big data\ncar il permet d‚Äôempiler des donn√©es\nqui ne sont pas compl√®tes. Il\ns‚Äôagit d‚Äôun des formats privil√©gi√©s du paradigme No-SQL pour lequel\ncet excellent cours propose plus de d√©tails.‚Ü©Ô∏é\nSuivant les API, nous avons soit besoin de rien de plus si nous parvenons directement √† obtenir un json, soit devoir utiliser un parser comme BeautifulSoup dans le cas contraire. Ici, le JSON peut √™tre format√© relativement ais√©ment.‚Ü©Ô∏é",
    "crumbs": [
      "R√©cup√©rer des donn√©es avec des API depuis Python"
    ]
  },
  {
    "objectID": "content/visualisation/index.html",
    "href": "content/visualisation/index.html",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "",
    "text": "Une partie essentielle du travail du data scientist\nconsiste √† synth√©tiser l‚Äôinformation que\ncontient ses\njeux de donn√©es afin de distinguer\nce qui rel√®ve du signal, sur lequel il\npourra se concentrer, et ce qui rel√®ve\ndu bruit\ninh√©rent √† tout jeu de donn√©es.\nDans le travail du data scientist, lors d‚Äôune phase\nexploratoire, il y a\ndonc un aller-retour constant entre information synth√©tique\net jeu de donn√©es d√©sagr√©g√©. Il\nest ainsi essentiel de savoir synth√©tiser l‚Äôinformation\ndans un jeu de donn√©es avant d‚Äôen saisir la structure, cette\nderni√®re pouvant ensuite guider les exploitations ult√©rieures,\npour une phase de mod√©lisation ou de correction de\ndonn√©es (d√©tection d‚Äôanomalies ou de mauvaises remont√©es de donn√©es).\nNous avons d√©j√† explor√© une partie essentielle de ce travail,\n√† savoir la construction de statistiques descriptives pertinentes\net fiables. N√©anmoins, si on se contentait de pr√©senter l‚Äôinformation\nen utilisant des sorties brutes issues du combo groupby et agg\nsur un DataFrame Pandas, notre connaissance des donn√©es serait assez\nlimit√©e. La mise en oeuvre de tableaux stylis√©s √† partir\nde great tables constituait d√©j√† un progr√®s dans cette d√©marche mais, en v√©rit√©,\nnotre cerveau se repr√©sente l‚Äôinformation de mani√®re beaucoup plus intuitive\npar le biais de visualisations graphiques simples.\n\n\nEn tant qu‚Äôhumains,\nnos\ncapacit√©s cognitives √©tant limit√©es, nous ne pouvons\nappr√©hender qu‚Äôune information limit√©e l√† o√π l‚Äôordinateur est capable de traiter\nde grands volumes d‚Äôinformation. En tant que data scientist, cela signifie\nqu‚Äôutiliser nos comp√©tences informatiques et statistiques pour obtenir\ndes repr√©sentations synth√©tiques de nos nombreux jeux de donn√©es est\nessentiel pour √™tre en mesure de r√©pondre √† nos besoins op√©rationnels ou\nstatistiques.\nL‚Äôensemble des m√©thodes et des outils qui constituent la bo√Æte √† outil\ndes data scientists vise √† simplifier l‚Äôappr√©hension puis l‚Äôexploitation\nde jeux de donn√©es dont le volume d√©passe nos capacit√©s cognitives.\nCeci nous entra√Æne vers la question de la visualisation des donn√©es,\nun ensemble d‚Äôoutils et de principes pour repr√©senter de mani√®re\nsynth√©tique des faits stylis√©s ou contextualiser une donn√©e individuelle.\nLa visualisation de donn√©es est l‚Äôart et la science de repr√©senter visuellement des informations complexes et abstraites √† l‚Äôaide d‚Äô√©l√©ments visuels.\nSon objectif principal est de synth√©tiser l‚Äôinformation pr√©sente dans un ensemble de donn√©es afin de faciliter\nla compr√©hension des enjeux de celle-ci pour une analyse ult√©rieure.\nLa visualisation de donn√©es permet, entre autres, de mettre en √©vidence des tendances, des corr√©lations ou\ndes anomalies qui pourraient √™tre difficiles voire impossibles √† saisir simplement en examinant des donn√©es brutes, ces derni√®res n√©cessitant\nune certaine mise en contexte pour porter du sens.\nLa visualisation de donn√©es joue un r√¥le crucial dans le\nprocessus d‚Äôanalyse de donn√©es en fournissant des moyens visuels pour explorer, interpr√©ter et communiquer des informations.\nElle facilite la communication entre experts de la donn√©es, d√©cideurs et grand public,\nen permettant de raconter des histoires bas√©es sur les donn√©es de mani√®re plus convaincante et engageante.\n\n\n\nLa visualisation des donn√©es n‚Äôest pas restreinte √† la phase finale d‚Äôun projet,\n√† la communication de r√©sultats √† une audience qui n‚Äôa pas acc√®s √† la donn√©e\nou n‚Äôa pas les moyens de la valoriser.\nLa visualisation intervient √† toutes les √©tapes du processus de valorisation\nde la donn√©e. Il s‚Äôagit d‚Äôailleurs d‚Äôun travail essentiel pour trouver\ncomment basculer de l‚Äôenregistrement, un instantan√© d‚Äôun ph√©nom√®ne, √† une donn√©e,\nun enregistrement qui a une valeur parce qu‚Äôil porte une information en tant que telle\nou lorsqu‚Äôil est combin√© avec d‚Äôautres enregistrements.\nLe travail quotidien du data scientist\nconsiste √† regarder un jeu de donn√©es sous toutes ses coutures\npour identifier les axes prioritaires d‚Äôextraction de valeur.\nSavoir rapidement quelles statistiques repr√©senter, et comment,\nest essentiel pour gagner du temps sur cette partie exploratoire.\nIl s‚Äôagit principalement d‚Äôun travail de communication envers soi-m√™me\nqui peut se permettre d‚Äô√™tre brouillon car il s‚Äôagit de d√©grossir\nle travail avant de polir certains angles. L‚Äôenjeu √† ce niveau du\nprocessus est de ne pas manquer une dimension qui pourrait √™tre\nporteuse de valeur.\nLe travail de communication r√©ellement chronophage intervient plut√¥t\nlorsqu‚Äôon communique √† une audience ayant un acc√®s limit√© √† des\ndonn√©es, ne connaissant pas bien les sources, ayant\nun temps d‚Äôattention sur limit√©\nou n‚Äôayant pas des comp√©tences quantitatives. Ces\npublics ne peuvent se satisfaire d‚Äôune sortie brute comme\nun DataFrame dans un notebook ou un graphique produit\nen quelques secondes avec la m√©thode plot de Pandas.\nIl convient de s‚Äôadapter √† leurs attentes, qui √©voluent,\net aux outils qu‚Äôils connaissent, d‚Äôo√π la place de plus en\nplus importante prise par les sites\nweb de data visualisations.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#la-visualisation-des-donn√©es-une-part-essentiel-du-travail-de-communication",
    "href": "content/visualisation/index.html#la-visualisation-des-donn√©es-une-part-essentiel-du-travail-de-communication",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "",
    "text": "En tant qu‚Äôhumains,\nnos\ncapacit√©s cognitives √©tant limit√©es, nous ne pouvons\nappr√©hender qu‚Äôune information limit√©e l√† o√π l‚Äôordinateur est capable de traiter\nde grands volumes d‚Äôinformation. En tant que data scientist, cela signifie\nqu‚Äôutiliser nos comp√©tences informatiques et statistiques pour obtenir\ndes repr√©sentations synth√©tiques de nos nombreux jeux de donn√©es est\nessentiel pour √™tre en mesure de r√©pondre √† nos besoins op√©rationnels ou\nstatistiques.\nL‚Äôensemble des m√©thodes et des outils qui constituent la bo√Æte √† outil\ndes data scientists vise √† simplifier l‚Äôappr√©hension puis l‚Äôexploitation\nde jeux de donn√©es dont le volume d√©passe nos capacit√©s cognitives.\nCeci nous entra√Æne vers la question de la visualisation des donn√©es,\nun ensemble d‚Äôoutils et de principes pour repr√©senter de mani√®re\nsynth√©tique des faits stylis√©s ou contextualiser une donn√©e individuelle.\nLa visualisation de donn√©es est l‚Äôart et la science de repr√©senter visuellement des informations complexes et abstraites √† l‚Äôaide d‚Äô√©l√©ments visuels.\nSon objectif principal est de synth√©tiser l‚Äôinformation pr√©sente dans un ensemble de donn√©es afin de faciliter\nla compr√©hension des enjeux de celle-ci pour une analyse ult√©rieure.\nLa visualisation de donn√©es permet, entre autres, de mettre en √©vidence des tendances, des corr√©lations ou\ndes anomalies qui pourraient √™tre difficiles voire impossibles √† saisir simplement en examinant des donn√©es brutes, ces derni√®res n√©cessitant\nune certaine mise en contexte pour porter du sens.\nLa visualisation de donn√©es joue un r√¥le crucial dans le\nprocessus d‚Äôanalyse de donn√©es en fournissant des moyens visuels pour explorer, interpr√©ter et communiquer des informations.\nElle facilite la communication entre experts de la donn√©es, d√©cideurs et grand public,\nen permettant de raconter des histoires bas√©es sur les donn√©es de mani√®re plus convaincante et engageante.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#la-place-de-la-visualisation-dans-le-processus-de-valorisation-de-la-donn√©e",
    "href": "content/visualisation/index.html#la-place-de-la-visualisation-dans-le-processus-de-valorisation-de-la-donn√©e",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "",
    "text": "La visualisation des donn√©es n‚Äôest pas restreinte √† la phase finale d‚Äôun projet,\n√† la communication de r√©sultats √† une audience qui n‚Äôa pas acc√®s √† la donn√©e\nou n‚Äôa pas les moyens de la valoriser.\nLa visualisation intervient √† toutes les √©tapes du processus de valorisation\nde la donn√©e. Il s‚Äôagit d‚Äôailleurs d‚Äôun travail essentiel pour trouver\ncomment basculer de l‚Äôenregistrement, un instantan√© d‚Äôun ph√©nom√®ne, √† une donn√©e,\nun enregistrement qui a une valeur parce qu‚Äôil porte une information en tant que telle\nou lorsqu‚Äôil est combin√© avec d‚Äôautres enregistrements.\nLe travail quotidien du data scientist\nconsiste √† regarder un jeu de donn√©es sous toutes ses coutures\npour identifier les axes prioritaires d‚Äôextraction de valeur.\nSavoir rapidement quelles statistiques repr√©senter, et comment,\nest essentiel pour gagner du temps sur cette partie exploratoire.\nIl s‚Äôagit principalement d‚Äôun travail de communication envers soi-m√™me\nqui peut se permettre d‚Äô√™tre brouillon car il s‚Äôagit de d√©grossir\nle travail avant de polir certains angles. L‚Äôenjeu √† ce niveau du\nprocessus est de ne pas manquer une dimension qui pourrait √™tre\nporteuse de valeur.\nLe travail de communication r√©ellement chronophage intervient plut√¥t\nlorsqu‚Äôon communique √† une audience ayant un acc√®s limit√© √† des\ndonn√©es, ne connaissant pas bien les sources, ayant\nun temps d‚Äôattention sur limit√©\nou n‚Äôayant pas des comp√©tences quantitatives. Ces\npublics ne peuvent se satisfaire d‚Äôune sortie brute comme\nun DataFrame dans un notebook ou un graphique produit\nen quelques secondes avec la m√©thode plot de Pandas.\nIl convient de s‚Äôadapter √† leurs attentes, qui √©voluent,\net aux outils qu‚Äôils connaissent, d‚Äôo√π la place de plus en\nplus importante prise par les sites\nweb de data visualisations.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#les-packages-de-visualisations-de-donn√©es",
    "href": "content/visualisation/index.html#les-packages-de-visualisations-de-donn√©es",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "4.1 Les packages de visualisations de donn√©es",
    "text": "4.1 Les packages de visualisations de donn√©es\nL‚Äô√©cosyst√®me Python pour la visualisation de donn√©es est tr√®s riche et\ntr√®s √©clat√©.\nIl est\npossible de consacrer des livres entiers √† celui-ci (Dale 2022).\nPython propose\nde nombreuses librairies pour produire de mani√®re rapide et relativement\nsimple des visualisations de donn√©es1.\nLes librairies graphiques se distinguent principalement en deux familles:\n\nLes librairies de repr√©sentations fig√©es. Celles-ci ont plut√¥t vocation √† √™tre int√©gr√©es\ndans des publications fig√©es type PDF ou documents texte. Nous pr√©senterons\nprincipalement Matplotlib et Seaborn mais il en existe d‚Äôautres, en pleine √©mergence,\ncomme Plotnine, l‚Äôadaptation de ggplot2 √† l‚Äô√©cosyst√®me Python.\nLes librairies de repr√©sentations r√©actives. Celles-ci sont adapt√©es √† des repr√©sentations\nweb et offrent la possibilit√© aux lecteurs d‚Äôagir sur la repr√©sentation graphique affich√©e.\nLes librairies qui proposent ces fonctionnalit√©s reposent g√©n√©ralement sur JavaScript, l‚Äô√©cosyst√®me\ndu d√©veloppement web, pour lequel elles offrent un point d‚Äôentr√©e via Python.\nNous √©voquerons principalement Plotly et Folium dans cette famille mais il existe de nombreux\nautres frameworks dans ce domaine2.\n\nIl est tout √† fait possible\nde faire des visualisations sophistiqu√©es avec\nune chaine de bout en bout Python puisqu‚Äôil s‚Äôagit d‚Äôun langage couteau-suisse\ndont l‚Äô√©cosyst√®me est tr√®s\nriche. N√©anmoins, Python n‚Äôest pas la panac√©e et il peut parfois\n√™tre utile, pour obtenir un produit fini parfaitement poli,\nde finaliser le travail avec d‚Äôautres langages, comme Javascript\npour les visualisations r√©actives ou QGIS pour le\ntravail cartographique. Ce cours donnera les outils minimums\npour faire un travail rapide et plaisant mais le diable √©tant dans\nles d√©tails, il ne faut pas s‚Äôarcbouter √† vouloir utiliser\nPython pour tout et n‚Äôimporte quoi.\nDans le domaine de la visualisation, ce cours adopte le parti pris\nd‚Äôexplorer quelques\nlibrairies centrales √† partir d‚Äôun nombre restreint d‚Äôexemples en\nr√©pliquant des graphiques qu‚Äôon peut trouver sur le site d‚Äôopen data de la\nmairie de Paris.\nLa meilleure √©cole pour la visualisation restant\nla pratique sur des jeux de donn√©es, il est recommand√© d‚Äôexplorer la richesse\nde l‚Äô√©cosyst√®me de l‚Äôopen data pour exp√©rimenter des visualisations.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#les-applications-de-visualisation",
    "href": "content/visualisation/index.html#les-applications-de-visualisation",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "4.2 Les applications de visualisation",
    "text": "4.2 Les applications de visualisation\nCette partie du cours se focalise sur des repr√©sentations synth√©tiques simples.\nElle n‚Äô√©voque pas (encore ?) la construction d‚Äôapplications de visualisation\nde donn√©es o√π un ensemble de graphiques se mettent √† jour de mani√®re synchrone\nen fonction d‚Äôactions d‚Äôutilisateurs.\nCeci d√©passe en effet le cadre d‚Äôun cours d‚Äôintroduction car construire\nces applications\nimpliquent\nde ma√Ætriser des concepts plus complexes comme l‚Äôinteraction entre une page\nweb et un serveur, d‚Äôavoir des rudiments de connaissance en Linux, etc.\nLes concepts n√©cessaires √† la compr√©hension de ces outils sont au coeur\ndu cours de 3e ann√©e ‚ÄúMise en production de projets de data science‚Äù\nque Romain Avouac donnons en 3e ann√©e d‚ÄôENSAE.\nN√©anmoins, comme la valorisation de donn√©es sous une forme applicative est tr√®s\ncommune, il\nil est utile a minima d‚Äô√©voquer la dualit√© entre sites statiques\net applications dynamiques afin de donner les bons gestes et pointer vers les\noutils ad√©quat.\nDans le monde de l‚Äôapplicatif, il est important de distinguer le front (la page\nvisible par les utilisateurs de l‚Äôapplication) du back office (le moteur\nqui effectue des actions en fonction des param√®tres choisis par l‚Äôutilisateur\nde la page).\nIl existe principalement deux paradigmes pour faire\ninteragir ces deux √©l√©ments. La distinction principale entre ces deux approches est qu‚Äôelles s‚Äôappuient sur des serveurs diff√©rents. Un site statique repose sur un serveur web l√† o√π Streamlit s‚Äôappuie sur serveur classique en backend. La diff√©rence principale entre ces deux types de serveurs r√©side principalement dans leur fonction et leur utilisation:\n\nUn serveur web est sp√©cifiquement con√ßu pour stocker, traiter et livrer des pages web (le front) aux clients. Cela inclut des fichiers HTML, CSS, JavaScript, images, etc. Les serveurs web √©coutent les requ√™tes HTTP/HTTPS provenant des navigateurs des utilisateurs et y r√©pondent en envoyant les donn√©es demand√©es. Cela n‚Äôemp√™che pas d‚Äôavoir des √©tapes complexes de valorisation de donn√©es, ni de la r√©activit√© en embarquant du Javascript dans l‚Äôapplication mais les √©tapes de traitement en Python sont faites en amont de la mise √† disposition de l‚Äôapplication. Pour les utilisateurs de Python, il existe plusieurs constructeurs de sites statiques avant une mise √† disposition par le biais d‚Äôun h√©bergement sur Github Pages. Les deux √©cosyst√®mes les plus communs sont Quarto Markdown et Django, le premier √©tant plus simple d‚Äôusage et de maintenance que le second. Ce site, par exemple, est construit gr√¢ce √† Quarto ce qui assure la reproductibilit√© des exemples pr√©sent√©s et une mise en forme ergonomique et param√©trable des r√©sultats.\n\nUn serveur backend classique est con√ßu pour effectuer des op√©rations en r√©ponse √† un front, en l‚Äôoccurrence une page web. Dans le contexte d‚Äôune application construite avec Python, il s‚Äôagit d‚Äôun serveur avec l‚Äôenvironnement Python ad hoc pour ex√©cuter le code n√©cessaire √† r√©pondre √† toute action d‚Äôun utilisateur de l‚Äôapplication. Le code est ex√©cut√© √† la vol√©e et non une fois pour toute comme dans l‚Äôapproche pr√©c√©dente. Il s‚Äôagit donc d‚Äôun paradigme pouvant permettre plus de complexit√© applicative mais repr√©sentant un d√©fi suppl√©mentaire lors de la phase de mise en production. Dans l‚Äô√©cosyst√®me Python, les deux principaux outils permettant de construire de telles applications sont Streamlit et Dash, le premier √©tant plus rapide √† mettre en oeuvre que le second. Plus r√©cemment, l‚Äô√©cosyst√®me √©quivalent dominant en R, Shiny a √©t√© adapt√© en Python par Posit.\n\n\n\n\n\n\n\nFait-on toujours du tkinter ?\n\n\n\n\n\nLes √©cosyst√®mes pr√©sent√©s ci-dessus pour les applications r√©actives sont des frameworks web. Il se distinguent des clients lourds comme tkinter,\nl‚Äôoutil historique pour faire des interfaces graphiques. Outre l‚Äôaspect plus rudimentaire des\ninterfaces tkinter par rapport √† celles de Streamlit, Dash ou Shiny, il existe\ndes raisons fortes pour privil√©gier ces derniers √† tkinter.\nCe dernier est un client lourd. Autrement dit, il est adh√©rent √† un syst√®me d‚Äôexploitation\net √† des installations de packages en amont du fonctionnement de l‚Äôinterface.\nIl est bien s√ªr possible de rendre portable celle-ci mais, comme cela est d√©velopp√©\ndans le cours de mise en production,\nil y a de nombreuses raisons pour lesquelles cette approche peut provoquer des erreurs\nou des bugs inattendus. Les frameworks web pr√©sentent l‚Äôint√©r√™t de simplifier\ncette mise √† disposition en dissociant le front (des pages HTML et du CSS) du back (du\ncode Python). Ils se sont donc impos√©s naturellement m√™me si on retrouve encore beaucoup\nde ressources en ligne dat√©es sur le d√©veloppement d‚Äôapplications avec tkinter.\n\n\n\nEn ce qui concerne la construction d‚Äôapplications, le premier r√©flexe\n√† avoir est: ‚Äúai-je besoin de faire une application r√©active ou un site\nstatique ne suffit-il pas ?‚Äù. Ce dernier √©tant beaucoup plus facile √†\nmettre en oeuvre et ayant une charge de maintenance minimale, c‚Äôest souvent\nun choix rationnel. S‚Äôil devient complexe de faire un site statique, par\nexemple parce qu‚Äôils impliquent des calculs sophistiqu√©s qu‚Äôil serait\ncomplexe de mettre en oeuvre sans comp√©tences JavaScript, on peut alors\nse poser la question de la s√©paration entre front et back\nen reportant les calculs vers une API, construite par exemple par le biais de FastAPI. Il s‚Äôagit, par exemple, d‚Äôune m√©thode pratique pour mettre\n√† disposition un mod√®le de machine learning comme le\ndernier chapitre\nde la partie mod√©lisation l‚Äô√©voquera. Si la mise en oeuvre d‚Äôune API\nest compliqu√©e ou bien est un bazooka pour tuer une mouche,\nalors on pourra aller vers une application r√©active du type\nde Streamlit.\nEncore une fois, la construction d‚Äôune application fait\nappel √† des concepts qui d√©passent\nun niveau introductif en Python. Avoir conscience des bons r√©flexes\npeut n√©anmoins faire √©conomiser un temps non n√©gligeable en √©vitant de patauger\ndans la semoule √† cause d‚Äôun mauvais choix initial.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#r√©sum√©-de-cette-partie",
    "href": "content/visualisation/index.html#r√©sum√©-de-cette-partie",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "4.3 R√©sum√© de cette partie",
    "text": "4.3 R√©sum√© de cette partie\nPour en revenir au contenu de cette partie apr√®s cet apart√©, celle-ci\nest divis√©e en deux et chaque chapitre est lui-m√™me\ndual, selon qu‚Äôon s‚Äôint√©resse aux repr√©sentations fig√©es\nou dynamiques :\n\nDans un premier temps, nous √©voquerons des\nrepr√©sentations graphiques standards (histogrammes, diagrammes\nen barre‚Ä¶) pour synth√©tiser certaines informations quantitatives ;\n\nLes repr√©sentations fixes reposeront sur Pandas, Matplotlib et Seaborn\nLes graphiques r√©actifs s‚Äôappuieront sur Plotly\n\nDans un deuxi√®me temps, nous pr√©senterons les repr√©sentations\ncartographiques:\n\nLes cartes fixes avec Geopandas ou Geoplot\nLes cartes r√©actives avec Folium (adaptation Python de la librairie Leaflet.js)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#r√©f√©rences-utiles",
    "href": "content/visualisation/index.html#r√©f√©rences-utiles",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "4.4 R√©f√©rences utiles",
    "text": "4.4 R√©f√©rences utiles\nLa visualisation de donn√©es est un art qui s‚Äôapprend, au d√©but, principalement\npar la pratique. N√©anmoins, il n‚Äôest pas √©vident de produire\ndes visualisations lisibles et ergonomiques\net il est utile de s‚Äôinspirer d‚Äôexemples de\nsp√©cialistes (les grands titres de presse disposent d‚Äôexcellentes visualisations).\nVoici quelques ressources utiles sur ces sujets :\n\nDatawrapper propose un excellent blog sur les\nbonnes pratiques de visualisation, notamment\navec les articles de Lisa Charlotte Muth. Je recommande notamment cet article sur\nles couleurs ou\ncelui-ci sur les textes ;\nLe blog d‚ÄôEric Mauvi√®re ;\n‚ÄúLa S√©miologie graphique de Jacques Bertin a cinquante ans‚Äù ;\nLes visualisations trending sur Observable ;\nLe New York Times (les rois de la dataviz) revient tous les ans sur les meilleures visualisations\nde l‚Äôann√©e dans la veine du data scrollytelling. Voir par exemple la r√©trospective de l‚Äôann√©e 2022.\n\n\n\n\n\n\n\nQuelques ressources sur Streamlit ou Dash\n\n\n\nOutre notre cours de 3e ann√©e,\nle lab de data science de l‚ÄôInsee a construit de nombreux tutoriels\npour s‚Äôappropier les √©cosyst√®mes d‚Äôapplications r√©actives en Python qui\nsont l‚Äôun des produits les plus attractifs de l‚Äô√©cosyst√®me Python.\nVoici par exemple un tutoriel 101 tr√®s d√©taill√© sur Streamlit permettant de cr√©er une application type Yuka\nsur les donn√©es de l‚Äôopenfoodfacts.\n\n\nEt quelques r√©f√©rences suppl√©mentaires, cit√©es dans cette introduction :\n\n\nBertin, Jacques. 1967. S√©miologie Graphique. Paris: Mouton/Gauthier-Villars.\n\n\nDale, Kyran. 2022. Data Visualization with Python and JavaScript. \" O‚ÄôReilly Media, Inc.\".\n\n\nPalsky, Gilles. 2017. ‚ÄúLa s√©miologie Graphique de Jacques Bertin a Cinquante Ans.‚Äù Visions Carto (En Ligne).\n\n\nWilke, Claus O. 2019. Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O‚ÄôReilly Media.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#informations-additionnelles",
    "href": "content/visualisation/index.html#informations-additionnelles",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd02515b\n\n\n2024-04-27 21:32:25\n\n\nLino Galiana\n\n\nEl√©ments sur les applis & √©valuation (#495)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n2dc82e7\n\n\n2022-10-18 22:46:47\n\n\nLino Galiana\n\n\nRelec Kim (visualisation + API) (#302)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\na4e2426\n\n\n2022-06-16 19:34:18\n\n\nLino Galiana\n\n\nImprove style (#238)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n66a5276\n\n\n2021-11-23 16:13:20\n\n\nLino Galiana\n\n\nRelecture partie visualisation (#181)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n5ac3cbe\n\n\n2020-09-28 18:59:24\n\n\nLino Galiana\n\n\nContinue la partie graphiques (#54)\n\n\n\n\n8ed01f4\n\n\n2020-09-24 21:27:29\n\n\nLino Galiana\n\n\nAjout d‚Äôune partie visualisation\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nUn exemple de deux visualisations faites sur le m√™me jeu de donn√©es par Eric Mauvi√®re, voir Note¬†2.1",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/index.html#footnotes",
    "href": "content/visualisation/index.html#footnotes",
    "title": "Partie 2: communiquer √† partir de donn√©es",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour √™tre honn√™te, pendant longtemps Python a √©t√© sur ce point un peu moins agr√©able\nque R qui b√©n√©ficie de\nl‚Äôincontournable librairie ggplot2.\nN‚Äô√©tant pas\nconstruite sur la grammaire des graphiques,\nla principe librairie de graphiques en Python qu‚Äôest Matplotlib est plus fastidieuse\n√† utiliser que ggplot2.\nseaborn, que nous pr√©senterons,\nfacilite un peu le travail de repr√©sentation graphique mais, l√† encore, il est difficile de faire\nplus mall√©able et universel que ggplot2.\nLa librairie plotnine vise √† proposer une impl√©mentation similaire\n√† ggplot pour les utilisateurs de Python. Son d√©veloppement est √† suivre.‚Ü©Ô∏é\nA cet √©gard, je recommande vivement de suivre l‚Äôactualit√© de la dataviz\nsur la plateforme Observable qui tend √†\nrapprocher les communaut√©s des sp√©cialistes de la dataviz et des analystes\nde donn√©es. La librairie Plot pourrait devenir\nun nouveau standard dans les prochaines ann√©es, sorte d‚Äôinterm√©diaire\nentre ggplot et d3.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/visualisation/maps.html",
    "href": "content/visualisation/maps.html",
    "title": "De belles cartes avec python : mise en pratique",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nLa pratique de la cartographie se fera, dans ce cours, en r√©pliquant des cartes qu‚Äôon peut trouver sur\nla page de l‚Äôopen-data de la ville de Paris\nici.\nNote\nProduire de belles cartes demande du temps mais aussi du bon sens. En fonction de la structure des donn√©es, certaines repr√©sentations sont √† √©viter voire √† exclure. L‚Äôexcellent guide disponible ici propose quelques r√®gles et √©voque les erreurs √† √©viter lorsqu‚Äôon d√©sire effectuer des\nrepr√©sentations spatiales.\nCelui-ci reprend un guide de s√©miologie cartographique\nproduit par l‚ÄôInsee qui propose de nombreux conseils pratiques pour produire des repr√©sentations\ncartographiques sens√©es.\nCe TP vise √† initier :\nLes donn√©es utilis√©es sont :\nAttention\nCertaines librairies g√©ographiques d√©pendent de rtree qui est parfois difficile √† installer car\nce package d√©pend de librairies compil√©es qui sont compliqu√©es √† installer sur Windows.\nPour installer rtree sur Windows, le mieux est d‚Äôutiliser Anaconda.\nAvant de pouvoir commencer, il est n√©cessaire d‚Äôinstaller quelques\npackages au pr√©alable:\n# Sur colab\n!pip install pandas fiona shapely pyproj rtree # √† faire obligatoirement en premier pour utiliser rtree ou pygeos pour les jointures spatiales\n!pip install contextily\n!pip install geopandas\n!pip install geoplot\nDans la premi√®re partie, nous allons utiliser les packages suivants :\nimport pandas as pd\nimport geopandas as gpd\nimport contextily as ctx\nimport geoplot\nimport matplotlib.pyplot as plt\nimport folium\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed",
    "crumbs": [
      "De belles cartes avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/maps.html#densit√©-de-population-dans-la-petite-couronne-parisienne",
    "href": "content/visualisation/maps.html#densit√©-de-population-dans-la-petite-couronne-parisienne",
    "title": "De belles cartes avec python : mise en pratique",
    "section": "3.1 Densit√© de population dans la petite couronne parisienne",
    "text": "3.1 Densit√© de population dans la petite couronne parisienne\nPour cet exercice, le package cartiflette\nva √™tre pratique pour r√©cup√©rer un fonds de carte m√©langeant arrondissements\nparisiens et communes dans les autres villes.\nNous allons privil√©gier une carte √† ronds proportionnels (bubble map)\naux cartes chorol√®pthes qui trompent\nl‚Äôoeil.\n\n\n Exercice: bubble map de densit√© des populations\n\nR√©cup√©rer le fond de carte des d√©partements 75, 92, 93 et 94\navec cartiflette. Pour cela, utiliser carti_download\ndepuis cartiflette en fixant l‚Äôoption borders √† COMMUNE_ARRONDISSEMENT.\nNommer cet objet df.\nAfin que les calculs ult√©rieurs de surface ne soient pas fauss√©s,\nassurez-vous que les donn√©es sont en Lambert 93 en reprojetant\nnos contours (code EPSG: 2154).\nCr√©er un objet departements avec dissolve pour √©galement disposer\nd‚Äôun fond de carte des d√©partements\nCr√©er une variable surface et utilisant la m√©thode area. L‚Äôunit√©\ndoit √™tre le km¬≤, il faut donc diviser par \\(10^6\\)\nCr√©er une variable densite\nUtiliser pd.cut avec les seuils 5000, 15000 et 30000 personnes\npar km¬≤. Vous pouvez utiliser l‚Äôoption label pour d√©nommer les tranches\nCr√©er un GeoDataFrame de points en utilisant la m√©thode centroid. Celui-ci\nnous servira √† localiser le centre de nos ronds.\nRepr√©senter la densit√© communale sous forme de carte avec ronds proportionnels.\nVous pouvez utiliser la variable cr√©√©e √† la question 5 pour les couleurs.\n\n\n\nLa carte obtenue devrait ressembler √† celle-ci :\n\n\nText(0.3, 0.15, 'Source: IGN - AdminExpress')",
    "crumbs": [
      "De belles cartes avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/visualisation/maps.html#informations-additionnelles",
    "href": "content/visualisation/maps.html#informations-additionnelles",
    "title": "De belles cartes avec python : mise en pratique",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\nce33d5d\n\n\n2024-01-16 15:47:22\n\n\nLino Galiana\n\n\nAdapte les exemples de code de cartiflette (#482)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\nad654c5\n\n\n2023-10-10 14:23:05\n\n\nlinogaliana\n\n\nCQuick fix gzip csv\n\n\n\n\n1c64660\n\n\n2023-10-04 15:52:52\n\n\nLino Galiana\n\n\nQuick fix remove contextily (#420)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\nc7f8c94\n\n\n2023-09-01 09:27:43\n\n\nLino Galiana\n\n\nAjoute un champ citation (#403)\n\n\n\n\n17a238f\n\n\n2023-08-30 15:06:18\n\n\nLino Galiana\n\n\nNouvelles donn√©es compteurs (#402)\n\n\n\n\n0035b74\n\n\n2023-08-29 14:51:26\n\n\nLino Galiana\n\n\nTemporary fix for cartography pipeline (#401)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n8df7cb2\n\n\n2023-07-20 17:16:03\n\n\nlinogaliana\n\n\nChange link\n\n\n\n\nf0c583c\n\n\n2023-07-07 14:12:22\n\n\nLino Galiana\n\n\nImages viz (#371)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\nb0abd02\n\n\n2022-12-12 07:57:22\n\n\nLino Galiana\n\n\nFix cartiflette in additional exercise (#334)\n\n\n\n\ne56f6fd\n\n\n2022-12-03 17:00:55\n\n\nLino Galiana\n\n\nCorrige typos exo compteurs (#329)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n66a5276\n\n\n2021-11-23 16:13:20\n\n\nLino Galiana\n\n\nRelecture partie visualisation (#181)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n2924215\n\n\n2020-10-08 13:35:18\n\n\nLino Galiana\n\n\nmodif slug cartographie\n\n\n\n\n6477687\n\n\n2020-10-08 13:31:00\n\n\nLino Galiana\n\n\nVisualisation cartographique (#68)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "De belles cartes avec python : mise en pratique"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html",
    "href": "content/modelisation/0_preprocessing.html",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise le jeu de donn√©es pr√©sent√© dans l‚Äôintroduction\nde cette partie :\nles donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines de 2020 au niveau des comt√©s\ncrois√©es √† des variables socio-d√©mographiques.\nLe code de consitution de la base de donn√©es\nest disponible sur Github.\nL‚Äôexercice 1 permet, √† ceux qui le d√©sirent, d‚Äôessayer de le reconstituer pas √† pas.\nLe guide utilisateur de Scikit est une r√©f√©rence pr√©cieuse,\n√† consulter r√©guli√®rement. La partie sur le preprocessing est\ndisponible ici.\nL‚Äôobjectif de ce chapitre est de pr√©senter quelques √©l√©ments de\npr√©paration des donn√©es. Il s‚Äôagit d‚Äôune √©tape fondamentale, √† ne\npas n√©gliger. Les mod√®les reposent sur certaines hypoth√®ses, g√©n√©ralement\nrelatives √† la distribution th√©orique des variables qui y sont int√©gr√©es.\nIl est n√©cessaire de faire correspondre la distribution empirique\n√† ces hypoth√®ses, ce qui implique un travail de restructuration des donn√©es.\nCelui-ci permettra d‚Äôavoir des r√©sultats de mod√©lisation plus pertinents.\nNous verrons dans le chapitre sur les pipelines comment industrialiser\nces √©tapes de preprocessing afin de se simplifier la vie pour appliquer\nun mod√®le sur un jeu de donn√©es diff√©rent de celui sur lequel il a √©t√© estim√©.\nScikit-Learn \nscikit-learn est aujourd‚Äôhui la librairie de r√©f√©rence dans l‚Äô√©cosyst√®me du\nMachine Learning. Il s‚Äôagit d‚Äôune librairie qui, malgr√© les tr√®s nombreuses\nm√©thodes impl√©ment√©es, pr√©sente l‚Äôavantage d‚Äô√™tre un point d‚Äôentr√©e unifi√©.\nCet aspect unifi√© est l‚Äôune des raisons du succ√®s pr√©coce de celle-ci. R n‚Äôa\nb√©n√©fici√© que plus r√©cemment d‚Äôune librairie unifi√©e,\n√† savoir tidymodels.\nUne autre raison du succ√®s de scikit est son approche op√©rationnelle : la mise\nen production de mod√®les d√©velopp√©s via les pipelines scikit est peu co√ªteuse.\nUn chapitre sp√©cial de ce cours est d√©di√© aux pipelines.\nAvec Romain Avouac, nous proposons un cours plus avanc√©\nen derni√®re ann√©e d‚ÄôENSAE o√π nous pr√©sentons certains enjeux relatifs\n√† la mise en production de mod√®les d√©velopp√©s avec scikit.\nLe coeur de l‚Äô√©quipe de d√©veloppement de scikit-learn est situ√©\n√† l‚ÄôInria üá´üá∑.\nPour d√©couvrir la richesse de l‚Äô√©cosyst√®me scikit, il\nest recommand√© de suivre le\nMOOC scikit,\nd√©velopp√© dans le cadre de l‚Äôinitiative Inria Academy.\nLes packages suivants sont n√©cessaires pour importer et visualiser\nles donn√©es d‚Äô√©lection :\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nDans ce chapitre, nous allons nous focaliser sur la pr√©paration\ndes donn√©es √† faire en amont du travail de mod√©lisation.\nCette √©tape est indispensable pour s‚Äôassurer de la coh√©rence\nentre les donn√©es et les hypoth√®ses de mod√©lisation mais aussi\npour produire des analyses valides scientifiquement.\nLa d√©marche g√©n√©rale que nous adopterons dans ce chapitre, et\nqui sera ensuite raffin√©e dans les prochains chapitres,\nest la suivante :\nC‚Äôest l‚Äôapproche classique du machine learning. On d√©coupe\nl‚Äôensemble des donn√©es disponibles en deux parties, √©chantillons\nd‚Äôapprentissage et de validation. Le premier sert √† entra√Æner\nun mod√®le et la qualit√© des pr√©dictions de celui-ci est\n√©valu√©e sur le deuxi√®me pour limiter\nle biais de surapprentissage. Le chapitre suivant approfondira\ncette question de l‚Äô√©valuation des mod√®les. A ce stade de notre\nprogression, on se concentrera dans ce chapitre\nsur la question des donn√©es. La librairie Scikit est non seulement\nparticuli√®rement\npratique parce qu‚Äôelle propose √©norm√©ment d‚Äôalgorithmes de machine learning\nmais aussi parce qu‚Äôelle facilite la pr√©paration des donn√©es en amont,\nce qui est l‚Äôobjet de ce chapitre.\nN√©anmoins, avant de se concentrer sur la pr√©paration des donn√©es, nous\nallons passer un peu de temps √† explorer la structure des donn√©es\n√† partir de laquelle nous d√©sirons construire une mod√©lisation. Ceci\nest indispensable afin de comprendre la nature de celles-ci et choisir\nune mod√©lisation ad√©quate.",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#standardisation",
    "href": "content/modelisation/0_preprocessing.html#standardisation",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.1 Standardisation",
    "text": "3.1 Standardisation\nLa standardisation consiste √† transformer des donn√©es pour que la distribution empirique suive une loi \\(\\mathcal{N}(0,1)\\). Pour √™tre performants, la plupart des mod√®les de machine learning n√©cessitent souvent d‚Äôavoir des donn√©es dans cette distribution.\n\n\n Exercice 3: Standardisation\n\nStandardiser la variable Median_Household_Income_2019 (ne pas √©craser les valeurs !) et regarder l‚Äôhistogramme avant/apr√®s normalisation.\n\nNote : On obtient bien une distribution centr√©e √† z√©ro et on pourrait v√©rifier que la variance empirique soit bien √©gale √† 1. On pourrait aussi v√©rifier que ceci est vrai √©galement quand on transforme plusieurs colonnes √† la fois.\n\nCr√©er scaler, un Transformer que vous construisez sur les 1000 premi√®res lignes de votre DataFrame df2 √† l‚Äôexception de la variable √† expliquer winner. V√©rifier la moyenne et l‚Äô√©cart-type de chaque colonne sur ces m√™mes observations.\n\nNote : Les param√®tres qui seront utilis√©s pour une standardisation ult√©rieure sont stock√©s dans les attributs .mean_ et .scale_\nOn peut voir ces attributs comme des param√®tres entra√Æn√©s sur un certain jeu de\ndonn√©es et qu‚Äôon peut r√©utiliser sur un autre, √† condition que les\ndimensions co√Øncident.\n\nAppliquer scaler sur les autres lignes du DataFrame et comparer les distributions obtenues de la variable Median_Household_Income_2019.\n\nNote : Une fois appliqu√©s √† un autre DataFrame, on peut remarquer que la distribution n‚Äôest pas exactement centr√©e-r√©duite dans le DataFrame sur lequel les param√®tres n‚Äôont pas √©t√© estim√©s. C‚Äôest normal, l‚Äô√©chantillon initial n‚Äô√©tait pas al√©atoire, les moyennes et variances de cet √©chantillon n‚Äôont pas de raison de co√Øncider avec les moments de l‚Äô√©chantillon complet.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMoyenne de chaque variable sur 1000 premi√®res observations avant :  [ 1.73616500e+04  3.84530000e+00  5.51891150e+04  1.29669150e+01\n  2.15813433e+01 -2.73468885e-02]\nEcart-type de chaque variable sur 1000 premi√®res observations avant :  [3.28113703e+04 1.28903822e+00 1.33256197e+04 6.45536365e+00\n 9.41139584e+00 9.23129044e-01]\nMoyenne de chaque variable sur 1000 premi√®res observations apr√®s :  [-3.37507799e-17  2.66453526e-17  1.58095759e-16  1.42108547e-17\n  1.24344979e-17 -1.59872116e-17]\nEcart-type de chaque variable sur 1000 premi√®res observations apr√®s :  [1. 1. 1. 1. 1. 1.]",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#normalisation",
    "href": "content/modelisation/0_preprocessing.html#normalisation",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.2 Normalisation",
    "text": "3.2 Normalisation\nLa normalisation est l‚Äôaction de transformer les donn√©es de mani√®re\n√† obtenir une norme (\\(\\mathcal{l}_1\\) ou \\(\\mathcal{l}_2\\)) unitaire.\nAutrement dit, avec la norme ad√©quate, la somme des √©l√©ments est √©gale √† 1.\nPar d√©faut, la norme est dans \\(\\mathcal{l}_2\\).\nCette transformation est particuli√®rement utilis√©e en classification de texte ou pour effectuer du clustering.\n\n\n Exercice 4 : Normalisation\n\nNormaliser la variable Median_Household_Income_2019 (ne pas √©craser les valeurs !) et regarder l‚Äôhistogramme avant/apr√®s normalisation.\nV√©rifier que la norme \\(\\mathcal{l}_2\\) est bien √©gale √† 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\narray([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#encodage-des-valeurs-cat√©gorielles",
    "href": "content/modelisation/0_preprocessing.html#encodage-des-valeurs-cat√©gorielles",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.3 Encodage des valeurs cat√©gorielles",
    "text": "3.3 Encodage des valeurs cat√©gorielles\nLes donn√©es cat√©gorielles doivent √™tre recod√©es\nsous forme de valeurs num√©riques pour √™tre int√©gr√©s aux mod√®les de machine learning.\nCela peut √™tre fait de plusieurs mani√®res :\n\nLabelEncoder: transforme un vecteur [\"a\",\"b\",\"c\"] en vecteur num√©rique [0,1,2].\nCette approche a l‚Äôinconv√©nient d‚Äôintroduire un ordre dans les modalit√©s, ce qui n‚Äôest pas toujours souhaitable\nOrdinalEncoder: une version g√©n√©ralis√©e du LabelEncoder qui a vocation √† s‚Äôappliquer sur des matrices (\\(X\\)),\nalors que LabelEncoder s‚Äôapplique plut√¥t √† un vecteur (\\(y\\))\npandas.get_dummies effectue une op√©ration de dummy expansion.\nUn vecteur de taille n avec K cat√©gories sera transform√© en matrice de taille \\(n \\times K\\)\npour lequel chaque colonne sera une variable dummy pour la modalit√© k.\nIl y a ici \\(K\\) modalit√©s et il y a donc multicolin√©arit√©.\nAvec une r√©gression lin√©aire avec constante,\nil convient de retirer une modalit√© avant l‚Äôestimation.\nOneHotEncoder est une version g√©n√©ralis√©e (et optimis√©e) de la dummy expansion.\nIl a plut√¥t vocation √† s‚Äôappliquer sur les features (\\(X\\)) du mod√®le",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#imputation",
    "href": "content/modelisation/0_preprocessing.html#imputation",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.4 Imputation",
    "text": "3.4 Imputation\nLes donn√©es peuvent souvent contenir des valeurs manquantes, autrement dit des cases de notre DataFrame contenant un NaN.\nCes trous dans les donn√©es peuvent √™tre √† l‚Äôorigine de bugs ou de mauvaises interpr√©tations lorsque l‚Äôon passe √† la mod√©lisation.\nPour y rem√©dier, une premi√®re approche peut √™tre de retirer toutes les observations pr√©sentant un NaN dans au moins l‚Äôune des colonnes.\nCependant, si notre table contient beaucoup de NaN, ou bien que ces derniers sont r√©partis sur de nombreuses colonnes,\nc‚Äôest aussi prendre le risque de retirer un nombre important de lignes, et avec cela de l‚Äôinformation importante pour un mod√®le car les valeurs manquantes sont rarement r√©parties de mani√®re al√©atoire.\nM√™me si dans plusieurs situations, cette solution reste tout √† fait viable, il existe une autre approche plus robuste appel√©e imputation.\nCette m√©thode consiste √† remplacer les valeurs vides par une valeur donn√©e. Par exemple :\n\nImputation par la moyenne : remplacer tous les NaN dans une colonne par la valeur moyenne de la colonne ;\nImputation par la m√©diane sur le m√™me principe, ou par la valeur de la colonne la plus fr√©quente pour les variables cat√©gorielles ;\nImputation par r√©gression : se servir d‚Äôautres variables pour essayer d‚Äôinterpoler une valeur de remplacement adapt√©e.\n\nDes m√©thodes plus complexes existent, mais dans de nombreux cas,\nles approches ci-dessus peuvent suffire pour donner des r√©sultats beaucoup plus satisfaisants.\nLe package Scikit permet de faire de l‚Äôimputation de mani√®re tr√®s simple (documentation ici).",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#gestion-des-outliers",
    "href": "content/modelisation/0_preprocessing.html#gestion-des-outliers",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "3.5 Gestion des outliers",
    "text": "3.5 Gestion des outliers\nLes valeurs aberrantes (outliers en anglais) sont des observations qui se situent significativement √† l‚Äôext√©rieur de la tendance g√©n√©rale des autres observations dans un ensemble de donn√©es. En d‚Äôautres termes, ce sont des points de donn√©es qui se d√©marquent de mani√®re inhabituelle par rapport √† la distribution globale des donn√©es.\nCela peut √™tre d√ª √† des erreurs de remplissage, des personnes ayant mal r√©pondu √† un questionnaire, ou\nparfois simplement des valeurs extr√™mes qui peuvent biaiser un mod√®le de fa√ßon trop importante.\nA titre d‚Äôexemple, cela va √™tre 3 individus mesurant plus de 4 m√®tres dans une population,\nou bien des revenus de m√©nage d√©passant les 10M d‚Äôeuros par mois sur l‚Äô√©chelle d‚Äôun pays, etc.\nUne bonne pratique peut donc √™tre de syst√©matiquement regarder la distribution des variables √† disposition,\npour se rendre compte si certaines valeurs s‚Äô√©loignent de fa√ßon trop importante des autres.\nCes valeurs vont parfois nous int√©resser, si par exemple on se concentre uniquement sur les tr√®s hauts revenus (top 0.1%)\nen France. Cependant, ces donn√©es vont souvent nous g√™ner plus qu‚Äôautre chose, surtout si elles n‚Äôont pas de sens dans le monde r√©el.\nSi l‚Äôon estime que la pr√©sence de ces donn√©es extr√™mes, ou outliers, dans notre base de donn√©es vont √™tre probl√©matiques plus qu‚Äôautre chose,\nalors il est tout √† fait entendable et possible de simplement les retirer.\nLa plupart du temps, on va se donner une proportion des donn√©es √† retirer, par exemple 0.1%, 1% ou 5%,\npuis retirer dans les deux queues de la distribution les valeurs extr√™mes correspondantes.\nPlusieurs packages permettent de faire ce type d‚Äôop√©rations, qui sont parfois plus complexes si on s‚Äôint√©resse aux outlier sur plusieurs variables.\nOn pourra notamment citer la fonction IsolationForest() du package sklearn.ensemble.\n\nPour plus de d√©tails sur ces deux derniers points, il est recommand√© d‚Äôaller voir l‚Äôexemple Pour aller plus loin en bas de la page.\n\n\n Exercice 5 : Encoder des variables cat√©gorielles\n\nCr√©er df qui conserve uniquement les variables state_name et county_name dans votes.\nAppliquer √† state_name un LabelEncoder\nNote : Le r√©sultat du label encoding est relativement intuitif, notamment quand on le met en relation avec le vecteur initial.\nRegarder la dummy expansion de state_name\nAppliquer un OrdinalEncoder √† df[['state_name', 'county_name']]\nNote : Le r√©sultat du ordinal encoding est coh√©rent avec celui du label encoding\nAppliquer un OneHotEncoder √† df[['state_name', 'county_name']]\n\nNote : scikit optimise l‚Äôobjet n√©cessaire pour stocker le r√©sultat d‚Äôun mod√®le de transformation. Par exemple, le r√©sultat de l‚Äôencoding One Hot est un objet tr√®s volumineux. Dans ce cas, scikit utilise une matrice Sparse.\n\n\n\n\narray([[23, 'Missouri'],\n       [25, 'Nebraska'],\n       [30, 'New York'],\n       ...,\n       [41, 'Texas'],\n       [41, 'Texas'],\n       [41, 'Texas']], dtype=object)\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\nArizona\nArkansas\nCalifornia\nColorado\nConnecticut\nDelaware\nDistrict of Columbia\nFlorida\nGeorgia\n...\nSouth Dakota\nTennessee\nTexas\nUtah\nVermont\nVirginia\nWashington\nWest Virginia\nWisconsin\nWyoming\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3102\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3103\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3104\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3105\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3106\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n3107 rows √ó 49 columns\n\n\n\n\n\n\narray([23., 25., 30., ..., 41., 41., 41.])\n\n\n\n\n&lt;3107x1891 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n    with 6214 stored elements in Compressed Sparse Row format&gt;",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/0_preprocessing.html#informations-additionnelles",
    "href": "content/modelisation/0_preprocessing.html#informations-additionnelles",
    "title": "Pr√©paration des donn√©es pour construire un mod√®le",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\nfd3c955\n\n\n2023-11-18 14:22:38\n\n\nLino Galiana\n\n\nFormattage des chapitres scikit (#453)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nebca985\n\n\n2023-06-11 18:14:51\n\n\nLino Galiana\n\n\nChange handling precision (#361)\n\n\n\n\n129b001\n\n\n2022-12-26 20:36:01\n\n\nLino Galiana\n\n\nCSS for ipynb (#337)\n\n\n\n\nf5f0f9c\n\n\n2022-11-02 19:19:07\n\n\nLino Galiana\n\n\nRelecture d√©but partie mod√©lisation KA (#318)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n640b960\n\n\n2022-06-10 15:42:04\n\n\nLino Galiana\n\n\nFinir de r√©gler le probl√®me plotly (#236)\n\n\n\n\n5698e30\n\n\n2022-06-03 18:28:37\n\n\nLino Galiana\n\n\nFinalise widget (#232)\n\n\n\n\n7b9f27b\n\n\n2022-06-03 17:05:15\n\n\nLino Galiana\n\n\nEssaie r√©gler les probl√®mes widgets JS (#231)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n8f99cd3\n\n\n2021-12-08 15:26:28\n\n\nlinogaliana\n\n\nhide otuput\n\n\n\n\n9c5f718\n\n\n2021-12-08 14:36:59\n\n\nlinogaliana\n\n\nformat dico :sob:\n\n\n\n\n41c8986\n\n\n2021-12-08 14:25:18\n\n\nlinogaliana\n\n\ncorrection erreur\n\n\n\n\n6474746\n\n\n2021-12-08 14:08:06\n\n\nlinogaliana\n\n\ndict ici aussi\n\n\n\n\n8e73912\n\n\n2021-12-08 12:32:17\n\n\nlinogaliana\n\n\ncoquille plotly :sob:\n\n\n\n\n3704213\n\n\n2021-12-08 11:57:51\n\n\nlinogaliana\n\n\nessaye avec un dict classique\n\n\n\n\n85565d5\n\n\n2021-12-08 08:15:29\n\n\nlinogaliana\n\n\nreformat\n\n\n\n\n9ace7b9\n\n\n2021-12-07 17:49:18\n\n\nlinogaliana\n\n\n√©vite la boucle crado\n\n\n\n\n3514e09\n\n\n2021-12-07 16:05:28\n\n\nlinogaliana\n\n\ns√©pare et document\n\n\n\n\n63e67e6\n\n\n2021-12-07 15:15:34\n\n\nLino Galiana\n\n\nDebug du plotly (temporaire) (#193)\n\n\n\n\n65cecdd\n\n\n2021-12-07 10:29:18\n\n\nLino Galiana\n\n\nEncore une erreur de nom de colonne (#192)\n\n\n\n\n81b7023\n\n\n2021-12-07 09:27:35\n\n\nLino Galiana\n\n\nMise √† jour liste des colonnes (#191)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nd91a5eb\n\n\n2021-12-06 18:53:33\n\n\nLino Galiana\n\n\nLa bonne branche c‚Äôest master\n\n\n\n\nd86129c\n\n\n2021-12-06 18:02:32\n\n\nLino Galiana\n\n\nverbose\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec (antuki?) partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n49e2826\n\n\n2021-05-13 18:11:20\n\n\nLino Galiana\n\n\nCorrige quelques images n‚Äôapparaissant pas (#108)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Pr√©paration des donn√©es pour construire un mod√®le"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html",
    "href": "content/modelisation/2_SVM.html",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nPour ce TP, nous aurons besoin des packages suivants :\nimport pandas as pd\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html#la-m√©thode-des-svm-support-vector-machines",
    "href": "content/modelisation/2_SVM.html#la-m√©thode-des-svm-support-vector-machines",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "0.1 La m√©thode des SVM (Support Vector Machines)",
    "text": "0.1 La m√©thode des SVM (Support Vector Machines)\nL‚Äôune des m√©thodes de machine learning les\nplus utilis√©es en classification sont les SVM (Support Vector Machines).\nIl s‚Äôagit de trouver, dans un syst√®me de projection ad√©quat (noyau ou kernel),\nles param√®tres de l‚Äôhyperplan (en fait d‚Äôun hyperplan √† marges maximales)\ns√©parant les classes de donn√©es :\n\n\n\n Formalisation math√©matique\nLes SVM sont l‚Äôune des m√©thodes de machine learning les plus intuitives\ndu fait de l‚Äôinterpr√©tation g√©om√©trique simple de la m√©thode. Il s‚Äôagit\naussi d‚Äôun des algorithmes de machine learning √† la formalisation\nla moins complexe pour les praticiens ayant des notions en statistique\ntraditionnelle. Cette bo√Æte revient dessus. N√©anmoins,\ncelle-ci n‚Äôest pas n√©cessaire √† la compr√©hension du chapitre.\nEn machine learning, plus que les d√©tails math√©matiques, l‚Äôimportant\nest d‚Äôavoir des intuitions.\nL‚Äôobjectif des SVM est, rappelons-le, de trouver un hyperplan qui permette\nde s√©parer les diff√©rentes classes au mieux. Par exemple, dans un espace\n√† deux dimensions, il s‚Äôagit de trouver une droite avec des marges\nqui permette de s√©parer au mieux l‚Äôespace en partie avec\ndes labels homog√®nes.\nOn peut, sans perdre de g√©n√©ralit√©,\nsupposer que le probl√®me consiste √† supposer l‚Äôexistence d‚Äôune loi de probabilit√© \\(\\mathbb{P}(x,y)\\) (\\(\\mathbb{P} \\to \\{-1,1\\}\\)) qui est inconnue. Le probl√®me de discrimination\nvise √† construire un estimateur de la fonction de d√©cision id√©ale qui minimise la probabilit√© d‚Äôerreur, autrement dit\n\\[\n\\theta = \\arg\\min_\\Theta \\mathbb{P}(h_\\theta(X) \\neq y |x)\n\\]\nLes SVM les plus simples sont les SVM lin√©aires. Dans ce cas, on suppose qu‚Äôil existe un s√©parateur lin√©aire qui permet d‚Äôassocier chaque classe √† son signe:\n\\[\nh_\\theta(x) = \\text{signe}(f_\\theta(x)) ; \\text{ avec } f_\\theta(x) = \\theta^T x + b\n\\]\navec \\(\\theta \\in \\mathbb{R}^p\\) et \\(w \\in \\mathbb{R}\\).\n\nLorsque des observations sont lin√©airement s√©parables,\nil existe une infinit√© de fronti√®res de d√©cision lin√©aire s√©parant les deux classes. Le ‚Äúmeilleur‚Äù choix est de prendre la marge maximale permettant de s√©parer les donn√©es. La distance entre les deux marges est \\(\\frac{2}{||\\theta||}\\). Donc maximiser cette distance entre deux hyperplans revient √† minimiser \\(||\\theta||^2\\) sous la contrainte \\(y_i(\\theta^Tx_i + b) \\geq 1\\).\nDans le cas non lin√©airement s√©parable, la hinge loss \\(\\max\\big(0,y_i(\\theta^Tx_i + b)\\big)\\) permet de lin√©ariser la fonction de perte:\n\nce qui donne le programme d‚Äôoptimisation suivant :\n\\[\n\\frac{1}{n} \\sum_{i=1}^n \\max\\big(0,y_i(\\theta^Tx_i + b)\\big) + \\lambda ||\\theta||^2\n\\]\nLa g√©n√©ralisation au cas non lin√©aire implique d‚Äôintroduire des noyaux transformant l‚Äôespace de coordonn√©es des observations.",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html#application",
    "href": "content/modelisation/2_SVM.html#application",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "0.2 Application",
    "text": "0.2 Application\nPour appliquer un mod√®le de classification, il nous faut\ntrouver une variable dichotomique. Le choix naturel est\nde prendre la variable dichotomique qu‚Äôest la victoire ou\nd√©faite d‚Äôun des partis.\nM√™me si les R√©publicains ont perdu en 2020, ils l‚Äôont emport√©\ndans plus de comt√©s (moins peupl√©s). Nous allons consid√©rer\nque la victoire des R√©publicains est notre label 1 et la d√©faite 0.\n\n\n Exercice 1 : Premier algorithme de classification\n\nCr√©er une variable dummy appel√©e y dont la valeur vaut 1 quand les r√©publicains l‚Äôemportent.\nEn utilisant la fonction pr√™te √† l‚Äôemploi nomm√©e train_test_split de la librairie sklearn.model_selection,\ncr√©er des √©chantillons de test (20 % des observations) et d‚Äôestimation (80 %) avec comme features : 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Percent of adults with less than a high school diploma, 2015-19', \"Percent of adults with a bachelor's degree or higher, 2015-19\" et comme label la variable y.\n\nNote: Il se peut que vous ayez le warning suivant :\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel()\n\nNote : Pour √©viter ce warning √† chaque fois que vous estimez votre mod√®le, vous pouvez utiliser DataFrame[['y']].values.ravel() plut√¥t que DataFrame[['y']] lorsque vous constituez vos √©chantillons.\n\nEntra√Æner un classifieur SVM avec comme param√®tre de r√©gularisation C = 1. Regarder les mesures de performance suivante : accuracy, f1, recall et precision.\nV√©rifier la matrice de confusion : vous devriez voir que malgr√© des scores en apparence pas si mauvais, il y a un probl√®me notable.\nRefaire les questions pr√©c√©dentes avec des variables normalis√©es. Le r√©sultat est-il diff√©rent ?\nChanger de variables x. Utiliser uniquement le r√©sultat pass√© du vote d√©mocrate (ann√©e 2016) et le revenu. Les variables en question sont share_2016_republican et Median_Household_Income_2019. Regarder les r√©sultats, notamment la matrice de confusion.\n[OPTIONNEL] Faire une 5-fold validation crois√©e pour d√©terminer le param√®tre C id√©al.\n\n\n\nA l‚Äôissue de la question 3,\nle classifieur avec C = 1\ndevrait avoir les performances suivantes :\n\n\n\n\nScore\n\n\n\n\nAccuracy\n0.882637\n\n\nRecall\n0.897297\n\n\nPrecision\n0.968872\n\n\nF1\n0.931712\n\n\n\nLa matrice de confusion associ√©e\nprend cette forme:\n\n\nA l‚Äôissue de la question 6,\nle nouveau classifieur avec devrait avoir les performances suivantes :\n\n\n\n\nScore\n\n\n\n\nAccuracy\n0.882637\n\n\nRecall\n0.897297\n\n\nPrecision\n0.968872\n\n\nF1\n0.931712\n\n\n\nEt la matrice de confusion associ√©e :",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/2_SVM.html#informations-additionnelles",
    "href": "content/modelisation/2_SVM.html#informations-additionnelles",
    "title": "Classification: premier mod√®le avec les SVM",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\nb68369d\n\n\n2023-11-18 18:21:13\n\n\nLino Galiana\n\n\nReprise du chapitre sur la classification (#455)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n8d81b5f\n\n\n2023-02-18 18:21:59\n\n\nLino Galiana\n\n\nChange source get_vectorfile (#355)\n\n\n\n\n2ed4aa7\n\n\n2022-11-07 15:57:31\n\n\nLino Galiana\n\n\nReprise 2e partie ML + R√®gle probl√®me mathjax (#319)\n\n\n\n\na26b865\n\n\n2022-09-03 15:34:28\n\n\nlinogaliana\n\n\nFix problem with SVM wikipedia image\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n0a14dfa\n\n\n2021-07-07 15:17:11\n\n\nLino Galiana\n\n\nR√©gler bug sc_recall (#119)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n671f75a\n\n\n2020-10-21 15:15:24\n\n\nLino Galiana\n\n\nIntroduction au Machine Learning (#72)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Classification: premier mod√®le avec les SVM"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html",
    "href": "content/modelisation/4_featureselection.html",
    "title": "S√©lection de variables : une introduction",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre utilise toujours le m√™me jeu de donn√©es, pr√©sent√© dans l‚Äôintroduction\nde cette partie : les donn√©es de vote aux √©lections pr√©sidentielles am√©ricaines\ncrois√©es √† des variables sociod√©mographiques.\nLe code\nest disponible sur Github.\n!pip install --upgrade xlrd #colab bug verson xlrd\n!pip install geopandas\nimport requests\n\nurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/modelisation/get_data.py\"\nr = requests.get(url, allow_redirects=True)\nopen(\"getdata.py\", \"wb\").write(r.content)\n\nimport getdata\n\nvotes = getdata.create_votes_dataframes()\nJusqu‚Äô√† pr√©sent, nous avons suppos√© que les variables utiles √† la pr√©vision du\nvote R√©publicain √©taient connues du mod√©lisateur. Nous n‚Äôavons ainsi exploit√© qu‚Äôune partie\nlimit√©e des variables disponibles dans nos donn√©es. N√©anmoins, outre le fl√©au\ncomputationnel que repr√©senterait la construction d‚Äôun mod√®le avec un grand\nnombre de variables, le choix d‚Äôun nombre restreint de variables\n(mod√®le parcimonieux) limite le risque de sur-apprentissage.\nComment, d√®s lors, choisir le bon nombre de variables et la meilleure\ncombinaison de ces variables ? Il existe de multiples m√©thodes, parmi lesquelles :\nDans ce chapitre, nous allons pr√©senter\nles enjeux principaux de la s√©lection\nde variables par le biais du LASSO.\nNous allons utiliser par la suite les fonctions ou\npackages suivants :\nimport numpy as np\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Lasso\nimport sklearn.metrics\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import lasso_path\nimport seaborn as sns",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#principe-g√©n√©ral",
    "href": "content/modelisation/4_featureselection.html#principe-g√©n√©ral",
    "title": "S√©lection de variables : une introduction",
    "section": "1.1 Principe g√©n√©ral",
    "text": "1.1 Principe g√©n√©ral\nLa classe des mod√®les de feature selection est ainsi tr√®s vaste et regroupe\nun ensemble tr√®s diverse de mod√®les. Nous allons nous focaliser sur le LASSO\n(Least Absolute Shrinkage and Selection Operator)\nqui est une extension de la r√©gression lin√©aire qui vise √† s√©lectionner des\nmod√®les sparses. Ce type de mod√®le est central dans le champ du\nCompressed sensing (o√π on emploie plut√¥t le terme\nde L1-regularization que de LASSO). Le LASSO est un cas particulier des\nr√©gressions elastic-net dont un autre cas fameux est la r√©gression ridge.\nContrairement √† la r√©gression lin√©aire classique, elles fonctionnent √©galement\ndans un cadre o√π \\(p&gt;N\\), c‚Äôest √† dire o√π le nombre de r√©gresseurs est tr√®s grand puisque sup√©rieur\nau nombre d‚Äôobservations.",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#p√©nalisation",
    "href": "content/modelisation/4_featureselection.html#p√©nalisation",
    "title": "S√©lection de variables : une introduction",
    "section": "1.2 P√©nalisation",
    "text": "1.2 P√©nalisation\nEn adoptant le principe d‚Äôune fonction objectif p√©nalis√©e,\nle LASSO permet de fixer un certain nombre de coefficients √† 0.\nLes variables dont la norme est non nulle passent ainsi le test de s√©lection.\n\n\n Hint\nLe LASSO est un programme d‚Äôoptimisation sous contrainte. On cherche √† trouver l‚Äôestimateur \\(\\beta\\) qui minimise l‚Äôerreur quadratique (r√©gression lin√©aire) sous une contrainte additionnelle r√©gularisant les param√®tres:\n\\[\n\\min_{\\beta} \\frac{1}{2}\\mathbb{E}\\bigg( \\big( X\\beta - y  \\big)^2 \\bigg) \\\\\n\\text{s.t. } \\sum_{j=1}^p |\\beta_j| \\leq t\n\\]\nCe programme se reformule gr√¢ce au Lagrangien est permet ainsi d‚Äôobtenir un programme de minimisation plus maniable :\n\\[\n\\beta^{\\text{LASSO}} = \\arg \\min_{\\beta} \\frac{1}{2}\\mathbb{E}\\bigg( \\big( X\\beta - y  \\big)^2 \\bigg) + \\alpha \\sum_{j=1}^p |\\beta_j| = \\arg \\min_{\\beta} ||y-X\\beta||_{2}^{2} + \\lambda ||\\beta||_1\n\\]\no√π \\(\\lambda\\) est une r√©√©criture de la r√©gularisation pr√©c√©dente qui d√©pend de \\(\\alpha\\). La force de la p√©nalit√© appliqu√©e aux mod√®les non parcimonieux d√©pend de ce param√®tre.",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#premi√®re-r√©gression-lasso",
    "href": "content/modelisation/4_featureselection.html#premi√®re-r√©gression-lasso",
    "title": "S√©lection de variables : une introduction",
    "section": "1.3 Premi√®re r√©gression LASSO",
    "text": "1.3 Premi√®re r√©gression LASSO\nComme nous cherchons √† trouver les\nmeilleurs pr√©dicteurs du vote R√©publicain,\nnous allons retirer les variables\nqui sont d√©rivables directement de celles-ci: les scores des concurrents !\n\nimport pandas as pd\n\ndf2 = pd.DataFrame(votes.drop(columns=\"geometry\"))\ndf2 = df2.loc[\n    :,\n    ~df2.columns.str.endswith(\n        (\"_democrat\", \"_green\", \"_other\", \"winner\", \"per_point_diff\", \"per_dem\")\n    ),\n]\n\n\ndf2 = df2.loc[:, ~df2.columns.duplicated()]\n\nDans cet exercice, nous utiliserons\n√©galement une fonction pour extraire\nles variables s√©lectionn√©es par le LASSO,\nla voici\n\n\nFonction pour r√©cup√©rer les variables valid√©es par l‚Äô√©tape de s√©lection\nfrom sklearn.linear_model import Lasso\nfrom sklearn.pipeline import Pipeline\n\n\ndef extract_features_selected(\n    lasso: Pipeline, preprocessing_step_name: str = \"preprocess\"\n) -&gt; pd.Series:\n    \"\"\"\n    Extracts selected features based on the coefficients obtained from Lasso regression.\n\n    Parameters:\n    - lasso (Pipeline): The scikit-learn pipeline containing a trained Lasso regression model.\n    - preprocessing_step_name (str): The name of the preprocessing step in the pipeline. Default is 'preprocess'.\n\n    Returns:\n    - pd.Series: A Pandas Series containing selected features with non-zero coefficients.\n    \"\"\"\n    # Check if lasso object is provided\n    if not isinstance(lasso, Pipeline):\n        raise ValueError(\"The provided lasso object is not a scikit-learn pipeline.\")\n\n    # Extract the final transformer from the pipeline\n    lasso_model = lasso[-1]\n\n    # Check if lasso_model is a Lasso regression model\n    if not isinstance(lasso_model, Lasso):\n        raise ValueError(\n            \"The final step of the pipeline is not a Lasso regression model.\"\n        )\n\n    # Check if lasso model has 'coef_' attribute\n    if not hasattr(lasso_model, \"coef_\"):\n        raise ValueError(\n            \"The provided Lasso regression model does not have 'coef_' attribute. \"\n            \"Make sure it is a trained Lasso regression model.\"\n        )\n\n    # Get feature names from the preprocessing step\n    features_preprocessing = lasso[preprocessing_step_name].get_feature_names_out()\n\n    # Extract selected features based on non-zero coefficients\n    features_selec = pd.Series(features_preprocessing[np.abs(lasso_model.coef_) &gt; 0])\n\n    return features_selec\n\n\n\n\n Exercice 1 : Premier LASSO\nOn cherche toujours √† pr√©dire la variable per_gop. Avant de faire notre estimation, nous allons cr√©er certains objets interm√©diaires qui seront utilis√©s pour\nd√©finir notre pipeline:\n\nDans notre DataFrame, remplacer les valeurs infinies par des NaN.\nCr√©ez un √©chantillon d‚Äôentra√Ænement et un √©chantillon test.\n\nMaintenant nous pouvons passer au coeur de la d√©finition de notre pipeline.\nCet exemple pourra servir de source\nd‚Äôinspiration, ainsi que celui-ci.\n\nCr√©er en premier lieu les √©tapes\nde preprocessing pour notre mod√®le.\nPour cela, il est d‚Äôusage de s√©parer les √©tapes appliqu√©es aux variables num√©riques continues des autres variables, dites\ncat√©gorielles.\n\n\nPour les variables num√©riques, imputer √† la moyenne puis effectuer une standardisation ;\nPour les variables cat√©gorielles, les techniques de r√©gression lin√©aires impliquent d‚Äôutiliser une expansion par one hot encoding. Avant de faire ce one hot encoding, faire une imputation par valeur la plus fr√©quente.\n\n\nFinaliser le pipeline en ajoutant l‚Äô√©tape d‚Äôestimation puis estimer un mod√®le LASSO p√©nalis√© avec \\(\\alpha = 0.1\\).\n\nEn supposant que votre pipeline soit dans un objet nomm√© pipeline et que la derni√®re √©tape\nest nomm√©e model, vous pouvez\ndirectement acc√©der √† cette √©tape en utilisant l‚Äôobjet pipeline['model']\n\nAfficher les valeurs des coefficients. Quelles variables ont une valeur non nulle ?\nMontrer que les variables s√©lectionn√©es sont parfois tr√®s corr√©l√©es.\nComparer la performance de ce mod√®le parcimonieux avec celle d‚Äôun mod√®le avec plus de variables\n\n\n\nAide pour la question 1\n\n# Remplacer les infinis par des NaN\ndf2.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n\n\nAide pour la question 3\n\nLa d√©finition d‚Äôun pipeline\nsuit la structure suivante,\nnumeric_pipeline = Pipeline(steps=[\n    ('impute', #definir la methode d'imputation ici\n     ),\n    ('scale', #definir la m√©thode de standardisation ici\n    )\n])\n\ncategorical_pipeline = #adapter le template\n\n# a vous de d√©finir en amont numerical_features et categorical_features\npreprocessor = ColumnTransformer(transformers=[\n    ('number', numeric_pipeline, numerical_features),\n    ('category', categorical_pipeline, categorical_features)\n])\n\n\n\nLe pipeline de preprocessing (question 3) prend la forme suivante:\n\n\nColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†ColumnTransformer?Documentation for ColumnTransformeriNot fittedColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])]) number['ALAND', 'AWATER', 'votes_gop', 'votes_dem', 'total_votes', 'diff', 'FIPS_y', 'Rural-urban_Continuum Code_2003', 'Rural-urban_Continuum Code_2013', 'Urban_Influence_Code_2003', 'Urban_Influence_Code_2013', 'Economic_typology_2015', 'CENSUS_2010_POP', 'ESTIMATES_BASE_2010', 'POP_ESTIMATE_2010', 'POP_ESTIMATE_2011', 'POP_ESTIMATE_2012', 'POP_ESTIMATE_2013', 'POP_ESTIMATE_2014', 'POP_ESTIMATE_2015', 'POP_ESTIMATE_2016', 'POP_ESTIMATE_2017', 'POP_ESTIMATE_2018', 'POP_ESTIMATE_2019', 'N_POP_CHG_2010', 'N_POP_CHG_2011', 'N_POP_CHG_2012', 'N_POP_CHG_2013', 'N_POP_CHG_2014', 'N_POP_CHG_2015', 'N_POP_CHG_2016', 'N_POP_CHG_2017', 'N_POP_CHG_2018', 'N_POP_CHG_2019', 'Births_2010', 'Births_2011', 'Births_2012', 'Births_2013', 'Births_2014', 'Births_2015', 'Births_2016', 'Births_2017', 'Births_2018', 'Births_2019', 'Deaths_2010', 'Deaths_2011', 'Deaths_2012', 'Deaths_2013', 'Deaths_2014', 'Deaths_2015', 'Deaths_2016', 'Deaths_2017', 'Deaths_2018', 'Deaths_2019', 'NATURAL_INC_2010', 'NATURAL_INC_2011', 'NATURAL_INC_2012', 'NATURAL_INC_2013', 'NATURAL_INC_2014', 'NATURAL_INC_2015', 'NATURAL_INC_2016', 'NATURAL_INC_2017', 'NATURAL_INC_2018', 'NATURAL_INC_2019', 'INTERNATIONAL_MIG_2010', 'INTERNATIONAL_MIG_2011', 'INTERNATIONAL_MIG_2012', 'INTERNATIONAL_MIG_2013', 'INTERNATIONAL_MIG_2014', 'INTERNATIONAL_MIG_2015', 'INTERNATIONAL_MIG_2016', 'INTERNATIONAL_MIG_2017', 'INTERNATIONAL_MIG_2018', 'INTERNATIONAL_MIG_2019', 'DOMESTIC_MIG_2010', 'DOMESTIC_MIG_2011', 'DOMESTIC_MIG_2012', 'DOMESTIC_MIG_2013', 'DOMESTIC_MIG_2014', 'DOMESTIC_MIG_2015', 'DOMESTIC_MIG_2016', 'DOMESTIC_MIG_2017', 'DOMESTIC_MIG_2018', 'DOMESTIC_MIG_2019', 'NET_MIG_2010', 'NET_MIG_2011', 'NET_MIG_2012', 'NET_MIG_2013', 'NET_MIG_2014', 'NET_MIG_2015', 'NET_MIG_2016', 'NET_MIG_2017', 'NET_MIG_2018', 'NET_MIG_2019', 'RESIDUAL_2010', 'RESIDUAL_2011', 'RESIDUAL_2012', 'RESIDUAL_2013', 'RESIDUAL_2014', 'RESIDUAL_2015', 'RESIDUAL_2016', 'RESIDUAL_2017', 'RESIDUAL_2018', 'RESIDUAL_2019', 'GQ_ESTIMATES_BASE_2010', 'GQ_ESTIMATES_2010', 'GQ_ESTIMATES_2011', 'GQ_ESTIMATES_2012', 'GQ_ESTIMATES_2013', 'GQ_ESTIMATES_2014', 'GQ_ESTIMATES_2015', 'GQ_ESTIMATES_2016', 'GQ_ESTIMATES_2017', 'GQ_ESTIMATES_2018', 'GQ_ESTIMATES_2019', 'R_birth_2011', 'R_birth_2012', 'R_birth_2013', 'R_birth_2014', 'R_birth_2015', 'R_birth_2016', 'R_birth_2017', 'R_birth_2018', 'R_birth_2019', 'R_death_2011', 'R_death_2012', 'R_death_2013', 'R_death_2014', 'R_death_2015', 'R_death_2016', 'R_death_2017', 'R_death_2018', 'R_death_2019', 'R_NATURAL_INC_2011', 'R_NATURAL_INC_2012', 'R_NATURAL_INC_2013', 'R_NATURAL_INC_2014', 'R_NATURAL_INC_2015', 'R_NATURAL_INC_2016', 'R_NATURAL_INC_2017', 'R_NATURAL_INC_2018', 'R_NATURAL_INC_2019', 'R_INTERNATIONAL_MIG_2011', 'R_INTERNATIONAL_MIG_2012', 'R_INTERNATIONAL_MIG_2013', 'R_INTERNATIONAL_MIG_2014', 'R_INTERNATIONAL_MIG_2015', 'R_INTERNATIONAL_MIG_2016', 'R_INTERNATIONAL_MIG_2017', 'R_INTERNATIONAL_MIG_2018', 'R_INTERNATIONAL_MIG_2019', 'R_DOMESTIC_MIG_2011', 'R_DOMESTIC_MIG_2012', 'R_DOMESTIC_MIG_2013', 'R_DOMESTIC_MIG_2014', 'R_DOMESTIC_MIG_2015', 'R_DOMESTIC_MIG_2016', 'R_DOMESTIC_MIG_2017', 'R_DOMESTIC_MIG_2018', 'R_DOMESTIC_MIG_2019', 'R_NET_MIG_2011', 'R_NET_MIG_2012', 'R_NET_MIG_2013', 'R_NET_MIG_2014', 'R_NET_MIG_2015', 'R_NET_MIG_2016', 'R_NET_MIG_2017', 'R_NET_MIG_2018', 'R_NET_MIG_2019', '2003 Rural-urban Continuum Code', '2003 Urban Influence Code', '2013 Rural-urban Continuum Code', '2013 Urban Influence Code', 'Less than a high school diploma, 1970', 'High school diploma only, 1970', 'Some college (1-3 years), 1970', 'Four years of college or higher, 1970', 'Percent of adults with less than a high school diploma, 1970', 'Percent of adults with a high school diploma only, 1970', 'Percent of adults completing some college (1-3 years), 1970', 'Percent of adults completing four years of college or higher, 1970', 'Less than a high school diploma, 1980', 'High school diploma only, 1980', 'Some college (1-3 years), 1980', 'Four years of college or higher, 1980', 'Percent of adults with less than a high school diploma, 1980', 'Percent of adults with a high school diploma only, 1980', 'Percent of adults completing some college (1-3 years), 1980', 'Percent of adults completing four years of college or higher, 1980', 'Less than a high school diploma, 1990', 'High school diploma only, 1990', \"Some college or associate's degree, 1990\", \"Bachelor's degree or higher, 1990\", 'Percent of adults with less than a high school diploma, 1990', 'Percent of adults with a high school diploma only, 1990', \"Percent of adults completing some college or associate's degree, 1990\", \"Percent of adults with a bachelor's degree or higher, 1990\", 'Less than a high school diploma, 2000', 'High school diploma only, 2000', \"Some college or associate's degree, 2000\", \"Bachelor's degree or higher, 2000\", 'Percent of adults with less than a high school diploma, 2000', 'Percent of adults with a high school diploma only, 2000', \"Percent of adults completing some college or associate's degree, 2000\", \"Percent of adults with a bachelor's degree or higher, 2000\", 'Less than a high school diploma, 2015-19', 'High school diploma only, 2015-19', \"Some college or associate's degree, 2015-19\", \"Bachelor's degree or higher, 2015-19\", 'Percent of adults with less than a high school diploma, 2015-19', 'Percent of adults with a high school diploma only, 2015-19', \"Percent of adults completing some college or associate's degree, 2015-19\", \"Percent of adults with a bachelor's degree or higher, 2015-19\", 'Rural_urban_continuum_code_2013', 'Urban_influence_code_2013', 'Metro_2013', 'Civilian_labor_force_2000', 'Employed_2000', 'Unemployed_2000', 'Unemployment_rate_2000', 'Civilian_labor_force_2001', 'Employed_2001', 'Unemployed_2001', 'Unemployment_rate_2001', 'Civilian_labor_force_2002', 'Employed_2002', 'Unemployed_2002', 'Unemployment_rate_2002', 'Civilian_labor_force_2003', 'Employed_2003', 'Unemployed_2003', 'Unemployment_rate_2003', 'Civilian_labor_force_2004', 'Employed_2004', 'Unemployed_2004', 'Unemployment_rate_2004', 'Civilian_labor_force_2005', 'Employed_2005', 'Unemployed_2005', 'Unemployment_rate_2005', 'Civilian_labor_force_2006', 'Employed_2006', 'Unemployed_2006', 'Unemployment_rate_2006', 'Civilian_labor_force_2007', 'Employed_2007', 'Unemployed_2007', 'Unemployment_rate_2007', 'Civilian_labor_force_2008', 'Employed_2008', 'Unemployed_2008', 'Unemployment_rate_2008', 'Civilian_labor_force_2009', 'Employed_2009', 'Unemployed_2009', 'Unemployment_rate_2009', 'Civilian_labor_force_2010', 'Employed_2010', 'Unemployed_2010', 'Unemployment_rate_2010', 'Civilian_labor_force_2011', 'Employed_2011', 'Unemployed_2011', 'Unemployment_rate_2011', 'Civilian_labor_force_2012', 'Employed_2012', 'Unemployed_2012', 'Unemployment_rate_2012', 'Civilian_labor_force_2013', 'Employed_2013', 'Unemployed_2013', 'Unemployment_rate_2013', 'Civilian_labor_force_2014', 'Employed_2014', 'Unemployed_2014', 'Unemployment_rate_2014', 'Civilian_labor_force_2015', 'Employed_2015', 'Unemployed_2015', 'Unemployment_rate_2015', 'Civilian_labor_force_2016', 'Employed_2016', 'Unemployed_2016', 'Unemployment_rate_2016', 'Civilian_labor_force_2017', 'Employed_2017', 'Unemployed_2017', 'Unemployment_rate_2017', 'Civilian_labor_force_2018', 'Employed_2018', 'Unemployed_2018', 'Unemployment_rate_2018', 'Civilian_labor_force_2019', 'Employed_2019', 'Unemployed_2019', 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Med_HH_Income_Percent_of_State_Total_2019', 'Rural-urban_Continuum_Code_2003', 'Rural-urban_Continuum_Code_2013', 'POVALL_2019', 'CI90LBALL_2019', 'CI90UBALL_2019', 'PCTPOVALL_2019', 'CI90LBALLP_2019', 'CI90UBALLP_2019', 'POV017_2019', 'CI90LB017_2019', 'CI90UB017_2019', 'PCTPOV017_2019', 'CI90LB017P_2019', 'CI90UB017P_2019', 'POV517_2019', 'CI90LB517_2019', 'CI90UB517_2019', 'PCTPOV517_2019', 'CI90LB517P_2019', 'CI90UB517P_2019', 'MEDHHINC_2019', 'CI90LBINC_2019', 'CI90UBINC_2019', 'POV04_2019', 'CI90LB04_2019', 'CI90UB04_2019', 'PCTPOV04_2019', 'CI90LB04P_2019', 'CI90UB04P_2019', 'candidatevotes_2000_republican', 'candidatevotes_2004_republican', 'candidatevotes_2008_republican', 'candidatevotes_2012_republican', 'candidatevotes_2016_republican', 'share_2000_republican', 'share_2004_republican', 'share_2008_republican', 'share_2012_republican', 'share_2016_republican'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() category['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'FIPS_x', 'state_name', 'county_fips', 'county_name', 'State', 'Area_Name', 'FIPS'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) \n\n\n\n\n/opt/mamba/lib/python3.11/site-packages/sklearn/impute/_base.py:577: UserWarning:\n\nSkipping features without any observed values: ['POV04_2019' 'CI90LB04_2019' 'CI90UB04_2019' 'PCTPOV04_2019'\n 'CI90LB04P_2019' 'CI90UB04P_2019']. At least one non-missing value is needed for imputation with strategy='mean'.\n\n\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))]) ¬†preprocess: ColumnTransformer?Documentation for preprocess: ColumnTransformerColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])]) number['ALAND', 'AWATER', 'votes_gop', 'votes_dem', 'total_votes', 'diff', 'FIPS_y', 'Rural-urban_Continuum Code_2003', 'Rural-urban_Continuum Code_2013', 'Urban_Influence_Code_2003', 'Urban_Influence_Code_2013', 'Economic_typology_2015', 'CENSUS_2010_POP', 'ESTIMATES_BASE_2010', 'POP_ESTIMATE_2010', 'POP_ESTIMATE_2011', 'POP_ESTIMATE_2012', 'POP_ESTIMATE_2013', 'POP_ESTIMATE_2014', 'POP_ESTIMATE_2015', 'POP_ESTIMATE_2016', 'POP_ESTIMATE_2017', 'POP_ESTIMATE_2018', 'POP_ESTIMATE_2019', 'N_POP_CHG_2010', 'N_POP_CHG_2011', 'N_POP_CHG_2012', 'N_POP_CHG_2013', 'N_POP_CHG_2014', 'N_POP_CHG_2015', 'N_POP_CHG_2016', 'N_POP_CHG_2017', 'N_POP_CHG_2018', 'N_POP_CHG_2019', 'Births_2010', 'Births_2011', 'Births_2012', 'Births_2013', 'Births_2014', 'Births_2015', 'Births_2016', 'Births_2017', 'Births_2018', 'Births_2019', 'Deaths_2010', 'Deaths_2011', 'Deaths_2012', 'Deaths_2013', 'Deaths_2014', 'Deaths_2015', 'Deaths_2016', 'Deaths_2017', 'Deaths_2018', 'Deaths_2019', 'NATURAL_INC_2010', 'NATURAL_INC_2011', 'NATURAL_INC_2012', 'NATURAL_INC_2013', 'NATURAL_INC_2014', 'NATURAL_INC_2015', 'NATURAL_INC_2016', 'NATURAL_INC_2017', 'NATURAL_INC_2018', 'NATURAL_INC_2019', 'INTERNATIONAL_MIG_2010', 'INTERNATIONAL_MIG_2011', 'INTERNATIONAL_MIG_2012', 'INTERNATIONAL_MIG_2013', 'INTERNATIONAL_MIG_2014', 'INTERNATIONAL_MIG_2015', 'INTERNATIONAL_MIG_2016', 'INTERNATIONAL_MIG_2017', 'INTERNATIONAL_MIG_2018', 'INTERNATIONAL_MIG_2019', 'DOMESTIC_MIG_2010', 'DOMESTIC_MIG_2011', 'DOMESTIC_MIG_2012', 'DOMESTIC_MIG_2013', 'DOMESTIC_MIG_2014', 'DOMESTIC_MIG_2015', 'DOMESTIC_MIG_2016', 'DOMESTIC_MIG_2017', 'DOMESTIC_MIG_2018', 'DOMESTIC_MIG_2019', 'NET_MIG_2010', 'NET_MIG_2011', 'NET_MIG_2012', 'NET_MIG_2013', 'NET_MIG_2014', 'NET_MIG_2015', 'NET_MIG_2016', 'NET_MIG_2017', 'NET_MIG_2018', 'NET_MIG_2019', 'RESIDUAL_2010', 'RESIDUAL_2011', 'RESIDUAL_2012', 'RESIDUAL_2013', 'RESIDUAL_2014', 'RESIDUAL_2015', 'RESIDUAL_2016', 'RESIDUAL_2017', 'RESIDUAL_2018', 'RESIDUAL_2019', 'GQ_ESTIMATES_BASE_2010', 'GQ_ESTIMATES_2010', 'GQ_ESTIMATES_2011', 'GQ_ESTIMATES_2012', 'GQ_ESTIMATES_2013', 'GQ_ESTIMATES_2014', 'GQ_ESTIMATES_2015', 'GQ_ESTIMATES_2016', 'GQ_ESTIMATES_2017', 'GQ_ESTIMATES_2018', 'GQ_ESTIMATES_2019', 'R_birth_2011', 'R_birth_2012', 'R_birth_2013', 'R_birth_2014', 'R_birth_2015', 'R_birth_2016', 'R_birth_2017', 'R_birth_2018', 'R_birth_2019', 'R_death_2011', 'R_death_2012', 'R_death_2013', 'R_death_2014', 'R_death_2015', 'R_death_2016', 'R_death_2017', 'R_death_2018', 'R_death_2019', 'R_NATURAL_INC_2011', 'R_NATURAL_INC_2012', 'R_NATURAL_INC_2013', 'R_NATURAL_INC_2014', 'R_NATURAL_INC_2015', 'R_NATURAL_INC_2016', 'R_NATURAL_INC_2017', 'R_NATURAL_INC_2018', 'R_NATURAL_INC_2019', 'R_INTERNATIONAL_MIG_2011', 'R_INTERNATIONAL_MIG_2012', 'R_INTERNATIONAL_MIG_2013', 'R_INTERNATIONAL_MIG_2014', 'R_INTERNATIONAL_MIG_2015', 'R_INTERNATIONAL_MIG_2016', 'R_INTERNATIONAL_MIG_2017', 'R_INTERNATIONAL_MIG_2018', 'R_INTERNATIONAL_MIG_2019', 'R_DOMESTIC_MIG_2011', 'R_DOMESTIC_MIG_2012', 'R_DOMESTIC_MIG_2013', 'R_DOMESTIC_MIG_2014', 'R_DOMESTIC_MIG_2015', 'R_DOMESTIC_MIG_2016', 'R_DOMESTIC_MIG_2017', 'R_DOMESTIC_MIG_2018', 'R_DOMESTIC_MIG_2019', 'R_NET_MIG_2011', 'R_NET_MIG_2012', 'R_NET_MIG_2013', 'R_NET_MIG_2014', 'R_NET_MIG_2015', 'R_NET_MIG_2016', 'R_NET_MIG_2017', 'R_NET_MIG_2018', 'R_NET_MIG_2019', '2003 Rural-urban Continuum Code', '2003 Urban Influence Code', '2013 Rural-urban Continuum Code', '2013 Urban Influence Code', 'Less than a high school diploma, 1970', 'High school diploma only, 1970', 'Some college (1-3 years), 1970', 'Four years of college or higher, 1970', 'Percent of adults with less than a high school diploma, 1970', 'Percent of adults with a high school diploma only, 1970', 'Percent of adults completing some college (1-3 years), 1970', 'Percent of adults completing four years of college or higher, 1970', 'Less than a high school diploma, 1980', 'High school diploma only, 1980', 'Some college (1-3 years), 1980', 'Four years of college or higher, 1980', 'Percent of adults with less than a high school diploma, 1980', 'Percent of adults with a high school diploma only, 1980', 'Percent of adults completing some college (1-3 years), 1980', 'Percent of adults completing four years of college or higher, 1980', 'Less than a high school diploma, 1990', 'High school diploma only, 1990', \"Some college or associate's degree, 1990\", \"Bachelor's degree or higher, 1990\", 'Percent of adults with less than a high school diploma, 1990', 'Percent of adults with a high school diploma only, 1990', \"Percent of adults completing some college or associate's degree, 1990\", \"Percent of adults with a bachelor's degree or higher, 1990\", 'Less than a high school diploma, 2000', 'High school diploma only, 2000', \"Some college or associate's degree, 2000\", \"Bachelor's degree or higher, 2000\", 'Percent of adults with less than a high school diploma, 2000', 'Percent of adults with a high school diploma only, 2000', \"Percent of adults completing some college or associate's degree, 2000\", \"Percent of adults with a bachelor's degree or higher, 2000\", 'Less than a high school diploma, 2015-19', 'High school diploma only, 2015-19', \"Some college or associate's degree, 2015-19\", \"Bachelor's degree or higher, 2015-19\", 'Percent of adults with less than a high school diploma, 2015-19', 'Percent of adults with a high school diploma only, 2015-19', \"Percent of adults completing some college or associate's degree, 2015-19\", \"Percent of adults with a bachelor's degree or higher, 2015-19\", 'Rural_urban_continuum_code_2013', 'Urban_influence_code_2013', 'Metro_2013', 'Civilian_labor_force_2000', 'Employed_2000', 'Unemployed_2000', 'Unemployment_rate_2000', 'Civilian_labor_force_2001', 'Employed_2001', 'Unemployed_2001', 'Unemployment_rate_2001', 'Civilian_labor_force_2002', 'Employed_2002', 'Unemployed_2002', 'Unemployment_rate_2002', 'Civilian_labor_force_2003', 'Employed_2003', 'Unemployed_2003', 'Unemployment_rate_2003', 'Civilian_labor_force_2004', 'Employed_2004', 'Unemployed_2004', 'Unemployment_rate_2004', 'Civilian_labor_force_2005', 'Employed_2005', 'Unemployed_2005', 'Unemployment_rate_2005', 'Civilian_labor_force_2006', 'Employed_2006', 'Unemployed_2006', 'Unemployment_rate_2006', 'Civilian_labor_force_2007', 'Employed_2007', 'Unemployed_2007', 'Unemployment_rate_2007', 'Civilian_labor_force_2008', 'Employed_2008', 'Unemployed_2008', 'Unemployment_rate_2008', 'Civilian_labor_force_2009', 'Employed_2009', 'Unemployed_2009', 'Unemployment_rate_2009', 'Civilian_labor_force_2010', 'Employed_2010', 'Unemployed_2010', 'Unemployment_rate_2010', 'Civilian_labor_force_2011', 'Employed_2011', 'Unemployed_2011', 'Unemployment_rate_2011', 'Civilian_labor_force_2012', 'Employed_2012', 'Unemployed_2012', 'Unemployment_rate_2012', 'Civilian_labor_force_2013', 'Employed_2013', 'Unemployed_2013', 'Unemployment_rate_2013', 'Civilian_labor_force_2014', 'Employed_2014', 'Unemployed_2014', 'Unemployment_rate_2014', 'Civilian_labor_force_2015', 'Employed_2015', 'Unemployed_2015', 'Unemployment_rate_2015', 'Civilian_labor_force_2016', 'Employed_2016', 'Unemployed_2016', 'Unemployment_rate_2016', 'Civilian_labor_force_2017', 'Employed_2017', 'Unemployed_2017', 'Unemployment_rate_2017', 'Civilian_labor_force_2018', 'Employed_2018', 'Unemployed_2018', 'Unemployment_rate_2018', 'Civilian_labor_force_2019', 'Employed_2019', 'Unemployed_2019', 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Med_HH_Income_Percent_of_State_Total_2019', 'Rural-urban_Continuum_Code_2003', 'Rural-urban_Continuum_Code_2013', 'POVALL_2019', 'CI90LBALL_2019', 'CI90UBALL_2019', 'PCTPOVALL_2019', 'CI90LBALLP_2019', 'CI90UBALLP_2019', 'POV017_2019', 'CI90LB017_2019', 'CI90UB017_2019', 'PCTPOV017_2019', 'CI90LB017P_2019', 'CI90UB017P_2019', 'POV517_2019', 'CI90LB517_2019', 'CI90UB517_2019', 'PCTPOV517_2019', 'CI90LB517P_2019', 'CI90UB517P_2019', 'MEDHHINC_2019', 'CI90LBINC_2019', 'CI90UBINC_2019', 'POV04_2019', 'CI90LB04_2019', 'CI90UB04_2019', 'PCTPOV04_2019', 'CI90LB04P_2019', 'CI90UB04P_2019', 'candidatevotes_2000_republican', 'candidatevotes_2004_republican', 'candidatevotes_2008_republican', 'candidatevotes_2012_republican', 'candidatevotes_2016_republican', 'share_2000_republican', 'share_2004_republican', 'share_2008_republican', 'share_2012_republican', 'share_2016_republican'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() category['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'FIPS_x', 'state_name', 'county_fips', 'county_name', 'State', 'Area_Name', 'FIPS'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†Lasso?Documentation for LassoLasso(alpha=0.1) \n\n\nLe pipeline prend la forme suivante, une\nfois finalis√© (question 4):\n\n\nPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('number',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  ['ALAND', 'AWATER',\n                                                   'votes_gop', 'votes_dem',\n                                                   'total_votes', 'diff',\n                                                   'FIPS_y',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2003',\n                                                   'Rural-urban_Continuum '\n                                                   'Code_2013',\n                                                   'Urban_Influence_Code_2003',\n                                                   'Urban_Influence_Code_2013',\n                                                   'Economi...\n                                                   'N_POP_CHG_2015', ...]),\n                                                 ('category',\n                                                  Pipeline(steps=[('impute',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('one-hot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['STATEFP', 'COUNTYFP',\n                                                   'COUNTYNS', 'AFFGEOID',\n                                                   'GEOID', 'NAME', 'LSAD',\n                                                   'FIPS_x', 'state_name',\n                                                   'county_fips', 'county_name',\n                                                   'State', 'Area_Name',\n                                                   'FIPS'])])),\n                ('model', Lasso(alpha=0.1))]) ¬†preprocess: ColumnTransformer?Documentation for preprocess: ColumnTransformerColumnTransformer(transformers=[('number',\n                                 Pipeline(steps=[('impute', SimpleImputer()),\n                                                 ('scale', StandardScaler())]),\n                                 ['ALAND', 'AWATER', 'votes_gop', 'votes_dem',\n                                  'total_votes', 'diff', 'FIPS_y',\n                                  'Rural-urban_Continuum Code_2003',\n                                  'Rural-urban_Continuum Code_2013',\n                                  'Urban_Influence_Code_2003',\n                                  'Urban_Influence_Code_2013',\n                                  'Economic_typology_2015', 'CENSUS_2010_POP'...\n                                  'N_POP_CHG_2013', 'N_POP_CHG_2014',\n                                  'N_POP_CHG_2015', ...]),\n                                ('category',\n                                 Pipeline(steps=[('impute',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('one-hot',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False))]),\n                                 ['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID',\n                                  'GEOID', 'NAME', 'LSAD', 'FIPS_x',\n                                  'state_name', 'county_fips', 'county_name',\n                                  'State', 'Area_Name', 'FIPS'])]) number['ALAND', 'AWATER', 'votes_gop', 'votes_dem', 'total_votes', 'diff', 'FIPS_y', 'Rural-urban_Continuum Code_2003', 'Rural-urban_Continuum Code_2013', 'Urban_Influence_Code_2003', 'Urban_Influence_Code_2013', 'Economic_typology_2015', 'CENSUS_2010_POP', 'ESTIMATES_BASE_2010', 'POP_ESTIMATE_2010', 'POP_ESTIMATE_2011', 'POP_ESTIMATE_2012', 'POP_ESTIMATE_2013', 'POP_ESTIMATE_2014', 'POP_ESTIMATE_2015', 'POP_ESTIMATE_2016', 'POP_ESTIMATE_2017', 'POP_ESTIMATE_2018', 'POP_ESTIMATE_2019', 'N_POP_CHG_2010', 'N_POP_CHG_2011', 'N_POP_CHG_2012', 'N_POP_CHG_2013', 'N_POP_CHG_2014', 'N_POP_CHG_2015', 'N_POP_CHG_2016', 'N_POP_CHG_2017', 'N_POP_CHG_2018', 'N_POP_CHG_2019', 'Births_2010', 'Births_2011', 'Births_2012', 'Births_2013', 'Births_2014', 'Births_2015', 'Births_2016', 'Births_2017', 'Births_2018', 'Births_2019', 'Deaths_2010', 'Deaths_2011', 'Deaths_2012', 'Deaths_2013', 'Deaths_2014', 'Deaths_2015', 'Deaths_2016', 'Deaths_2017', 'Deaths_2018', 'Deaths_2019', 'NATURAL_INC_2010', 'NATURAL_INC_2011', 'NATURAL_INC_2012', 'NATURAL_INC_2013', 'NATURAL_INC_2014', 'NATURAL_INC_2015', 'NATURAL_INC_2016', 'NATURAL_INC_2017', 'NATURAL_INC_2018', 'NATURAL_INC_2019', 'INTERNATIONAL_MIG_2010', 'INTERNATIONAL_MIG_2011', 'INTERNATIONAL_MIG_2012', 'INTERNATIONAL_MIG_2013', 'INTERNATIONAL_MIG_2014', 'INTERNATIONAL_MIG_2015', 'INTERNATIONAL_MIG_2016', 'INTERNATIONAL_MIG_2017', 'INTERNATIONAL_MIG_2018', 'INTERNATIONAL_MIG_2019', 'DOMESTIC_MIG_2010', 'DOMESTIC_MIG_2011', 'DOMESTIC_MIG_2012', 'DOMESTIC_MIG_2013', 'DOMESTIC_MIG_2014', 'DOMESTIC_MIG_2015', 'DOMESTIC_MIG_2016', 'DOMESTIC_MIG_2017', 'DOMESTIC_MIG_2018', 'DOMESTIC_MIG_2019', 'NET_MIG_2010', 'NET_MIG_2011', 'NET_MIG_2012', 'NET_MIG_2013', 'NET_MIG_2014', 'NET_MIG_2015', 'NET_MIG_2016', 'NET_MIG_2017', 'NET_MIG_2018', 'NET_MIG_2019', 'RESIDUAL_2010', 'RESIDUAL_2011', 'RESIDUAL_2012', 'RESIDUAL_2013', 'RESIDUAL_2014', 'RESIDUAL_2015', 'RESIDUAL_2016', 'RESIDUAL_2017', 'RESIDUAL_2018', 'RESIDUAL_2019', 'GQ_ESTIMATES_BASE_2010', 'GQ_ESTIMATES_2010', 'GQ_ESTIMATES_2011', 'GQ_ESTIMATES_2012', 'GQ_ESTIMATES_2013', 'GQ_ESTIMATES_2014', 'GQ_ESTIMATES_2015', 'GQ_ESTIMATES_2016', 'GQ_ESTIMATES_2017', 'GQ_ESTIMATES_2018', 'GQ_ESTIMATES_2019', 'R_birth_2011', 'R_birth_2012', 'R_birth_2013', 'R_birth_2014', 'R_birth_2015', 'R_birth_2016', 'R_birth_2017', 'R_birth_2018', 'R_birth_2019', 'R_death_2011', 'R_death_2012', 'R_death_2013', 'R_death_2014', 'R_death_2015', 'R_death_2016', 'R_death_2017', 'R_death_2018', 'R_death_2019', 'R_NATURAL_INC_2011', 'R_NATURAL_INC_2012', 'R_NATURAL_INC_2013', 'R_NATURAL_INC_2014', 'R_NATURAL_INC_2015', 'R_NATURAL_INC_2016', 'R_NATURAL_INC_2017', 'R_NATURAL_INC_2018', 'R_NATURAL_INC_2019', 'R_INTERNATIONAL_MIG_2011', 'R_INTERNATIONAL_MIG_2012', 'R_INTERNATIONAL_MIG_2013', 'R_INTERNATIONAL_MIG_2014', 'R_INTERNATIONAL_MIG_2015', 'R_INTERNATIONAL_MIG_2016', 'R_INTERNATIONAL_MIG_2017', 'R_INTERNATIONAL_MIG_2018', 'R_INTERNATIONAL_MIG_2019', 'R_DOMESTIC_MIG_2011', 'R_DOMESTIC_MIG_2012', 'R_DOMESTIC_MIG_2013', 'R_DOMESTIC_MIG_2014', 'R_DOMESTIC_MIG_2015', 'R_DOMESTIC_MIG_2016', 'R_DOMESTIC_MIG_2017', 'R_DOMESTIC_MIG_2018', 'R_DOMESTIC_MIG_2019', 'R_NET_MIG_2011', 'R_NET_MIG_2012', 'R_NET_MIG_2013', 'R_NET_MIG_2014', 'R_NET_MIG_2015', 'R_NET_MIG_2016', 'R_NET_MIG_2017', 'R_NET_MIG_2018', 'R_NET_MIG_2019', '2003 Rural-urban Continuum Code', '2003 Urban Influence Code', '2013 Rural-urban Continuum Code', '2013 Urban Influence Code', 'Less than a high school diploma, 1970', 'High school diploma only, 1970', 'Some college (1-3 years), 1970', 'Four years of college or higher, 1970', 'Percent of adults with less than a high school diploma, 1970', 'Percent of adults with a high school diploma only, 1970', 'Percent of adults completing some college (1-3 years), 1970', 'Percent of adults completing four years of college or higher, 1970', 'Less than a high school diploma, 1980', 'High school diploma only, 1980', 'Some college (1-3 years), 1980', 'Four years of college or higher, 1980', 'Percent of adults with less than a high school diploma, 1980', 'Percent of adults with a high school diploma only, 1980', 'Percent of adults completing some college (1-3 years), 1980', 'Percent of adults completing four years of college or higher, 1980', 'Less than a high school diploma, 1990', 'High school diploma only, 1990', \"Some college or associate's degree, 1990\", \"Bachelor's degree or higher, 1990\", 'Percent of adults with less than a high school diploma, 1990', 'Percent of adults with a high school diploma only, 1990', \"Percent of adults completing some college or associate's degree, 1990\", \"Percent of adults with a bachelor's degree or higher, 1990\", 'Less than a high school diploma, 2000', 'High school diploma only, 2000', \"Some college or associate's degree, 2000\", \"Bachelor's degree or higher, 2000\", 'Percent of adults with less than a high school diploma, 2000', 'Percent of adults with a high school diploma only, 2000', \"Percent of adults completing some college or associate's degree, 2000\", \"Percent of adults with a bachelor's degree or higher, 2000\", 'Less than a high school diploma, 2015-19', 'High school diploma only, 2015-19', \"Some college or associate's degree, 2015-19\", \"Bachelor's degree or higher, 2015-19\", 'Percent of adults with less than a high school diploma, 2015-19', 'Percent of adults with a high school diploma only, 2015-19', \"Percent of adults completing some college or associate's degree, 2015-19\", \"Percent of adults with a bachelor's degree or higher, 2015-19\", 'Rural_urban_continuum_code_2013', 'Urban_influence_code_2013', 'Metro_2013', 'Civilian_labor_force_2000', 'Employed_2000', 'Unemployed_2000', 'Unemployment_rate_2000', 'Civilian_labor_force_2001', 'Employed_2001', 'Unemployed_2001', 'Unemployment_rate_2001', 'Civilian_labor_force_2002', 'Employed_2002', 'Unemployed_2002', 'Unemployment_rate_2002', 'Civilian_labor_force_2003', 'Employed_2003', 'Unemployed_2003', 'Unemployment_rate_2003', 'Civilian_labor_force_2004', 'Employed_2004', 'Unemployed_2004', 'Unemployment_rate_2004', 'Civilian_labor_force_2005', 'Employed_2005', 'Unemployed_2005', 'Unemployment_rate_2005', 'Civilian_labor_force_2006', 'Employed_2006', 'Unemployed_2006', 'Unemployment_rate_2006', 'Civilian_labor_force_2007', 'Employed_2007', 'Unemployed_2007', 'Unemployment_rate_2007', 'Civilian_labor_force_2008', 'Employed_2008', 'Unemployed_2008', 'Unemployment_rate_2008', 'Civilian_labor_force_2009', 'Employed_2009', 'Unemployed_2009', 'Unemployment_rate_2009', 'Civilian_labor_force_2010', 'Employed_2010', 'Unemployed_2010', 'Unemployment_rate_2010', 'Civilian_labor_force_2011', 'Employed_2011', 'Unemployed_2011', 'Unemployment_rate_2011', 'Civilian_labor_force_2012', 'Employed_2012', 'Unemployed_2012', 'Unemployment_rate_2012', 'Civilian_labor_force_2013', 'Employed_2013', 'Unemployed_2013', 'Unemployment_rate_2013', 'Civilian_labor_force_2014', 'Employed_2014', 'Unemployed_2014', 'Unemployment_rate_2014', 'Civilian_labor_force_2015', 'Employed_2015', 'Unemployed_2015', 'Unemployment_rate_2015', 'Civilian_labor_force_2016', 'Employed_2016', 'Unemployed_2016', 'Unemployment_rate_2016', 'Civilian_labor_force_2017', 'Employed_2017', 'Unemployed_2017', 'Unemployment_rate_2017', 'Civilian_labor_force_2018', 'Employed_2018', 'Unemployed_2018', 'Unemployment_rate_2018', 'Civilian_labor_force_2019', 'Employed_2019', 'Unemployed_2019', 'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Med_HH_Income_Percent_of_State_Total_2019', 'Rural-urban_Continuum_Code_2003', 'Rural-urban_Continuum_Code_2013', 'POVALL_2019', 'CI90LBALL_2019', 'CI90UBALL_2019', 'PCTPOVALL_2019', 'CI90LBALLP_2019', 'CI90UBALLP_2019', 'POV017_2019', 'CI90LB017_2019', 'CI90UB017_2019', 'PCTPOV017_2019', 'CI90LB017P_2019', 'CI90UB017P_2019', 'POV517_2019', 'CI90LB517_2019', 'CI90UB517_2019', 'PCTPOV517_2019', 'CI90LB517P_2019', 'CI90UB517P_2019', 'MEDHHINC_2019', 'CI90LBINC_2019', 'CI90UBINC_2019', 'POV04_2019', 'CI90LB04_2019', 'CI90UB04_2019', 'PCTPOV04_2019', 'CI90LB04P_2019', 'CI90UB04P_2019', 'candidatevotes_2000_republican', 'candidatevotes_2004_republican', 'candidatevotes_2008_republican', 'candidatevotes_2012_republican', 'candidatevotes_2016_republican', 'share_2000_republican', 'share_2004_republican', 'share_2008_republican', 'share_2012_republican', 'share_2016_republican'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() category['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD', 'FIPS_x', 'state_name', 'county_fips', 'county_name', 'State', 'Area_Name', 'FIPS'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent') ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†Lasso?Documentation for LassoLasso(alpha=0.1) \n\n\nA l‚Äôissue de la question 5,\nles variables s√©lectionn√©es sont :\nLe mod√®le est assez parcimonieux puisqu‚Äôun sous-√©chantillon de nos\nvariables initiales (d‚Äôautant que nos variables cat√©gorielles\nont √©t√© √©clat√©es en de nombreuses variables\npar le one hot encoding)\n\n\n0                                                 ALAND\n1                                                FIPS_y\n2                                INTERNATIONAL_MIG_2017\n3                                     DOMESTIC_MIG_2014\n4                                     DOMESTIC_MIG_2017\n5                                         RESIDUAL_2010\n6                                         RESIDUAL_2019\n7                                          R_death_2012\n8                                          R_death_2019\n9                                    R_NATURAL_INC_2019\n10                             R_INTERNATIONAL_MIG_2011\n11                                  R_DOMESTIC_MIG_2012\n12    Percent of adults with a bachelor's degree or ...\n13    Percent of adults with a high school diploma o...\n14    Percent of adults with a bachelor's degree or ...\n15    Percent of adults with a bachelor's degree or ...\n16                      Rural_urban_continuum_code_2013\n17                                           Metro_2013\n18                               Unemployment_rate_2002\n19                               Unemployment_rate_2003\n20                               Unemployment_rate_2012\n21                      Rural-urban_Continuum_Code_2003\n22                      Rural-urban_Continuum_Code_2013\n23                                      CI90LB517P_2019\n24                       candidatevotes_2016_republican\n25                                share_2012_republican\n26                                share_2016_republican\ndtype: object\n\n\nCertaines variables font sens, comme les variables d‚Äô√©ducation par exemple. Notamment, un des meilleurs pr√©dicteurs pour le score des R√©publicains en 2020 est‚Ä¶ le score des R√©publicains (et m√©caniquement des d√©mocrates) en 2016 et 2012.\nPar ailleurs, on s√©lectionne des variables redondantes. Une phase plus approfondie de nettoyage des donn√©es serait en r√©alit√© n√©cessaire.\nLe mod√®le parcimonieux est (l√©g√®rement) plus performant:\n\n\n\n\n\n\n\n\nparcimonieux\nnon parcimonieux\n\n\n\n\nRMSE\n2.703622\n2.309011\n\n\nR2\n0.972728\n0.980108\n\n\nNombre de param√®tres\n27.000000\n332.000000\n\n\n\n\n\n\nD‚Äôailleurs, on pourrait d√©j√† remarquer\nque r√©gresser le score de 2020 sur celui\nde 2016 am√®ne d√©j√† √† de tr√®s bonnes\nperformances explicatives, ce qui sugg√®re\nque le vote se comporte comme un processus\nautor√©gressif:\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsmf.ols(\"per_gop ~ share_2016_republican\", data=df2).fit().summary()\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\nper_gop\nR-squared:\n0.968\n\n\nModel:\nOLS\nAdj. R-squared:\n0.968\n\n\nMethod:\nLeast Squares\nF-statistic:\n9.292e+04\n\n\nDate:\nMon, 27 May 2024\nProb (F-statistic):\n0.00\n\n\nTime:\n17:02:36\nLog-Likelihood:\n6603.5\n\n\nNo. Observations:\n3107\nAIC:\n-1.320e+04\n\n\nDf Residuals:\n3105\nBIC:\n-1.319e+04\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0109\n0.002\n5.056\n0.000\n0.007\n0.015\n\n\nshare_2016_republican\n1.0101\n0.003\n304.835\n0.000\n1.004\n1.017\n\n\n\n\n\n\nOmnibus:\n2045.232\nDurbin-Watson:\n1.982\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n51553.266\n\n\nSkew:\n2.731\nProb(JB):\n0.00\n\n\nKurtosis:\n22.193\nCond. No.\n9.00\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/4_featureselection.html#informations-additionnelles",
    "href": "content/modelisation/4_featureselection.html#informations-additionnelles",
    "title": "S√©lection de variables : une introduction",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n7d12af8\n\n\n2023-12-05 10:30:08\n\n\nlinogaliana\n\n\nModularise la partie import pour l‚Äôavoir partout\n\n\n\n\n417fb66\n\n\n2023-12-04 18:49:21\n\n\nLino Galiana\n\n\nCorrections partie ML (#468)\n\n\n\n\n0b405bc\n\n\n2023-11-27 20:58:37\n\n\nLino Galiana\n\n\nUpdate box lasso\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\ne12187b\n\n\n2023-06-12 10:31:40\n\n\nLino Galiana\n\n\nFeature selection deprecated functions (#363)\n\n\n\n\nf5ad021\n\n\n2022-11-15 17:40:16\n\n\nLino Galiana\n\n\nRelec clustering et lasso (#322)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n7058752\n\n\n2022-03-04 15:35:17\n\n\nLino Galiana\n\n\nRelecture Word2Vec (#216)\n\n\n\n\nc3bf4d4\n\n\n2021-12-06 19:43:26\n\n\nLino Galiana\n\n\nFinalise debug partie ML (#190)\n\n\n\n\nfb14d40\n\n\n2021-12-06 17:00:52\n\n\nLino Galiana\n\n\nModifie l‚Äôimport du script (#187)\n\n\n\n\n37ecfa3\n\n\n2021-12-06 14:48:05\n\n\nLino Galiana\n\n\nEssaye nom diff√©rent (#186)\n\n\n\n\n2c8fd0d\n\n\n2021-12-06 13:06:36\n\n\nLino Galiana\n\n\nProbl√®me d‚Äôex√©cution du script import data ML (#185)\n\n\n\n\n5d0a5e3\n\n\n2021-12-04 07:41:43\n\n\nLino Galiana\n\n\nMAJ URL script recup data (#184)\n\n\n\n\n5c10490\n\n\n2021-12-03 17:44:08\n\n\nLino Galiana\n\n\nRelec @antuki partie modelisation (#183)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n8fea62e\n\n\n2020-11-13 11:58:17\n\n\nLino Galiana\n\n\nCorrection de quelques typos partie ML (#85)\n\n\n\n\n347f50f\n\n\n2020-11-12 15:08:18\n\n\nLino Galiana\n\n\nSuite de la partie machine learning (#78)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "S√©lection de variables : une introduction"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html",
    "href": "content/modelisation/6_pipeline.html",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre pr√©sente la premi√®re application\nd‚Äôune journ√©e de cours que j‚Äôai\ndonn√© √† l‚ÄôUniversit√© Dauphine dans le cadre\ndes PSL Data Week.\nPour lire les donn√©es de mani√®re efficace, nous\nproposons d‚Äôutiliser le package duckdb.\nPour l‚Äôinstaller, voici la commande :\n!pip install duckdb",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#d√©finitions-pr√©alables",
    "href": "content/modelisation/6_pipeline.html#d√©finitions-pr√©alables",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "1.1 D√©finitions pr√©alables",
    "text": "1.1 D√©finitions pr√©alables\nCe chapitre nous am√®nera √† explorer plusieurs √©cosyst√®mes, pour lesquels on retrouve quelques buzz-words dont voici les d√©finitions :\n\n\n\n\n\n\n\nTerme\nD√©finition\n\n\n\n\nDevOps\nMouvement en ing√©nierie informatique et une pratique technique visant √† l‚Äôunification du d√©veloppement logiciel (dev) et de l‚Äôadministration des infrastructures informatiques (ops)\n\n\nMLOps\nEnsemble de pratiques qui vise √† d√©ployer et maintenir des mod√®les de machine learning en production de mani√®re fiable et efficace\n\n\n\nCe chapitre fera des r√©f√©rences r√©guli√®res au cours\nde 3e ann√©e de l‚ÄôENSAE\n‚ÄúMise en production de projets data science‚Äù.",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#objectif",
    "href": "content/modelisation/6_pipeline.html#objectif",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "1.2 Objectif",
    "text": "1.2 Objectif\nLes chapitres pr√©c√©dents ont permis de montrer des bouts de code\n√©pars pour entra√Æner des mod√®les ou faire du preprocessing.\nCette d√©marche est int√©ressante pour t√¢tonner mais risque d‚Äô√™tre co√ªteuse\nult√©rieurement s‚Äôil est n√©cessaire d‚Äôajouter une √©tape de preprocessing\nou de changer d‚Äôalgorithme.\nLes pipelines sont pens√©s pour simplifier la mise en production\nult√©rieure d‚Äôun mod√®le de machine learning.\nIls sont au coeur de la d√©marche de MLOps qui est\npr√©sent√©e\ndans le cours de 3e ann√©e de l‚ÄôENSAE\nde ‚ÄúMise en production de projets data science‚Äù,\nqui vise √† simplifier la mise en oeuvre op√©rationnelle de\nprojets utilisant des techniques de machine learning.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#les-pipelines-scikit",
    "href": "content/modelisation/6_pipeline.html#les-pipelines-scikit",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "1.3 Les pipelines Scikit",
    "text": "1.3 Les pipelines Scikit\nHeureusement, Scikit propose un excellent outil pour proposer un cadre\ng√©n√©ral pour cr√©er une cha√Æne de production machine learning. Il\ns‚Äôagit des\npipelines.\nIls pr√©sentent de nombreux int√©r√™ts, parmi lesquels :\n\nIls sont tr√®s pratiques et lisibles. On rentre des donn√©es en entr√©e, on n‚Äôappelle qu‚Äôune seule fois les m√©thodes fit et predict ce qui permet de s‚Äôassurer une gestion coh√©rente des transformations de variables, par exemple apr√®s l‚Äôappel d‚Äôun StandardScaler ;\nLa modularit√© rend ais√©e la mise √† jour d‚Äôun pipeline et renforce la capacit√© √† le r√©utiliser ;\nIls permettent de facilement chercher les hyperparam√®tres d‚Äôun mod√®le. Sans pipeline, √©crire un code qui fait du tuning d‚Äôhyperparam√®tres peut √™tre p√©nible. Avec les pipelines, c‚Äôest une ligne de code ;\nLa s√©curit√© d‚Äô√™tre certain que les √©tapes de preprocessing sont bien appliqu√©es aux jeux de donn√©es d√©sir√©s avant l‚Äôestimation.\n\n\n\n Hint\nUn des int√©r√™ts des pipelines scikit est qu‚Äôils fonctionnent aussi avec\ndes m√©thodes qui ne sont pas issues de scikit.\nIl est possible d‚Äôintroduire un mod√®le de r√©seau de neurone Keras dans\nun pipeline scikit.\nPour introduire un mod√®le √©conom√©trique statsmodels\nc‚Äôest un peu plus co√ªteux mais nous allons proposer des exemples\nqui peuvent servir de mod√®le et qui montrent que c‚Äôest faisable\nsans trop de difficult√©.",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#donn√©es-utilis√©es",
    "href": "content/modelisation/6_pipeline.html#donn√©es-utilis√©es",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "2.1 Donn√©es utilis√©es",
    "text": "2.1 Donn√©es utilis√©es\nNous allons utiliser les donn√©es\nde transactions immobili√®res DVF pour chercher\nla meilleure mani√®re de pr√©dire, sachant les caract√©ristiques d‚Äôun bien, son\nprix.\nCes donn√©es sont mises √† disposition\nsur data.gouv.\nN√©anmoins, le format csv n‚Äô√©tant pas pratique pour importer des jeux de donn√©es\nvolumineux, nous proposons de privil√©gier la version Parquet mise √†\ndisposition par Eric Mauvi√®re sur data.gouv.\nL‚Äôapproche la plus efficace pour lire ces donn√©es est\nd‚Äôutiliser DuckDB afin de lire le fichier, extraire les colonnes\nd‚Äôint√©r√™t puis passer √† Pandas (pour en savoir plus sur\nl‚Äôint√©r√™t de DuckDB pour lire des fichiers volumineux, vous pouvez\nconsulter ce post de blog ou\ncelui-ci √©crit\npar Eric Mauvi√®re).\nM√™me si, en soi, les gains de temps sont faibles car DuckDB optimise\nles requ√™tes HTTPS n√©cessaires √† l‚Äôimport des donn√©es, nous proposons\nde t√©l√©charger les donn√©es pour r√©duire les besoins de bande passante.\n\nimport requests\nimport os\n\nurl = \"https://www.data.gouv.fr/fr/datasets/r/56bde1e9-e214-408b-888d-34c57ff005c4\"\nfile_name = \"dvf.parquet\"\n\n# Check if the file already exists\nif not os.path.exists(file_name):\n    response = requests.get(url)\n\n    if response.status_code == 200:\n        with open(file_name, \"wb\") as f:\n            f.write(response.content)\n        print(\"T√©l√©chargement r√©ussi.\")\n    else:\n        print(f\"√âchec du t√©l√©chargement. Code d'√©tat : {response.status_code}\")\nelse:\n    print(f\"Le fichier '{file_name}' existe d√©j√†. Aucun t√©l√©chargement n√©cessaire.\")\n\nEn premier lieu, puisque cela va faciliter les requ√™tes SQL ult√©rieures, on cr√©e\nune vue :\n\nimport duckdb\n\nduckdb.sql(f'CREATE OR REPLACE VIEW dvf AS SELECT * FROM read_parquet(\"dvf.parquet\")')\n\nLes donn√©es prennent la forme suivante :\n\nduckdb.sql(f\"SELECT * FROM dvf LIMIT 5\")\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Identifiant de doc‚Ä¶  ‚îÇ Reference document ‚îÇ ‚Ä¶ ‚îÇ Nature culture ‚îÇ Nature culture spe‚Ä¶  ‚îÇ Surface terrain ‚îÇ\n‚îÇ       varchar        ‚îÇ      varchar       ‚îÇ   ‚îÇ    varchar     ‚îÇ       varchar        ‚îÇ      int64      ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ NULL           ‚îÇ NULL                 ‚îÇ            NULL ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ S              ‚îÇ NULL                 ‚îÇ              84 ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ S              ‚îÇ NULL                 ‚îÇ              88 ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ NULL           ‚îÇ NULL                 ‚îÇ            NULL ‚îÇ\n‚îÇ NULL                 ‚îÇ NULL               ‚îÇ ‚Ä¶ ‚îÇ T              ‚îÇ NULL                 ‚îÇ             510 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ 5 rows                                                                             43 columns (5 shown) ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\nLes variables que nous allons conserver sont les suivantes,\nnous allons les reformater pour la suite de l‚Äôexercice.\n\nxvars = [\n    \"Date mutation\",\n    \"Valeur fonciere\",\n    \"Nombre de lots\",\n    \"Code type local\",\n    \"Nombre pieces principales\",\n]\nxvars = \", \".join([f'\"{s}\"' for s in xvars])\n\n\nmutations = duckdb.sql(\n    f\"\"\"\n    SELECT\n    date_part('month', \"Date mutation\") AS month,\n    substring(\"Code postal\", 1, 2) AS dep,\n    {xvars},\n    COLUMNS('Surface Carrez.*')\n    FROM dvf\n    \"\"\"\n).to_df()\n\ncolonnes_surface = mutations.columns[mutations.columns.str.startswith(\"Surface Carrez\")]\nmutations.loc[:, colonnes_surface] = (\n    mutations.loc[:, colonnes_surface]\n    .replace({\",\": \".\"}, regex=True)\n    .astype(float)\n    .fillna(0)\n)\n\n\n\n\n\n\n Note\nLe fichier Parquet mis √† disposition sur data.gouv pr√©sente une incoh√©rence de mise en forme de\ncertaines colonnes √† cause des virgules qui emp√™chent le formattage sous forme de colonne\nnum√©rique.\nLe code ci-dessus effectue la conversion ad√©quate au niveau de Pandas.\n\n\n\nmutations.head(2)\n\n\n\n\n\n\n\n\n\nmonth\ndep\nDate mutation\nValeur fonciere\nNombre de lots\nCode type local\nNombre pieces principales\nSurface Carrez du 1er lot\nSurface Carrez du 2eme lot\nSurface Carrez du 3eme lot\nSurface Carrez du 4eme lot\nSurface Carrez du 5eme lot\n\n\n\n\n0\n1\n01\n2022-01-03\n55000.0\n1\n2.0\n1.0\n24.1\n0.0\n0.0\n0.0\n0.0\n\n\n1\n1\n01\n2022-01-03\n143000.0\n0\nNaN\nNaN\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\n\n\n\nIntroduire un effet confinement\n\nSi vous travaillez avec les donn√©es de 2020, n‚Äôoubliez pas\nd‚Äôint√©grer l‚Äôeffet\nconfinement dans vos mod√®les puisque cela a lourdement\naffect√© les possibilit√©s de transaction sur cette p√©riode, donc\nl‚Äôeffet potentiel de certaines variables explicatives du prix.\nPour introduire cet effet, vous pouvez cr√©er une variable\nindicatrice entre les dates en question:\nmutations[\"confinement\"] = (\n    mutations[\"Date mutation\"]\n    .between(pd.to_datetime(\"2020-03-17\"), pd.to_datetime(\"2020-05-03\"))\n    .astype(int)\n)\nComme nous travaillons sur les donn√©es de 2022,\nnous pouvons nous passer de cette variable.\n\n\nLes donn√©es DVF proposent une observation par transaction.\nCes transactions\npeuvent concerner plusieurs lots. Par exemple, un appartement\navec garage et cave comportera trois lots.\nPour simplifier,\non va cr√©er une variable de surface qui agr√®ge les diff√©rentes informations\nde surface disponibles dans le jeu de donn√©es.\nLes agr√©ger revient √† supposer que le mod√®le de fixation des prix est le m√™me\nentre chaque lot. C‚Äôest une hypoth√®se simplificatrice qu‚Äôune personne plus\nexperte du march√© immobilier, ou qu‚Äôune approche propre de s√©lection\nde variable pourrait amener √† nier. En effet, les variables\nen question sont faiblement corr√©l√©es les unes entre elles, √† quelques\nexceptions pr√®s (Figure¬†2.1):\n\ncorr = mutations.loc[\n    :, mutations.columns[mutations.columns.str.startswith(\"Surface Carrez\")].tolist()\n]\ncorr.columns = corr.columns.str.replace(\"Carrez du \", \"\")\ncorr = corr.corr()\n\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n\nfig, ax = plt.subplots(1)\ng = sns.heatmap(\n    corr,\n    ax=ax,\n    mask=mask,\n    vmax=0.3,\n    center=0,\n    square=True,\n    linewidths=0.5,\n    cbar_kws={\"shrink\": 0.5},\n    xticklabels=corr.columns.values,\n    yticklabels=corr.columns.values,\n    cmap=cmap,\n    annot=True,\n    fmt=\".2f\",\n)\ng\n\n\n\n\n\n\n\nFigure¬†2.1: Matrice de corr√©lation des variables de surface\n\n\n\n\n\n\nmutations[\"lprix\"] = np.log(mutations[\"Valeur fonciere\"])\nmutations[\"surface\"] = mutations.loc[:, colonnes_surface].sum(axis=1).astype(int)\n\n/opt/mamba/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning:\n\ndivide by zero encountered in log\n\n\n\n\nmutations[\"surface\"] = mutations.loc[\n    :, mutations.columns[mutations.columns.str.startswith(\"Surface Carrez\")].tolist()\n].sum(axis=1)",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#d√©finition-des-ensembles-train-et-test",
    "href": "content/modelisation/6_pipeline.html#d√©finition-des-ensembles-train-et-test",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "3.1 D√©finition des ensembles train et test",
    "text": "3.1 D√©finition des ensembles train et test\nNous allons donc nous restreindre √† un sous-ensemble de colonnes dans un\npremier temps.\nNous allons √©galement ne conserver que les\ntransactions inf√©rieures √† 5 millions\nd‚Äôeuros (on anticipe que celles ayant un montant sup√©rieur sont des transactions\nexceptionnelles dont le m√©canisme de fixation du prix diff√®re)\n\nmutations2 = mutations.drop(\n    colonnes_surface.tolist()\n    + [\"Date mutation\", \"lprix\"],  # ajouter \"confinement\" si donn√©es 2020\n    axis=\"columns\",\n).copy()\n\nmutations2 = mutations2.loc[\n    mutations2[\"Valeur fonciere\"] &lt; 5e6\n]  # keep only values below 5 millions\n\nmutations2.columns = mutations2.columns.str.replace(\" \", \"_\")\nmutations2 = mutations2.dropna(subset=[\"dep\", \"Code_type_local\", \"month\"])\n\nNotre pipeline va incorporer deux types de variables: les variables\ncat√©gorielles et les variables num√©riques.\nCes diff√©rents types vont b√©n√©ficier d‚Äô√©tapes de preprocessing\ndiff√©rentes.\n\nnumeric_features = mutations2.columns[\n    ~mutations2.columns.isin([\"dep\", \"Code_type_local\", \"month\", \"Valeur_fonciere\"])\n].tolist()\ncategorical_features = [\"dep\", \"Code_type_local\", \"month\"]\n\nAu passage, nous avons abandonn√© la variable de code postal pour privil√©gier\nle d√©partement afin de r√©duire la dimension de notre jeu de donn√©es. Si on voulait\nvraiment avoir un bon mod√®le, il faudrait faire autrement car le code postal\nest probablement un tr√®s bon pr√©dicteur du prix d‚Äôun bien, une fois que\nles caract√©ristiques du bien sont contr√¥l√©es.\n\n\n Exercice 1 : D√©coupage des √©chantillons\nNous allons stratifier notre √©chantillonage de train/test par d√©partement\nafin de tenir compte, de mani√®re minimale, de la g√©ographie.\nPour acc√©l√©rer les calculs pour ce tutoriel, nous n‚Äôallons consid√©rer que\n30% des transactions observ√©es sur chaque d√©partement.\nVoici le code pour le faire:\nmutations2 = mutations2.groupby(\"dep\").sample(frac=0.1, random_state=123)\nAvec la fonction ad√©quate de Scikit, faire un d√©coupage de mutations2\nen train et test sets\nen suivant les consignes suivantes:\n\n20% des donn√©es dans l‚Äô√©chantillon de test ;\nL‚Äô√©chantillonnage est stratifi√© par d√©partements ;\nPour avoir des r√©sultats reproductibles, choisir une racine √©gale √† 123.",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#d√©finition-du-premier-pipeline",
    "href": "content/modelisation/6_pipeline.html#d√©finition-du-premier-pipeline",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "3.2 D√©finition du premier pipeline",
    "text": "3.2 D√©finition du premier pipeline\nPour commencer, nous allons fixer la taille des arbres de d√©cision avec\nl‚Äôhyperparam√®tre max_depth = 2.\nNotre pipeline va int√©grer les √©tapes suivantes :\n\nPreprocessing :\n\nLes variables num√©riques vont √™tre standardis√©es avec un StandardScaler.\nPour cela, nous allons utiliser la liste numeric_features d√©finie pr√©c√©demment.\nLes variables cat√©gorielles vont √™tre explos√©es avec un one hot encoding\n(m√©thode OneHotEncoder de scikit)\nPour cela, nous allons utiliser la liste categorical_features\n\nRandom forest : nous allons appliquer l‚Äôestimateur ad hoc de Scikit.\n\n\n\n Exercice 2 : Construction d'un premier pipeline formel\n\nInitialiser un random forest de profondeur 2. Fixer la racine √† 123 pour avoir des r√©sultats reproductibles.\nLa premi√®re √©tape du pipeline (nommer cette couche preprocessor) consiste √† appliquer les √©tapes de preprocessing adapt√©es √† chaque type de variables:\n\nPour les variables num√©riques, appliquer une √©tape d‚Äôimputation √† la moyenne puis standardiser celles-ci\nPour les variables cat√©gorielles, appliquer un one hot encoding\n\nAppliquer comme couche de sortie le mod√®le d√©fini plus t√¥t.\n\nüí° Il est recommand√© de s‚Äôaider de la documentation de Scikit. Si vous avez besoin d‚Äôun indice suppl√©mentaire, consulter le pipeline pr√©sent√© ci-dessous.\n\n\nA l‚Äôissue de cet exercice, nous devrions obtenir le pipeline suivant.\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiNot fittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))]) ¬†preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('pipeline',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer()),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['Nombre_de_lots', 'Nombre_pieces_principales',\n                                  'surface']),\n                                ('onehotencoder',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['dep', 'Code_type_local', 'month'])]) pipeline['Nombre_de_lots', 'Nombre_pieces_principales', 'surface'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder['dep', 'Code_type_local', 'month'] ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor(max_depth=2, random_state=123) \n\n\nNous avons construit ce pipeline sous forme de couches successives. La couche\nrandomforest prendra automatiquement le r√©sultat de la couche preprocessor\nen input. La couche features permet d‚Äôintroduire de mani√®re relativement\nsimple (quand on a les bonnes m√©thodes) la complexit√© du preprocessing\nsur donn√©es r√©elles dont les types divergent.\nA cette √©tape, rien n‚Äôa encore √©t√© estim√©.\nC‚Äôest tr√®s simple √† mettre en oeuvre\navec un pipeline.\n\n\n Exercice 3 : Mise en oeuvre du pipeline\n\nEstimer les param√®tres du mod√®le sur le jeu d‚Äôentra√Ænement\nObserver la mani√®re dont les donn√©es d‚Äôentra√Ænement sont transform√©es\npar l‚Äô√©tape de preprocessing avec les m√©thodes ad√©quates sur 4 observations de X_train\ntir√©es al√©atoirement\nUtiliser ce mod√®le pour pr√©dire le prix sur l‚Äô√©chantillon de test. A partir de ces quelques pr√©dictions,\nquel semble √™tre le probl√®me ?\nObserver la mani√®re dont ce preprocessing peut s‚Äôappliquer sur deux exemples fictifs :\n\nUn appartement (code_type_local = 2) dans le 75, vendu au mois de mai, unique lot de la vente avec 3 pi√®ces, faisant 75m¬≤ ;\nUne maison (code_type_local = 1) dans le 06, vendue en d√©cembre, dans une transaction avec 2 lots. La surface compl√®te est de 180m¬≤ et le bien comporte 6 pi√®ces.\n\nD√©duire sur ces deux exemples le prix pr√©dit par le mod√®le.\nCalculer et interpr√©ter le RMSE sur l‚Äô√©chantillon de test. Ce mod√®le est-il satisfaisant ?\n\n\n\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.¬†¬†Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('pipeline',\n                                                  Pipeline(steps=[('simpleimputer',\n                                                                   SimpleImputer()),\n                                                                  ('standardscaler',\n                                                                   StandardScaler())]),\n                                                  ['Nombre_de_lots',\n                                                   'Nombre_pieces_principales',\n                                                   'surface']),\n                                                 ('onehotencoder',\n                                                  OneHotEncoder(handle_unknown='ignore',\n                                                                sparse_output=False),\n                                                  ['dep', 'Code_type_local',\n                                                   'month'])])),\n                ('randomforest',\n                 RandomForestRegressor(max_depth=2, random_state=123))]) ¬†preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('pipeline',\n                                 Pipeline(steps=[('simpleimputer',\n                                                  SimpleImputer()),\n                                                 ('standardscaler',\n                                                  StandardScaler())]),\n                                 ['Nombre_de_lots', 'Nombre_pieces_principales',\n                                  'surface']),\n                                ('onehotencoder',\n                                 OneHotEncoder(handle_unknown='ignore',\n                                               sparse_output=False),\n                                 ['dep', 'Code_type_local', 'month'])]) pipeline['Nombre_de_lots', 'Nombre_pieces_principales', 'surface'] ¬†SimpleImputer?Documentation for SimpleImputerSimpleImputer() ¬†StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder['dep', 'Code_type_local', 'month'] ¬†OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore', sparse_output=False) ¬†RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor(max_depth=2, random_state=123) \n\n\n\n\narray([282871.63598981, 301165.65351098, 301165.65351098, ...,\n       282871.63598981, 471048.40037679, 282871.63598981])\n\n\n\n\narray([642280.20111587, 282871.63598981])\n\n\n\n\n433497.6437239088",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#variable-importance",
    "href": "content/modelisation/6_pipeline.html#variable-importance",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "3.3 Variable importance",
    "text": "3.3 Variable importance\nLes pr√©dictions semblent avoir une assez faible variance, comme si des variables\nde seuils intervenaient. Nous allons donc devoir essayer de comprendre pourquoi.\nLa ‚Äúvariable importance‚Äù\nse r√©f√®re √† la mesure de l‚Äôinfluence de chaque variable d‚Äôentr√©e sur la performance du mod√®le.\nL‚Äôimpuret√© fait r√©f√©rence √† l‚Äôincertitude ou √† l‚Äôentropie pr√©sente dans un ensemble de donn√©es.\nDans le contexte des random forest, cette mesure est souvent calcul√©e en √©valuant la r√©duction moyenne de l‚Äôimpuret√© des n≈ìuds de d√©cision caus√©e par une variable sp√©cifique.\nCette approche permet de quantifier l‚Äôimportance des variables dans le processus de prise de d√©cision du mod√®le, offrant ainsi des intuitions sur les caract√©ristiques les plus informatives pour la pr√©diction (plus de d√©tails sur ce blog).\nOn ne va repr√©senter, parmi notre ensemble important de colonnes, que celles\nqui ont une importance non nulle.\n\n\n Exercice 4 : Compr√©hension du mod√®le\n\nR√©cup√©rer la feature importance directement depuis la couche adapt√©e de votre pipeline\nUtiliser le code suivant pour calculer l‚Äôintervalle de confiance de cette mesure d‚Äôimportance:\n\nstd = np.std(\n    [tree.feature_importances_ for tree in pipe[\"randomforest\"].estimators_], axis=0\n)\n\nRepr√©senter les variables d‚Äôimportance non nulle. Qu‚Äôen concluez-vous ?\n\n\n\nLe graphique d‚Äôimportance des variables que vous devriez obtenir √† l‚Äôissue\nde cet exercice est le suivant.\n\n\n\n\n\n\n\n\n\n\n\n&lt;Axes: title={'center': 'Feature importances using MDI'}, ylabel='Mean decrease in impurity'&gt;\n\n\nLes statistiques obtenues par le biais de cette variable importance\nsont un peu rudimentaires mais permettent d√©j√† de comprendre\nle probl√®me de notre mod√®le.\nOn voit donc que deux de nos variables d√©terminantes sont des effets fixes\ng√©ographiques (qui servent √† ajuster de la diff√©rence de prix entre\nParis et les Hauts de Seine et le reste de la France), une autre variable\nest un effet fixe type de bien. Les deux variables qui pourraient introduire\nde la variabilit√©, √† savoir la surface et, dans une moindre mesure, le\nnombre de lots, ont une importance moindre.\n\n\n Note\nId√©alement, on utiliserait Yellowbrick pour repr√©senter l‚Äôimportance des variables\nMais en l‚Äô√©tat actuel du pipeline on a beaucoup de variables dont le poids\nest nul qui viennent polluer la visualisation. Vous pouvez\nconsulter la\ndocumentation de Yellowbrick sur ce sujet\n\n\nLes pr√©dictions peuvent nous sugg√©rer √©galement\nqu‚Äôil y a un probl√®me:\n\ncompar = pd.DataFrame([y_test, pipe.predict(X_test)]).T\ncompar.columns = [\"obs\", \"pred\"]\ncompar[\"diff\"] = compar.obs - compar.pred\n\ng = sns.relplot(data=compar, x=\"obs\", y=\"pred\", color=\"royalblue\", alpha=0.8)\ng.set(\n    ylim=(0, 2e6),\n    xlim=(0, 2e6),\n    title=\"Evaluating estimation error on test sample\",\n    xlabel=\"Observed values\",\n    ylabel=\"Predicted values\",\n)\ng.ax.axline(xy1=(0, 0), slope=1, color=\"red\", dashes=(5, 2))",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#informations-additionnelles",
    "href": "content/modelisation/6_pipeline.html#informations-additionnelles",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n8f0d2e1\n\n\n2024-05-07 15:06:45\n\n\nlgaliana\n\n\nDuplicate data from datagouv\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n8c316d0\n\n\n2024-04-05 19:00:59\n\n\nLino Galiana\n\n\nFix cartiflette deprecated snippets (#487)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1684220\n\n\n2023-12-02 12:06:40\n\n\nAntoine Palazzolo\n\n\nPremi√®re partie de relecture de fin du cours (#467)\n\n\n\n\ne4642ee\n\n\n2023-11-27 17:02:05\n\n\nLino Galiana\n\n\nDeploy ML model as API (#460)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n4960f2b\n\n\n2023-11-22 12:02:32\n\n\nLino Galiana\n\n\nChapitre pipeline scikit sur DVF (#454)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n38693f6\n\n\n2023-04-19 17:22:36\n\n\nLino Galiana\n\n\nRebuild visualisation part (#357)\n\n\n\n\n3248633\n\n\n2023-02-18 13:11:52\n\n\nLino Galiana\n\n\nShortcode rawhtml (#354)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\ned2ddec\n\n\n2022-01-04 13:32:43\n\n\nExpressso\n\n\nretire typo (#212)\n\n\n\n\n66e2837\n\n\n2021-12-24 16:54:45\n\n\nLino Galiana\n\n\nFix a few typos in the new pipeline tutorial (#208)\n\n\n\n\ne94c1c5\n\n\n2021-12-23 21:34:46\n\n\nLino Galiana\n\n\nUn tutoriel sur les pipelines :tada: (#203)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†2.1: Matrice de corr√©lation des variables de surface",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/modelisation/6_pipeline.html#footnotes",
    "href": "content/modelisation/6_pipeline.html#footnotes",
    "title": "Premier pas vers l‚Äôindustrialisation avec les pipelines scikit",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLes random forest sont l‚Äôune des principales m√©thodes\nensemblistes. Outre cette approche, les plus connues sont\nle bagging (boostrap aggregating) et le boosting\nqui consistent √† choisir la pr√©diction √† privil√©gier\nselon des algorithmes de choix diff√©rens.\nPar exemple le bagging est une technique bas√©e sur le vote majoritaire (Breiman 1996).\nCette technique s‚Äôinspire du bootstrap qui, en √©conom√©trie,\nconsiste √† r√©-estimer sur K sous-√©chantillons\nal√©atoires des donn√©es un estimateur afin d‚Äôen tirer, par exemple, un intervalle\nde confiance empirique √† 95%. Le principe du bagging est le m√™me. On r√©-estime\nK fois notre estimateur (par exemple un arbre de d√©cision) et propose une\nr√®gle d‚Äôagr√©gation pour en tirer une r√®gle moyennis√©e et donc une pr√©diction.\nLe boosting fonctionne selon un principe diff√©rent, bas√© sur\nl‚Äôoptimisation de combinaisons de classifieurs faibles.‚Ü©Ô∏é",
    "crumbs": [
      "Premier pas vers l'industrialisation avec les pipelines scikit"
    ]
  },
  {
    "objectID": "content/NLP/index.html",
    "href": "content/NLP/index.html",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "",
    "text": "Les parties pr√©c√©dentes √©taient consacr√©es √† l‚Äôacquisition de comp√©tences\ntransversales pour la valorisation des donn√©es. De mani√®re naturelle,\nnous nous sommes jusqu‚Äô√† pr√©sent plut√¥t consacr√©s\n√† la valorisation de donn√©es structur√©es, d‚Äôune\ndimension certes modeste mais qui ouvraient d√©j√† √©norm√©ment de\nprobl√©matiques √† creuser. Cette partie propose maintenant de se\nconsacrer √† un sujet dont il n‚Äôest pas √©vident a priori que\nles ordinateurs s‚Äôemparent, source de d√©bats philosophiques s√©culaires, de Platon √† Saussure : le langage humain et sa richesse.\nEn faisant l‚Äôanalogie entre langue et langage, c‚Äôest-√†-dire en d√©finissant ce dernier comme la capacit√© d‚Äôexpression et de communication d‚Äôune pens√©e par le biais de signes et en d√©finissant la langue comme la mise en oeuvre conventionnelle de cette capacit√©, on peut se placer dans les traces de la linguistique\net repr√©senter le langage sous une forme de donn√©es.\nCeci ouvre la voix √† l‚Äôanalyse statistique ou algorithmique. N√©anmoins, m√™me s‚Äôil existe des r√©gularit√©s statistiques , comment\ndes ordinateurs, qui au fond ne connaissent que le 0 et le 1, peuvent-ils\ns‚Äôapproprier cet objet √©minemment complexe qu‚Äôest le langage et qu‚Äôun\nhumain met lui-m√™me des ann√©es √† comprendre et s‚Äôapproprier ?1",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#nettoyages-textuels-et-analyse-de-fr√©quences",
    "href": "content/NLP/index.html#nettoyages-textuels-et-analyse-de-fr√©quences",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "3.1 Nettoyages textuels et analyse de fr√©quences",
    "text": "3.1 Nettoyages textuels et analyse de fr√©quences\nPython est un excellent outil pour l‚Äôanalyse de donn√©es textuelles.\nLes m√©thodes de base de transformation de donn√©es textuelles ou de dictionnaires, associ√©es √† des librairies sp√©cialis√©es\ncomme NLTK et SpaCy, permettent d‚Äôeffectuer des t√¢ches de normalisation et d‚Äôanalyse de donn√©es textuelles de mani√®re\ntr√®s efficace. Python est bien mieux outill√© que R pour l‚Äôanalyse de\ndonn√©es textuelles.\nLes ressources en ligne sur le sujet sont tr√®s\nnombreuses et la meilleure des √©coles dans le domaine reste la pratique sur un corpus √† nettoyer.\nDans un premier temps, cette partie propose\nde revenir sur la mani√®re de structurer et nettoyer un corpus\ntextuel au travers de l‚Äôapproche bag of words (sac de mots).\nElle vise √† montrer comment transformer un corpus en outil propre √† une\nanalyse statistique :\n\nElle propose d‚Äôabord une introduction aux enjeux du nettoyage des donn√©es\ntextuelles √† travers l‚Äôanalyse du Comte de Monte Cristo d‚ÄôAlexandre Dumas\nici qui permet de synth√©tiser rapidement l‚Äôinformation disponible\ndans un large volume de donn√©es (√† l‚Äôimage de la ?@fig-wordcloud-dumas)\nElle propose ensuite une s√©rie d‚Äôexercices sur le nettoyage de textes √† partir des\noeuvres d‚ÄôEdgar Allan Poe, Mary Shelley et H.P. Lovecraft visant √† distinguer la\nsp√©cificit√© du vocabulaire employ√© par chaque auteurs (par exemple ?@fig-waffle-fear). Ces exercices sont\ndisponibles dans le deuxi√®me chapitre de la partie.\n\nCette analyse fr√©quentiste permet de prendre du recul sur la nature des donn√©es textuelles et sur les enjeux r√©currents dans la r√©duction de dimension de corpus en langue naturelle. Comme la statistique descriptive entra√Æne naturellement la mod√©lisation, cette approche fr√©quentiste va g√©n√©ralement amener rapidement √† vouloir synth√©tiser quelques lois derri√®re nos corpus textuels.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#mod√©lisation-du-langage",
    "href": "content/NLP/index.html#mod√©lisation-du-langage",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "3.2 Mod√©lisation du langage",
    "text": "3.2 Mod√©lisation du langage\nLa suite de cette partie proposera une introduction aux enjeux de mod√©lisation\ndu langage. Ceux-ci sont tr√®s √† la mode du fait du succ√®s de ChatGPT. N√©anmoins, avant\nd‚Äôen arriver aux grands mod√®les de langage (LLM), ces r√©seaux de neurone ayant des milliards de param√®tres et entra√Æn√©s sur des volumes massifs de donn√©es, il est n√©cessaire de passer par quelques mod√©lisations\npr√©liminaires.\nNous proposerons d‚Äôabord d‚Äôexplorer une approche alternative, prenant en compte\nle contexte d‚Äôapparition d‚Äôun mot. L‚Äôintroduction √† la\nLatent Dirichlet Allocation (LDA) sera l‚Äôoccasion de pr√©senter la mod√©lisation\nde documents sous la forme de topics. Celle-ci est n√©anmoins pass√©e de mode au profit des m√©thodes li√©es au concept d‚Äôembedding.\nNous introduirons ainsi √† la fin de cette partie du cours les enjeux de la transformation de champs textuels\nsous forme de vecteurs num√©riques. Pour cela, nous pr√©senterons le principe\nde Word2Vec qui permet ainsi, par exemple,\nmalgr√© une distance syntaxique importante,\nde dire que s√©mantiquement Homme et Femme sont proches.\nCe chapitre est une passerelle vers le concept d‚Äôembedding, v√©ritable\nr√©volution r√©cente du NLP, et qui permet de rapprocher des corpus\nnon seulement sur leur proximit√© syntaxique (partagent-ils par exemple des mots\ncommuns ?) mais aussi sur leur proximit√© s√©mantique (partagent-ils un th√®me ou un sens commun ?)4. Ce passage par Word2Vec permettra aux curieux de pouvoir ensuite passer aux mod√®les de type transformers, les mod√®les faisant aujourd‚Äôhui office de r√©f√©rence dans le domaine du NLP.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#pour-aller-plus-loin",
    "href": "content/NLP/index.html#pour-aller-plus-loin",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\nLa recherche dans le domaine du NLP est tr√®s active. Il est donc recommand√©\nde faire preuve de curiosit√© pour en apprendre plus car une ressource\nunique ne compilera pas l‚Äôensemble des connaissances, a fortiori dans\nun champ de recherche aussi dynamique que le NLP.\nPour approfondir les comp√©tences √©voqu√©es dans ce cours, je recommande vivement\nce cours d‚ÄôHuggingFace.\nPour comprendre l‚Äôarchitecture interne d‚Äôun LLM,\nce post de Sebastian Raschka\nest tr√®s utile.\nCes chapitres n‚Äô√©puisent pas les cas d‚Äôusage du NLP pour les data scientists. Ils n‚Äôen sont que la surface √©merg√©e de l‚Äôiceberg.\nPar exemple,\ndans le domaine de la statistique publique, un des principaux cas d‚Äôusage du NLP est l‚Äôutilisation\nde techniques de classification automatique pour transformer des r√©ponses libres dans des questionnaires\nen champs pr√©d√©finis dans une nomenclature.\nIl s‚Äôagit donc d‚Äôune adaptation, un peu sp√©cifique √† la statistique publique, grande utilisatrice de nomenclatures normalis√©es, de probl√©matiques de classification multi-niveaux.\nVoici un exemple sur un projet de classification automatis√©e des professions dans la typologie\ndes nomenclatures d‚Äôactivit√©s (les PCS) √† partir d‚Äôun mod√®le entra√Æn√© par la librairie Fasttext :\n\nviewof activite = Inputs.text( \n  {label: '', value: 'data scientist', width: 800}\n)\n\n\n\n\n\n\n\nd3.json(urlApe).then(res =&gt; {\n  var IC, results;\n\n  ({ IC, ...results } = res);\n\n  IC = parseFloat(IC);\n\n  const rows = Object.values(results).map(obj =&gt; {\n    return `\n    &lt;tr&gt;\n      &lt;td&gt;${obj.code} | ${obj.libelle}&lt;/td&gt;\n      &lt;td&gt;${obj.probabilite.toFixed(3)}&lt;/td&gt;\n    &lt;/tr&gt;\n  `;\n  }).join('');\n\n  const confidenceRow = `&lt;tr&gt;\n    &lt;td colspan=\"2\" style=\"text-align:left; \"&gt;&lt;em&gt;Indice de confiance : ${IC.toFixed(3)}&lt;/em&gt;&lt;/td&gt;\n  &lt;/tr&gt;`;\n\n  const tableHTML = html`\n  &lt;table&gt;\n    &lt;caption&gt;\n      Pr√©diction de l'activit√©\n    &lt;/caption&gt;\n    &lt;tr&gt;\n      &lt;th style=\"text-align:center;\"&gt;Libell√© (NA2008)&lt;/th&gt;\n      &lt;th&gt;Probabilit√©&lt;/th&gt;\n    &lt;/tr&gt;\n      ${rows}\n      ${confidenceRow}\n  &lt;/table&gt;`;\n\n  // Now you can use the tableHTML as needed, for example, inserting it into the DOM.\n  // For example, assuming you have a container with the id \"tableContainer\":\n  return tableHTML;\n});\n\n\n\n\n\n\n\nactivite_debounce = debounce(viewof activite, 2000)\nurlApe = `https://codification-ape-test.lab.sspcloud.fr/predict?nb_echos_max=3&prob_min=0&text_feature=${activite_debounce}`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport {debounce} from \"@mbostock/debouncing-input\"",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#informations-additionnelles",
    "href": "content/NLP/index.html#informations-additionnelles",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nff42cf2\n\n\n2024-04-25 20:05:33\n\n\nlinogaliana\n\n\nEditorisalisation NLP\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na1ab3d9\n\n\n2023-11-24 10:57:02\n\n\nLino Galiana\n\n\nReprise des chapitres NLP (#459)\n\n\n\n\n7bd768a\n\n\n2023-08-28 09:14:55\n\n\nlinogaliana\n\n\nErreur image\n\n\n\n\n862ea4b\n\n\n2023-08-28 11:07:31\n\n\nLino Galiana\n\n\nAjoute r√©f√©rence au post de Raschka (#398)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\na408cc9\n\n\n2023-02-01 09:07:27\n\n\nLino Galiana\n\n\nAjoute bouton sugg√©rer modification (#347)\n\n\n\n\n164fa68\n\n\n2022-11-30 09:13:45\n\n\nLino Galiana\n\n\nTravail partie NLP (#328)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n4f67528\n\n\n2021-12-12 08:37:21\n\n\nLino Galiana\n\n\nImprove website appareance (#194)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/index.html#footnotes",
    "href": "content/NLP/index.html#footnotes",
    "title": "Partie 4 : Natural Language Processing (NLP)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEn √©crivant ces lignes j‚Äôai demand√© √† ChatGPT de me faire une blague.\n\nPourquoi les programmeurs d√©testent-ils la plage ?\nParce que le sable change tout le temps de paradigme !\n\nNe l‚Äôayant pas comprise, je lui\nai demand√© de me l‚Äôexpliquer. Voici sa r√©ponse :\n\nBien s√ªr, je serais ravi de l‚Äôexpliquer ! Cette blague joue sur le double sens du mot ‚Äúparadigme‚Äù et fait un jeu de mots avec les notions li√©es √† la programmation et √† la plage.\nDans le domaine de la programmation, un ‚Äúparadigme‚Äù d√©signe un mod√®le ou une m√©thode de programmation, comme la programmation orient√©e objet, la programmation fonctionnelle, etc. Les programmeurs sont souvent familiers avec diff√©rents paradigmes de programmation.\nD‚Äôautre part, en contexte de plage, ‚Äúparadigme‚Äù est utilis√© pour signifier ‚Äúmar√©e qui monte et descend‚Äù, se r√©f√©rant √† l‚Äôaction naturelle du sable et de l‚Äôeau sur la plage.\nLa blague joue sur la frustration humoristique que peuvent ressentir les programmeurs lorsqu‚Äôils doivent s‚Äôadapter √† de nouveaux paradigmes de programmation, tout comme le sable de la plage qui change constamment avec les mar√©es. En associant les deux sens du mot ‚Äúparadigme‚Äù, la blague cr√©e une situation absurde et amusante, faisant sourire ceux qui comprennent les r√©f√©rences √† la programmation et √† la plage.\n\nFinalement, j‚Äôai trouv√© son explication plus dr√¥le que sa blague.‚Ü©Ô∏é\nLe concept de natural language processing tend √† remplacer celui\nde text mining dont le p√©rim√®tre √©tait plus sp√©cifique. Le text mining\nrenvoie √† la recherche d‚Äôinformation - la fouille - dans un ensemble de\ntextes. C‚Äôest l‚Äôun des champs d‚Äôapplications\ndu natural language processing mais ce n‚Äôest pas l‚Äôunique. L‚Äôaccroissement des ressources de calcul et les progr√®s dans la formalisation du langage ont permis d‚Äô√©largir le champ des domaines o√π la linguistique computationnelle intervient.‚Ü©Ô∏é\nPar exemple, le concept d‚Äôembedding - transformation d‚Äôun champ\ntextuel en un vecteur num√©rique multidimensionnel - aujourd‚Äôhui central\ndans le NLP n‚Äôest √©voqu√© qu‚Äô√† quelques reprises.‚Ü©Ô∏é\nUn exemple d‚Äôint√©r√™t de ce type d‚Äôapproche est la ?@fig-relevanc-table-embedding.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html",
    "href": "content/NLP/02_exoclean.html",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page approfondit certains aspects pr√©sent√©s dans la\npartie introductive. Apr√®s avoir travaill√© sur le\nComte de Monte Cristo, on va continuer notre exploration de la litt√©rature\navec cette fois des auteurs anglophones :\nLes donn√©es sont disponibles sur un CSV mis √† disposition sur Github. L‚ÄôURL pour les r√©cup√©rer directement est\nhttps://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv.\nLe but va √™tre dans un premier temps de regarder dans le d√©tail les termes les plus fr√©quemment utilis√©s par les auteurs et de les repr√©senter graphiquement. Il s‚Äôagit donc d‚Äôune approche bas√©e sur l‚Äôanalyse de fr√©quences.\nOn prendra appui sur l‚Äôapproche bag of words pr√©sent√©e dans le chapitre pr√©c√©dent1.\nIl n‚Äôy aura pas de mod√©lisation particuli√®re, ceci est r√©serv√© aux chapitres suivants.\nCe chapitre s‚Äôinspire de plusieurs ressources disponibles en ligne:\nLes chapitres suivants permettront d‚Äôintroduire aux enjeux de mod√©lisation\nde corpus textuels. Dans un premier temps, le mod√®le LDA permettra d‚Äôexplorer\nle principe des mod√®les bay√©siens √† couche cach√©es pour mod√©liser les sujets (topics)\npr√©sents dans un corpus et segmenter ces topics selon les mots qui les composent.\nLe dernier chapitre de la partie visera √†\npr√©dire quel texte correspond √† quel auteur √† partir d‚Äôun mod√®le Word2Vec.\nCela sera un pas suppl√©mentaire dans la formalisation puisqu‚Äôil s‚Äôagira de\nrepr√©senter chaque mot d‚Äôun texte sous forme d‚Äôun vecteur de grande dimension, ce\nqui nous permettra de rapprocher les mots entre eux dans un espace complexe.\nCette technique, dite des plongements de mots (Word Embeddings),\npermet ainsi de transformer une information complexe difficilement quantifiable\ncomme un mot\nen un objet num√©rique qui peut ainsi √™tre rapproch√© d‚Äôautres par des m√©thodes\nalg√©briques. Pour d√©couvrir ce concept, ce post de blog\nest particuli√®rement utile. En pratique, la technique des\nplongements de mots permet d‚Äôobtenir des tableaux comme celui-ci :",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#fr√©quence-dun-mot",
    "href": "content/NLP/02_exoclean.html#fr√©quence-dun-mot",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "2.1 Fr√©quence d‚Äôun mot",
    "text": "2.1 Fr√©quence d‚Äôun mot\nAvant de s‚Äôadonner √† une analyse syst√©matique du champ lexical de chaque\nauteur, on va se focaliser dans un premier temps sur un unique mot, le mot fear.\n\n\n Note\nL‚Äôexercice ci-dessous pr√©sente une repr√©sentation graphique nomm√©e\nwaffle chart. Il s‚Äôagit d‚Äôune approche pr√©f√©rable aux\ncamemberts qui sont des graphiques manipulables car l‚Äôoeil humain se laisse\nfacilement berner par cette repr√©sentation graphique qui ne respecte pas\nles proportions.\n\n\n\n\n Exercice 2 : Fr√©quence d'un mot\n\nCompter le nombre de phrases, pour chaque auteur, o√π appara√Æt le mot fear.\nUtiliser pywaffle pour obtenir les graphiques ci-dessous qui r√©sument\nde mani√®re synth√©tique le nombre d‚Äôoccurrences du mot ‚Äúfear‚Äù par auteur.\nRefaire l‚Äôanalyse avec le mot ‚Äúhorror‚Äù.\n\n\n\nA l‚Äôissue de la question 1, vous devriez obtenir le tableau\nde fr√©quence suivant :\n\n\n\n\n\n\n\n\n\n\nText\nID\nwordtoplot\n\n\nAuthor\n\n\n\n\n\n\n\nEAP\nThis process, however, afforded me no means of...\n2630511008096741351519322166071718908441148621...\n70\n\n\nHPL\nIt never once occurred to me that the fumbling...\n1756912958197641888620836080752790708121117330...\n160\n\n\nMWS\nHow lovely is spring As we looked from Windsor...\n2776322965009121673712799131170076400683052582...\n211\n\n\n\n\n\n\n\n\nCeci permet d‚Äôobtenir le waffle chart suivant :\n\n\n\n\n\n\n\n\nFigure¬†2.1: R√©partition du terme fear dans le corpus de nos trois auteurs\n\n\n\n\n\nOn remarque ainsi de mani√®re tr√®s intuitive\nle d√©s√©quilibre de notre jeu de donn√©es\nlorsqu‚Äôon se focalise sur le terme ‚Äúpeur‚Äù\no√π Mary Shelley repr√©sente pr√®s de 50%\ndes observations.\nSi on reproduit cette analyse avec le terme ‚Äúhorror‚Äù, on peut\nen conclure que la peur est plus √©voqu√©e par Mary Shelley\n(sentiment assez naturel face √† la cr√©ature du docteur Frankenstein) alors\nque Lovecraft n‚Äôa pas vol√© sa r√©putation d‚Äô√©crivain de l‚Äôhorreur !",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#premier-wordcloud",
    "href": "content/NLP/02_exoclean.html#premier-wordcloud",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "2.2 Premier wordcloud",
    "text": "2.2 Premier wordcloud\nPour aller plus loin dans l‚Äôanalyse du champ lexical de chaque auteur,\non peut repr√©senter un wordcloud qui permet d‚Äôafficher chaque mot avec une\ntaille proportionnelle au nombre d‚Äôoccurrence de celui-ci.\n\n\n Exercice 3 : Wordcloud\n\nEn utilisant la fonction wordCloud, faire trois nuages de mot pour repr√©senter les mots les plus utilis√©s par chaque auteur.\nCalculer les 25 mots plus communs pour chaque auteur et repr√©senter les trois histogrammes des d√©comptes.\n\n\n\nLe wordcloud pour nos diff√©rents auteurs est le suivant :\n\n\n\n\n\n\n\n\n\nEnfin, si on fait un histogramme des fr√©quences,\ncela donnera :\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\nOn voit ici que ce sont des mots communs, comme ‚Äúthe‚Äù, ‚Äúof‚Äù, etc. sont tr√®s\npr√©sents. Mais ils sont peu porteurs d‚Äôinformation, on peut donc les √©liminer\navant de faire une analyse syntaxique pouss√©e.\nCeci est une d√©monstration par l‚Äôexemple qu‚Äôil vaut mieux nettoyer le texte avant de\nl‚Äôanalyser (sauf si on est int√©ress√©\npar la loi de Zipf, cf.¬†exercice suivant).\nA noter que l‚Äôhistogramme produit\npar le biais de Matplotlib ou Seaborn est\npeu lisible. Il vaut mieux privil√©gier Plotly\npour faire celui-ci afin d‚Äôavoir les mots qui s‚Äôaffichent en\npassant sa souris sur chaque barre.",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#apart√©-la-loi-de-zipf",
    "href": "content/NLP/02_exoclean.html#apart√©-la-loi-de-zipf",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "2.3 Apart√© : la loi de Zipf",
    "text": "2.3 Apart√© : la loi de Zipf\n\n\n La loi de Zipf\nDans son sens strict, la loi de Zipf pr√©voit que\ndans un texte donn√©, la fr√©quence d‚Äôoccurrence \\(f(n_i)\\) d‚Äôun mot est\nli√©e √† son rang \\(n_i\\) dans l‚Äôordre des fr√©quences par une loi de la forme\n\\(f(n_i) = c/n_i\\) o√π \\(c\\) est une constante. Zipf, dans les ann√©es 1930, se basait sur l‚Äôoeuvre\nde Joyce, Ulysse pour cette affirmation.\nPlus g√©n√©ralement, on peut d√©river la loi de Zipf d‚Äôune distribution exponentielle des fr√©quences : \\(f(n_i) = cn_{i}^{-k}\\). Cela permet d‚Äôutiliser la famille des mod√®les lin√©aires g√©n√©ralis√©s, notamment les r√©gressions poissonniennes, pour mesurer les param√®tres de la loi. Les mod√®les lin√©aire traditionnels en log souffrent en effet, dans ce contexte, de biais (la loi de Zipf est un cas particulier d‚Äôun mod√®le gravitaire, o√π appliquer des OLS est une mauvaise id√©e, cf.¬†Galiana et al. (2020) pour les limites).\n\n\nUn mod√®le exponentiel peut se repr√©senter par un mod√®le de Poisson ou, si\nles donn√©es sont tr√®s dispers√©es, par un mod√®le binomial n√©gatif. Pour\nplus d‚Äôinformations, consulter l‚Äôannexe de Galiana et al. (2020).\nLa technique √©conom√©trique associ√©e pour l‚Äôestimation est\nles mod√®les lin√©aires g√©n√©ralis√©s (GLM) qu‚Äôon peut\nutiliser en Python via le\npackage statsmodels2:\n\\[\n\\mathbb{E}\\bigg( f(n_i)|n_i \\bigg) = \\exp(\\beta_0 + \\beta_1 \\log(n_i))\n\\]\nPrenons les r√©sultats de l‚Äôexercice pr√©c√©dent et enrichissons les du rang et de la fr√©quence d‚Äôoccurrence d‚Äôun mot :\n\ncount_words = pd.DataFrame(\n    {\n        \"counter\": train.groupby(\"Author\")\n        .apply(lambda s: \" \".join(s[\"Text\"]).split())\n        .apply(lambda s: Counter(s))\n        .apply(lambda s: s.most_common())\n        .explode()\n    }\n)\ncount_words[[\"word\", \"count\"]] = pd.DataFrame(\n    count_words[\"counter\"].tolist(), index=count_words.index\n)\ncount_words = count_words.reset_index()\n\ncount_words = count_words.assign(\n    tot_mots_auteur=lambda x: (x.groupby(\"Author\")[\"count\"].transform(\"sum\")),\n    freq=lambda x: x[\"count\"] / x[\"tot_mots_auteur\"],\n    rank=lambda x: x.groupby(\"Author\")[\"count\"].transform(\"rank\", ascending=False),\n)\n\n/tmp/ipykernel_5595/3685081206.py:3: DeprecationWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n\n\nCommen√ßons par repr√©senter la relation entre la fr√©quence et le rang:\n\nfrom plotnine import *\n\ng = (\n    ggplot(count_words)\n    + geom_point(aes(y=\"freq\", x=\"rank\", color=\"Author\"), alpha=0.4)\n    + scale_x_log10()\n    + scale_y_log10()\n    + theme_minimal()\n)\n\nNous avons bien, graphiquement, une relation log-lin√©aire entre les deux :\n\n\n\n\n\n\n\n\n\nAvec statsmodels, v√©rifions plus formellement cette relation:\n\nimport statsmodels.api as sm\n\nexog = sm.add_constant(np.log(count_words[\"rank\"].astype(float)))\n\nmodel = sm.GLM(\n    count_words[\"freq\"].astype(float), exog, family=sm.families.Poisson()\n).fit()\n\n# Afficher les r√©sultats du mod√®le\nprint(model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                   freq   No. Observations:                69301\nModel:                            GLM   Df Residuals:                    69299\nModel Family:                 Poisson   Df Model:                            1\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -23.011\nDate:                Mon, 27 May 2024   Deviance:                     0.065676\nTime:                        17:05:26   Pearson chi2:                   0.0656\nNo. Iterations:                     5   Pseudo R-squ. (CS):          0.0002431\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.4388      1.089     -2.239      0.025      -4.574      -0.303\nrank          -0.9831      0.189     -5.196      0.000      -1.354      -0.612\n==============================================================================\n\n\nLe coefficient de la r√©gression est presque 1 ce qui sugg√®re bien une relation\nquasiment log-lin√©aire entre le rang et la fr√©quence d‚Äôoccurrence d‚Äôun mot.\nDit autrement, le mot le plus utilis√© l‚Äôest deux fois plus que le deuxi√®me mot le plus fr√©quent qui l‚Äôest trois plus que le troisi√®me, etc.",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#informations-additionnelles",
    "href": "content/NLP/02_exoclean.html#informations-additionnelles",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na1ab3d9\n\n\n2023-11-24 10:57:02\n\n\nLino Galiana\n\n\nReprise des chapitres NLP (#459)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\na8f90c2\n\n\n2023-08-28 09:26:12\n\n\nLino Galiana\n\n\nUpdate featured paths (#396)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\nf2905a7\n\n\n2023-08-11 17:24:57\n\n\nLino Galiana\n\n\nIntroduction de la partie NLP (#388)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\na9b384e\n\n\n2023-07-18 18:07:16\n\n\nLino Galiana\n\n\nS√©pare les notebooks (#373)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n934149d\n\n\n2023-02-13 11:45:23\n\n\nLino Galiana\n\n\nget_feature_names is deprecated in scikit 1.0.X versions (#351)\n\n\n\n\n164fa68\n\n\n2022-11-30 09:13:45\n\n\nLino Galiana\n\n\nTravail partie NLP (#328)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n494a85a\n\n\n2022-08-05 14:49:56\n\n\nLino Galiana\n\n\nImages featured ‚ú® (#252)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n3299f1d\n\n\n2022-01-08 16:50:11\n\n\nLino Galiana\n\n\nClean NLP notebooks (#215)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n17092b2\n\n\n2021-12-13 09:17:13\n\n\nLino Galiana\n\n\nRetouches partie NLP (#199)\n\n\n\n\n3c87483\n\n\n2021-12-13 08:46:52\n\n\nLino Galiana\n\n\nNotebooks NLP update (#198)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n49e2826\n\n\n2021-05-13 18:11:20\n\n\nLino Galiana\n\n\nCorrige quelques images n‚Äôapparaissant pas (#108)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nFigure¬†1: Illustration de l‚Äôint√©r√™t des embeddings (Galiana and Castillo 2022)\nFigure¬†2.1: R√©partition du terme fear dans le corpus de nos trois auteurs",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/02_exoclean.html#footnotes",
    "href": "content/NLP/02_exoclean.html#footnotes",
    "title": "Nettoyer un texte : des exercices pour d√©couvrir l‚Äôapproche bag-of-words",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nL‚Äôapproche bag of words est d√©j√†, si on la pousse √† ses limites, tr√®s int√©ressante. Elle peut notamment\nfaciliter la mise en coh√©rence de diff√©rents corpus\npar la m√©thode des appariements flous\n(cf.¬†Galiana and Castillo (2022).\nLe chapitre sur ElasticSearch pr√©sent dans cette partie du cours pr√©sente quelques\n√©l√©ments de ce travail sur les donn√©es de l‚ÄôOpenFoodFacts.‚Ü©Ô∏é\nLa litt√©rature sur les mod√®les gravitaires, pr√©sent√©e dans Galiana et al. (2020),\ndonne quelques arguments pour privil√©gier les mod√®les GLM √† des mod√®les log-lin√©aires\nestim√©s par moindres carr√©s ordinaires.‚Ü©Ô∏é\nOn parle de bigrams pour les co-occurences de mots deux-√†-deux, trigrams pour les co-occurences trois-√†-trois, etc.‚Ü©Ô∏é",
    "crumbs": [
      "Nettoyer un texte : des exercices pour d√©couvrir l'approche bag-of-words"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html",
    "href": "content/NLP/04_word2vec.html",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "",
    "text": "Cette page approfondit certains aspects pr√©sent√©s dans la\npartie introductive. Apr√®s avoir travaill√© sur le\nComte de Monte Cristo, on va continuer notre exploration de la litt√©rature\navec cette fois des auteurs anglophones :\nLes donn√©es sont disponibles sur un CSV mis √† disposition sur Github. L‚ÄôURL pour les r√©cup√©rer directement est\nhttps://github.com/GU4243-ADS/spring2018-project1-ginnyqg/raw/master/data/spooky.csv.\nLe but va √™tre dans un premier temps de regarder dans le d√©tail les termes les plus fr√©quents utilis√©s par les auteurs et de les repr√©senter graphiquement, puis on va ensuite essayer de pr√©dire quel texte correspond √† quel auteur √† partir de diff√©rents mod√®les de vectorisation, notamment les word embeddings.\nCe chapitre s‚Äôinspire de plusieurs ressources disponibles en ligne:",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#preprocessing",
    "href": "content/NLP/04_word2vec.html#preprocessing",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "2.1 Preprocessing",
    "text": "2.1 Preprocessing\nEn NLP, la premi√®re √©tape est souvent celle du preprocessing, qui inclut notamment les √©tapes de tokenization et de nettoyage du texte. Comme celles-ci ont √©t√© vues en d√©tail dans le pr√©c√©dent chapitre, on se contentera ici d‚Äôun preprocessing minimaliste : suppression de la ponctuation et des stop words (pour la visualisation et les m√©thodes de vectorisation bas√©es sur des comptages).\nJusqu‚Äô√† pr√©sent, nous avons utilis√© principalement nltk pour le\npreprocessing de donn√©es textuelles. Cette fois, nous proposons\nd‚Äôutiliser la librairie spaCy qui permet de mieux automatiser sous forme de\npipelines de preprocessing.\nPour initialiser le processus de nettoyage,\non va utiliser le corpus en_core_web_sm (voir plus\nhaut pour l‚Äôinstallation de ce corpus):\n\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nOn va utiliser un pipe spacy qui permet d‚Äôautomatiser, et de parall√©liser,\nun certain nombre d‚Äôop√©rations. Les pipes sont l‚Äô√©quivalent, en NLP, de\nnos pipelines scikit ou des pipes pandas. Il s‚Äôagit donc d‚Äôun outil\ntr√®s appropri√© pour industrialiser un certain nombre d‚Äôop√©rations de\npreprocessing :\n\ndef clean_docs(texts, remove_stopwords=False, n_process=4):\n\n    docs = nlp.pipe(\n        texts, n_process=n_process, disable=[\"parser\", \"ner\", \"lemmatizer\", \"textcat\"]\n    )\n    stopwords = nlp.Defaults.stop_words\n\n    docs_cleaned = []\n    for doc in docs:\n        tokens = [tok.text.lower().strip() for tok in doc if not tok.is_punct]\n        if remove_stopwords:\n            tokens = [tok for tok in tokens if tok not in stopwords]\n        doc_clean = \" \".join(tokens)\n        docs_cleaned.append(doc_clean)\n\n    return docs_cleaned\n\nOn applique la fonction clean_docs √† notre colonne pandas.\nLes pandas.Series √©tant it√©rables, elles se comportent comme des listes et\nfonctionnent ainsi tr√®s bien avec notre pipe spacy.\n\nspooky_df[\"text_clean\"] = clean_docs(spooky_df[\"text\"])\n\n\nspooky_df.head()",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#encodage-de-la-variable-√†-pr√©dire",
    "href": "content/NLP/04_word2vec.html#encodage-de-la-variable-√†-pr√©dire",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "2.2 Encodage de la variable √† pr√©dire",
    "text": "2.2 Encodage de la variable √† pr√©dire\nOn r√©alise un simple encodage de la variable √† pr√©dire :\nil y a trois cat√©gories (auteurs), repr√©sent√©es par des entiers 0, 1 et 2.\nPour cela, on utilise le LabelEncoder de scikit d√©j√† pr√©sent√©\ndans la partie mod√©lisation. On va utiliser la m√©thode\nfit_transform qui permet, en un tour de main, d‚Äôappliquer √† la fois\nl‚Äôentra√Ænement (fit), √† savoir la cr√©ation d‚Äôune correspondance entre valeurs\nnum√©riques et labels, et l‚Äôappliquer (transform) √† la m√™me colonne.\n\nle = LabelEncoder()\nspooky_df[\"author_encoded\"] = le.fit_transform(spooky_df[\"author\"])\n\nOn peut v√©rifier les classes de notre LabelEncoder :\n\nle.classes_",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#construction-des-bases-dentra√Ænement-et-de-test",
    "href": "content/NLP/04_word2vec.html#construction-des-bases-dentra√Ænement-et-de-test",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "2.3 Construction des bases d‚Äôentra√Ænement et de test",
    "text": "2.3 Construction des bases d‚Äôentra√Ænement et de test\nOn met de c√¥t√© un √©chantillon de test (20 %) avant toute analyse (m√™me descriptive).\nCela permettra d‚Äô√©valuer nos diff√©rents mod√®les toute √† la fin de mani√®re tr√®s rigoureuse,\npuisque ces donn√©es n‚Äôauront jamais utilis√©es pendant l‚Äôentra√Ænement.\nNotre √©chantillon initial n‚Äôest pas √©quilibr√© (balanced) : on retrouve plus d‚Äôoeuvres de\ncertains auteurs que d‚Äôautres. Afin d‚Äôobtenir un mod√®le qui soit √©valu√© au mieux, nous allons donc stratifier notre √©chantillon de mani√®re √† obtenir une r√©partition similaire d‚Äôauteurs dans nos\nensembles d‚Äôentra√Ænement et de test.\nAper√ßu du premier √©l√©ment de X_train :\n\nX_train[0]\n\nOn peut aussi v√©rifier qu‚Äôon est capable de retrouver\nla correspondance entre nos auteurs initiaux avec\nla m√©thode inverse_transform :\n\nprint(y_train[0], le.inverse_transform([y_train[0]])[0])",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#r√©partition-des-labels",
    "href": "content/NLP/04_word2vec.html#r√©partition-des-labels",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "3.1 R√©partition des labels",
    "text": "3.1 R√©partition des labels\nRefaisons un graphique que nous avons d√©j√† produit pr√©c√©demment pour voir\nla r√©partition de notre corpus entre auteurs :\n\nfig = pd.Series(le.inverse_transform(y_train)).value_counts().plot(kind=\"bar\")\nfig\n\nOn observe une petite asym√©trie : les passages des livres d‚ÄôEdgar Allen Poe sont plus nombreux que ceux des autres auteurs dans notre corpus d‚Äôentra√Ænement, ce qui peut √™tre probl√©matique dans le cadre d‚Äôune t√¢che de classification.\nL‚Äô√©cart n‚Äôest pas dramatique, mais on essaiera d‚Äôen tenir compte dans l‚Äôanalyse en choisissant une m√©trique d‚Äô√©valuation pertinente.",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#mots-les-plus-fr√©quemment-utilis√©s-par-chaque-auteur",
    "href": "content/NLP/04_word2vec.html#mots-les-plus-fr√©quemment-utilis√©s-par-chaque-auteur",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "3.2 Mots les plus fr√©quemment utilis√©s par chaque auteur",
    "text": "3.2 Mots les plus fr√©quemment utilis√©s par chaque auteur\nOn va supprimer les stop words pour r√©duire le bruit dans notre jeu\nde donn√©es.\n\n# Suppression des stop words\nX_train_no_sw = clean_docs(X_train, remove_stopwords=True)\nX_train_no_sw = np.array(X_train_no_sw)\n\nPour visualiser rapidement nos corpus, on peut utiliser la technique des\nnuages de mots d√©j√† vue √† plusieurs reprises.\nVous pouvez essayer de faire vous-m√™me les nuages ci-dessous\nou cliquer sur la ligne ci-dessous pour afficher le code ayant\ng√©n√©r√© les figures :\n\nCliquer pour afficher le code üëá\n\ndef plot_top_words(initials, ax, n_words=20):\n    # Calcul des mots les plus fr√©quemment utilis√©s par l'auteur\n    texts = X_train_no_sw[le.inverse_transform(y_train) == initials]\n    all_tokens = \" \".join(texts).split()\n    counts = Counter(all_tokens)\n    top_words = [word[0] for word in counts.most_common(n_words)]\n    top_words_counts = [word[1] for word in counts.most_common(n_words)]\n\n    # Repr√©sentation sous forme de barplot\n    ax = sns.barplot(ax=ax, x=top_words, y=top_words_counts)\n    ax.set_title(f\"Most Common Words used by {initials_to_author[initials]}\")\n\n\ninitials_to_author = {\n    \"EAP\": \"Edgar Allen Poe\",\n    \"HPL\": \"H.P. Lovecraft\",\n    \"MWS\": \"Mary Wollstonecraft Shelley\",\n}\n\nfig, axs = plt.subplots(3, 1, figsize=(12, 12))\n\nplot_top_words(\"EAP\", ax=axs[0])\nplot_top_words(\"HPL\", ax=axs[1])\nplot_top_words(\"MWS\", ax=axs[2])\n\n\n\nBeaucoup de mots se retrouvent tr√®s utilis√©s par les trois auteurs.\nIl y a cependant des diff√©rences notables : le mot ‚Äúlife‚Äù\nest le plus employ√© par MWS, alors qu‚Äôil n‚Äôappara√Æt pas dans les deux autres tops.\nDe m√™me, le mot ‚Äúold‚Äù est le plus utilis√© par HPL\nl√† o√π les deux autres ne l‚Äôutilisent pas de mani√®re surrepr√©sent√©e.\nIl semble donc qu‚Äôil y ait des particularit√©s propres √† chacun des auteurs\nen termes de vocabulaire,\nce qui laisse penser qu‚Äôil est envisageable de pr√©dire les auteurs √† partir\nde leurs textes dans une certaine mesure.",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#d√©marche",
    "href": "content/NLP/04_word2vec.html#d√©marche",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "4.1 D√©marche",
    "text": "4.1 D√©marche\nComme nous nous int√©ressons plus √† l‚Äôeffet de la vectorisation qu‚Äô√† la t√¢che de classification en elle-m√™me,\nnous allons utiliser un algorithme de classification simple (un SVM lin√©aire), avec des param√®tres non fine-tun√©s (c‚Äôest-√†-dire des param√®tres pas n√©cessairement choisis pour √™tre les meilleurs de tous).\n\nclf = LinearSVC(max_iter=10000, C=0.1, dual=\"auto\")\n\nCe mod√®le est connu pour √™tre tr√®s performant sur les t√¢ches de classification de texte, et nous fournira donc un bon mod√®le de r√©f√©rence (baseline). Cela nous permettra √©galement de comparer de mani√®re objective l‚Äôimpact des m√©thodes de vectorisation sur la performance finale.\nPour les deux premi√®res m√©thodes de vectorisation\n(bas√©es sur des fr√©quences et fr√©quences relatives des mots),\non va simplement normaliser les donn√©es d‚Äôentr√©e, ce qui va permettre au SVM de converger plus rapidement, ces mod√®les √©tant sensibles aux diff√©rences d‚Äô√©chelle dans les donn√©es.\nOn va √©galement fine-tuner via grid-search\ncertains hyperparam√®tres li√©s √† ces m√©thodes de vectorisation :\n\non teste diff√©rents ranges de n-grams (unigrammes et unigrammes + bigrammes)\non teste avec et sans stop-words\n\nAfin d‚Äô√©viter le surapprentissage,\non va √©valuer les diff√©rents mod√®les via validation crois√©e, calcul√©e sur 4 blocs.\nOn r√©cup√®re √† la fin le meilleur mod√®le selon une m√©trique sp√©cifi√©e.\nOn choisit le score F1,\nmoyenne harmonique de la pr√©cision et du rappel,\nqui donne un poids √©quilibr√© aux deux m√©triques, tout en p√©nalisant fortement le cas o√π l‚Äôune des deux est faible.\nPr√©cis√©ment, on retient le score F1 *micro-averaged* :\nles contributions des diff√©rentes classes √† pr√©dire sont agr√©g√©es,\npuis on calcule le score F1 sur ces donn√©es agr√©g√©es.\nL‚Äôavantage de ce choix est qu‚Äôil permet de tenir compte des diff√©rences\nde fr√©quences des diff√©rentes classes.",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#pipeline-de-pr√©diction",
    "href": "content/NLP/04_word2vec.html#pipeline-de-pr√©diction",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "4.2 Pipeline de pr√©diction",
    "text": "4.2 Pipeline de pr√©diction\nOn va utiliser un pipeline scikit ce qui va nous permettre d‚Äôavoir\nun code tr√®s concis pour effectuer cet ensemble de t√¢ches coh√©rentes.\nDe plus, cela va nous assurer de g√©rer de mani√®re coh√©rentes nos diff√©rentes\ntransformations (cf.¬†partie sur les pipelines)\nPour se faciliter la vie, on d√©finit une fonction fit_vectorizers qui\nint√®gre dans un pipeline g√©n√©rique une m√©thode d‚Äôestimation scikit\net fait de la validation crois√©e en cherchant le meilleur mod√®le\n(en excluant/incluant les stop words et avec unigrammes/bigrammes)\n\ndef fit_vectorizers(vectorizer):\n    pipeline = Pipeline(\n        [\n            (\"vect\", vectorizer()),\n            (\"scaling\", StandardScaler(with_mean=False)),\n            (\"clf\", clf),\n        ]\n    )\n\n    parameters = {\n        \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigrams\n        \"vect__stop_words\": (\"english\", None),\n    }\n\n    grid_search = GridSearchCV(\n        pipeline, parameters, scoring=\"f1_micro\", cv=4, n_jobs=4, verbose=1\n    )\n    grid_search.fit(X_train, y_train)\n\n    best_parameters = grid_search.best_estimator_.get_params()\n    for param_name in sorted(parameters.keys()):\n        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n\n    print(f\"CV scores {grid_search.cv_results_['mean_test_score']}\")\n    print(f\"Mean F1 {np.mean(grid_search.cv_results_['mean_test_score'])}\")\n\n    return grid_search",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#informations-additionnelles",
    "href": "content/NLP/04_word2vec.html#informations-additionnelles",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n06d003a\n\n\n2024-04-23 10:09:22\n\n\nLino Galiana\n\n\nContinue la restructuration des sous-parties (#492)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3437373\n\n\n2023-12-16 20:11:06\n\n\nLino Galiana\n\n\nAm√©liore l‚Äôexercice sur le LASSO (#473)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\ndeaafb6\n\n\n2023-12-11 13:44:34\n\n\nThomas Faria\n\n\nRelecture Thomas partie NLP (#472)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n6855667\n\n\n2023-11-29 10:21:01\n\n\nRomain Avouac\n\n\nCorrections tp vectorisation + improve badge creation (#465)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9a4e226\n\n\n2023-08-28 17:11:52\n\n\nLino Galiana\n\n\nAction to check URL still exist (#399)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n78ea2cb\n\n\n2023-07-20 20:27:31\n\n\nLino Galiana\n\n\nChange titles levels (#381)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nb395985\n\n\n2023-02-13 17:29:36\n\n\nLino Galiana\n\n\nRetire shortcode spoiler (#352)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n7058752\n\n\n2022-03-04 15:35:17\n\n\nLino Galiana\n\n\nRelecture Word2Vec (#216)\n\n\n\n\nce1f2b5\n\n\n2022-02-16 13:54:27\n\n\nLino Galiana\n\n\nspacy corpus pre-downloaded\n\n\n\n\n66e2837\n\n\n2021-12-24 16:54:45\n\n\nLino Galiana\n\n\nFix a few typos in the new pipeline tutorial (#208)\n\n\n\n\n8ab1956\n\n\n2021-12-23 21:07:30\n\n\nRomain Avouac\n\n\nTP vectorization prediction authors (#206)\n\n\n\n\n09b60a1\n\n\n2021-12-21 19:58:58\n\n\nLino Galiana\n\n\nRelecture suite du NLP (#205)\n\n\n\n\n495599d\n\n\n2021-12-19 18:33:05\n\n\nLino Galiana\n\n\nDes √©l√©ments suppl√©mentaires dans la partie NLP (#202)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\nd164635\n\n\n2020-12-08 16:22:00\n\n\nLino Galiana\n\n\n:books: Premi√®re partie NLP (#87)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/NLP/04_word2vec.html#footnotes",
    "href": "content/NLP/04_word2vec.html#footnotes",
    "title": "M√©thodes de vectorisation : comptages et word embeddings",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nJeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation.‚Ü©Ô∏é",
    "crumbs": [
      "M√©thodes de vectorisation : comptages et word embeddings"
    ]
  },
  {
    "objectID": "content/modern-ds/index.html",
    "href": "content/modern-ds/index.html",
    "title": "Partie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart",
    "section": "",
    "text": "Les parties pr√©c√©dentes √©taient tr√®s tourn√©es sur l‚Äôacquisition\nde comp√©tences minimales dans chaque domaine de l‚Äôanalyse de donn√©es.\nCette partie propose des √©l√©ments plus avanc√©s mais plus repr√©sentatifs\ndu travail quotidien du data scientist. Cette partie\npr√©sente la mani√®re dont Python peut √™tre utilis√© dans une architecture\nmoderne de type cloud. Elle illustre la mani√®re dont Python peut\nservir de couteau-suisse faisant l‚Äôinterface entre diff√©rents\nlangages plus efficaces ou plusieurs types de donn√©es.\nCette partie est en cours de construction et pr√©sentera les\n√©l√©ments suivants :",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modern-ds/index.html#contenu-de-la-partie",
    "href": "content/modern-ds/index.html#contenu-de-la-partie",
    "title": "Partie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart",
    "section": "0.1 Contenu de la partie",
    "text": "0.1 Contenu de la partie\n{{&lt; list_children  &gt;}}",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modern-ds/index.html#informations-additionnelles",
    "href": "content/modern-ds/index.html#informations-additionnelles",
    "title": "Partie 5: Introduction aux outils et m√©thodes √† l‚Äô√©tat de l‚Äôart",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html",
    "href": "content/modern-ds/s3.html",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre est une introduction √† la question\ndu stockage des donn√©es et aux innovations\nr√©centes dans ce domaine. L‚Äôobjectif\nest d‚Äôabord de pr√©senter les avantages\ndu format Parquet et la mani√®re dont\non peut utiliser les\nlibrairies pyarrow\nou duckdb pour traiter\nde mani√®re efficace des donn√©es volumineuses\nau format Parquet. Ensuite, on pr√©sentera\nla mani√®re dont ce format parquet s‚Äôint√®gre\nbien avec des syst√®mes de stockage cloud,\nqui tendent √† devenir la norme dans le monde\nde la data science.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#principe-du-stockage-de-la-donn√©e",
    "href": "content/modern-ds/s3.html#principe-du-stockage-de-la-donn√©e",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "1.1 Principe du stockage de la donn√©e",
    "text": "1.1 Principe du stockage de la donn√©e\nPour comprendre les apports du format Parquet, il est n√©cessaire\nde faire un d√©tour pour comprendre la mani√®re dont une information\nest stock√©e et accessible √† un langage de traitement de la donn√©e.\nIl existe deux approches dans le monde du stockage de la donn√©e.\nLa premi√®re est celle de la base de donn√©es relationnelle. La seconde est le\nprincipe du fichier.\nLa diff√©rence entre les deux est dans la mani√®re dont l‚Äôacc√®s aux\ndonn√©es est organis√©.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#les-fichiers",
    "href": "content/modern-ds/s3.html#les-fichiers",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "1.2 Les fichiers",
    "text": "1.2 Les fichiers\nDans un fichier, les donn√©es sont organis√©es selon un certain format et\nle logiciel de traitement de la donn√©e va aller chercher et structurer\nl‚Äôinformation en fonction de ce format. Par exemple, dans un fichier\n.csv, les diff√©rentes informations seront stock√©es au m√™me niveau\navec un caract√®re pour les s√©parer (la virgule , dans les .csv anglosaxons, le point virgule dans les .csv fran√ßais, la tabulation dans les .tsv). Le fichier suivant\nnom ; profession \nAst√©rix ; \nOb√©lix ; Tailleur de menhir ;\nAssurancetourix ; Barde\nsera ainsi organis√© naturellement sous forme tabul√©e par Python\n\n\n\n\n\n\n\n\n\n\nnom\nprofession\n\n\n\n\n0\nAst√©rix\n\n\n\n1\nOb√©lix\nTailleur de menhir\n\n\n2\nAssurancetourix\nBarde\n\n\n\n\n\n\n\n\nA propos des fichiers de ce type, on parle de fichiers plats car\nles enregistrements relatifs √† une observation sont stock√©s ensemble,\nsans hi√©rarchie.\nCertains formats de donn√©es vont permettre d‚Äôorganiser les informations\nde mani√®re diff√©rente. Par exemple, le format JSON va\nhi√©rarchiser diff√©remment la m√™me information [^1]:\n[\n  {\n    \"nom\": \"Ast√©rix\"\n  },\n  {\n    \"nom\": \"Ob√©lix\",\n    \"profession\": \"Tailleur de menhir\"\n  },\n  {\n    \"nom\": \"Assurancetourix\",\n    \"profession\": \"Barde\"\n  }\n]\n\n\n Hint \nLa diff√©rence entre le CSV et le format JSON va au-del√† d‚Äôun simple ‚Äúformattage‚Äù des donn√©es.\nPar sa nature non tabulaire, le format JSON permet des mises √† jour beaucoup plus facile de la donn√©e dans les entrep√¥ts de donn√©es.\nPar exemple, un site web qui collecte de nouvelles donn√©es n‚Äôaura pas √† mettre √† jour l‚Äôensemble de ses enregistrements ant√©rieurs\npour stocker la nouvelle donn√©e (par exemple pour indiquer que pour tel ou tel client cette donn√©e n‚Äôa pas √©t√© collect√©e)\nmais pourra la stocker dans\nun nouvel item. Ce sera √† l‚Äôoutil de requ√™te (Python ou un autre outil)\nde cr√©er une relation entre les enregistrements stock√©s √† des endroits\ndiff√©rents.\nCe type d‚Äôapproche flexible est l‚Äôun des fondements de l‚Äôapproche NoSQL,\nsur laquelle nous allons revenir, qui a permis l‚Äô√©mergence de technologies au coeur de l‚Äô√©cosyst√®me actuel du big-data comme Hadoop ou ElasticSearch.\n\n\nCette fois, quand on n‚Äôa pas d‚Äôinformation, on ne se retrouve pas avec nos deux s√©parateurs accol√©s (cf.¬†la ligne ‚ÄúAst√©rix‚Äù) mais l‚Äôinformation\nn‚Äôest tout simplement pas collect√©e.\n\n\n Note\nIl se peut tr√®s bien que l‚Äôinformation sur une observation soit diss√©min√©e\ndans plusieurs fichiers dont les formats diff√®rent.\nPar exemple, dans le domaine des donn√©es g√©ographiques,\nlorsqu‚Äôune donn√©e est disponible sous format de fichier(s), elle peut l‚Äô√™tre de deux mani√®res!\n\nSoit la donn√©e est stock√©e dans un seul fichier qui m√©lange contours g√©ographiques et valeurs attributaires\n(la valeur associ√©e √† cette observation g√©ographique, par exemple le taux d‚Äôabstention). Ce principe est celui du geojson.\nSoit la donn√©e est stock√©e dans plusieurs fichiers qui sont sp√©cialis√©s : un fichier va stocker les contours g√©ographiques,\nl‚Äôautre les donn√©es attributaires et d‚Äôautres fichiers des informations annexes (comme le syst√®me de projection). Ce principe est celui du shapefile.\nC‚Äôest alors le logiciel qui requ√™te\nles donn√©es (Python par exemple) qui saura o√π aller chercher l‚Äôinformation\ndans les diff√©rents fichiers et associer celle-ci de mani√®re coh√©rente.\n\n\n\nUn concept suppl√©mentaire dans le monde du fichier est celui du file system. Le file system est\nle syst√®me de localisation et de nommage des fichiers.\nPour simplifier, le file system est la mani√®re dont votre ordinateur saura\nretrouver, dans son syst√®me de stockage, les bits pr√©sents dans tel ou tel fichier\nappartenant √† tel ou tel dossier.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#les-bases-de-donn√©es",
    "href": "content/modern-ds/s3.html#les-bases-de-donn√©es",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "1.3 Les bases de donn√©es",
    "text": "1.3 Les bases de donn√©es\nLa logique des bases de donn√©es est diff√©rente. Elle est plus syst√©mique.\nUn syst√®me de gestion de base de donn√©es (Database Management System)\nest un logiciel qui g√®re √† la fois le stockage d‚Äôun ensemble de donn√©es reli√©e,\npermet de mettre √† jour celle-ci (ajout ou suppression d‚Äôinformations, modification\ndes caract√©ristiques d‚Äôune table‚Ä¶)\net qui g√®re √©galement\nles modalit√©s d‚Äôacc√®s √† la donn√©e (type de requ√™te, utilisateurs\nayant les droits en lecture ou en √©criture‚Ä¶).\nLa relation entre les entit√©s pr√©sentes dans une base de donn√©es\nprend g√©n√©ralement la forme d‚Äôun sch√©ma en √©toile. Une base va centraliser\nles informations disponibles qui seront ensuite d√©taill√©es dans des tables\nd√©di√©es.\n\nSource: La documentation Databricks sur le sch√©ma en √©toile\nLe logiciel associ√© √† la base de donn√©es fera ensuite le lien\nentre ces tables √† partir de requ√™tes SQL. L‚Äôun des logiciels les plus efficaces dans ce domaine\nest PostgreSQL. Python est tout √† fait\nutilisable pour passer une requ√™te SQL √† un gestionnaire de base de donn√©es.\nLes packages sqlalchemy et psycopg2\npeuvent servir √† utiliser PostgreSQL pour requ√™ter une\nbase de donn√©e ou la mettre √† jour.\nLa logique de la base de donn√©es est donc tr√®s diff√©rente de celle du fichier.\nCes derniers sont beaucoup plus l√©gers pour plusieurs raisons.\nD‚Äôabord, parce qu‚Äôils sont moins adh√©rents √†\nun logiciel gestionnaire. L√† o√π le fichier ne n√©cessite, pour la gestion,\nqu‚Äôun file system, install√© par d√©faut sur\ntout syst√®me d‚Äôexploitation, une base de donn√©es va n√©cessiter un\nlogiciel sp√©cialis√©. L‚Äôinconv√©nient de l‚Äôapproche fichier, sous sa forme\nstandard, est qu‚Äôelle\nne permet pas une gestion fine des droits d‚Äôacc√®s et am√®ne g√©n√©ralement √† une\nduplication de la donn√©e pour √©viter que la source initiale soit\nr√©-√©crite (involontairement ou de mani√®re intentionnelle par un utilisateur malveillant).\nR√©soudre ce probl√®me est l‚Äôune des\ninnovations des syst√®mes cloud, sur lesquelles nous reviendrons en √©voquant le\nsyst√®me S3.\nUn deuxi√®me inconv√©nient de l‚Äôapproche base de donn√©es par\nrapport √† l‚Äôapproche fichier, pour un utilisateur de Python,\nest que les premiers n√©cessitent l‚Äôinterm√©diation du logiciel de gestion\nde base de donn√©es l√† o√π, dans le second cas, on va se contenter d‚Äôune\nlibrairie, donc un syst√®me beaucoup plus l√©ger,\nqui sait comment transformer la donn√©e brute en DataFrame.\nPour ces raisons, entre autres, les bases de donn√©es sont donc moins √† la\nmode dans l‚Äô√©cosyst√®me r√©cent de la data science que les fichiers.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#lire-un-parquet-en-python-la-librairie-pyarrow",
    "href": "content/modern-ds/s3.html#lire-un-parquet-en-python-la-librairie-pyarrow",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "2.1 Lire un parquet en Python: la librairie pyarrow",
    "text": "2.1 Lire un parquet en Python: la librairie pyarrow\nLa librairie pyarrow permet la lecture et l‚Äô√©criture\nde fichiers parquet avec Python1. Elle repose\nsur un type particulier de dataframe, le pyarrow.Table\nqui peut √™tre utilis√© en substitut ou en compl√©ment\ndu DataFrame\nde pandas. Il est recommand√© de r√©guli√®rement\nconsulter la documentation officielle de pyarrow\nconcernant la lecture et √©criture de fichiers et celle relative\naux manipulations de donn√©es.\nPour illustrer les fonctionalit√©s de pyarrow,\nrepartons de notre CSV initial que nous allons\nenrichir d‚Äôune nouvelle variable num√©rique\net que nous\nallons\nconvertir en objet pyarrow avant de l‚Äô√©crire au format parquet:\n\nimport pandas as pd\nfrom io import StringIO\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\ns = \"\"\"\nnom;cheveux;profession\nAst√©rix;blond;\nOb√©lix;roux;Tailleur de menhir\nAssurancetourix;blond;Barde\n\"\"\"\n\nsource = StringIO(s)\n\ndf = pd.read_csv(source, sep=\";\", index_col=False)\ndf[\"taille\"] = [155, 190, 175]\ntable = pa.Table.from_pandas(df)\n\ntable\n\npq.write_table(table, \"example.parquet\")\n\n\n\n Hint \nL‚Äôutilisation des noms pa pour pyarrow et pq pour\npyarrow.parquet est une convention communautaire\nqu‚Äôil est recommand√© de suivre.\n\n\nPour importer et traiter ces donn√©es, on peut conserver\nles donn√©es sous le format pyarrow.Table\nou transformer en pandas.DataFrame. La deuxi√®me\noption est plus lente mais pr√©sente l‚Äôavantage\nde permettre ensuite d‚Äôappliquer toutes les\nmanipulations offertes par l‚Äô√©cosyst√®me\npandas qui est g√©n√©ralement mieux connu que\ncelui d‚ÄôArrow.\nSupposons qu‚Äôon ne s‚Äôint√©resse qu‚Äô√† la taille et √† la couleur\nde cheveux de nos gaulois.\nIl n‚Äôest pas n√©cessaire d‚Äôimporter l‚Äôensemble de la base, cela\nferait perdre du temps pour rien. On appelle\ncette approche le column pruning qui consiste √†\nne parcourir, dans le fichier, que les colonnes qui nous\nint√©ressent. Du fait du stockage orient√© colonne du parquet,\nil suffit de ne consid√©rer que les blocs qui nous\nint√©ressent (alors qu‚Äôavec un CSV il faudrait scanner tout\nle fichier avant de pouvoir √©liminer certaines colonnes).\nCe principe du column pruning se mat√©rialise avec\nl‚Äôargument columns dans parquet.\nEnsuite, avec pyarrow, on pourra utiliser pyarrow.compute pour\neffectuer des op√©rations directement sur une table\nArrow :\n\nimport pyarrow.compute as pc\n\ntable = pq.read_table(\"example.parquet\", columns=[\"taille\", \"cheveux\"])\n\ntable.group_by(\"cheveux\").aggregate([(\"taille\", \"mean\")])\n\nLa mani√®re √©quivalente de proc√©der en passant\npar l‚Äôinterm√©diaire de pandas est\n\ntable = pq.read_table(\"example.parquet\", columns=[\"taille\", \"cheveux\"])\n\ntable.to_pandas().groupby(\"cheveux\")[\"taille\"].mean()\n\ncheveux\nblond    165.0\nroux     190.0\nName: taille, dtype: float64\n\n\nIci, comme les donn√©es sont peu volumineuses, deux des\navantages du parquet par rapport\nau CSV (donn√©es moins\nvolumineuses et vitesse de l‚Äôimport)\nne s‚Äôappliquent pas vraiment.\n\n\n Note\nUn autre principe d‚Äôoptimisation de la performance qui est\nau coeur de la librairie Arrow est le filter pushdown\n(ou predicate pushdown).\nQuand on ex√©cute un filtre de s√©lection de ligne\njuste apr√®s avoir charg√© un jeu de donn√©es,\nArrow va essayer de le mettre en oeuvre lors de l‚Äô√©tape de lecture\net non apr√®s. Autrement dit, Arrow va modifier le plan\nd‚Äôex√©cution pour pousser le filtre en amont de la s√©quence d‚Äôex√©cution\nafin de ne pas essayer de lire les lignes inutiles.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#quest-ce-que-le-syst√®me-de-stockage-s3",
    "href": "content/modern-ds/s3.html#quest-ce-que-le-syst√®me-de-stockage-s3",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.1 Qu‚Äôest-ce que le syst√®me de stockage S3 ?",
    "text": "4.1 Qu‚Äôest-ce que le syst√®me de stockage S3 ?\nDans les entreprises et administrations,\nun nombre croissant de donn√©es sont\ndisponibles depuis un syst√®me de stockage\nnomm√© S3.\nLe syst√®me S3 (Simple Storage System) est un syst√®me de stockage d√©velopp√©\npar Amazon et qui est maintenant devenu une r√©f√©rence pour le stockage en ligne.\nIl s‚Äôagit d‚Äôune architecture √† la fois\ns√©curis√©e (donn√©es crypt√©es, acc√®s restreints) et performante.\nLe concept central du syst√®me S3 est le bucket.\nUn bucket est un espace (priv√© ou partag√©) o√π on peut stocker une\narborescence de fichiers. Pour acc√©der aux fichiers figurant\ndans un bucket priv√©, il faut des jetons d‚Äôacc√®s (l‚Äô√©quivalent d‚Äôun mot de passe)\nreconnus par le serveur de stockage. On peut alors lire et √©crire dans le bucket.\n::: {.cell .markdown}\n\n Note\nLes exemples suivants seront r√©plicables pour les utilisateurs de la plateforme\nSSP Cloud\n\n\nIls peuvent √©galement l‚Äô√™tre pour des utilisateurs ayant un\nacc√®s √† AWS, il suffit de changer l‚ÄôURL du endpoint\npr√©sent√© ci-dessous.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#comment-faire-avec-python",
    "href": "content/modern-ds/s3.html#comment-faire-avec-python",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.2 Comment faire avec Python ?",
    "text": "4.2 Comment faire avec Python ?\n\n4.2.1 Les librairies principales\nL‚Äôinteraction entre ce syst√®me distant de fichiers et une session locale de Python\nest possible gr√¢ce √† des API. Les deux principales librairies sont les suivantes :\n\nboto3, une librairie cr√©√©e et maintenue par Amazon ;\ns3fs, une librairie qui permet d‚Äôinteragir avec les fichiers stock√©s √† l‚Äôinstar d‚Äôun filesystem classique.\n\nLa librairie pyarrow que nous avons d√©j√† pr√©sent√©e permet √©galement\nde traiter des donn√©es stock√©es sur le cloud comme si elles\n√©taient sur le serveur local. C‚Äôest extr√™mement pratique\net permet de fiabiliser la lecture ou l‚Äô√©criture de fichiers\ndans une architecture cloud.\nUn exemple, assez court, est disponible\ndans la documentation officielle\nIl existe √©galement d‚Äôautres librairies permettant de g√©rer\ndes pipelines de donn√©es (chapitre √† venir) de mani√®re\nquasi indiff√©rente entre une architecture locale et une architecture\ncloud. Parmi celles-ci, nous pr√©senterons quelques exemples\navec snakemake.\nEn arri√®re-plan, snakemake\nva utiliser boto3 pour communiquer avec le syst√®me\nde stockage.\nEnfin, selon le m√™me principe du comme si les donn√©es\n√©taient en local, il existe l‚Äôoutil en ligne de commande\nmc (Minio Client) qui permet de g√©rer par des lignes\nde commande Linux les d√©p√¥ts distants comme s‚Äôils √©taient\nlocaux.\nToutes ces librairies offrent la possibilit√© de se connecter depuis Python,\n√† un d√©p√¥t de fichiers distant, de lister les fichiers disponibles dans un\nbucket, d‚Äôen t√©l√©charger un ou plusieurs ou de faire de l‚Äôupload\nNous allons pr√©senter quelques-unes des op√©rations les plus fr√©quentes,\nen mode cheatsheet.",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#connexion-√†-un-bucket",
    "href": "content/modern-ds/s3.html#connexion-√†-un-bucket",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.3 Connexion √† un bucket",
    "text": "4.3 Connexion √† un bucket\nPar la suite, on va utiliser des alias pour les trois valeurs suivantes, qui servent\n√† s‚Äôauthentifier.\nkey_id = \"MY_KEY_ID\"\naccess_key = \"MY_ACCESS_KEY\"\ntoken = \"MY_TOKEN\"\nCes valeurs peuvent √™tre √©galement disponibles dans\nles variables d‚Äôenvironnement de Python. Comme il s‚Äôagit d‚Äôune information\nd‚Äôauthentification personnelle, il ne faut pas stocker les vraies valeurs de ces\nvariables dans un projet, sous peine de partager des traits d‚Äôidentit√© sans le\nvouloir lors d‚Äôun partage de code.\n\nboto3 üëá\nAvec boto3, on cr√©√© d‚Äôabord un client puis on ex√©cute des requ√™tes dessus.\nPour initialiser un client, il suffit, en supposant que l‚Äôurl du d√©p√¥t S3 est\n\"https://minio.lab.sspcloud.fr\", de faire:\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\n\n\n\nS3FS üëá\nLa logique est identique avec s3fs.\nSi on a des jetons d‚Äôacc√®s √† jour et dans les variables d‚Äôenvironnement\nad√©quates:\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n\n\n\nArrow üëá\nLa logique d‚ÄôArrow est proche de celle de s3fs. Seuls les noms\nd‚Äôarguments changent\nSi on a des jetons d‚Äôacc√®s √† jour et dans les variables d‚Äôenvironnement\nad√©quates:\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\n\n\nSnakemake üëá\nLa logique de Snakemake est, quant √† elle,\nplus proche de celle de boto3. Seuls les noms\nd‚Äôarguments changent\nSi on a des jetons d‚Äôacc√®s √† jour et dans les variables d‚Äôenvironnement\nad√©quates:\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n\nS3 = S3RemoteProvider(host=\"https://\" + os.getenv(\"AWS_S3_ENDPOINT\"))\n\n\nIl se peut que la connexion √† ce stade soit refus√©e (HTTP error 403).\nCela peut provenir\nd‚Äôune erreur dans l‚ÄôURL utilis√©. Cependant, cela refl√®te plus g√©n√©ralement\ndes param√®tres d‚Äôauthentification erron√©s.\n\nboto3 üëá\nLes param√®tres d‚Äôauthentification sont des arguments suppl√©mentaires:\nimport boto3\n\ns3 = boto3.client(\n    \"s3\",\n    endpoint_url=\"https://minio.lab.sspcloud.fr\",\n    aws_access_key_id=key_id,\n    aws_secret_access_key=access_key,\n    aws_session_token=token,\n)\n\n\n\nS3FS üëá\nLa logique est la m√™me, seuls les noms d‚Äôarguments diff√®rent\nimport s3fs\n\nfs = s3fs.S3FileSystem(\n    client_kwargs={\"endpoint_url\": \"https://\" + \"minio.lab.sspcloud.fr\"},\n    key=key_id,\n    secret=access_key,\n    token=token,\n)\n\n\n\nArrow üëá\nTout est en argument cette fois:\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(\n    access_key=key_id,\n    secret_key=access_key,\n    session_token=token,\n    endpoint_override=\"https://\" + \"minio.lab.sspcloud.fr\",\n    scheme=\"https\",\n)\n\n\n\nSnakemake üëá\nLa logique est la m√™me, seuls les noms d‚Äôarguments diff√®rent\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n\nS3 = S3RemoteProvider(\n    host=\"https://\" + os.getenv(\"AWS_S3_ENDPOINT\"),\n    access_key_id=key_id,\n    secret_access_key=access_key,\n)\n\n\n\n\n Note\nDans le SSP Cloud,\nlorsque l‚Äôinitialisation du service Jupyter du SSP Cloud est r√©cente\n(moins de 12 heures), il est possible d‚Äôutiliser\nautomatiquement les jetons stock√©s automatiquement √† la cr√©ation du d√©p√¥t.\nSi on d√©sire acc√©der aux donn√©es du SSP Cloud depuis une session Python du\ndatalab (service VSCode, Jupyter‚Ä¶),\nil faut remplacer l‚Äôurl par http://minio.lab.sspcloud.fr",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#lister-les-fichiers",
    "href": "content/modern-ds/s3.html#lister-les-fichiers",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.4 Lister les fichiers",
    "text": "4.4 Lister les fichiers\nS‚Äôil n‚Äôy a pas d‚Äôerreur √† ce stade, c‚Äôest que la connexion est bien effective.\nPour le v√©rifier, on peut essayer de faire la liste des fichiers disponibles\ndans un bucket auquel on d√©sire acc√©der.\nPar exemple, on peut vouloir\ntester l‚Äôacc√®s aux bases FILOSOFI (donn√©es de revenu localis√©es disponibles\nsur https://www.insee.fr) au sein du bucket donnees-insee.\n\nboto3 üëá\nPour cela,\nla m√©thode list_objects offre toutes les options n√©cessaires:\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\nfor key in s3.list_objects(Bucket=\"donnees-insee\", Prefix=\"diffusion/FILOSOFI\")[\n    \"Contents\"\n]:\n    print(key[\"Key\"])\n\n\n\nS3FS üëá\nPour lister les fichiers, c‚Äôest la m√©thode ls (celle-ci ne liste pas par\nd√©faut les fichiers de mani√®re r√©cursive comme boto3):\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\nfs.ls(\"donnees-insee/diffusion\")\n\n\n\nArrow üëá\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(endpoint_override=\"https://\" + \"minio.lab.sspcloud.fr\")\ns3.get_file_info(fs.FileSelector(\"donnees-insee/diffusion\", recursive=True))\n\n\n\nmc üëá\nmc ls -r",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#t√©l√©charger-un-fichier-depuis-s3-pour-lenregistrer-en-local",
    "href": "content/modern-ds/s3.html#t√©l√©charger-un-fichier-depuis-s3-pour-lenregistrer-en-local",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.5 T√©l√©charger un fichier depuis S3 pour l‚Äôenregistrer en local",
    "text": "4.5 T√©l√©charger un fichier depuis S3 pour l‚Äôenregistrer en local\nCette m√©thode n‚Äôest en g√©n√©ral pas recommand√©e car, comme on va le voir\npar la suite, il est possible de lire √† la vol√©e des fichiers. Cependant,\nt√©l√©charger un fichier depuis le cloud pour l‚Äô√©crire sur le disque\nlocal peut parfois √™tre utile (par exemple, lorsqu‚Äôil est n√©cessaire\nde d√©zipper un fichier).\n\nboto3 üëá\nOn utilise cette fois la m√©thode download_file\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\ns3.download_file(\n    \"donnees-insee\", \"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\", \"data.csv\"\n)\n\n\n\nS3FS üëá\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\nfs.download(\"donnees-insee/diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\", \"test.csv\")\n\n\n\nSnakemake üëá\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\nS3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\nbucket = \"mon-bucket\"\n\nrule ma_super_regle_s3:\n    input:\n        fichier = S3.remote(f'{bucket}/moninput.csv')\n    output:\n        fichier='mon_dossier_local/monoutput.csv'\n    run:\n        shell(\"cp {input[0]} {output[0]}\")\n\n\n\nmc üëá\nmc cp \"donnees-insee/FILOSOFI/2014/FILOSOFI_COM.csv\" 'data.csv'",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#lire-un-fichier-directement",
    "href": "content/modern-ds/s3.html#lire-un-fichier-directement",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.6 Lire un fichier directement",
    "text": "4.6 Lire un fichier directement\nLa m√©thode pr√©c√©dente n‚Äôest pas optimale. En effet, l‚Äôun des int√©r√™ts des API\nest qu‚Äôon peut traiter un fichier sur S3 comme s‚Äôil s‚Äôagissait d‚Äôun fichier\nsur son PC. Cela est d‚Äôailleurs une mani√®re plus s√©curis√©e de proc√©der puisqu‚Äôon\nlit les donn√©es √† la vol√©e, sans les √©crire dans un filesystem local.\n\nboto3 üëá\nimport boto3\n\ns3 = boto3.client(\"s3\", endpoint_url=\"https://minio.lab.sspcloud.fr\")\nobj = s3.get_object(\n    Bucket=\"donnees-insee\", Key=\"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\"\n)\ndf = pd.read_csv(obj[\"Body\"], sep=\";\")\ndf.head(2)\n\n\n\nS3FS üëá\nLe code suivant devrait permettre d‚Äôeffectuer la m√™me op√©ration avec s3fs\nimport pandas as pd\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\ndf = pd.read_csv(\n    fs.open(\n        \"{}/{}\".format(\"donnees-insee\", \"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\"),\n        mode=\"rb\",\n    ),\n    sep=\";\",\n)\n\ndf.head(2)\n\n\n\nSnakemake üëá\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\nS3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\nbucket = \"mon-bucket\"\n\nrule ma_super_regle_s3:\n    input:\n        fichier = S3.remote(f'{bucket}/moninput.csv')\n    run:\n        import pandas as pd\n        df = pd.read_csv(input.fichier)\n        # PLUS D'OPERATIONS\n\n\n\nArrow üëá\nArrow est une librairie qui permet de lire des CSV.\nIl est n√©anmoins\nbeaucoup plus pratique d‚Äôutiliser le format parquet avec arrow.\nDans un premier temps, on configure le filesystem avec les\nfonctionalit√©s d‚ÄôArrow (cf.¬†pr√©c√©demment).\n\nfrom pyarrow import fs\n\ns3 = fs.S3FileSystem(endpoint_override=\"http://\" + \"minio.lab.sspcloud.fr\")\n\nPour lire un csv, on fera:\nfrom pyarrow import fs\nfrom pyarrow import csv\n\ns3 = fs.S3FileSystem(endpoint_override=\"https://\" + \"minio.lab.sspcloud.fr\")\n\nwith s3.open_input_file(\n    \"donnees-insee/diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\"\n) as file:\n    df = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\nPour un fichier au format parquet, la d√©marche est plus simple gr√¢ce √† l‚Äôargument\nfilesystem dans pyarrow.parquet.ParquetDataset :\nimport pyarrow.parquet as pq\n\n# bucket = \"\"\n# parquet_file=\"\"\ndf = (\n    pq.ParquetDataset(f\"{bucket}/{parquet_file}\", filesystem=s3)\n    .read_pandas()\n    .to_pandas()\n)",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#uploader-un-fichier",
    "href": "content/modern-ds/s3.html#uploader-un-fichier",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.7 Uploader un fichier",
    "text": "4.7 Uploader un fichier\n\nboto3 üëá\ns3.upload_file(file_name, bucket, object_name)\n\n\n\nS3FS üëá\nfs.put(filepath, f\"{bucket}/{object_name}\", recursive=True)\n\n\n\nArrow üëá\nSupposons que df soit un pd.DataFrame\nDans un syst√®me local, on convertirait\nen table Arrow puis on √©crirait en parquet\n(voir la documentation officielle).\nQuand on est sur un syst√®me S3, il s‚Äôagit seulement d‚Äôajouter\nnotre connexion √† S3 dans l‚Äôargument filesystem\n(voir la page sur ce sujet dans la documentation Arrow)\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\ntable = pa.Table.from_pandas(df)\npq.write_table(table, f\"{bucket}/{path}\", filesystem=s3)\n\n\n\nSnakemake üëá\nfrom snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\nS3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\nbucket = \"mon-bucket\"\n\nrule ma_super_regle_s3:\n    input:\n        fichier='mon_dossier_local/moninput.csv'\n    output:\n        fichier=S3.remote(f'{bucket}/monoutput.csv')\n    run:\n        shell(\"cp output.fichier input.fichier\")\n\n\n\nmc üëá\nmc cp 'data.csv' \"MONBUCKET/monoutput.csv\"",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#pour-aller-plus-loin",
    "href": "content/modern-ds/s3.html#pour-aller-plus-loin",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "4.8 Pour aller plus loin",
    "text": "4.8 Pour aller plus loin\n\nLa documentation sur MinIO du SSPCloud",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#informations-additionnelles",
    "href": "content/modern-ds/s3.html#informations-additionnelles",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n8556b79\n\n\n2023-09-27 17:29:23\n\n\nJulien PRAMIL\n\n\nTypo chapitre S3 (#415)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n3f60d55\n\n\n2023-02-02 18:59:16\n\n\nLino Galiana\n\n\nWIP: Change path S3 (#349)\n\n\n\n\n9000723\n\n\n2023-01-22 12:01:25\n\n\nLino Galiana\n\n\nCorrige code s3fs upload (#345)\n\n\n\n\n1fe65ac\n\n\n2022-12-25 21:39:51\n\n\nLino Galiana\n\n\nDark boxes (#336)\n\n\n\n\n2227f8e\n\n\n2022-12-25 18:56:57\n\n\nLino Galiana\n\n\nFix problem s3 chapter (#335)\n\n\n\n\n8e5edba\n\n\n2022-09-02 11:59:57\n\n\nLino Galiana\n\n\nAjoute un chapitre dask (#264)\n\n\n\n\n688cc15\n\n\n2022-09-01 18:38:59\n\n\nLino Galiana\n\n\nUpdate index.qmd\n\n\n\n\n2117d2c\n\n\n2022-09-01 08:54:38\n\n\nLino Galiana\n\n\nAjoute des √©l√©ments sur arrow (#262)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nd201e3c\n\n\n2022-08-03 15:50:34\n\n\nLino Galiana\n\n\nPimp la homepage ‚ú® (#249)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\naa945cb\n\n\n2022-03-31 09:28:14\n\n\nLino Galiana\n\n\ncorrige une ou deux typos (#225)\n\n\n\n\n34b08ec\n\n\n2022-03-24 16:37:37\n\n\nLino Galiana\n\n\nAjoute code sur write_parquet dans S3\n\n\n\n\nc51a87b\n\n\n2022-03-24 16:29:39\n\n\nLino Galiana\n\n\nretire typo nom bucket (#223)\n\n\n\n\n3b1d9ff\n\n\n2022-03-09 10:38:15\n\n\nLino Galiana\n\n\nAjoute d√©tails arrow dans la partie S3 (#220)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\n2e4d586\n\n\n2021-09-02 12:03:39\n\n\nLino Galiana\n\n\nSimplify badges generation (#130)\n\n\n\n\n80877d2\n\n\n2021-06-28 11:34:24\n\n\nLino Galiana\n\n\nAjout d‚Äôun exercice de NLP √† partir openfood database (#98)\n\n\n\n\n6729a72\n\n\n2021-06-22 18:07:05\n\n\nLino Galiana\n\n\nMise √† jour badge onyxia (#115)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n0a0d034\n\n\n2021-03-26 20:16:22\n\n\nLino Galiana\n\n\nAjout d‚Äôune section sur S3 (#97)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/s3.html#footnotes",
    "href": "content/modern-ds/s3.html#footnotes",
    "title": "Les nouveaux modes d‚Äôacc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nElle permet aussi la lecture et l‚Äô√©criture\nde .csv.‚Ü©Ô∏é\nD‚Äôailleurs, les g√©n√©rations n‚Äôayant connu nativement\nque ce type de stockage ne sont pas familiaris√©es\nau concept de file system et pr√©f√®rent\npayer le temps de recherche. Voir\ncet article\nsur le sujet.‚Ü©Ô∏é\nD‚Äôailleurs, les g√©n√©rations n‚Äôayant connu nativement\nque ce type de stockage ne sont pas familiaris√©es\nau concept de file system et pr√©f√®rent\npayer le temps de recherche. Voir\ncet article\nsur le sujet.‚Ü©Ô∏é\nD‚Äôailleurs, les g√©n√©rations n‚Äôayant connu nativement\nque ce type de stockage ne sont pas familiaris√©es\nau concept de file system et pr√©f√®rent\npayer le temps de recherche. Voir\ncet article\nsur le sujet.‚Ü©Ô∏é",
    "crumbs": [
      "Les nouveaux modes d'acc√®s aux donn√©es : le format parquet et les donn√©es sur le cloud"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html",
    "href": "content/modern-ds/elastic_intro.html",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "",
    "text": "Pour essayer les exemples pr√©sents dans ce tutoriel :\npath = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCe chapitre a √©t√© √©crit avec Milena Suarez-Castillo\net pr√©sente quelques √©l√©ments qui servent de base √† un travail en cours\nsur les in√©galit√©s socio√©conomiques dans les\nchoix de consommation alimentaire.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#r√©plication-de-ce-chapitre",
    "href": "content/modern-ds/elastic_intro.html#r√©plication-de-ce-chapitre",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "1.1 R√©plication de ce chapitre",
    "text": "1.1 R√©plication de ce chapitre\nCe chapitre est plus exigeant en termes d‚Äôinfrastructures que les pr√©c√©dents.\nSi la premi√®re partie de ce chapitre peut √™tre men√©e avec une\ninstallation standard de Python, ce n‚Äôest pas le cas de la\ndeuxi√®me qui n√©cessite un serveur ElasticSearch. Les utilisateurs du\nSSP Cloud pourront r√©pliquer les exemples de ce cours\ncar cette technologie est disponible (que ce soit pour indexer une base ou\npour requ√™ter une base existante).\n‚ö†Ô∏è Ce\nchapitre n√©cessite une version particuli√®re du\npackage ElasticSearch pour tenir compte de l‚Äôh√©ritage de la version 7 du moteur Elastic.\nPour cela, faire\n\n!pip install elasticsearch==8.2.0\n!pip install unidecode\n!pip install rapidfuzz\n!pip install xlrd\n\nLa premi√®re partie de ce tutoriel ne n√©cessite pas d‚Äôarchitecture particuli√®re et\npeut ainsi √™tre ex√©cut√©e en utilisant les packages suivants :\n\nimport time\nimport pandas as pd\n\nLe script functions.py, disponible sur Github,\nregroupe un certain nombre de fonctions utiles permettant\nd‚Äôautomatiser certaines t√¢ches de nettoyage classiques\nen NLP.\n\n\n Hint\nPlusieurs m√©thodes peuvent √™tre mises en oeuvre pour r√©cup√©rer\nle script d‚Äôutilitaires. Vous pouvez trouver en dessous\nde cet encadr√© une m√©thode qui va chercher la derni√®re\nversion sur le d√©p√¥t Github du cours\n\n\n\nimport requests\n\nurl = \"https://github.com/linogaliana/python-datascientist/raw/master/content/modern-ds/functions.py\"\nr = requests.get(url, allow_redirects=True)\n\nopen(\"functions.py\", \"wb\").write(r.content)\n\nApr√®s l‚Äôavoir r√©cup√©r√© (cf.¬†encadr√© d√©di√©),\nil convient d‚Äôimporter les fonctions sous forme de module:\n\nimport functions as fc",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#cas-dusage",
    "href": "content/modern-ds/elastic_intro.html#cas-dusage",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "1.2 Cas d‚Äôusage",
    "text": "1.2 Cas d‚Äôusage\nCe notebook recense et propose d‚Äôappr√©hender quelques outils utilis√©s\npour le papier pr√©sent√© aux\nJourn√©es de M√©thodologie Statistiques 2022: Galiana and Suarez-Castillo, ‚ÄúFuzzy matching on big-data: an illustration with scanner data and crowd-sourced nutritional data‚Äù\n(travail en cours!)\nOn va partir du cas d‚Äôusage suivant :\n\nCombien de calories dans ma recette de cuisine de ce soir? Combien de calories dans mes courses de la semaine?\n\nL‚Äôobjectif est de reconstituer, √† partir de libell√©s de produits, les caract√©ristiques nutritionnelles d‚Äôune recette.\nLe probl√®me est que les libell√©s des tickets de caisse ne sont pas des champs textuels tr√®s propres, ils contiennent,\npar exemple, beaucoup d‚Äôabbr√©viations, toutes n‚Äô√©tant pas √©videntes.\nVoici par exemple une s√©rie de noms de produits qu‚Äôon va utiliser par la suite:\n\nticket = [\n    \"CROISSANTS X6 400G\",\n    \"MAQUEREAUX MOUTAR.\",\n    \"IGP OC SAUVIGNON B\",\n    \"LAIT 1/2 ECRM UHT\",\n    \"6 OEUFS FRAIS LOCA\",\n    \"ANANAS C2\",\n    \"L POMME FUDJI X6 CAL 75/80 1KG ENV\",\n    \"PLT MIEL\",\n    \"STELLA ARTOIS X6\",\n    \"COTES DU LUBERON AIGUEBRUN 75C\",\n]\n\nA ces produits, s‚Äôajoutent les ingr√©dients suivants, issus de la\nrecette du velout√© de potiron et carottes de Marmiton\nqui sera notre plat principal :\n\ningredients = [\n    \"500 g de carottes\",\n    \"2 pommes de terre\",\n    \"1 gousse d'ail\",\n    \"1/2 l de lait\",\n    \"1/2 l de bouillon de volaille\",\n    \"1 cuill√®re √† soupe de huile d'olive\",\n    \"1 kg de potiron\",\n    \"1 oignon\",\n    \"10 cl de cr√®me liquide (facultatif)\",\n]\n\nEssayer de r√©cup√©rer par web scraping cette liste est un bon exercice pour r√©viser\nles concepts vus pr√©c√©demment\nOn va donc cr√©er une liste de course compilant\nces deux\nlistes h√©t√©rog√®nes de noms de produits:\n\nlibelles = ticket + ingredients\n\nOn part avec cette liste dans notre supermarch√© virtuel. L‚Äôobjectif sera de trouver\nune m√©thode permettant de passer √† l‚Äô√©chelle:\nautomatiser les traitements, effectuer des recherches efficaces, garder une certaine g√©n√©ralit√© et flexibilit√©.\nCe chapitre montrera par l‚Äôexemple l‚Äôint√©r√™t d‚ÄôElastic par rapport √† une solution\nqui n‚Äôutiliserait que du Python.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#les-bases-offrant-des-informations-nutritionnelles",
    "href": "content/modern-ds/elastic_intro.html#les-bases-offrant-des-informations-nutritionnelles",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "2.1 Les bases offrant des informations nutritionnelles",
    "text": "2.1 Les bases offrant des informations nutritionnelles\nPour un nombre restreint de produits, on pourrait bien s√ªr chercher √†\nla main les caract√©ristiques des produits en utilisant les\nfonctionalit√©s d‚Äôun moteur de recherche:\n\nCependant, cette approche serait tr√®s fastidieuse et\nn√©cessiterait de r√©cuperer, √† la main, chaque caract√©ristique\npour chaque produit. Ce n‚Äôest donc pas envisageable.\nLes donn√©es disponibles sur Google viennent de l‚ÄôUSDA,\nl‚Äô√©quivalent am√©ricain de notre Minist√®re de l‚ÄôAgriculture.\nCependant, pour des recettes comportant des noms de produits fran√ßais, ainsi que\ndes produits potentiellement transform√©s, ce n‚Äôest pas tr√®s pratique d‚Äôutiliser\nune base de donn√©es de produits agricoles en Fran√ßais. Pour cette raison,\nnous proposons d‚Äôutiliser les deux bases suivantes,\nqui servent de base au travail de\nGaliana and Suarez Castillo (2022)\n\nL‚ÄôOpenFoodFacts database qui est une base\ncollaborative fran√ßaise de produits alimentaires. Issue d‚Äôun projet Data4Good, il s‚Äôagit d‚Äôune\nalternative opensource et opendata √† la base de donn√©es de l‚Äôapplication Yuka.\nLa table de composition nutritionnelle Ciqual produite par l‚ÄôAnses. Celle-ci\npropose la composition nutritionnelle moyenne des aliments les plus consomm√©s en France. Il s‚Äôagit d‚Äôune base de donn√©es\nenrichie par rapport √† celle de l‚ÄôUSDA puisqu‚Äôelle ne se cantonne pas aux produits agricoles non transform√©s.\nAvec cette base, il ne s‚Äôagit pas de trouver un produit exact mais essayer de trouver un produit type proche du produit\ndont on d√©sire conna√Ætre les caract√©ristiques.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#import",
    "href": "content/modern-ds/elastic_intro.html#import",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "2.2 Import",
    "text": "2.2 Import\nQuelques fonctions utiles sont regroup√©es dans le script functions.py et import√©es dans le notebook.\nLa base OpenFood peut √™tre r√©cup√©r√©e en ligne\nvia la fonction fc.import_openfood. N√©anmoins, cette op√©ration n√©cessitant\nun certain temps (les donn√©es brutes faisant autour de 2Go), nous proposons une m√©thode\npour les utilisateurs du SSP Cloud o√π une version est disponible sur\nl‚Äôespace de stockage.\nLa base Ciqual, qui plus l√©g√®re, est r√©cup√©r√©e elle directement en ligne\nvia la fonction fc.import_ciqual.\n\n# Pour les utilisateurs du SSP Cloud\nopenfood = fc.import_openfood_s3()\n# Pour les utilisateurs hors du SSP Cloud\n# openfood = fc.import_openfood()\nciqual = fc.import_ciqual()\n\n\nopenfood.head()\n\n\nciqual.head()",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#quest-ce-quelastic",
    "href": "content/modern-ds/elastic_intro.html#quest-ce-quelastic",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "3.1 Qu‚Äôest-ce qu‚ÄôElastic ?",
    "text": "3.1 Qu‚Äôest-ce qu‚ÄôElastic ?\nElasticSearch c‚Äôest un logiciel qui fournit un moteur de recherche install√© sur\nun serveur (ou une machine personnelle) qu‚Äôil est possible de requ√™ter depuis un client\n(une session Python par exemple).\nC‚Äôest un moteur de recherche\ntr√®s performant, puissant et flexible, extr√™mement utilis√© dans le domaine de la datascience\nsur donn√©es textuelles.\nUn cas d‚Äôusage est par exemple de trouver,\ndans un corpus de grande dimension\n(plusieurs sites web, livres‚Ä¶), un certain texte en s‚Äôautorisant des termes voisins\n(verbes conjugu√©s, fautes de frappes‚Ä¶).\nUn index est une collection de documents dans lesquels on souhaite chercher, pr√©alablement ing√©r√©s dans un moteur de recherche les documents sont les √©tablissements.\nL‚Äôindexation consiste √† pr√©-r√©aliser les traitements des termes des documents pour gagner en efficacit√© lors de la phase de recherche.\nL‚Äôindexation est faite une fois pour de nombreuses recherches potentielles, pour lesquelles la rapidit√© de r√©ponse peut √™tre cruciale.\nApr√®s avoir index√© une base, on effectuera des requ√™tes qui sont des recherches\nd‚Äôun document dans la base index√© (√©quivalent de notre web) √† partir de\ntermes de recherche normalis√©s.\nLe principe est le m√™me que celui d‚Äôun moteur de recherche du web comme Google.\nD‚Äôun c√¥t√©, l‚Äôensemble √† parcourir est index√© pour √™tre en\nmesure de parcourir de mani√®re efficace l‚Äôensemble du corpus.\nDe l‚Äôautre c√¥t√©, la phase de recherche permet de retrouver l‚Äô√©l√©ment du corpus le\nplus coh√©rent avec la requ√™te de recherche.\nL‚Äôindexation consiste, par exemple,\n√† pr√©-d√©finir des traitements des termes du corpus pour gagner en efficacit√©\nlors de la phase de recherche. En effet, l‚Äôindexation est une op√©ration peu fr√©quente\npar rapport √† la recherche. Pour cette derni√®re, l‚Äôefficacit√© est cruciale (un site web\nqui prend plusieurs secondes √† interpr√©ter une requ√™te simple ne sera pas utilis√©). Mais, pour\nl‚Äôindexation, ceci est moins crucial.\nLes documents sont constitu√©s de variables, les champs (‚Äòfields‚Äô),\ndont le type est sp√©cifi√© (‚Äútext‚Äù, ‚Äúkeywoard‚Äù, ‚Äúgeo_point‚Äù, ‚Äúnumeric‚Äù‚Ä¶) √† l‚Äôindexation.\nElasticSearch propose une interface graphique nomm√©e Kibana.\nCelle-ci est pratique\npour tester des requ√™tes et pour superviser le serveur Elastic. Cependant,\npour le passage √† l‚Äô√©chelle, notamment pour mettre en lien une base index√©e dans\nElastic avec une autre source de donn√©es, les API propos√©es par ElasticSearch\nsont beaucoup plus pratiques. Ces API permettent de connecter une session Python (idem pour R)\n√† un serveur Elastic afin de communiquer avec lui\n(√©changer des flux via une API REST).",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#elasticsearch-et-python",
    "href": "content/modern-ds/elastic_intro.html#elasticsearch-et-python",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "3.2 ElasticSearch et Python",
    "text": "3.2 ElasticSearch et Python\nEn Python, le package officiel est elasticsearch.\nCe dernier permet de configurer les param√®tres pour interagir avec un serveur, indexer\nune ou plusieurs bases, envoyer de mani√®re automatis√©e un ensemble de requ√™tes\nau serveur, r√©cup√©rer les r√©sultats directement dans une session Python‚Ä¶",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#premier-essai-les-produits-ciqual-les-plus-similaires-aux-produits-de-la-recette",
    "href": "content/modern-ds/elastic_intro.html#premier-essai-les-produits-ciqual-les-plus-similaires-aux-produits-de-la-recette",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "4.1 Premier essai: les produits Ciqual les plus similaires aux produits de la recette",
    "text": "4.1 Premier essai: les produits Ciqual les plus similaires aux produits de la recette\nOn pourrait √©crire une fonction qui prend en argument\nune liste de libell√©s d‚Äôint√©r√™t et une liste de candidat au match et\nrenvoie le libell√© le plus proche.\nCependant, le risque est que cet algorithme soit relativement lent s‚Äôil n‚Äôest pas cod√©\nparfaitement.\nIl est, √† mon avis, plus simple, quand\non est habitu√© √† la logique Pandas,\nde faire un produit cart√©sien pour obtenir un vecteur mettant en miroir\nchaque produit de notre recette avec l‚Äôensembles des produits Ciqual et ensuite comparer les deux vecteurs pour prendre,\npour chaque produit, le meilleur match.\nLes bases √©tant de taille limit√©e, le produit cart√©sien n‚Äôest pas probl√©matique.\nAvec des bases plus cons√©quentes, une strat√©gie plus parcimonieuse en m√©moire devrait √™tre envisag√©e.\nPour faire cette op√©ration, on va utiliser la fonction match_product de\nnote script d‚Äôutilitaires.\n\ndist_leven = fc.match_product(libelles, ciqual)\ndist_leven\n\nCette premi√®re √©tape na√Øve est d√©cevante √† plusieurs √©gards:\n\nCertes, on a des matches coh√©rent (par exemple ‚ÄúOignon rouge, cru‚Äù et ‚Äú1 oignon‚Äù)\nmais on a plus de couples incoh√©rents ;\nLe temps de calcul peut appara√Ætre faible mais le passage √† l‚Äô√©chelle risque d‚Äô√™tre compliqu√© ;\nLes besoins m√©moires sont potentiellement importants lors de l‚Äôappel √†\nrapidfuzz.process.extract ce qui peut bloquer le passage √† l‚Äô√©chelle ;\nLa distance textuelle n‚Äôest pas n√©cessairement la plus pertinente.\n\nOn a, en fait, n√©glig√© une √©tape importante: la normalisation (ou nettoyage des textes) pr√©sent√©e dans la\npartie NLP, notamment:\n\nharmonisation de la casse, suppression des accents‚Ä¶\nsuppressions des mots outils (e.g.¬†ici on va d‚Äôabord n√©gliger les quantit√©s pour trouver la nature de l‚Äôaliment, en particulier pour Ciqual)\n\n\n\n\n\n\n\n\n\n\nScanner-data avant nettoyage\n\n\n\n\n\n\n\nOpenFood data avant nettoyage\n\n\n\n\n\n\n\n\n\nScanner-data apr√®s nettoyage\n\n\n\n\n\n\n\nOpenFood data apr√®s nettoyage\n\n\n\n\n\nFaisons donc en apparence un retour en arri√®re qui sera\nn√©anmoins salvateur pour am√©liorer\nla pertinence des liens faits entre nos\nbases de donn√©es.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#objectif",
    "href": "content/modern-ds/elastic_intro.html#objectif",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.1 Objectif",
    "text": "5.1 Objectif\nLe preprocessing correspond √† l‚Äôensemble des op√©rations\nayant lieu avant l‚Äôanalyse √† proprement parler.\nIci, ce preprocessing est int√©ressant √† plusieurs\n√©gards:\n\nIl r√©duit le bruit dans nos jeux de donn√©es (par exemple des mots de liaisons) ;\nIl permet de normaliser et harmoniser les syntaxes dans nos diff√©rentes sources.\n\nL‚Äôobjectif est ainsi de r√©duire nos noms de produits √† la substantifique moelle\npour am√©liorer la pertinence de la recherche.\nPour √™tre pertinent, le preprocessing comporte g√©n√©ralement deux types de\ntraitements. En premier lieu, ceux qui sont g√©n√©raux et applicables\n√† tous types de corpus textuels: retrait des stopwords, de la ponctuation, etc.\nles m√©thodes disponibles dans la partie NLP.\nEnsuite, il est n√©cessaire de mettre en oeuvre des nettoyages plus sp√©cifiques √† chaque corpus.\nPar exemple dans la source Ciqual,\nla cuisson est souvent renseign√©e et bruite les appariemments.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#d√©marche",
    "href": "content/modern-ds/elastic_intro.html#d√©marche",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.2 D√©marche",
    "text": "5.2 D√©marche\n\n\n Exercice 1: preprocessing\n\nPour transformer les lettres avec accents en leur √©quivalent\nsans accent, la fonction unidecode\n(du package du m√™me nom) est pratique.\nLa tester sur le jeu de donn√©es ciqual en cr√©ant une nouvelle\ncolonne nomm√©e libel_clean\nLa casse diff√©rente selon les jeux de donn√©es peut √™tre p√©nalisante\npour trouver des produits similaires. Pour √©viter ces probl√®mes,\nmettre tout en majuscule.\nLes informations sur les quantit√©s ou le packaging peuvent apporter\ndu bruit dans notre comparaison. Nous allons retirer ces mots,\n√† travers la liste ['KG','CL','G','L','CRUE?S?', 'PREEMBALLEE?S?'],\nqu‚Äôon peut consid√©rer comme un dictionnaire de stop-words m√©tier.\nPour cela, il convient d‚Äôutiliser une expression r√©guli√®re dans la m√©thode\nstr.replace de Pandas.\nAvec ceux-ci, on va utiliser la liste des stop-words de\nla librairie nltk pour retirer les stop-words classiques (_‚Äúle‚Äù,‚Äúla‚Äù, etc.).\nLa librairie SpaCy, plus riche, pourrait √™tre utilis√©e ; nous laissons\ncela sous la forme d‚Äôexercice suppl√©mentaire.\nOn a encore des signes de ponctuation ou des chiffres qui peuvent\npoluer la comparaison. Les retirer gr√¢ce √† la m√©thode replace et\nune regex [^a-zA-Z]\nEnfin, par s√©curit√©, on peut supprimer les espaces multiples.\nUtiliser la regex '([ ]{2,})' pour cela. Observer le r√©sultat\nfinal.\n(Optionnel). Comme exercice suppl√©mentaire, faire la m√™me chose avec les\npipelines SpaCy.\n\n\n\nA l‚Äôissue de la question 1, le jeu de donn√©es ciqual devrait\nressembler √† celui-ci :\nApr√®s avoir mis en majuscule, on se retrouve avec le jeu de donn√©es\nsuivant :\nApr√®s retrait des stop-words, nos libell√©s prennent\nla forme suivante :\nLa regex pour √©liminer les caract√®res de ponctuation permet ainsi d‚Äôobtenir:\nEnfin, √† l‚Äôissue de la question 5, le DataFrame obtenu est le suivant :\nCes √©tapes de nettoyage ont ainsi permis de concentrer l‚Äôinformation\ndans les noms de produits sur ce qui l‚Äôidentifie vraiment.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#approche-syst√©matique",
    "href": "content/modern-ds/elastic_intro.html#approche-syst√©matique",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.3 Approche syst√©matique",
    "text": "5.3 Approche syst√©matique\nPour syst√©matiser cette approche √† nos diff√©rents DataFrame, rien de mieux\nqu‚Äôune fonction. Celle-ci est pr√©sente dans le module functions\nsous le nom clean_libelle.\n\nfrom functions import clean_libelle\n\nPour r√©sumer l‚Äôexercice pr√©c√©dent, cette fonction va :\n\nHarmoniser la casse et retirer les accents (voir functions.py) ;\nRetirer tout les caract√®res qui ne sont pas des lettres (chiffres, ponctuations) ;\nRetirer les caract√®res isol√©s.\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nnltk.download(\"stopwords\")\n\nstop_words = [\"KG\", \"CL\", \"G\", \"L\", \"CRUE?S?\", \"PREEMBALLEE?S?\"]\nstop_words += [l.upper() for l in stopwords.words(\"french\")]\n\nreplace_regex = {r\"[^A-Z]\": \" \", r\"\\b[A-Z0-9]{1,2}?\\b\": \" \"}  #\n\nCela permet d‚Äôobtenir les bases nettoy√©es suivantes :\n\nciqual = clean_libelle(\n    ciqual, yvar=\"alim_nom_fr\", replace_regex=replace_regex, stopWords=stop_words\n)\nciqual.sample(10)\n\n\nopenfood = clean_libelle(\n    openfood, yvar=\"product_name\", replace_regex=replace_regex, stopWords=stop_words\n)\nopenfood.sample(10)\n\n\ncourses = pd.DataFrame(libelles, columns=[\"libel\"])\ncourses = clean_libelle(\n    courses, yvar=\"libel\", replace_regex=replace_regex, stopWords=stop_words\n)\ncourses.sample(10)\n\nLes noms de produits sont d√©j√† plus harmonis√©s.\nVoyons voir si cela permet de trouver un\nmatch dans l‚ÄôOpenfood database:\n\ndist_leven_openfood = fc.match_product(courses[\"libel_clean\"], openfood, \"libel_clean\")\ndist_leven_openfood.sample(10)\n\nPas encore parfait, mais on progresse sur les produits appari√©s!\nConcernant le temps de calcul, les quelques secondes n√©cessaires √†\nce calcul peuvent appara√Ætre un faible prix √† payer. Cependant,\nil convient de rappeler que le nombre de produits dans l‚Äôensemble\nde recherche est faible. Cette solution n‚Äôest donc pas g√©n√©ralisable.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#r√©duire-les-temps-de-recherche",
    "href": "content/modern-ds/elastic_intro.html#r√©duire-les-temps-de-recherche",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "5.4 R√©duire les temps de recherche",
    "text": "5.4 R√©duire les temps de recherche\nFinalement, l‚Äôid√©al serait de disposer d‚Äôun moteur de recherche adapt√© √† notre besoin,\ncontenant les produits candidats, que l‚Äôon pourrait interroger, rapide en lecture, capable de classer les √©chos renvoy√©s par pertinence, que l‚Äôon pourrait requ√™ter de mani√®re flexible.\nPar exemple, on pourrait vouloir signaler qu‚Äôun\n√©cho nous int√©resse seulement si la donn√©e calorique n‚Äôest pas manquante.\nOn pourrait m√™me vouloir qu‚Äôil effectue pour nous des pr√©traitements sur les donn√©es.\nCela para√Æt beaucoup demander. Mais c‚Äôest exactement ce que fait ElasticSearch.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#cr√©er-un-cluster-elastic-sur-le-datalab",
    "href": "content/modern-ds/elastic_intro.html#cr√©er-un-cluster-elastic-sur-le-datalab",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.1 Cr√©er un cluster Elastic sur le DataLab",
    "text": "6.1 Cr√©er un cluster Elastic sur le DataLab\nPour lancer un service Elastic, il faut cliquer sur ce lien.\nUne fois cr√©√©, vous pouvez explorer l‚Äôinterface graphique Kibana.\nCependant, gr√¢ce √† l‚ÄôAPI Elastic\nde Python, on se passera de celle-ci. Donc, en pratique,\nune fois lanc√©, pas besoin d‚Äôouvrir ce service Elastic pour continuer √† suivre1.\nDans un terminal, vous pouvez aussi v√©rifier que vous √™tes en mesure de dialoguer avec votre cluster Elastic,\nqui est pr√™t √† vous √©couter:\nkubectl get statefulset\nPasser par la ligne de commande serait peu commode pour industrialiser notre\nrecherche.\nNous allons utiliser la librairie elasticsearch pour dialoguer avec notre moteur de recherche Elastic.\nLes instructions ci-dessous indiquent comment √©tablir la connection.\n\nfrom elasticsearch import Elasticsearch\n\nHOST = \"elasticsearch-master\"\n\n\ndef elastic():\n    \"\"\"Connection avec Elastic sur le data lab\"\"\"\n    es = Elasticsearch(\n        [{\"host\": HOST, \"port\": 9200, \"scheme\": \"http\"}],\n        http_compress=True,\n        request_timeout=200,\n    )\n    return es\n\n\nes = elastic()\n\n&lt;Elasticsearch([{'host': 'elasticsearch-master', 'port': 9200}])&gt;\nMaintenant que la connection est √©tablie, deux √©tapes nous attendent:\n\nIndexation Envoyer les documents parmi lesquels on veut chercher des echos pertinents dans notre elastic. Un index est une collection de document. Nous pourrions en cr√©er deux : un pour les produits ciqual, un pour les produits openfood\nRequ√™te Chercher les documents les plus pertinents suivant une recherche textuelle flexible. Nous allons rechercher les libell√©s de notre recette et de notre liste de course.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#premi√®re-indexation",
    "href": "content/modern-ds/elastic_intro.html#premi√®re-indexation",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.2 Premi√®re indexation",
    "text": "6.2 Premi√®re indexation\nOn cr√©e donc nos deux index:\n\nif not es.indices.exists(index=\"openfood\"):\n    es.indices.create(index=\"openfood\")\nif not es.indices.exists(index=\"ciqual\"):\n    es.indices.create(index=\"ciqual\")\n\nPour l‚Äôinstant, nos index sont vides! Ils contiennent 0 documents.\n\nes.count(index=\"openfood\")\n\n{'count': 0, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\nNous allons en rajouter quelques-uns !\n\nes.create(\n    index=\"openfood\",\n    id=1,\n    body={\n        \"product_name\": \"Tarte noix de coco\",\n        \"product_name_clean\": \"TARTE NOIX COCO\",\n    },\n)\nes.create(\n    index=\"openfood\",\n    id=2,\n    body={\"product_name\": \"Noix de coco\", \"product_name_clean\": \"NOIX COCO\"},\n)\nes.create(\n    index=\"openfood\",\n    id=3,\n    body={\"product_name\": \"Beurre doux\", \"product_name_clean\": \"BEURRE DOUX\"},\n)\n\n\nes.count(index=\"openfood\")\n\n{'count': 3, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\nDans l‚Äôinterface graphique Kibana,\non peut v√©rifier que l‚Äôindexation\na bien eue lieu en allant dans Management &gt; Stack Management",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#premi√®re-recherche",
    "href": "content/modern-ds/elastic_intro.html#premi√®re-recherche",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.3 Premi√®re recherche",
    "text": "6.3 Premi√®re recherche\nFaisons notre premi√®re recherche: cherchons des noix de p√©can!\n\nes.search(index=\"openfood\", q=\"noix de p√©can\")\n\nObjectApiResponse({'took': 116, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 2, 'relation': 'eq'}, 'max_score': 0.9400072, 'hits': [{'_index': 'openfood', '_type': '_doc', '_id': '2', '_score': 0.9400072, '_source': {'product_name': 'Noix de coco', 'product_name_clean': 'NOIX COCO'}}, {'_index': 'openfood', '_type': '_doc', '_id': '1', '_score': 0.8272065, '_source': {'product_name': 'Tarte noix de coco', 'product_name_clean': 'TARTE NOIX COCO'}}]}})\nInt√©ressons nous aux hits (r√©sultats pertinents, ou echos) : nous en avons 2.\nLe score maximal parmi les hits est mentionn√© dans max_score et correspond √† celui du deuxi√®me document index√©.\nElastic nous fournit ici un score de pertinence dans notre recherche d‚Äôinformation, et classe ainsi les documents renvoy√©s.\nIci nous utilisons la configuration par d√©faut. Mais comment est calcul√© ce score? Demandons √† Elastic de nous expliquer le score du document 2 dans la requ√™te \"noix de p√©can\".\n\nes.explain(index=\"openfood\", id=2, q=\"noix de p√©can\")\n\nObjectApiResponse({'_index': 'openfood', '_type': '_doc', '_id': '2', 'matched': True, 'explanation': {'value': 0.9400072, 'description': 'max of:', 'details': [{'value': 0.49917626, 'description': 'sum of:', 'details': [{'value': 0.49917626, 'description': 'weight(product_name_clean:noix in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.49917626, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.48275858, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 2.0, 'description': 'dl, length of field', 'details': []}, {'value': 2.3333333, 'description': 'avgdl, average length of field', 'details': []}]}]}]}]}, {'value': 0.9400072, 'description': 'sum of:', 'details': [{'value': 0.4700036, 'description': 'weight(product_name:noix in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.4700036, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.45454544, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 3.0, 'description': 'dl, length of field', 'details': []}, {'value': 3.0, 'description': 'avgdl, average length of field', 'details': []}]}]}]}, {'value': 0.4700036, 'description': 'weight(product_name:de in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.4700036, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.45454544, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 3.0, 'description': 'dl, length of field', 'details': []}, {'value': 3.0, 'description': 'avgdl, average length of field', 'details': []}]}]}]}]}]}})\nElastic nous explique donc que le score 0.9400072 est le maximum entre deux sous-scores, 0.4991 et 0.9400072.\nPour chacun de ces sous-scores, le d√©tail de son calcul est donn√©.\nLe premier sous-score n‚Äôa accord√© un score que par rapport au premier mot (noix), tandis que le second a accord√© un score sur la base des deux mots d√©j√† connu dans les documents (‚Äúnoix‚Äù et ‚Äúde‚Äù). Il a ignor√© p√©can! Jusqu‚Äô√† pr√©sent, ce terme n‚Äôest pas connu dans l‚Äôindex.\nLa pertinence d‚Äôun mot pour notre recherche est construite sur une variante de la TF-IDF,\nconsid√©rant qu‚Äôun terme est pertinent s‚Äôil est souvent pr√©sent dans le document (Term Frequency)\nalors qu‚Äôil est peu fr√©quent dans les autres document (inverse document frequency).\nIci les notations des documents 1 et 2 sont tr√®s proches, la diff√©rence est d√ªe √† des IDF plus faibles dans le document 1,\nqui est p√©nalis√© pour √™tre l√©g√©rement plus long.\nBref, tout √ßa est un peu lourd, mais assez efficace,\nen tout cas moins rudimentaire que les distances caract√®res √† caract√®res pour ramener des echos pertinents.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#limite-de-cette-premi√®re-indexation",
    "href": "content/modern-ds/elastic_intro.html#limite-de-cette-premi√®re-indexation",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "6.4 Limite de cette premi√®re indexation",
    "text": "6.4 Limite de cette premi√®re indexation\nPour l‚Äôinstant, Elastic n‚Äôa pas l‚Äôair de g√©rer les fautes de frappes!\nPas le droit √† l‚Äôerreur dans la requ√™te:\n\nes.search(index=\"openfood\", q=\"TART NOI\")\n\nObjectApiResponse({'took': 38, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}})\nCela s‚Äôexplique par la repr√©sentation des champs (‚Äòproduct_name‚Äô par exemple) qu‚ÄôElastic a inf√©r√©,\npuisque nous n‚Äôavons rien sp√©cifi√©.\nLa repr√©sentation d‚Äôune variable conditionne la fa√ßon dont les champs sont analys√©s pour calculer la pertinence.\nPar exemple, regardons la repr√©sentation du champ product_name\n\nes.indices.get_field_mapping(index=\"openfood\", fields=\"product_name\")\n\nObjectApiResponse({'openfood': {'mappings': {'product_name': {'full_name': 'product_name', 'mapping': {'product_name': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}}}})\nElastic a compris qu‚Äôil s‚Äôagissait d‚Äôun champ textuel.\nEn revanche, le type est keyword n‚Äôautorise pas des analyses approximatives donc\nne permet pas de tenir compte de fautes de frappes.\nPour qu‚Äôun echo remonte, un des termes doit matcher exactement. Dommage !\nMais c‚Äôest parce qu‚Äôon a utilis√© le mapping par d√©faut.\nEn r√©alit√©, il est assez simple de pr√©ciser un mapping plus riche,\nautorisant une analyse ‚Äúfuzzy‚Äù ou ‚Äúflou‚Äù.",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#nos-premi√®res-requ√™tes",
    "href": "content/modern-ds/elastic_intro.html#nos-premi√®res-requ√™tes",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "7.1 Nos premi√®res requ√™tes",
    "text": "7.1 Nos premi√®res requ√™tes\nV√©rifions qu‚Äôon recup√®re quelques tartes aux noix m√™me si l‚Äôon fait plein de fautes:\n\nes.search(index=\"openfood\", q=\"TART NOI\", size=3)\n\nObjectApiResponse({'took': 60, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10000, 'relation': 'gte'}, 'max_score': 22.837925, 'hits': [{'_index': 'openfood', '_type': '_doc', '_id': '405332', '_score': 22.837925, '_source': {'product_name': 'Tarte noix', 'libel_clean': 'TARTE NOIX', 'energy_100g': 1833.0, 'nutriscore_score': 23.0}}, {'_index': 'openfood', '_type': '_doc', '_id': '1103594', '_score': 22.82367, '_source': {'product_name': 'Tarte aux noix', 'libel_clean': 'TARTE NOIX', 'energy_100g': 4.0, 'nutriscore_score': 4.0}}, {'_index': 'openfood', '_type': '_doc', '_id': '1150755', '_score': 22.82367, '_source': {'product_name': 'Tarte aux noix', 'libel_clean': 'TARTE NOIX', 'energy_100g': 1929.0, 'nutriscore_score': 21.0}}]}})\nSi on pr√©f√®re sous une forme de DataFrame:\n\ndf = pd.json_normalize(\n    es.search(index=\"openfood\", q=\"TART NOI\", size=3)[\"hits\"][\"hits\"]\n)\ndf.columns = df.columns.str.replace(\"_source.\", \"\", regex=False)\ndf.head(2)\n\n\\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n_index_type_id_scoreproduct_namelibel_cleanenergy_100gnutriscore_score0openfood_doc40533222.837925Tarte noixTARTE NOIX1833.023.01openfood_doc110359422.823670Tarte aux noixTARTE NOIX4.04.02openfood_doc115075522.823670Tarte aux noixTARTE NOIX1929.021.0\nPour automatiser l‚Äôenvoi de requ√™tes et la r√©cup√©ration du meilleur\n√©cho, on peut d√©finir la fonction suivante\n\ndef matchElastic(libelles):\n    start_time = time.time()\n    matches = {}\n    for l in libelles:\n        response = es.search(index=\"openfood\", q=l, size=1)\n        if len(response[\"hits\"][\"hits\"]) &gt; 0:\n            matches[l] = pd.json_normalize(response[\"hits\"][\"hits\"])\n    print(80 * \"-\")\n    print(f\"Temps d'ex√©cution total : {(time.time() - start_time):.2f} secondes ---\")\n\n    return matches\n\n\nmatches = matchElastic(courses[\"libel_clean\"])\nmatches = pd.concat(matches)\nmatches.sample(3)\n\n\\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n_index_type_id_score_source.product_name_source.libel_clean_source.energy_100g_source.nutriscore_scoreGOUSSE AIL0openfood_doc198206257.93140Gousse d\\'ailGOUSSE AIL498.05.0IGP SAUVIGNON0openfood_doc180140696.55756vin blanc SauvignonVIN BLANC SAUVIGNON66.31.0POTIRON0openfood_doc104396175.96385PotironPOTIRON172.00.0\nEt voil√†, on a un outil tr√®s rapide de requ√™te !\nLa pertinence des r√©sultats est encore douteuse.\nPour cela, il conviendrait de pr√©ciser des requ√™tes plus sophistiqu√©es!2\n\nreq = {\n    \"bool\": {\n        \"should\": [\n            {\"match\": {\"libel_clean\": {\"query\": \"HUILE OLIVE\", \"boost\": 10}}},\n            {\"match\": {\"libel_clean.ngr\": \"HUILE OLIVE\"}},\n        ],\n        \"minimum_should_match\": 1,\n        \"filter\": [{\"range\": {\"nutriscore_score\": {\"gte\": 10, \"lte\": 20}}}],\n    }\n}\n\n\nout = es.search(index=\"openfood\", query=req, size=1)\npd.json_normalize(out[\"hits\"][\"hits\"])\n\n\\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n  \\n    \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n      \\n    \\n  \\n_index_type_id_score_source.product_name_source.libel_clean_source.energy_100g_source.nutriscore_score0openfood_doc960041174.27896Huile d oliveHUILE OLIVE3761.011.0\nQu‚Äôa-t-on demand√© ici?\n- De renvoyer 1 et 1 seul echo (\"size\":\"1\") et seulement si celui ci a:\n+ \"should\": Au moins un (\"minimum_should_match\":\"1\") des termes des deux champs libel_clean et libel_clean.ngr qui matche sur un terme de HUILE OLIVE, l‚Äôanalyse (la d√©finition du ‚Äúterme‚Äù) √©tant r√©alis√© soit en tant que text (‚Äúlibel_clean‚Äù) soit en tant que n-gramme ngr (‚Äúlibel_clean.ngr‚Äù, une analyse que nous avons sp√©cifi√© dans le mapping)\n+ \"filter\": Le champ float nutriscore_score doit √™tre compris entre 10 et 20 (‚Äúfilter‚Äù).\nA noter :\n\nLes clauses (\"should\"+\"minimum_should_match\":\"1\") peuvent √™tre remplac√© par un \"must\". Auquel cas, l‚Äô√©cho doit obligatoirement matcher sur chaque clause.\nPr√©ciser dans \"filter\" (plut√¥t que dans \"should\") une condition signifie que celle-ci ne participe pas au score de pertinence.\n\nOn n‚Äôa pas encore un appariemment tr√®s satisfaisant, en particulier sur les boissons. Comment faire ? La r√©ponse est dans Galiana and Suarez Castillo (2022)\n\nA vous, de calculer le nombre de calories de notre recette de course !",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#informations-additionnelles",
    "href": "content/modern-ds/elastic_intro.html#informations-additionnelles",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nPython version used:\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n3fba612\n\n\n2023-12-17 18:16:42\n\n\nLino Galiana\n\n\nRemove some badges from python (#476)\n\n\n\n\n4cd44f3\n\n\n2023-12-11 17:37:50\n\n\nAntoine Palazzolo\n\n\nRelecture NLP (#474)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\na06a268\n\n\n2023-11-23 18:23:28\n\n\nAntoine Palazzolo\n\n\n2√®me relectures chapitres ML (#457)\n\n\n\n\n69cf52b\n\n\n2023-11-21 16:12:37\n\n\nAntoine Palazzolo\n\n\n[On-going] Suggestions chapitres mod√©lisation (#452)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\ndf6a66b\n\n\n2023-11-05 10:56:31\n\n\nJulien PRAMIL\n\n\nPb redirection snippet elastic (#445)\n\n\n\n\n652009d\n\n\n2023-10-09 13:56:34\n\n\nLino Galiana\n\n\nFinalise le cleaning (#430)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n9977c5d\n\n\n2023-08-28 10:43:36\n\n\nLino Galiana\n\n\nFix bug path pandas (#397)\n\n\n\n\n8082302\n\n\n2023-08-25 17:48:36\n\n\nLino Galiana\n\n\nMise √† jour des scripts de construction des notebooks (#395)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n29ff3f5\n\n\n2023-07-07 14:17:53\n\n\nlinogaliana\n\n\ndescription everywhere\n\n\n\n\nf21a24d\n\n\n2023-07-02 10:58:15\n\n\nLino Galiana\n\n\nPipeline Quarto & Pages üöÄ (#365)\n\n\n\n\n003a625\n\n\n2022-10-28 18:53:05\n\n\nLino Galiana\n\n\nRebuild (#311)\n\n\n\n\ne3a6b2d\n\n\n2022-10-28 08:01:32\n\n\nLino Galiana\n\n\nProposition utilisation minio pour download openfood (#307)\n\n\n\n\n044abdb\n\n\n2022-10-25 13:57:53\n\n\nLino Galiana\n\n\nFinalise tuto elastic (#306)\n\n\n\n\n3e26719\n\n\n2022-10-24 19:09:22\n\n\nLino Galiana\n\n\nTutoriel Elastic reprise (#305)\n\n\n\n\n1f1668a\n\n\n2022-10-24 10:02:16\n\n\nLino Galiana\n\n\nCorrige tutoriel Elastic (#303)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\nbacb5a0\n\n\n2022-07-04 19:05:20\n\n\nLino Galiana\n\n\nEnrichir la partie elastic (#241)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n2a8809f\n\n\n2021-10-27 12:05:34\n\n\nLino Galiana\n\n\nSimplification des hooks pour gagner en flexibilit√© et clart√© (#166)\n\n\n\n\nb5615b4\n\n\n2021-09-09 16:52:47\n\n\nLino Galiana\n\n\nUn petit tuto Elastic (#135)\n\n\n\n\n8166e22\n\n\n2021-09-09 11:06:20\n\n\nLino Galiana\n\n\nWordcloud du site (#136)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')\n\n\n\n\n\n\n\n\n\nScanner-data avant nettoyage\nOpenFood data avant nettoyage\nScanner-data apr√®s nettoyage\nOpenFood data apr√®s nettoyage",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/modern-ds/elastic_intro.html#footnotes",
    "href": "content/modern-ds/elastic_intro.html#footnotes",
    "title": "Introduction √† ElasticSearch pour la recherche textuelle",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLe lancement du service a cr√©√© dans votre NAMESPACE Kubernetes (l‚Äôensemble de tout vos services) un cluster Elastic.\nVous n‚Äôavez droit qu‚Äô√† un cluster par namespace (ou compte d‚Äôutilisateur).\nVotre service Jupyter, VSCode, RStudio, etc. est associ√© au m√™me namespace.\nDe m√™me qu‚Äôil n‚Äôest pas n√©cessaire de comprendre comment fonctionne le moteur d‚Äôune voiture pour conduire,\nil n‚Äôest pas n√©cessaire de comprendre la mani√®re dont tout ce beau monde dialogue pour pouvoir utiliser le SSP Cloud.‚Ü©Ô∏é\nVous pouvez aussi explorer les possibilit√©s de requ√™tes via la doc Elastic et vous entrainer √† un √©crire avec votre index tout neuf.‚Ü©Ô∏é",
    "crumbs": [
      "Introduction √† ElasticSearch pour la recherche textuelle"
    ]
  },
  {
    "objectID": "content/git/introgit.html",
    "href": "content/git/introgit.html",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "",
    "text": "path = window.location.pathname.replace(\".html\", \".qmd\");\nhtml`${printBadges({fpath: path})}`\nhtml`\n&lt;details&gt;\n&lt;summary&gt;\nPour ouvrir la version corrig√©e sous forme de _notebook_\n&lt;/summary&gt;\n${printBadges({fpath: path, correction: true})}\n&lt;/details&gt;\n`\nfunction reminderBadges({\n    sourceFile = \"content/01_toto.Rmd\",\n    type = ['md', 'html'],\n    split = null,\n    onyxiaOnly = false,\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    if (Array.isArray(type)) {\n        type = type[0];\n    }\n\n    let notebook = sourceFile.replace(/(.Rmd|.qmd)/, \".ipynb\");\n    if (correction) {\n        notebook = notebook.replace(/content/, \"corrections\");\n    } else {\n        notebook = notebook.replace(/content/, \"notebooks\");\n    }\n\n    const githubRepoNotebooksSimplified = \"github/linogaliana/python-datascientist-notebooks\";\n    const githubAlias = githubRepoNotebooksSimplified.replace(\"github\", \"github.com\");\n    const githubRepoNotebooks = `https://${githubAlias}`;\n\n    let githubLink ;\n\n    if (notebook === \"\") {\n        githubLink = githubRepoNotebooks;\n    } else {\n        githubLink = `${githubRepoNotebooks}/blob/main`;\n    }\n\n    const notebookRelPath = `/${notebook}`;\n    const [section, chapter] = notebook.split(\"/\").slice(-2);\n\n\n    githubLink = `&lt;a href=\"${githubLink}${notebookRelPath}\" class=\"github\"&gt;&lt;i class=\"fab fa-github\"&gt;&lt;/i&gt;&lt;/a&gt;`;\n\n    const sectionLatest = section.split(\"/\").slice(-1)[0];\n    const chapterNoExtension = chapter.replace(\".ipynb\", \"\");\n    const onyxiaInitArgs = [sectionLatest, chapterNoExtension];\n\n    if (correction) {\n        onyxiaInitArgs.push(\"correction\");\n    }\n\n    const gpuSuffix = GPU ? \"-gpu\" : \"\";\n\n    const sspcloudJupyterLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/jupyter-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudJupyterLink;\n    if (type === \"md\") {\n        sspcloudJupyterLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange)](${sspcloudJupyterLinkLauncher})`;\n    } else {\n        sspcloudJupyterLink = `&lt;a href=\"${sspcloudJupyterLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 4) {\n        sspcloudJupyterLink += '&lt;br&gt;';\n    }\n\n    const sspcloudVscodeLinkLauncher = `https://datalab.sspcloud.fr/launcher/ide/vscode-${sspCloudService}${gpuSuffix}?autoLaunch=true&onyxia.friendlyName=%C2%AB${chapterNoExtension}%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-vscode.sh%C2%BB&init.personalInitArgs=%C2%AB${onyxiaInitArgs.join('%20')}%C2%BB&security.allowlist.enabled=false`;\n\n    let sspcloudVscodeLink;\n    if (type === \"md\") {\n        sspcloudVscodeLink = `[![Onyxia](https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue)](${sspcloudVscodeLinkLauncher})`;\n    } else {\n        sspcloudVscodeLink = `&lt;a href=\"${sspcloudVscodeLinkLauncher}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/badge/SSP%20Cloud-Tester_avec_VSCode-blue?logo=visualstudiocode&logoColor=blue\" alt=\"Onyxia\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 5) {\n        sspcloudVscodeLink += '&lt;br&gt;';\n    }\n\n    let colabLink;\n    if (type === \"md\") {\n        colabLink = `[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath})`;\n    } else {\n        colabLink = `&lt;a href=\"https://colab.research.google.com/${githubRepoNotebooksSimplified}/blob/main${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"&gt;&lt;/a&gt;`;\n    }\n\n    if (split === 7) {\n        colabLink += '&lt;br&gt;';\n    }\n\n    let vscodeLink;\n    if (type === \"md\") {\n        vscodeLink = `[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual Studio Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath})`;\n    } else {\n        vscodeLink = `&lt;a href=\"https://github.dev/linogaliana/python-datascientist-notebooks${notebookRelPath}\" target=\"_blank\" rel=\"noopener\"&gt;&lt;img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"&gt;&lt;/a&gt;&lt;/p&gt;`;\n    }\n\n    const badges = [\n        githubLink,\n        sspcloudVscodeLink,\n        sspcloudJupyterLink\n    ];\n\n    if (!onyxiaOnly) {\n        badges.push(colabLink);\n    }\n\n    let result = badges.join(\"\\n\");\n\n    if (type === \"html\") {\n        result = `&lt;p class=\"badges\"&gt;${result}&lt;/p&gt;`;\n    }\n\n    if (onyxiaOnly) {\n        result = `${sspcloudJupyterLink}${sspcloudVscodeLink}`;\n    }\n\n    return result;\n}\n\n\nfunction printBadges({\n    fpath,\n    onyxiaOnly = false,\n    split = 5,\n    type = \"html\",\n    sspCloudService = \"python\",\n    GPU = false,\n    correction = false\n} = {}) {\n    const badges = reminderBadges({\n        sourceFile: fpath,\n        type: type,\n        split: split,\n        onyxiaOnly: onyxiaOnly,\n        sspCloudService: sspCloudService,\n        GPU: GPU,\n        correction: correction\n    });\n\n    return badges\n}\nCette page reprend des √©l√©ments pr√©sents dans\nun cours d√©di√© fait avec Romain Avouac.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#les-probl√®mes-classiques",
    "href": "content/git/introgit.html#les-probl√®mes-classiques",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "1.1 Les probl√®mes classiques",
    "text": "1.1 Les probl√®mes classiques\nDans un projet, il est commun de se demander (ou de demander √† quelqu‚Äôun) :\n\nquelle √©tait la bonne version d‚Äôun programme ?\nqui √©tait l‚Äôauteur d‚Äôun bout de code en particulier ?\nsi un changement √©tait important ou juste un essai ?\no√π retrouver des traces d‚Äôun vieil essai abandonn√© mais potentiellement finalement prometteur ?\ncomment fusionner des programmes √©crits par plusieurs personnes ?\netc.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#la-solution-le-contr√¥le-de-version",
    "href": "content/git/introgit.html#la-solution-le-contr√¥le-de-version",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "1.2 La solution: le contr√¥le de version",
    "text": "1.2 La solution: le contr√¥le de version\nIl existe un outil informatique puissant qui r√©pond √† tous ces besoins :\nla gestion de version (version control system (VCS) en anglais). Ses avantages sont incontestables et permettent de facilement :\n\nenregistrer l‚Äôhistorique des modifications d‚Äôun ensemble de fichiers ;\nrevenir √† des versions pr√©c√©dentes d‚Äôun ou plusieurs fichiers ;\nrechercher les modifications qui ont pu cr√©er des erreurs ;\npartager ses modifications et r√©cup√©rer celles des autres ;\nproposer des modifications, les discuter, sans pour autant modifier d‚Äôembl√©e la derni√®re version existante ;\nidentifier les auteurs et la date des modifications.\n\nEn outre, ces outils fonctionnent avec tous les langages\ninformatiques (texte, R, Python, Markdown, LaTeX, Java, etc.)\ncar reposent sur la comparaison des lignes et des caract√®res des programmes.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#avantages-du-contr√¥le-de-version",
    "href": "content/git/introgit.html#avantages-du-contr√¥le-de-version",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "1.3 Avantages du contr√¥le de version",
    "text": "1.3 Avantages du contr√¥le de version\nOn peut ainsi r√©sumer les principaux avantages du contr√¥le de version\nde la mani√®re suivante :\n\nConserver et archiver l‚Äôensemble des versions d‚Äôun code ou d‚Äôune documentation\nTravailler efficacement en √©quipe\nAm√©liorer la qualit√© des codes\nSimplifier la communication autour d‚Äôun projet\n\n\n1.3.1 Conserver et archiver du code\nUne des principales fonctionnalit√©s de la gestion de version est de conserver\nl‚Äôensemble des fichiers de fa√ßon s√©curis√©e et de proposer un archivage\nstructur√© des codes. Les fichiers sont stock√©s dans un d√©p√¥t, qui constitue le projet.\nTout repose dans la gestion et la pr√©sentation de l‚Äôhistorique des modifications.\nChaque modification (ajout, suppression ou changement) sur un ou plusieurs fichiers est identifi√©e par son auteur,\nsa date et un bref descriptif1.\nChaque changement est donc unique et ais√©ment identifiable quand les modifications sont class√©es par ordre chronologique. Les groupes de modifications transmis au d√©p√¥t sont appel√©es commit.\nAvec des outils graphiques, on peut v√©rifier l‚Äô\nensemble des √©volutions d‚Äôun fichier (history),\nou l‚Äôhistoire d‚Äôun d√©p√¥t.\nOn peut aussi\nse concentrer sur une modification particuli√®re d‚Äôun fichier ou v√©rifier, pour un fichier, la\nmodification qui a entra√Æn√© l‚Äôapparition de telle ou telle ligne (blame)\nSur son poste de travail, les dizaines (voire centaines) de programmes organis√©s √† la main n‚Äôexistent plus. Tout est regroup√© dans un seul dossier, rassemblant les √©l√©ments du d√©p√¥t. Au sein du d√©p√¥t, tout l‚Äôhistorique est stock√© et accessible rapidement. Si on souhaite travailler sur la derni√®re version des programmes (ou sur une ancienne version sp√©cifique), il n‚Äôy a plus besoin de conserver les autres fichiers car ils sont dans l‚Äôhistorique du projet. Il est alors possible de choisir sur quelle version on veut travailler (la derni√®re commune √† tout le monde, la sienne en train d‚Äô√™tre d√©velopp√©e, celle de l‚Äôann√©e derni√®re, etc.).\n\n\n1.3.2 Travailler efficacement en √©quipe\nLe deuxi√®me avantage de la gestion de version repr√©sente une am√©lioration notable du travail en √©quipe sur des codes en commun.\nLa gestion de version permet de collaborer simplement et avec m√©thode. De fa√ßon organis√©e, elle permet de :\n\ntravailler en parall√®le et fusionner facilement du code\npartager une documentation des programmes gr√¢ce :\n\naux commentaires des modifications\n√† la possibilit√© d‚Äôune documentation commune et collaborative\n\ntrouver rapidement des erreurs et en diffuser rapidement la\ncorrection\n\nA ces avantages s‚Äôajoutent les fonctionalit√©s collaboratives des forges\nqui sont des plateformes o√π peuvent √™tre stock√©s des d√©p√¥ts.\nN√©anmoins, ces forges proposent aujourd‚Äôhui beaucoup de fonctionalit√©s\nqui vont au-del√† de l‚Äôarchivage de code :\ninteragir via\ndes issues,\nfaire des suggestions de modifications, ex√©cuter du code dans des\nenvironnements normalis√©s, etc.\nIl faut vraiment les voir comme des r√©seaux sociaux du code.\nLes principales plateformes dans ce domaine √©tant Github et Gitlab.\nL‚Äôusage individuel, c‚Äôest-√†-dire seul sur son projet,\npermet aussi de ‚Äútravailler en √©quipe avec soi-m√™me‚Äù car il permet de retrouver des mois plus tard le contenu et le contexte des modifications. Cela est notamment pr√©cieux lors des changements de poste ou des travaux r√©guliers mais espac√©s dans le temps (par exemple, un mois par an chaque ann√©e). M√™me lorsqu‚Äôon travaille tout seul, on collabore avec un moi futur qui peut ne plus se souvenir de la modification des fichiers.\n\n\n1.3.3 Am√©liorer la qualit√© des codes\nLe fonctionnement de la gestion de version, reposant sur l‚Äôarchivage structur√© des modifications et les commentaires les accompagnant, renforce la qualit√© des programmes informatiques. Ils sont plus document√©s, plus riches et mieux structur√©s. C‚Äôest pour cette raison que le contr√¥le de version ne doit pas √™tre consid√©r√© comme un outil r√©serv√© √† des d√©veloppeurs : toute personne travaillant sur des programmes informatiques gagne √† utiliser du contr√¥le de version.\nLes services d‚Äôint√©gration continue permettent de faire des tests automatiques\nde programmes informatiques, notamment de packages, qui renforcent la\nr√©plicabilit√© des programmes. Mettre en place des m√©thodes de travail fond√©es\nsur l‚Äôint√©gration continue rend les programmes plus robustes en for√ßant\nceux-ci √† tourner sur des machines autres que celles du d√©veloppeur du code.\n\n\n1.3.4 Simplifier la communication autour d‚Äôun projet\nLes sites de d√©p√¥ts Github et Gitlab permettent de faire beaucoup plus\nque seulement archiver des codes. Les fonctionalit√©s de d√©ploiement\nen continu permettent ainsi de :\n\ncr√©er des sites web pour valoriser des projets (par exemple les sites\nreadthedocs en python)\nd√©ployer de la documentation en continu\nrendre visible la qualit√© d‚Äôun projet avec des services de code coverage,\nde tests automatiques ou d‚Äôenvironnements int√©gr√©s de travail (binder, etc.)\nqu‚Äôon rend g√©n√©ralement visible au moyen de badges\n(exemple ici)",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#copies-de-travail-et-d√©p√¥t-collectif",
    "href": "content/git/introgit.html#copies-de-travail-et-d√©p√¥t-collectif",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "3.1 Copies de travail et d√©p√¥t collectif",
    "text": "3.1 Copies de travail et d√©p√¥t collectif\nGit est un syst√®me d√©centralis√© et asynchrone de gestion de version.\nCela signifie que:\n\nChaque membre d‚Äôun projet travaille sur une copie locale du d√©p√¥t\n(syst√®me decentralis√©). Cette copie de travail s‚Äôappelle un clone.\nCela signifie qu‚Äôon n‚Äôa pas une coh√©rence en continu de notre version\nde travail avec le d√©p√¥t ; on peut tr√®s bien ne jamais vouloir les\nmettre en coh√©rence (par exemple, si on teste une piste qui s‚Äôav√®re\ninfructueuse) ;\nC‚Äôest lorsqu‚Äôon propose la publication de modifications sur le d√©p√¥t\ncollectif qu‚Äôon doit s‚Äôassurer de la coh√©rence avec la version disponible\nen ligne (syst√®me asynchrone).\n\nLe d√©p√¥t distant est g√©n√©ralement stock√© sur\nune forge logicielle (Github ou Gitlab) et sert √† centraliser la version\ncollective d‚Äôun projet. Les copies locales sont des copies de travail\nqu‚Äôon utilise pour faire √©voluer un projet :\nIl est tout √† fait possible de faire du contr√¥le de version sans\nmettre en place de d√©p√¥t distant. Cependant,\n\nc‚Äôest dangereux puisque le d√©p√¥t distant fait office de sauvegarde\nd‚Äôun projet. Sans d√©p√¥t distant, on peut tout perdre en cas de probl√®me\nsur la copie locale de travail ;\nc‚Äôest d√©sirer √™tre moins efficace car, comme nous allons le montrer, les\nfonctionalit√©s des plateformes Github et Gitlab sont √©galement tr√®s\nb√©n√©fiques lorsqu‚Äôon travaille tout seul.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#principe",
    "href": "content/git/introgit.html#principe",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "3.2 Principe",
    "text": "3.2 Principe\nLes trois manipulations les plus courantes sont les suivantes et repr√©sent√©es sur le diagramme ci-apr√®s :\n\ncommit : je valide les modifications que j‚Äôai faites en local avec un message qui les explique\npull : je r√©cup√®re la derni√®re version des codes du d√©p√¥t distant\npush : je transmets mes modifications valid√©es au d√©p√¥t distant\n\n\nLes deux derni√®res manipulations correspondent aux interactions (notamment\nla mise en coh√©rence) avec\nle d√©p√¥t commun alors que la premi√®re manipulation commit correspond √†\nla modification des fichiers faite pour faire √©voluer un projet.\nDe mani√®re plus pr√©cise, il y a trois √©tapes avant d‚Äôenvoyer les modifications valid√©es (commit) au d√©p√¥t. Elles se d√©finissent en fonction des commandes qui permettent de les appliquer quand Git est utilis√© en lignes de commandes :\n\ndiff : inspection des modifications. Cela permet de comparer les fichiers modifi√©s et de distinguer les fichiers ajout√©s ou supprim√©s.\nstaging area : s√©lection des modifications.\ncommit : validation des modifications s√©lectionn√©es (avec commentaire).\n\n\nLors des √©tapes de push et pull, des conflits peuvent appara√Ætre, par exemple lorsque deux personnes ont modifi√© le m√™me programme simultan√©ment. Le terme conflit peut faire peur mais en fait c‚Äôest\nl‚Äôun des apports principaux de Git que de faciliter √©norm√©ment la gestion\nde versions diff√©rentes. Les exercices du chapitre suivant l‚Äôillustreront.",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#les-branches",
    "href": "content/git/introgit.html#les-branches",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "3.3 Les branches",
    "text": "3.3 Les branches\nC‚Äôest une des fonctionnalit√©s les plus pratiques de la gestion de version.\nLa cr√©ation de branches dans un projet (qui devient ainsi un arbre)\npermet de d√©velopper en parall√®le des correctifs ou une nouvelle fonctionnalit√©\nsans modifier le d√©p√¥t commun.\nCela permet de s√©parer le nouveau d√©veloppement et de faire cohabiter plusieurs versions, pouvant √©voluer s√©par√©ment ou pouvant √™tre facilement rassembl√©es. Git est optimis√© pour le travail sur les branches.\nDans un projet collaboratif, une branche dite master joue le r√¥le du tronc.\nC‚Äôest autour d‚Äôelle que vont pousser ou se greffer les branches.\nL‚Äôun des avantages de Git est qu‚Äôon peut toujours revenir en arri√®re. Ce\nfilet de s√©curit√© permet d‚Äôoser des exp√©rimentations, y compris au sein\nd‚Äôune branche. Il faut √™tre pr√™t √† aller dans la ligne de commande pour cela\nmais c‚Äôest extr√™mement confortable.\n\n\n Note\nComment nommer les branches ? L√† encore, il y a √©norm√©ment de conventions diff√©rentes. Une fr√©quemment observ√©e est :\n\npour les nouvelles fonctionnalit√©s : feature/nouvelle-fonctionnalite o√π nouvelle-fontionnalite est un nom court r√©sumant la fonctionnalit√©\npour les corrections de bug : issue-num o√π num est le num√©ro de l‚Äôissue\n\nN‚Äôh√©sitez pas √† aller encore plus loin dans la normalisation !",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#informations-additionnelles",
    "href": "content/git/introgit.html#informations-additionnelles",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nc9f9f8a\n\n\n2024-04-24 15:09:35\n\n\nLino Galiana\n\n\nDark mode and CSS improvements (#494)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n4c1c22d\n\n\n2023-12-10 11:50:56\n\n\nLino Galiana\n\n\nBadge en javascript plut√¥t (#469)\n\n\n\n\n09654c7\n\n\n2023-11-14 15:16:44\n\n\nAntoine Palazzolo\n\n\nSuggestions Git & Visualisation (#449)\n\n\n\n\ne3f1ef1\n\n\n2023-11-13 11:53:50\n\n\nThomas Faria\n\n\nRelecture git (#448)\n\n\n\n\n1229936\n\n\n2023-11-10 11:02:28\n\n\nlinogaliana\n\n\ngitignore\n\n\n\n\n57f108f\n\n\n2023-11-10 10:59:36\n\n\nlinogaliana\n\n\nIntro git\n\n\n\n\n9366e8d\n\n\n2023-10-09 12:06:23\n\n\nLino Galiana\n\n\nRetrait des box hugo sur l‚Äôexo git (#428)\n\n\n\n\na771183\n\n\n2023-10-09 11:27:45\n\n\nAntoine Palazzolo\n\n\nRelecture TD2 par Antoine (#418)\n\n\n\n\n5ab34aa\n\n\n2023-10-04 14:54:20\n\n\nKim A\n\n\nRelecture Kim pandas & git (#416)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n2dbf853\n\n\n2023-07-05 11:21:40\n\n\nLino Galiana\n\n\nAdd nice featured images (#368)\n\n\n\n\n34cc32c\n\n\n2022-10-14 22:05:47\n\n\nLino Galiana\n\n\nRelecture Git (#300)\n\n\n\n\nf394b23\n\n\n2022-10-13 14:32:05\n\n\nLino Galiana\n\n\nDernieres modifs geopandas (#298)\n\n\n\n\nf10815b\n\n\n2022-08-25 16:00:03\n\n\nLino Galiana\n\n\nNotebooks should now look more beautiful (#260)\n\n\n\n\n12965ba\n\n\n2022-05-25 15:53:27\n\n\nLino Galiana\n\n\n:launch: Bascule vers quarto (#226)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n0e01c33\n\n\n2021-11-10 12:09:22\n\n\nLino Galiana\n\n\nRelecture @antuki API+Webscraping + Git (#178)\n\n\n\n\nf95b174\n\n\n2021-11-03 12:08:34\n\n\nLino Galiana\n\n\nEnrichi la section sur la gestion des d√©pendances (#175)\n\n\n\n\n9a3f7ad\n\n\n2021-10-31 18:36:25\n\n\nLino Galiana\n\n\nNettoyage partie API + Git (#170)\n\n\n\n\n2f4d390\n\n\n2021-09-02 15:12:29\n\n\nLino Galiana\n\n\nUtilise un shortcode github (#131)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n7f9f97b\n\n\n2021-04-30 21:44:04\n\n\nLino Galiana\n\n\nüê≥ + üêç New workflow (docker üê≥) and new dataset for modelization (2020 üá∫üá∏ elections) (#99)\n\n\n\n\n283e8e9\n\n\n2020-10-02 18:54:30\n\n\nLino Galiana\n\n\nPremi√®re partie des exos git (#61)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/git/introgit.html#footnotes",
    "href": "content/git/introgit.html#footnotes",
    "title": "Git : un √©l√©ment essentiel au quotidien",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPlus pr√©cis√©ment, chaque modification est identifi√©e de mani√®re unique par un code SHA auquel est associ√© l‚Äôauteur, l‚Äôhorodatage et des m√©tadonn√©es (par exemple le message descriptif associ√©).‚Ü©Ô∏é",
    "crumbs": [
      "Git : un √©l√©ment essentiel au quotidien"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html",
    "href": "content/annexes/evaluation.html",
    "title": "Evaluation",
    "section": "",
    "text": "A la fin du semestre, les √©tudiants rendront un projet informatique par groupe de 2-3 personnes.\nCe projet dont le sujet est libre devra comporter:\n\nUne valorisation d‚Äôun ou plusieurs jeux de donn√©es open data ou collect√©s par le biais de scraping ou d‚ÄôAPI ;\nDe la visualisation ;\nDe la mod√©lisation.\n\nLes √©tudiants sont invit√©s √† proposer des sujets qui leur plaisent, √† faire valider par le charg√© de TD.\nLe projet doit utiliser Git et √™tre disponible sous\nGithub  (d√©p√¥t public ou d√©p√¥t priv√© √† partager avec le charg√© de TD) ;\nLe projet doit √™tre reproductible sous peine de sanction forte. Cela implique des morceaux de code reproductibles, une description des d√©pendances et des explications si n√©cessaire sur la r√©cup√©ration des donn√©es ;\nLa date du rendu est fix√©e au : 30 d√©cembre 2023 23h59\nLe 12 janvier 2024, auront lieu des soutenances",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#la-r√©cup√©ration-et-le-traitement-des-donn√©es",
    "href": "content/annexes/evaluation.html#la-r√©cup√©ration-et-le-traitement-des-donn√©es",
    "title": "Evaluation",
    "section": "2.1 La r√©cup√©ration et le traitement des donn√©es",
    "text": "2.1 La r√©cup√©ration et le traitement des donn√©es\nCes donn√©es peuvent √™tre directement disponibles sous la forme de fichiers txt, csv ‚Ä¶ ou provenir de sites internet (scraping, API). Plus le travail sur la r√©cup√©ration de donn√©es est important (par exemple scraping sur plusieurs sites, donn√©es crois√©es r√©cup√©r√©es par le biais d‚ÄôAPI et de fichiers‚Ä¶), plus la partie obtiendra de points. Si le jeu de donn√©es utilis√© est un t√©l√©chargement d‚Äôun jeu propre existant, il faudra chercher √† le compl√©ter d‚Äôune mani√®re ou d‚Äôune autre pour obtenir des points sur cette partie.\nVous obtiendrez vraisemblablement des donn√©es qui ne sont pas ¬´ propres ¬ª du premier coup : mettez en place des protocoles de nettoyage pour obtenir √† la fin de cette √©tape un ou des jeux de donn√©es fiable et robuste pour mener ensuite votre analyse. C‚Äôest √©galement le moment de cr√©er des variables plus appr√©hendables, mieux identifi√©es. N‚Äôoubliez pas de justifier les choix m√©thodologiques que vous avez pu faire car le charg√© de TD ne conna√Æt pas forc√©ment la base de donn√©es en question.",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#lanalyse-descriptive-et-la-repr√©sentation-graphique",
    "href": "content/annexes/evaluation.html#lanalyse-descriptive-et-la-repr√©sentation-graphique",
    "title": "Evaluation",
    "section": "2.2 L‚Äôanalyse descriptive et la repr√©sentation graphique",
    "text": "2.2 L‚Äôanalyse descriptive et la repr√©sentation graphique\nLa pr√©sence de statistiques descriptives est indispensable dans le projet. De la description de la base aux premi√®res grandes tendances des donn√©es, cette partie permet d‚Äôavoir une vision globale des donn√©es : le lien avec la probl√©matique, comment elle permet d‚Äôy r√©pondre, quels sont les premiers √©l√©ments de r√©ponse‚Ä¶ Chaque r√©sultat doit √™tre interpr√©t√© : pas la peine de faire un describe et de ne pas le commenter.\nEn termes de repr√©sentation graphique, plusieurs niveaux sont envisageables, selon le degr√© d‚Äôapprofondissement de cette partie. La base d‚Äôune bonne visualisation est de trouver le type de graphique ad√©quat pour ce que vous voulez montrer et de le rendre visible : une l√©gende qui a du sens, des axes avec des noms etc.\nEncore une fois, il faudra commenter votre graphique: qu‚Äôest ce qu‚Äôil montre, en quoi cela valide / contredit votre argumentaire ?\n\n\n\n\n\n\nNote¬†2.1: Les applications r√©actives\n\n\n\n\n\nDans le cadre de ce cours, nous pr√©sentons plusieurs librairies graphiques permettant de cr√©er des visualisations de donn√©es interactives, notamment Plotly ou Leaflet. Pour aller plus loin, vous pouvez d√©sirer cr√©er des applications encapsulant plusieurs graphiques construits automatiquement\nen fonction de choix de l‚Äôutilisateur sur une interface graphique.\nTout d‚Äôabord, ce n‚Äôest pas un pr√©requis pour ce cours. Le cours de 3e ann√©e ‚ÄúMise en production de projets de data science‚Äù\nque Romain Avouac et moi donnons √† l‚ÄôENSAE vous permettra de mettre en oeuvre ceci, qui fait appel √† des concepts plus avanc√©s qu‚Äôune introduction √† Python pour la science des donn√©es.\nC‚Äôest n√©anmoins un plus qui est appr√©ci√© et si vous d√©sirez aller dans cette voie, il est recommand√© de bien choisir son √©cosyst√®me. Il vaut mieux mettre en oeuvre des frameworks web modernes comme\nStreamlit que des clients lourds comme tkinter qui rendent le code difficilement reproductible\ncar adh√©rant √† une configuration logicielle. Pour en savoir plus, se reporter\n√† l‚Äôintroduction de la partie visualisation.\nSi vous faites une application r√©active, vous n‚Äô√™tes pas oblig√© de r√©diger un notebook.\nCependant, faites en sorte que votre application propose une page pr√©sentant votre d√©marche\nafin de faire comprendre √† votre lecteur la probl√©matique et les solutions mises en oeuvre.\nCette application doit √™tre reproductible sur le SSPCloud par le biais, par exemple,\nd‚Äôun streamlit run. Il est donc vivement recommand√© de d√©velopper celle-ci sur le SSPCloud\no√π la reproductibilit√© est maximale.",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#la-mod√©lisation",
    "href": "content/annexes/evaluation.html#la-mod√©lisation",
    "title": "Evaluation",
    "section": "2.3 La mod√©lisation",
    "text": "2.3 La mod√©lisation\nVient ensuite la phase de mod√©lisation : un mod√®le peut √™tre le bienvenu quand des statistiques descriptives ne suffisent pas √† apporter une solution compl√®te √† votre probl√©matique ou pour compl√©ter / renforcer l‚Äôanalyse descriptive. Le mod√®le importe peu (r√©gression lin√©aire, random forest ou autre) : il doit √™tre appropri√© (r√©pondre √† votre probl√©matique) et justifi√©.\nVous pouvez aussi confronter plusieurs mod√®les qui n‚Äôont pas la m√™me vocation : par exemple une CAH pour cat√©goriser et cr√©er des nouvelles variables / faire des groupes puis une r√©gression.\nM√™me si le projet n‚Äôest pas celui du cours de stats, il faut que la d√©marche soit scientifique et que les r√©sultats soient interpr√©t√©s.",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#informations-additionnelles",
    "href": "content/annexes/evaluation.html#informations-additionnelles",
    "title": "Evaluation",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd02515b\n\n\n2024-04-27 21:32:25\n\n\nLino Galiana\n\n\nEl√©ments sur les applis & √©valuation (#495)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\nc812322\n\n\n2023-11-29 10:13:21\n\n\nlbaudin\n\n\nDates d‚Äô√©valuation (#462)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n3276558\n\n\n2023-10-17 11:09:45\n\n\nRomain Avouac\n\n\nmore example projects (#436)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n202e7dc\n\n\n2023-08-11 15:52:52\n\n\nlinogaliana\n\n\nOrder execution\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n25adfdc\n\n\n2022-09-22 16:20:12\n\n\nLino Galiana\n\n\nSlides version 2022 (#275)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\n2360ff7\n\n\n2022-08-02 16:29:57\n\n\nLino Galiana\n\n\nTest wowchemy update (#247)\n\n\n\n\n3e919f9\n\n\n2022-03-28 10:00:49\n\n\njblaval\n\n\nAjoute projet √©l√®ve (#224)\n\n\n\n\ndece5e4\n\n\n2022-03-21 10:10:39\n\n\nM√©lissa Tamine\n\n\nAjoute projet √©l√®ves (#222)\n\n\n\n\n0601666\n\n\n2022-03-21 10:05:12\n\n\nIdrissa KONKOBO\n\n\nAjoute projet √©l√®ve (#221)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6cc6d81\n\n\n2021-12-31 09:40:17\n\n\nLino Galiana\n\n\nLien pour avoir des notebooks propres\n\n\n\n\n81ce124\n\n\n2021-09-20 15:36:05\n\n\nRomain Avouac\n\n\nQuelques √©l√©ments sur la reproductibilit√© (#148)\n\n\n\n\nbf5ebc5\n\n\n2021-09-01 14:41:17\n\n\nLino Galiana\n\n\nFix problem import pynsee (#128)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n8781c83\n\n\n2021-03-05 15:32:43\n\n\nromanegajdos\n\n\nProjet GPS v√©lo (#96)\n\n\n\n\nacfb010\n\n\n2021-03-03 18:50:32\n\n\nLino Galiana\n\n\nInt√©gration d‚Äôun endroit o√π lister les projets des √©l√®ves (#95)\n\n\n\n\n72092d7\n\n\n2020-11-10 17:43:52\n\n\nLino Galiana\n\n\nAjout dates rendu\n\n\n\n\nb47e1ae\n\n\n2020-11-09 14:58:18\n\n\nLino Galiana\n\n\nSection sur l‚Äôint√©gration continue (#77)\n\n\n\n\ne644cc7\n\n\n2020-10-21 15:48:12\n\n\nLino Galiana\n\n\nActualise la partie √©valuation (#73)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Evaluation"
    ]
  },
  {
    "objectID": "content/annexes/evaluation.html#informations-additionnelles-1",
    "href": "content/annexes/evaluation.html#informations-additionnelles-1",
    "title": "Evaluation",
    "section": "Informations additionnelles",
    "text": "Informations additionnelles\n\n\n environment files have been tested on.\n\nLatest built version: 2024-05-27\nPython version used:\n\n\n'3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:40:35) [GCC 12.3.0]'\n\n\n\n\n\n\n\nPackage\nVersion\n\n\n\n\naffine\n2.4.0\n\n\naiobotocore\n2.12.2\n\n\naiohttp\n3.9.3\n\n\naioitertools\n0.11.0\n\n\naiosignal\n1.3.1\n\n\nalembic\n1.13.1\n\n\naniso8601\n9.0.1\n\n\nannotated-types\n0.7.0\n\n\nappdirs\n1.4.4\n\n\narchspec\n0.2.3\n\n\nastroid\n3.1.0\n\n\nasttokens\n2.4.1\n\n\nattrs\n23.2.0\n\n\nBabel\n2.15.0\n\n\nbcrypt\n4.1.2\n\n\nbeautifulsoup4\n4.12.3\n\n\nblack\n24.4.2\n\n\nblinker\n1.7.0\n\n\nblis\n0.7.11\n\n\nbokeh\n3.4.0\n\n\nboltons\n23.1.1\n\n\nboto3\n1.34.51\n\n\nbotocore\n1.34.51\n\n\nbranca\n0.7.1\n\n\nBrotli\n1.1.0\n\n\ncachetools\n5.3.3\n\n\ncartiflette\n0.0.2\n\n\nCartopy\n0.23.0\n\n\ncatalogue\n2.0.10\n\n\ncattrs\n23.2.3\n\n\ncertifi\n2024.2.2\n\n\ncffi\n1.16.0\n\n\ncharset-normalizer\n3.3.2\n\n\nchromedriver-autoinstaller\n0.6.4\n\n\nclick\n8.1.7\n\n\nclick-plugins\n1.1.1\n\n\ncligj\n0.7.2\n\n\ncloudpathlib\n0.16.0\n\n\ncloudpickle\n3.0.0\n\n\ncolorama\n0.4.6\n\n\ncomm\n0.2.2\n\n\ncommonmark\n0.9.1\n\n\nconda\n24.3.0\n\n\nconda-libmamba-solver\n24.1.0\n\n\nconda-package-handling\n2.2.0\n\n\nconda_package_streaming\n0.9.0\n\n\nconfection\n0.1.4\n\n\ncontextily\n1.6.0\n\n\ncontourpy\n1.2.1\n\n\ncryptography\n42.0.5\n\n\ncycler\n0.12.1\n\n\ncymem\n2.0.8\n\n\ncytoolz\n0.12.3\n\n\ndask\n2024.4.1\n\n\ndask-expr\n1.0.10\n\n\ndebugpy\n1.8.1\n\n\ndecorator\n5.1.1\n\n\ndill\n0.3.8\n\n\ndistributed\n2024.4.1\n\n\ndistro\n1.9.0\n\n\ndocker\n7.0.0\n\n\nduckdb\n0.10.1\n\n\nen-core-web-sm\n3.7.1\n\n\nentrypoints\n0.4\n\n\net-xmlfile\n1.1.0\n\n\nexceptiongroup\n1.2.0\n\n\nexecuting\n2.0.1\n\n\nfastjsonschema\n2.19.1\n\n\nfiona\n1.9.6\n\n\nflake8\n7.0.0\n\n\nFlask\n3.0.2\n\n\nfolium\n0.16.0\n\n\nfontawesomefree\n6.5.1\n\n\nfonttools\n4.51.0\n\n\nfr-core-news-sm\n3.7.0\n\n\nfrozenlist\n1.4.1\n\n\nfsspec\n2023.12.2\n\n\nGDAL\n3.8.4\n\n\ngensim\n4.3.2\n\n\ngeographiclib\n2.0\n\n\ngeopandas\n0.12.2\n\n\ngeoplot\n0.5.1\n\n\ngeopy\n2.4.1\n\n\ngitdb\n4.0.11\n\n\nGitPython\n3.1.43\n\n\ngoogle-auth\n2.29.0\n\n\ngraphene\n3.3\n\n\ngraphql-core\n3.2.3\n\n\ngraphql-relay\n3.2.0\n\n\ngraphviz\n0.20.3\n\n\ngreat-tables\n0.6.1\n\n\ngreenlet\n3.0.3\n\n\ngunicorn\n21.2.0\n\n\nh11\n0.14.0\n\n\nhtmltools\n0.5.2\n\n\nhvac\n2.1.0\n\n\nidna\n3.6\n\n\nimageio\n2.34.1\n\n\nimportlib_metadata\n7.1.0\n\n\nimportlib_resources\n6.4.0\n\n\ninflate64\n1.0.0\n\n\nipykernel\n6.29.3\n\n\nipython\n8.22.2\n\n\nipywidgets\n8.1.2\n\n\nisort\n5.13.2\n\n\nitsdangerous\n2.1.2\n\n\njedi\n0.19.1\n\n\nJinja2\n3.1.3\n\n\njmespath\n1.0.1\n\n\njoblib\n1.3.2\n\n\njsonpatch\n1.33\n\n\njsonpointer\n2.4\n\n\njsonschema\n4.21.1\n\n\njsonschema-specifications\n2023.12.1\n\n\njupyter-cache\n1.0.0\n\n\njupyter_client\n8.6.1\n\n\njupyter_core\n5.7.2\n\n\njupyterlab_widgets\n3.0.10\n\n\nkaleido\n0.2.1\n\n\nkiwisolver\n1.4.5\n\n\nkubernetes\n29.0.0\n\n\nlangcodes\n3.4.0\n\n\nlanguage_data\n1.2.0\n\n\nlazy_loader\n0.4\n\n\nlibmambapy\n1.5.7\n\n\nllvmlite\n0.42.0\n\n\nlocket\n1.0.0\n\n\nlxml\n5.2.2\n\n\nlz4\n4.3.3\n\n\nMako\n1.3.2\n\n\nmamba\n1.5.7\n\n\nmapclassify\n2.6.1\n\n\nmarisa-trie\n1.1.1\n\n\nMarkdown\n3.6\n\n\nMarkupSafe\n2.1.5\n\n\nmatplotlib\n3.8.3\n\n\nmatplotlib-inline\n0.1.6\n\n\nmccabe\n0.7.0\n\n\nmenuinst\n2.0.2\n\n\nmercantile\n1.2.1\n\n\nmizani\n0.11.4\n\n\nmlflow\n2.11.3\n\n\nmlflow-skinny\n2.11.3\n\n\nmsgpack\n1.0.7\n\n\nmultidict\n6.0.5\n\n\nmultivolumefile\n0.2.3\n\n\nmunkres\n1.1.4\n\n\nmurmurhash\n1.0.10\n\n\nmypy\n1.9.0\n\n\nmypy-extensions\n1.0.0\n\n\nnbclient\n0.10.0\n\n\nnbformat\n5.10.4\n\n\nnest_asyncio\n1.6.0\n\n\nnetworkx\n3.3\n\n\nnltk\n3.8.1\n\n\nnumba\n0.59.1\n\n\nnumpy\n1.26.4\n\n\noauthlib\n3.2.2\n\n\nopencv-python-headless\n4.9.0.80\n\n\nopenpyxl\n3.1.2\n\n\noutcome\n1.3.0.post0\n\n\nOWSLib\n0.28.1\n\n\npackaging\n23.2\n\n\npandas\n2.2.1\n\n\nparamiko\n3.4.0\n\n\nparso\n0.8.4\n\n\npartd\n1.4.1\n\n\npathspec\n0.12.1\n\n\npatsy\n0.5.6\n\n\nPebble\n5.0.7\n\n\npexpect\n4.9.0\n\n\npickleshare\n0.7.5\n\n\npillow\n10.3.0\n\n\npip\n24.0\n\n\npkgutil_resolve_name\n1.3.10\n\n\nplatformdirs\n4.2.0\n\n\nplotly\n5.19.0\n\n\nplotnine\n0.13.6\n\n\npluggy\n1.4.0\n\n\npolars\n0.20.18\n\n\npreshed\n3.0.9\n\n\nprometheus_client\n0.20.0\n\n\nprometheus-flask-exporter\n0.23.0\n\n\nprompt-toolkit\n3.0.42\n\n\nprotobuf\n4.25.3\n\n\npsutil\n5.9.8\n\n\nptyprocess\n0.7.0\n\n\npure-eval\n0.2.2\n\n\npy7zr\n0.20.8\n\n\npyarrow\n15.0.0\n\n\npyarrow-hotfix\n0.6\n\n\npyasn1\n0.5.1\n\n\npyasn1-modules\n0.3.0\n\n\npybcj\n1.0.2\n\n\npycodestyle\n2.11.1\n\n\npycosat\n0.6.6\n\n\npycparser\n2.21\n\n\npycryptodomex\n3.20.0\n\n\npydantic\n2.7.1\n\n\npydantic_core\n2.18.2\n\n\npyflakes\n3.2.0\n\n\nPygments\n2.17.2\n\n\nPyJWT\n2.8.0\n\n\npylint\n3.1.0\n\n\nPyNaCl\n1.5.0\n\n\npynsee\n0.1.7\n\n\npyOpenSSL\n24.0.0\n\n\npyparsing\n3.1.2\n\n\npyppmd\n1.1.0\n\n\npyproj\n3.6.1\n\n\npyshp\n2.3.1\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.9.0\n\n\npython-dotenv\n1.0.1\n\n\npython-magic\n0.4.27\n\n\npytz\n2024.1\n\n\npyu2f\n0.1.5\n\n\npywaffle\n1.1.0\n\n\nPyYAML\n6.0.1\n\n\npyzmq\n25.1.2\n\n\npyzstd\n0.16.0\n\n\nQtPy\n2.4.1\n\n\nquerystring-parser\n1.2.4\n\n\nrasterio\n1.3.10\n\n\nreferencing\n0.34.0\n\n\nregex\n2023.12.25\n\n\nrequests\n2.31.0\n\n\nrequests-cache\n1.2.0\n\n\nrequests-oauthlib\n2.0.0\n\n\nrpds-py\n0.18.0\n\n\nrsa\n4.9\n\n\nRtree\n1.2.0\n\n\nruamel.yaml\n0.18.6\n\n\nruamel.yaml.clib\n0.2.8\n\n\ns3fs\n2023.12.2\n\n\ns3transfer\n0.10.1\n\n\nscikit-image\n0.23.2\n\n\nscikit-learn\n1.4.1.post1\n\n\nscipy\n1.13.0\n\n\nseaborn\n0.13.2\n\n\nselenium\n4.21.0\n\n\nsetuptools\n69.2.0\n\n\nshapely\n2.0.3\n\n\nsix\n1.16.0\n\n\nsmart-open\n6.4.0\n\n\nsmmap\n5.0.0\n\n\nsniffio\n1.3.1\n\n\nsnuggs\n1.4.7\n\n\nsortedcontainers\n2.4.0\n\n\nsoupsieve\n2.5\n\n\nspacy\n3.7.4\n\n\nspacy-legacy\n3.0.12\n\n\nspacy-loggers\n1.0.5\n\n\nSQLAlchemy\n2.0.29\n\n\nsqlparse\n0.4.4\n\n\nsrsly\n2.4.8\n\n\nstack-data\n0.6.2\n\n\nstatsmodels\n0.14.1\n\n\ntabulate\n0.9.0\n\n\ntblib\n3.0.0\n\n\ntenacity\n8.2.3\n\n\ntexttable\n1.7.0\n\n\nthinc\n8.2.3\n\n\nthreadpoolctl\n3.4.0\n\n\ntifffile\n2024.5.22\n\n\ntomli\n2.0.1\n\n\ntomlkit\n0.12.4\n\n\ntoolz\n0.12.1\n\n\ntopojson\n1.9\n\n\ntornado\n6.4\n\n\ntqdm\n4.66.2\n\n\ntraitlets\n5.14.2\n\n\ntrio\n0.25.1\n\n\ntrio-websocket\n0.11.1\n\n\ntruststore\n0.8.0\n\n\ntyper\n0.9.4\n\n\ntyping_extensions\n4.11.0\n\n\ntzdata\n2024.1\n\n\nUnidecode\n1.3.8\n\n\nurl-normalize\n1.4.3\n\n\nurllib3\n1.26.18\n\n\nwasabi\n1.1.2\n\n\nwcwidth\n0.2.13\n\n\nweasel\n0.3.4\n\n\nwebdriver-manager\n4.0.1\n\n\nwebsocket-client\n1.7.0\n\n\nWerkzeug\n3.0.2\n\n\nwheel\n0.43.0\n\n\nwidgetsnbextension\n4.0.10\n\n\nwordcloud\n1.9.3\n\n\nwrapt\n1.16.0\n\n\nwsproto\n1.2.0\n\n\nxgboost\n2.0.3\n\n\nxlrd\n2.0.1\n\n\nxyzservices\n2024.4.0\n\n\nyarl\n1.9.4\n\n\nyellowbrick\n1.5\n\n\nzict\n3.0.0\n\n\nzipp\n3.17.0\n\n\nzstandard\n0.22.0\n\n\n\n\n\n\n\n\n\n\n\nView file history \n\n\nmd`Ce fichier a √©t√© modifi√© __${table_commit.length}__ fois depuis sa cr√©ation le ${creation_string} (derni√®re modification le ${last_modification_string})`\n\n\n\n\n\n\n\ncreation = d3.min(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\nlast_modification = d3.max(\n  table_commit.map(d =&gt; new Date(d.Date))\n)\n\ncreation_string = creation.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\nlast_modification_string = last_modification.toLocaleString(\"fr\", {\n  \"day\": \"numeric\",\n  \"month\": \"long\",\n  \"year\": \"numeric\"\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_table}&lt;/div&gt;`\n\n\n\n\n\n\n\nhtml`&lt;div&gt;${git_history_plot}&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\nSHA\n\n\nDate\n\n\nAuthor\n\n\nDescription\n\n\n\n\n\n\nd02515b\n\n\n2024-04-27 21:32:25\n\n\nLino Galiana\n\n\nEl√©ments sur les applis & √©valuation (#495)\n\n\n\n\n005d89b\n\n\n2023-12-20 17:23:04\n\n\nLino Galiana\n\n\nFinalise l‚Äôaffichage des statistiques Git (#478)\n\n\n\n\n1f23de2\n\n\n2023-12-01 17:25:36\n\n\nLino Galiana\n\n\nStockage des images sur S3 (#466)\n\n\n\n\nc812322\n\n\n2023-11-29 10:13:21\n\n\nlbaudin\n\n\nDates d‚Äô√©valuation (#462)\n\n\n\n\n889a71b\n\n\n2023-11-10 11:40:51\n\n\nAntoine Palazzolo\n\n\nModification TP 3 (#443)\n\n\n\n\n3276558\n\n\n2023-10-17 11:09:45\n\n\nRomain Avouac\n\n\nmore example projects (#436)\n\n\n\n\n154f09e\n\n\n2023-09-26 14:59:11\n\n\nAntoine Palazzolo\n\n\nDes typos corrig√©es par Antoine (#411)\n\n\n\n\n3bdf3b0\n\n\n2023-08-25 11:23:02\n\n\nLino Galiana\n\n\nSimplification de la structure ü§ì (#393)\n\n\n\n\n30823c4\n\n\n2023-08-24 14:30:55\n\n\nLino Galiana\n\n\nLiens morts navbar (#392)\n\n\n\n\n202e7dc\n\n\n2023-08-11 15:52:52\n\n\nlinogaliana\n\n\nOrder execution\n\n\n\n\n5d4874a\n\n\n2023-08-11 15:09:33\n\n\nLino Galiana\n\n\nPimp les introductions des trois premi√®res parties (#387)\n\n\n\n\n25adfdc\n\n\n2022-09-22 16:20:12\n\n\nLino Galiana\n\n\nSlides version 2022 (#275)\n\n\n\n\nb2d4823\n\n\n2022-09-21 17:36:29\n\n\nLino Galiana\n\n\nRelec KA 21/09 (#273)\n\n\n\n\n2360ff7\n\n\n2022-08-02 16:29:57\n\n\nLino Galiana\n\n\nTest wowchemy update (#247)\n\n\n\n\n3e919f9\n\n\n2022-03-28 10:00:49\n\n\njblaval\n\n\nAjoute projet √©l√®ve (#224)\n\n\n\n\ndece5e4\n\n\n2022-03-21 10:10:39\n\n\nM√©lissa Tamine\n\n\nAjoute projet √©l√®ves (#222)\n\n\n\n\n0601666\n\n\n2022-03-21 10:05:12\n\n\nIdrissa KONKOBO\n\n\nAjoute projet √©l√®ve (#221)\n\n\n\n\n9c71d6e\n\n\n2022-03-08 10:34:26\n\n\nLino Galiana\n\n\nPlus d‚Äô√©l√©ments sur S3 (#218)\n\n\n\n\n6cc6d81\n\n\n2021-12-31 09:40:17\n\n\nLino Galiana\n\n\nLien pour avoir des notebooks propres\n\n\n\n\n81ce124\n\n\n2021-09-20 15:36:05\n\n\nRomain Avouac\n\n\nQuelques √©l√©ments sur la reproductibilit√© (#148)\n\n\n\n\nbf5ebc5\n\n\n2021-09-01 14:41:17\n\n\nLino Galiana\n\n\nFix problem import pynsee (#128)\n\n\n\n\n4cdb759\n\n\n2021-05-12 10:37:23\n\n\nLino Galiana\n\n\n:sparkles: :star2: Nouveau th√®me hugo :snake: :fire: (#105)\n\n\n\n\n8781c83\n\n\n2021-03-05 15:32:43\n\n\nromanegajdos\n\n\nProjet GPS v√©lo (#96)\n\n\n\n\nacfb010\n\n\n2021-03-03 18:50:32\n\n\nLino Galiana\n\n\nInt√©gration d‚Äôun endroit o√π lister les projets des √©l√®ves (#95)\n\n\n\n\n72092d7\n\n\n2020-11-10 17:43:52\n\n\nLino Galiana\n\n\nAjout dates rendu\n\n\n\n\nb47e1ae\n\n\n2020-11-09 14:58:18\n\n\nLino Galiana\n\n\nSection sur l‚Äôint√©gration continue (#77)\n\n\n\n\ne644cc7\n\n\n2020-10-21 15:48:12\n\n\nLino Galiana\n\n\nActualise la partie √©valuation (#73)\n\n\n\n\n4677769\n\n\n2020-09-15 18:19:24\n\n\nLino Galiana\n\n\nNettoyage des coquilles pour premiers TP (#37)\n\n\n\n\n913047d\n\n\n2020-09-08 14:44:41\n\n\nLino Galiana\n\n\nHarmonisation des niveaux de titre (#17)\n\n\n\n\n\n\ngit_history_table = Inputs.table(\n  table_commit,\n  {\n    format: {\n      SHA: x =&gt; md`[${x}](${github_repo}/commit/${x})`,\n      Description: x =&gt; md`${replacePullRequestPattern(x, github_repo)}`,\n      /*Date: x =&gt; x.toLocaleString(\"fr\", {\n        \"month\": \"numeric\",\n        \"day\": \"numeric\",\n        \"year\": \"numeric\"\n        })\n      */\n    }\n  }\n)\n\n\n\n\n\n\n\ngit_history_plot = Plot.plot({\n  marks: [\n    Plot.ruleY([0], {stroke: \"royalblue\"}),\n    Plot.dot(\n          table_commit,\n          Plot.pointerX({x: (d) =&gt; new Date(d.date), y: 0, stroke: \"red\"})),\n    Plot.dot(table_commit, {x: (d) =&gt; new Date(d.Date), y: 0, fill: \"royalblue\"})\n  ]\n})\n\n\n\n\n\n\n\nfunction replacePullRequestPattern(inputString, githubRepo) {\n    // Use a regular expression to match the pattern #digit\n    var pattern = /#(\\d+)/g;\n\n    // Replace the pattern with ${github_repo}/pull/#digit\n    var replacedString = inputString.replace(pattern, '[#$1](' + githubRepo + '/pull/$1)');\n\n    return replacedString;\n}\n\n\n\n\n\n\n\ngithub_repo = \"https://github.com/linogaliana/python-datascientist\"\n\n\n\n\n\n\n\ntable_commit = {\n\n// Get the HTML table by its class name\nvar table = document.querySelector('.commit-table');\n\n// Check if the table exists\nif (table) {\n    // Initialize an array to store the table data\n    var dataArray = [];\n\n    // Extract headers from the first row\n    var headers = [];\n    for (var i = 0; i &lt; table.rows[0].cells.length; i++) {\n        headers.push(table.rows[0].cells[i].textContent.trim());\n    }\n\n    // Iterate through the rows, starting from the second row\n    for (var i = 1; i &lt; table.rows.length; i++) {\n        var row = table.rows[i];\n        var rowData = {};\n\n        // Iterate through the cells in the row\n        for (var j = 0; j &lt; row.cells.length; j++) {\n            // Use headers as keys and cell content as values\n            rowData[headers[j]] = row.cells[j].textContent.trim();\n        }\n\n        // Push the rowData object to the dataArray\n        dataArray.push(rowData);\n    }\n  }\n\n  return dataArray\n\n}\n\n\n\n\n\n\n\n// Get the element with class 'git-details'\n{\n  var gitDetails = document.querySelector('.commit-table');\n\n  // Check if the element exists\n  if (gitDetails) {\n      // Hide the element\n      gitDetails.style.display = 'none';\n  }\n}\n\n\n\n\n\n\n\nPlot = require('@observablehq/plot@0.6.12/dist/plot.umd.min.js')",
    "crumbs": [
      "Evaluation"
    ]
  }
]