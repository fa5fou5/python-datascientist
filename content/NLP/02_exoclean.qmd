---
title: "Nettoyer un texte : des exercices pour découvrir l'approche bag-of-words"
draft: false
weight: 20
slug: nlpexo
tags:
  - NLP
  - nltk
  - Littérature
  - preprocessing
  - Exercice
categories:
  - NLP
  - Exercice
type: book
description: |
  Ce chapitre continue de présenter l'approche de __nettoyage de données__ 
  du `NLP` en s'appuyant sur le corpus de trois auteurs
  anglo-saxons : Mary Shelley, Edgar Allan Poe, H.P. Lovecraft.
  Dans cette série d'exercice nous mettons en oeuvre de manière
  plus approfondie les différentes méthodes présentées
  précédemment.
bibliography: ../../reference.bib
image: featured_nlp_exo.png
echo: false
---


La liste des modules à importer est assez longue, la voici :

```{python}
#| output: hide
#| echo: true
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import base64
import string
import re
import nltk

from collections import Counter
from time import time
# from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as stopwords
from sklearn.metrics import log_loss
import matplotlib.pyplot as plt
#!pip install pywaffle
from pywaffle import Waffle

from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import NMF, LatentDirichletAllocation

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('genesis')
nltk.download('wordnet')
nltk.download('omw-1.4')
```

