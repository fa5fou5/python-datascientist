---
title: "Statistiques par groupe et association de plusieurs jeux de données avec Pandas"
draft: false
weight: 20
tags:
  - Pandas
  - Pollution
  - Ademe
  - Tutoriel
  - Manipulation
categories:
  - Tutoriel
  - Manipulation
description: |
  Le chapitre d'introduction à `Pandas` a permis de présenter le principe de données organisées sous une forme de _DataFrame_ et la praticité de l'écosystème `Pandas` pour effectuer des opérations simples sur un jeu de données. Ce chapitre consolide ces principes en présentant deux types de traitements classiques de la boite à outil des _data scientists_ : statistiques par groupe et associations de données. 
bibliography: ../../reference.bib
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/panda_stretching.png
links:
- icon: journal-text
  name: Documentation Pandas
  url: https://pandas.pydata.org/docs/
---

# Introduction

Le [chapitre d'introduction à `Pandas`](/content/manipulation/02_pandas_intro.qmd) a permis de présenter le principe de données organisées sous une forme de _DataFrame_ et la praticité de l'écosystème `Pandas` pour effectuer des opérations simples sur un jeu de données.

Il est rare de travailler exclusivement sur une source brute. Un jeu de données prend généralement de la valeur lorsqu'il est comparé à d'autres sources. Pour des chercheurs, cela permettra de contextualiser l'information présente dans une source en la comparant ou en l'associant à d'autres sources. Pour des _data scientists_ dans le secteur privé, il s'agira souvent d'associer des informations sur une même personne dans plusieurs bases clientes ou comparer les clients entre eux.

L'un des apports des outils modernes de _data science_, notamment `Pandas` est la simplicité par laquelle ils permettent de restructurer des sources pour travailler sur plusieurs données sur un projet. 
Ce chapitre consolide ainsi les principes vus précédemment en raffinant les traitements faits sur les données. Il va explorer principalement deux types d'opérations:

- les statistiques descriptives par groupe ;
- l'association de données par des caractéristiques communes.

Effectuer ce travail de manière simple, fiable et efficace est indispensable pour les _data scientists_ tant cette tâche est courante. Heureusement `Pandas` permet de faire cela très bien avec des données structurées. Nous verrons dans les prochains chapitres, mais aussi dans l'ensemble de la [partie sur le traitement des données textuelles](/content/nlp/index.qmd), comment faire avec des données moins structurées.

::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Compétences à l'issue de ce chapitre</h3>
```

- Récupérer un jeu de données officiel de l'Insee ;
- Construire des statistiques descriptives par groupe et jongler entre les niveaux des données ;
- Associer des données (_reshape_, _merge_) pour leur donner plus de valeur ;
- Faire un beau tableau pour communiquer des statistiques descriptives.
```{=html}
</div>
```
:::


## Environnement

Le chapitre précédent utilisait quasi exclusivement la librairie `Pandas`. Nous allons dans ce chapitre utiliser d'autres _packages_ en complément de celui-ci. 

Comme expliqué ci-dessous, nous allons utiliser une librairie nommée `pynsee` pour récupérer les données de l'Insee utiles à enrichir notre jeu de données de l'Ademe. Cette librairie n'est pas installée par défaut dans `Python`. Avant de pouvoir l'utiliser,
il est nécessaire de l'installer, comme la librairie `great_tables` que nous verrons à la fin de ce chapitre:

```{python}
#| eval: false
#| echo: true
!pip install xlrd
!pip install pynsee
!pip install great_tables
```

L'instruction `!pip install <pkg>` est une manière de faire comprendre à `Jupyter`, le moteur d'exécution derrière les _notebooks_ que la commande qui suit (`pip install` ce `<pkg>`)
est une commande système, à exécuter hors de `Python` (dans le terminal par exemple pour un système `Linux`).  

Les premiers _packages_ indispensables pour démarrer ce chapitre sont les suivants:

```{python}
#| echo: true
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pynsee
import pynsee.download
```


## Données utilisées

Ce tutoriel continue à travailler sur le jeu de données du chapitre précédent:

* Les émissions de gaz à effet de serre estimées au niveau communal par l'ADEME. Le jeu de données est 
disponible sur [data.gouv](https://www.data.gouv.fr/fr/datasets/inventaire-de-gaz-a-effet-de-serre-territorialise/#_)
et requêtable directement dans `Python` avec
[cet url](https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert) ;


Les problématiques d'enrichissement de données (association d'une source à une autre à partir de caractéristiques communes) seront présentées à partir de deux sources produites par l'Insee:

* Le 
[code officiel géographique](https://www.insee.fr/fr/statistiques/fichier/6800675/v_commune_2023.csv),
un référentiel
produit par l'Insee utilisé pour identifier les communes à partir d'un code unique, contrairement au code postal ;
* Les données [_Filosofi_](https://www.insee.fr/fr/metadonnees/source/serie/s1172), une source sur les revenus des Français à une échelle spatiale fine construite par l'Insee à partir des déclarations fiscales et d'informations sur les prestations sociales. En l'occurrence, nous allons utiliser les niveaux de revenu et les populations[^poplegales] au niveau communal afin de les mettre en regard de nos données d'émissions.


[^poplegales]: Idéalement il serait plus cohérent, pour les données démographiques, d'utiliser les [populations légales](https://www.insee.fr/fr/information/2008354), issues du recensement. Néanmoins cette base n'est pas encore intégrée nativement dans la librairie `pynsee` que nous allons utiliser dans ce chapitre. Un exercice d'ouverture est proposé pour construire des agrégats de population à partir des jeux de données individuels anonymisés du recensement (les [fichiers détails](https://www.insee.fr/fr/information/2383306)).


Pour faciliter l'import de données Insee, il est recommandé d'utiliser le _package_
[`pynsee`](https://pynsee.readthedocs.io/en/latest/) qui simplifie l'accès aux principaux jeux de données
de l'Insee disponibles sur le site web [insee.fr](https://www.insee.fr/fr/accueil)
ou via des API. 

::: {.cell .markdown}
```{=html}
<div class="alert alert-info" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-comment"></i> Note</h3>
```

Le _package_ `pynsee` comporte deux principaux points d'entrée :

- Les API de l'Insee, ce qui sera illustré dans le chapitre consacré.
- Quelques jeux de données directement issus du site web de
l'Insee ([insee.fr](https://www.insee.fr/fr/accueil))

Dans ce chapitre, nous allons exclusivement utiliser cette deuxième
approche. Cela se fera par le module `pynsee.download`.  

La liste des données disponibles depuis ce _package_ est [ici](https://inseefrlab.github.io/DoReMIFaSol/articles/donnees_dispo.html).
La fonction `download_file` attend un identifiant unique
pour savoir quelle base de données aller chercher et
restructurer depuis le
site [insee.fr](https://www.insee.fr/fr/accueil). 

<details>
<summary>
Connaître la liste des bases disponibles
</summary>

Pour connaître la liste des bases disponibles, vous
pouvez utiliser la fonction `meta = pynsee.get_file_list()`
après avoir fait `import pynsee`. 
Celle-ci renvoie un `DataFrame` dans lequel on peut
rechercher, par exemple grâce à une recherche
de mots-clefs : 

```{python}
#| echo: true
import pynsee
meta = pynsee.get_file_list()
meta.loc[meta['label'].str.contains(r"Filosofi.*2016")]
```

Ici, `meta['label'].str.contains(r"Filosofi.*2016")` signifie:
"_`pandas` trouve moi tous les labels où sont contenus les termes Filosofi et 2016._"
 (`.*` signifiant "_peu m'importe le nombre de mots ou caractères entre_")

</details>

```{=html}
</div>
```
:::



# Récupération des jeux de données

## Données d'émission de l'Ademe

Comme expliqué au chapitre précédent, ces données peuvent être importées très simplement avec `Pandas`

```{python}
#| echo: true
import pandas as pd

emissions = pd.read_csv("https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert")
emissions.head(2)
```

Les exploitations ultérieures de ces données utiliseront la dimension départementale dont nous avons montré la construction au chapitre précédent:

```{python}
emissions['dep'] = emissions["INSEE commune"].str[:2]
```


## Données _Filosofi_


On va utiliser les données Filosofi (données de revenus) au niveau communal de 2016. 
Ce n'est pas la même année que les données d'émission de CO2, ce n'est donc pas parfaitement rigoureux,
mais cela permettra tout de même d'illustrer 
les principales fonctionnalités de `Pandas`

Le point d'entrée principal de la fonction `pynsee` est la fonction `download_file`.

Le code pour télécharger les données est le suivant :

```{python}
#| echo: true
#| output: false
from pynsee.download import download_file
filosofi = download_file("FILOSOFI_COM_2016")
```

Le _DataFrame_ en question a l'aspect suivant :

```{python}
filosofi.sample(5)
```

`Pandas` a géré automatiquement les types de variables. Il le fait relativement bien, mais une vérification est toujours utile pour les variables qui ont un statut spécifique.

Pour les variables qui ne sont pas en type `float` alors qu’elles devraient l’être, on modifie leur type.

```{python}
#| echo: true
filosofi.loc[:, filosofi.columns[2:]] = (
  filosofi.loc[:, filosofi.columns[2:]]
  .apply(pd.to_numeric, errors='coerce')
)
```

Un simple coup d'oeil sur les données
donne une idée assez précise de la manière dont les données sont organisées.
On remarque que certaines variables de `filosofi` semblent avoir beaucoup de valeurs manquantes (secret statistique)
alors que d'autres semblent complètes. 
Si on désire exploiter `filosofi`, il faut faire attention à la variable choisie.


Notre objectif à terme va être de relier l'information contenue entre ces
deux jeux de données. En effet, sinon, nous risquons d'être frustré : nous allons
vouloir en savoir plus sur les émissions de gaz carbonique mais seront très
limités dans les possibilités d'analyse sans ajout d'une information annexe
issue de `filosofi`.  
